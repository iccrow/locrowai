{
    "id": "transformers-4.46.3-py3-none-any.whl",
    "hashes": {
        "transformers/__init__.py": "71a729a440bba6c0c9d1f9209c6edd61edb21380c89154461be00063d86bc829",
        "transformers/activations.py": "10c37e915ce2b52d539a5b52ecaaf644e2b0c56d282db00778098d74342ebeee",
        "transformers/activations_tf.py": "bb663d7600d1816f986cdfc9fb199dd3910ae29db8ad5f19933ad0ce9cf89422",
        "transformers/audio_utils.py": "e4b5ee29dc3c56363f81096af3a76f112ecdaac0f9c1be9aa3125fc3913321df",
        "transformers/cache_utils.py": "380ed9e09d656fd7d93775376bac542a86b2ba60f7cb86aa205a51742b43fa01",
        "transformers/configuration_utils.py": "34fce0a8cc948bec4c1fb7439d50e56b72a7dae6b84688c9d879f10e3c98061e",
        "transformers/convert_graph_to_onnx.py": "7a8038ff82e6c702be762ac2801d00ef974020c9ffbfd068604a09fc76897354",
        "transformers/convert_pytorch_checkpoint_to_tf2.py": "85331e8b75c711373d6bd83154bb4d3e91799b841587f95013c0c8f899ff35a2",
        "transformers/convert_slow_tokenizer.py": "84fda4c33c984902204c6c784b303f36422936f588d3cf80891812b43298b5b6",
        "transformers/convert_slow_tokenizers_checkpoints_to_fast.py": "e458963a579938b4c2b51ed3f21da5d7e5daaf20b3f153db39f4fc94ae3abcc4",
        "transformers/convert_tf_hub_seq_to_seq_bert_to_pytorch.py": "772f728c44e29d6265d8c790fb0bf52791ed9869b78fa2a2debeb9a29b5e8d18",
        "transformers/debug_utils.py": "eaaf00ac1d74e0675c202daa7c143328bc4eecf7d798710a758b5f2f614e2b6c",
        "transformers/dependency_versions_check.py": "e876e0b53d96a7e41918e01dc943a4947bcd038ace5484c61eb5f7e1db4c3aa8",
        "transformers/dependency_versions_table.py": "325960d97496322c780790b76fc1f9ee66b5a86c6ee1e9e8ff712ff230cfa724",
        "transformers/dynamic_module_utils.py": "b60ff85c443cd062f9fc1949a2f87fd3f7c1ecbe51de52ec28f5e776bb4fee2c",
        "transformers/feature_extraction_sequence_utils.py": "c44e5fd1c4965a87448c2c0d0ec1b40e5f642f707d28fb3e4ac17861358d8743",
        "transformers/feature_extraction_utils.py": "a02883a2bed98b55ad317ffc9a607e92d5087dab04933e8cd64fe4f5e6855262",
        "transformers/file_utils.py": "a88edc593629172d2ff47652441012bf6caf0f65353898184a120eb10edc0948",
        "transformers/hf_argparser.py": "84da7f5ec15ee6f2b09fa15367e6dc932183934455a8c06fd1651e9d81df26d3",
        "transformers/hyperparameter_search.py": "c267c05a4fcd4d4423dcc7b33bfe82683689c94b7da5b01172cfad6e8fc175e3",
        "transformers/image_processing_base.py": "a030e30e5c9696a0965a05e893759b5916c3c8fd676514f98c322005f32a269b",
        "transformers/image_processing_utils.py": "10348be0efaa581a1fcb56b9b192cdb521bd6fe3ef169b5e0263fb53dfda8b42",
        "transformers/image_processing_utils_fast.py": "0b40c9af9c2e5cc308eba27c3502500e04290c120747efaa9c0a095f2f7e3b54",
        "transformers/image_transforms.py": "19eea5d85428daf0da5f4903faad06e73b61dc55015ab0baa0d1d46edfd1fe63",
        "transformers/image_utils.py": "416a054f1f31788bbe34ae2795a11c1208d1f4d293982bdd1228a21ace5bb51c",
        "transformers/keras_callbacks.py": "8bde67ac477f42c128d74c774fd46a65fdf11b37cf88c3a1994d447ff1ef9c61",
        "transformers/modelcard.py": "ee85eb0877de5837702b97528ee34352bb3eaeaae30a6b1f634b368d7b157e33",
        "transformers/modeling_attn_mask_utils.py": "6b48608887ba16712929165d8c05bde9c136b1d5cac19acfde68a5435a570cce",
        "transformers/modeling_flash_attention_utils.py": "2753ed0bdb9b37f72a4b4d0663e2f2833ad55a874be37d4599d69eb9a826ede0",
        "transformers/modeling_flax_outputs.py": "c17b1ed60f55c90c95399f43adb3c02dea1905d4b8e5fb0103d7cdac69f06997",
        "transformers/modeling_flax_pytorch_utils.py": "3f6d150ff263bab9198dce04b7fd6d9681655d508e7e0d4e788589d48ee67d47",
        "transformers/modeling_flax_utils.py": "928cfa73a1a02eb2b662925d2d442bfd6b013ca97d404f49fc6fe8ffb15b90ea",
        "transformers/modeling_gguf_pytorch_utils.py": "8f5524d4a6077ccf6d36c4febdd248a9276d4c6c87a1d5185c2a004477f0dd1a",
        "transformers/modeling_outputs.py": "098a638a3a9934e55473e922c432c8fa3305aeef4c8690d0be79dc49fa74c1be",
        "transformers/modeling_rope_utils.py": "c90ff1e80cc01ab4bdbe070e09053f51bb50727cb7ee8670dbfc97b376d8c5a7",
        "transformers/modeling_tf_outputs.py": "9d708c3a6159ec864556e890afb114d9c895f50ab03983d895dfebda30715691",
        "transformers/modeling_tf_pytorch_utils.py": "17d4410be94f219c130ac9c86650baf090a9754247d72ce023319fee99ea7e2d",
        "transformers/modeling_tf_utils.py": "e2fef5ab93a634663adb1ab03e9f08dee218cb8e37218e524dbfdae209d957fe",
        "transformers/modeling_utils.py": "118bd75838e78b19a55accddcf0a913386d822e812c215d50da99c3d0e91d3da",
        "transformers/optimization.py": "a4e8bedc00cca2f799294a907e2df245bcf2a659a2ff1e73fa06943611976c19",
        "transformers/optimization_tf.py": "50fb5b6de47ffd9a0f1bb7810f95cc0418987e301947c6b92f6cd626c08b2fff",
        "transformers/processing_utils.py": "9ab8ff70a0f39dab82af84c12957ffc786d61bae068a3e9fb79f9fa3beb20f6b",
        "transformers/pytorch_utils.py": "bb5e981aea295cc7825c6377ad5215db7c5321098172df41d25ac9d7dd50bafd",
        "transformers/safetensors_conversion.py": "b47cb20567384866dfc9a9807e1bd21bde0b9a4ecfcac48b58fea0fd723bde60",
        "transformers/testing_utils.py": "8b007f12e30a2bf1c23944c5730a294888ad3a80ef3d7a553df3dd08a69aa451",
        "transformers/tf_utils.py": "bf88b26c54dbdde443806ce10144d56229bea8d66f605da4eab94793bc138a2e",
        "transformers/time_series_utils.py": "313efcd18b5b661759733ec8f5627d5d5a66660095513d9e278fa0f2c9da62f4",
        "transformers/tokenization_utils.py": "932be3c5ad07b90608051bc41da5582cd838ae3fa1ae34469f5bacf467947d0f",
        "transformers/tokenization_utils_base.py": "fd4aeb8a706c0e1814a51872e484124b0d61efc084ade0129fce86a060d89c3a",
        "transformers/tokenization_utils_fast.py": "deea6e4f7a5b67ded3dd7dba813c9db1c1e484f2895eff87a5db37d50fe387e8",
        "transformers/trainer.py": "2b9e4c9dc063eef4f1a5a6e03eab98d513fe16257003f84af0b5081fd4bd12e4",
        "transformers/trainer_callback.py": "6e969d1355bbbf7b637287bff010e2667ccc860223e3c11ca4bd1ae39e8355d5",
        "transformers/trainer_pt_utils.py": "61b0828ad469d72cd4a8c9090fabb270246ff1500ac59640e2de7adeb55c4909",
        "transformers/trainer_seq2seq.py": "d6ebf6e7b70acd9419f08586995d9a9593dc00e72ae0dec7c436e06af2f07b82",
        "transformers/trainer_utils.py": "0ee2f17a935ee903a7be87bc7776f133f2d808263860e7a33ff6f8931f5e4ab9",
        "transformers/training_args.py": "6c594e97c4dd930612ccba8fe763650ef91ae9d7e20b20d326017bf7cd06f237",
        "transformers/training_args_seq2seq.py": "93cab23d0028e465a5713a0dded9f35bb744e31c8fee2ec74633ffb20c659650",
        "transformers/training_args_tf.py": "da6ecc0a4042b128871e67a3e7dc699952a061886827db0ce78e3144d960e867",
        "transformers/agents/__init__.py": "c158ef90869f508a2d4c80eb9e214cbaa31cfe2caae0c1801bd6a29bc55814c5",
        "transformers/agents/agent_types.py": "dbfa00f24925daa7677e9d2c2ed65a4e27ae060e1f8b1edfba8e7921030d3b5e",
        "transformers/agents/agents.py": "5a48ef69cf59fdb89797d26d23ac9ec3860086a3c388bb07099e1fa2073f1291",
        "transformers/agents/default_tools.py": "918e007bdca7d65fe1b3513ec107b7cd3e3c58153d862b48b013e20af6411555",
        "transformers/agents/document_question_answering.py": "fb1239bff4793004cf76b6b954c1c0122d59b77a2246ffdf26ee0dd7a131a649",
        "transformers/agents/evaluate_agent.py": "faae0aeafc821486cfc7cb98b5ff398e1f22edaeb0158feee573a245ab39f144",
        "transformers/agents/image_question_answering.py": "ca4ee918378bd0c568463e7a1f5d6ab7b24fc0d4d1fbcab9743f3491b687156f",
        "transformers/agents/llm_engine.py": "0ad066575eabff70b65f9a6ebcd6489b289e61f49bf5c70a831fb155afc291d3",
        "transformers/agents/monitoring.py": "c259a9d4d2b08adef663e0b6004951311f646e1da4c3837f32c618dd354b7210",
        "transformers/agents/prompts.py": "b96278f444d1fc9e0bcfa7ca99000b15429da23e79facc88c10b97b2fe9a2853",
        "transformers/agents/python_interpreter.py": "81004be65d11c19c88c6c0a9f55cb67b1ce6f8e52f97a270cd7706cc90f2a32e",
        "transformers/agents/search.py": "b190181e50ec21e93f199a4fa9f8dc91835c256a465391bdcb17752fc22cd7a7",
        "transformers/agents/speech_to_text.py": "f5535f339e9cf87f5b2f483ce21cc6903093d7f1161b006d17403c99062927cf",
        "transformers/agents/text_to_speech.py": "16155b4a894abcc952078e781c5fd1aad0142f281d43cc4c6acfc1d86f20232c",
        "transformers/agents/tools.py": "4125214a74933271e557907a87bcc9935f2f71362b495f7d388ec0cf506bf4da",
        "transformers/agents/translation.py": "3fe0e7937ad403734fac92a2bde44aa6d0b027f33ede4d4910fc8dcdeed50007",
        "transformers/benchmark/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "transformers/benchmark/benchmark.py": "79f49e207eb4eb1e6ef4803a0a42972fbb7b0a81fd90e44a4ab5f2a51f207c79",
        "transformers/benchmark/benchmark_args.py": "7631408c10b5d4c9c8f9abb1072096495540a91a97195eb9d0b7a8b1deb45660",
        "transformers/benchmark/benchmark_args_tf.py": "6c072c81fedb394ca8a3c00615289085c891f12e70309aa72f989596f6d0ce8c",
        "transformers/benchmark/benchmark_args_utils.py": "a6482fa2bdc8b82e6ff41b9b382155bb06e0187b281a4369d420dd809972062e",
        "transformers/benchmark/benchmark_tf.py": "c125e574bd13565373041d183944d0f511226bc1226fa9f3e16b0d83a51706c5",
        "transformers/benchmark/benchmark_utils.py": "6731c23673cab72810a5dab7bc3d6afe9e58dabc28e1cb662a339ce5ef2c71af",
        "transformers/commands/__init__.py": "6853b723b0ba1bd38b03d25949cff231a665d2094e42d8cd3e3a8c15fbbdc1f4",
        "transformers/commands/add_new_model_like.py": "365f2f747c8fd62b761627a28b29ae126ca35113f2b5b04d3618125b442cae05",
        "transformers/commands/convert.py": "947cf6b10b62f47b9b30dc0e6cb09cfecc3d63b2fe20f71a609312251fc05563",
        "transformers/commands/download.py": "18a3da771f981812fb74725211c529f9034e3f74762fbd7e80f18fd33e8d3502",
        "transformers/commands/env.py": "839e07c2dca9dd9a58abbf3670ac2f2eb9e588b8363e152b67bc8e42c3a06797",
        "transformers/commands/lfs.py": "e100c605b27105c4698268475ef8a065052c5ee4cfc2b458eb4b75a868f37d65",
        "transformers/commands/pt_to_tf.py": "738c5cce4d2c8e21ff638720ab99fd9ef59a617c5f3f91e83e08aaa83c75ca84",
        "transformers/commands/run.py": "9f211eda53a88fa7b410ec6329e174f21756f565566b5d35afd8565e5f6fdc9a",
        "transformers/commands/serving.py": "0a734715533f48affe68dc44267abbbc92b9741a83070edbc71422bf9b6bb845",
        "transformers/commands/train.py": "14a947f8862bde655ceff992e4e6c2c89687b3d2629dc60b83766de96433d5a8",
        "transformers/commands/transformers_cli.py": "ca7b1399ef53c91f35a013fa6bd8446c3751f2f66f43039a136fa5465b272efb",
        "transformers/commands/user.py": "5311d3c3b2f6a94f12bdd8fabf635bf0e07c9c62397515dac2b5eddfdf039174",
        "transformers/data/__init__.py": "132eb4f041fef4ff6a6a3288ac1c68a46287e05c3210be6d07c7d0dd27f34899",
        "transformers/data/data_collator.py": "cfb2f75481320059bfa5887af8fdde5dbbf39e9b1795120b7574ba9d8d8269ce",
        "transformers/data/datasets/__init__.py": "3c6cd42637664cf38f3328d5e3e4e3dec36b9a687e96ca63cb1ad56eb7c9a17f",
        "transformers/data/datasets/glue.py": "2b78762b18c88349167a03c2c3a8a46ce2fe94215b2a841ec1bed1f302d9a087",
        "transformers/data/datasets/language_modeling.py": "13e546c2ec9bd3d2782a657cbf7edb347e629fdd300cfb991c262ca86753ed6d",
        "transformers/data/datasets/squad.py": "3944d00ddebced2427b3b1d15830a00239eea3f6578a189f2d2ea31766e15217",
        "transformers/data/metrics/__init__.py": "a3db7f55342da94de5121aafa1c0f314c9bb3af00a0febb1ae33d6cb4afbe012",
        "transformers/data/metrics/squad_metrics.py": "98fe9e6837064cbb12e04867be70f753f632bdcb9afcb5601250a4bb1cb65c91",
        "transformers/data/processors/__init__.py": "96f3799a9f6676baf9bfa42f653e9572867bf33654bd78ae9939ba19dbe582fa",
        "transformers/data/processors/glue.py": "d6c1dc7d259b97ea2834812edde98a9839695bef795194f525f0e5198c794c50",
        "transformers/data/processors/squad.py": "ff858d2dc640e93032eee3593b8ebde3cb662f99e0545d0b481d32f27527eabb",
        "transformers/data/processors/utils.py": "1926996c9fbe5d8ab9eefab2455c7fe4b1d2478b6497317247b64a1c65ac4c0b",
        "transformers/data/processors/xnli.py": "b20718cfd6127c763d352d0b3bf61e151463abe9c916c0e11543f83497aef90e",
        "transformers/generation/__init__.py": "fd48cc6deba9ff669df23dff6f4105f3bb3eb2d8346d9d4249961eb3de6fac03",
        "transformers/generation/beam_constraints.py": "62df5db500115444ff59a0b6e928a5e3d0cef9bd987e8b3284fd91c7920b45e2",
        "transformers/generation/beam_search.py": "ac68ca36628f6bad4f382904879566667f6851aa8cdde209d635e1927ec23d85",
        "transformers/generation/candidate_generator.py": "07d570e6544c70dce65de8a7bd5bd88c049b262f129478d721526fb891eedd14",
        "transformers/generation/configuration_utils.py": "74899c9b641aec9d8b0897b804fef962098181db18f33737625ef26c5ff57921",
        "transformers/generation/flax_logits_process.py": "f7da4d12cd8bc3add53bad35e2005eb07c7283c9f73ca1b6a00b04c2177fec46",
        "transformers/generation/flax_utils.py": "c782796e54d1805569f28d252be52f8ce633a5e4cfe7891dcb99b978af1aa734",
        "transformers/generation/logits_process.py": "167cd938df5536877bda6b89398464834090847d0ff5ebfad8352a4f50876b62",
        "transformers/generation/stopping_criteria.py": "534bdc18702e040c6e49b57625bee715dda7d0093174c49e23ff2bbed1b94782",
        "transformers/generation/streamers.py": "02b2422805512882802ea746040b10bb4dfcf81c196e8d39b733976563fdca78",
        "transformers/generation/tf_logits_process.py": "95d8910d8e8cd6dd8b8f6c9dc08992e1be386c3dceda2e9309731c383a772248",
        "transformers/generation/tf_utils.py": "92e298ac2bcb6bf24300501edf00f4eb86f21fab7ada0b42d98faa415834edad",
        "transformers/generation/utils.py": "24e719be0942a06f1956cadd469a100a455012ea6f808cca894a3e94edb06bf3",
        "transformers/generation/watermarking.py": "f1de0016cf424671ac82e8aa2cacbc2f3ea0da9834c0b01a66d03003baac2310",
        "transformers/integrations/__init__.py": "810dcb0b4ca3326c4cc03cd01fd8086ed7fef5c9d4823f165bd0fc36b61e83d1",
        "transformers/integrations/aqlm.py": "838ba31e6a82afaeae8283fdde57a6b4868c40b2c33036754de791d14d4c20ec",
        "transformers/integrations/awq.py": "8198d50b15a1544ad588c875007b425b0ddb8ed1d11b096ee62724e90cb6a456",
        "transformers/integrations/bitnet.py": "cfd23ab04b1637a55830f7a87f5d1e58ba91d7bc7064e14933b7a1447830650a",
        "transformers/integrations/bitsandbytes.py": "620b0e48d29049abaffdc8143f65ff8acd55fc88eeb08d05455185c0fccd09a7",
        "transformers/integrations/deepspeed.py": "522d268cbee2eec9fa908d69998a23d1ba2fac5be8815eb1c96eaaa5b1e73ea3",
        "transformers/integrations/eetq.py": "643c5893abdf8c6b2342841e14e436a1d9f9f2173ac6b61bc1d2ad7cb743a7e4",
        "transformers/integrations/executorch.py": "2a57b51919323eb6cdc381a83080397573d523eb8e2d81f918e9f6ca7ea2020d",
        "transformers/integrations/fbgemm_fp8.py": "837db60391e1cfb6a0000087620784be1e8fe2059c9d1b7507191407061b30b0",
        "transformers/integrations/fsdp.py": "fe3915e787c893d4c8cfc66653fe75288254cdcdf210c8bf9c4f9d51d097c05c",
        "transformers/integrations/ggml.py": "164900d5131c07f79c0d2c208f56549ebd3aae9419022ecdf1780799c51caaba",
        "transformers/integrations/hqq.py": "99e0649a6cbdf4d82c4c6d0e8abf4ffc330489f460a5bb82bdb9a0bbbdca4d33",
        "transformers/integrations/integration_utils.py": "b385b907a85822921b4b4308453c124edb02edc82c6b275616fcf9a3de262185",
        "transformers/integrations/peft.py": "6669361ce70989c4df9cc9703698802a15ff5958e6a846ddc03a219f15a56f2d",
        "transformers/integrations/quanto.py": "9747a1f6d062e232ffa21ce63474fe923b4238fb692511d85c07891c23578239",
        "transformers/integrations/tpu.py": "63c60cc08ac4821d6cf8e08d6ce419143d7fdd3beaa68dded47e9e1024dc7925",
        "transformers/kernels/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "transformers/kernels/deformable_detr/ms_deform_attn.h": "1f66c15c6ca5d11fafd83a86573d756aca11bf16e367d89607d763a26653a606",
        "transformers/kernels/deformable_detr/vision.cpp": "f11bd9cbb3ff30cc79404b33a3f33034e0dd7492d0f2629c9a631f80b602fc70",
        "transformers/kernels/deformable_detr/cpu/ms_deform_attn_cpu.cpp": "55c0869bd22bbe056f9b266dd0ac8fd7a43e38d99b7a0e9b2b071c3fa29a74bd",
        "transformers/kernels/deformable_detr/cpu/ms_deform_attn_cpu.h": "9ef56c2a3f6769b43b21a358e1d8b9c55c7abbed252227d0bcb836242a318a29",
        "transformers/kernels/deformable_detr/cuda/ms_deform_attn_cuda.cu": "f57f76192dec88db1e87f4e819fc109befcdfe8fd94019a09b4ac06bab690b39",
        "transformers/kernels/deformable_detr/cuda/ms_deform_attn_cuda.h": "c713f5eda7abf92894f49e4048b1ddb4b2328459870b988b70f20f356db192b8",
        "transformers/kernels/deta/ms_deform_attn.h": "1f66c15c6ca5d11fafd83a86573d756aca11bf16e367d89607d763a26653a606",
        "transformers/kernels/deta/vision.cpp": "f11bd9cbb3ff30cc79404b33a3f33034e0dd7492d0f2629c9a631f80b602fc70",
        "transformers/kernels/deta/cpu/ms_deform_attn_cpu.cpp": "55c0869bd22bbe056f9b266dd0ac8fd7a43e38d99b7a0e9b2b071c3fa29a74bd",
        "transformers/kernels/deta/cpu/ms_deform_attn_cpu.h": "9ef56c2a3f6769b43b21a358e1d8b9c55c7abbed252227d0bcb836242a318a29",
        "transformers/kernels/deta/cuda/ms_deform_attn_cuda.cu": "339f9b5bd839cfeba94c530d3c87e7c8b02a293c463028c03ea06bd069961d7f",
        "transformers/kernels/deta/cuda/ms_deform_attn_cuda.h": "acf58e38ca3743215d07990c89ec690292c567876746dc780a5b84006c2c7cef",
        "transformers/kernels/falcon_mamba/__init__.py": "6edd23f39d45d6eb87edf952b13bc8a9d87dcdd2954ce54a5adddd6ad6f5e522",
        "transformers/kernels/falcon_mamba/selective_scan_with_ln_interface.py": "eb8f68243d2ca31d48f930a466e44c8d89b7b564244375683d72cd78e70dfecb",
        "transformers/kernels/mra/cuda_kernel.cu": "2f1c51613ca64a80444295971c0d0f333c19c29a257305fb985023c14f3e64c7",
        "transformers/kernels/mra/cuda_kernel.h": "509bd8abf303ce1729d3b6d9a5870e067f1918571ffc0c757729ee8954c1be60",
        "transformers/kernels/mra/cuda_launch.cu": "3b1e4c4c00ab882df4086ca7fa0d4a6f912041230065268de9fa62b77c4b1567",
        "transformers/kernels/mra/cuda_launch.h": "4550a437f7ae6acbe03cad33003351bd160659de1a87997d5feed41bf01c747f",
        "transformers/kernels/mra/torch_extension.cpp": "37461d04b557d2565a6dc909cd5fd16131d2d9ab4236f9f5dc4e08be86eddb98",
        "transformers/kernels/rwkv/wkv_cuda.cu": "12f694ac49f0feaaf612330a3fe3eaed53f315f1a53099c585d1cd2ed9f57cf5",
        "transformers/kernels/rwkv/wkv_cuda_bf16.cu": "0c6f614ed38096b9e90c56a18edf8c9a73b18ccba1194e7918fb26576d47b6b4",
        "transformers/kernels/rwkv/wkv_op.cpp": "a9213184a753ea9de1c9a4efe52ca90a71ff73b126697e876e14dc0a7b6f6568",
        "transformers/kernels/yoso/common.h": "4eadab394b44f18e0344052b4484afc08c15237bbc2417f6d568164806220e54",
        "transformers/kernels/yoso/common_cuda.h": "4a38bbd00b9572e652a2d2c5ec6a2d9ae9fd309b8e1e8f30124c62cca5cb46d7",
        "transformers/kernels/yoso/common_cuda_device.h": "cba59480089aa6730aaad851312e6cf8331258d5646abfe2f20e0a3c5bea8ae9",
        "transformers/kernels/yoso/fast_lsh_cumulation.cu": "2c0e0b18d8325d3de8b08c90b4505c45a9d2c8d4169bccaa9a9cfb01e2cfedcc",
        "transformers/kernels/yoso/fast_lsh_cumulation.h": "d5c4d66633a6ef9d471a2101e4ff943c9f1213554eed74725e6060cb1603ca32",
        "transformers/kernels/yoso/fast_lsh_cumulation_cuda.cu": "1ca18b5a5f96173e415e36803c74cd4db1ba2149098e105dbc57f62bb86b0d54",
        "transformers/kernels/yoso/fast_lsh_cumulation_cuda.h": "fca188f0741b545b423792807121a9ca22767e81a2dba44a7a7d77f0251cd9f6",
        "transformers/kernels/yoso/fast_lsh_cumulation_torch.cpp": "f9187ba37f59debb4e3f036710cf9ce754c2ab2c2955d2b4595680ed546b5db4",
        "transformers/loss/__init__.py": "a844eca82c1acaee989a3fc9e3f03f7a2c2268c4474349e858a337e6769a9f37",
        "transformers/loss/loss_deformable_detr.py": "ea7c9bc278bf763dbf1fc5047b77b6a3793298c54771b1613e98cfcb1f3b2aa7",
        "transformers/loss/loss_for_object_detection.py": "fff4a2cb99b5cc440f664d096d439c03766da09d2346dd2aabb770191e8c1ad0",
        "transformers/loss/loss_rt_detr.py": "d38906eae72909bb2e8a6f5eb42669a162d2d99288dd48b43f30dd8463c5a856",
        "transformers/loss/loss_utils.py": "3fce07011a7c927b424fcb73a9f52ef21a8346c801da05ceda268d4e1fd1053b",
        "transformers/models/__init__.py": "0a2145f91a19ebec2cf2d8d93b656d17bbdd7d62c166ec43dab1eb0531eee310",
        "transformers/models/albert/__init__.py": "5a343836d37128d8fb1ef93d940d8e5e67600ff48d169d702d2d9e78bdfe5a81",
        "transformers/models/albert/configuration_albert.py": "9f0062d46835311c3fcfef4fc2bee48ed27290b3a18f9ff3242f731b3820adf4",
        "transformers/models/albert/convert_albert_original_tf_checkpoint_to_pytorch.py": "b23db3cd3edad69a1046e129281ffd4541da20f57ab9cd0fe73860bd205f655d",
        "transformers/models/albert/modeling_albert.py": "adb33d93ecdd65f1ffaaa2900b0920c40689299414db2336688261790693b12a",
        "transformers/models/albert/modeling_flax_albert.py": "fe827cd6580b1f07d80bef4342af7a22cae58fdf63234d97e66a25e1ecaefe3e",
        "transformers/models/albert/modeling_tf_albert.py": "9787249ced8ef48bda1a04201c3e5daea0169048df3af32375cea8068a12a187",
        "transformers/models/albert/tokenization_albert.py": "cbbd710598dca4631da5693a3c2f258d0d4ee15e052cf0c71e4e901767be2db6",
        "transformers/models/albert/tokenization_albert_fast.py": "d88efee036df3ffc61de489beb5d5a2fb160158dd31374778eb082634294aaec",
        "transformers/models/align/__init__.py": "42a4ca93e678072958e849014a562f2975614f6b5efa6d8097adba394033fabe",
        "transformers/models/align/configuration_align.py": "43a22f7b2d148e5de671076677abb10a755cd0c052289d2a15933b756c93e542",
        "transformers/models/align/convert_align_tf_to_hf.py": "b733e810cc8b57f72456781876f27ab80159e9182cb97e792588c490832d3d38",
        "transformers/models/align/modeling_align.py": "9c1b8a33cf54c57def7c1b06932e72d8e9bf4e2906209f3284a8945be01a582e",
        "transformers/models/align/processing_align.py": "06ba488f553d9d8c319ee39033d366b0cc2ec562712beda0c87c6a869f9bf489",
        "transformers/models/altclip/__init__.py": "e34e488a350262bd441af3aa835c7376cfc61ce9710a5d070ac7f5ac8d30b4f6",
        "transformers/models/altclip/configuration_altclip.py": "a234f185e87c6ec92e6e9a1aac23fc517415396566473800ac8ad14e99a551b3",
        "transformers/models/altclip/modeling_altclip.py": "6f68442521bfc2d4ead44045d576ef075cd5af42493e450b26a504823ba2fd54",
        "transformers/models/altclip/processing_altclip.py": "6a4e402c9a30886894708ae030e20ad4e681606aa779042ec1cc6810bff5a922",
        "transformers/models/audio_spectrogram_transformer/__init__.py": "5a471f0a043f2b9c1eff612bcea66888963c59c5a93e04f94ebc37b8dd3d172f",
        "transformers/models/audio_spectrogram_transformer/configuration_audio_spectrogram_transformer.py": "3a993c7b53fb2238594208fc3dae58cdeb0b14f31251f32c4472e52d8e018059",
        "transformers/models/audio_spectrogram_transformer/convert_audio_spectrogram_transformer_original_to_pytorch.py": "72579c77b60577bfd1aad3216c7ac28e70bb28288f65245c27b11eec483ff45c",
        "transformers/models/audio_spectrogram_transformer/feature_extraction_audio_spectrogram_transformer.py": "08b31c754524f1e840d8f0bdc04070bd677af2d20c16d66cc0d8556d5c1759cf",
        "transformers/models/audio_spectrogram_transformer/modeling_audio_spectrogram_transformer.py": "afe73f452fe4f337720afb5e0df4bc26bcd0579a09a45c797fd132df1c91dca0",
        "transformers/models/auto/__init__.py": "aaf3b3e24e08c1d62c9dfd140057a93f804089ac71a7184d2b0d777144bdd642",
        "transformers/models/auto/auto_factory.py": "c017394b364a5750b1c91dd1ce8712f55af89021c2a8cd17053aad8698e781bd",
        "transformers/models/auto/configuration_auto.py": "0883d832754418be5ee9efbdf06d578870d3d954bbfcf5108926f8f28e1cbbb2",
        "transformers/models/auto/feature_extraction_auto.py": "bbf3c57abc6d828519a460f40755b1b73cbd8dfa59bc88019531d3b3f7e6e12a",
        "transformers/models/auto/image_processing_auto.py": "05bc7d3cbef564b222a020774089c9af49feaa2971bb68677f2f66ed0d154e6b",
        "transformers/models/auto/modeling_auto.py": "87f9ec1d1070327a5df1b459278020b8346f2f0b5f69e7d054d55cf1c6e7a886",
        "transformers/models/auto/modeling_flax_auto.py": "5130455dae6c67174effaeb7cd6be17091a976dd5b8692c2977dfb7992c1ec7d",
        "transformers/models/auto/modeling_tf_auto.py": "8603bc45eeab5b694f9b5afd7ad72340b9a01766a22152f99b5696cb2679b331",
        "transformers/models/auto/processing_auto.py": "67f728935888241f73f202c92604edbcd574206801a6d6039f1cb7765f8548b2",
        "transformers/models/auto/tokenization_auto.py": "ed7100f24fc7cde608747abcc9006f0b7ca1ce2d3664c1cd837ae4e22fa954a0",
        "transformers/models/autoformer/__init__.py": "e71bfd79be91fb83e6349e2ffa881ea3ba60a1b0d1a24165e275aaaa39d6208d",
        "transformers/models/autoformer/configuration_autoformer.py": "22a8f1ba33d4df5e872e39a58eb05aac01fcae74ec6c9ae59abc3247ba132cf5",
        "transformers/models/autoformer/modeling_autoformer.py": "9c7d0ce401c6bfa7edf217155363e918f64e05f8748069cd336419de8671d0cb",
        "transformers/models/bark/__init__.py": "d3270d0cb1ce0eed17968e932687bed00245c841f051bf1b8aae9a080b66291c",
        "transformers/models/bark/configuration_bark.py": "246d3b55b0cf2a0a7c20d7f8365582e2a3e6550d6f5e933ff19a4ff15c32fd9d",
        "transformers/models/bark/convert_suno_to_hf.py": "f4097d99c71d8485f5a53de4fdb1029863978a2db9831e83d40edd4acf785386",
        "transformers/models/bark/generation_configuration_bark.py": "e98899907ba5a1455b7eacd1dfac66be12a6e52676f9bd8c58c1d2c0cbd15930",
        "transformers/models/bark/modeling_bark.py": "84c889681e0f56eaa360d3d99c1270c9c3af7b37aac04ecd14fd42589909a7c9",
        "transformers/models/bark/processing_bark.py": "b49ac6d0e739cfdd263500fcc19345c4a6509c54ff8a415e00c33dc658d3dcc0",
        "transformers/models/bart/__init__.py": "d70691a2e2351f58c3070443baea4f108ddbf593540b713880f97d2018d9af7e",
        "transformers/models/bart/configuration_bart.py": "2ced707b34d94877adf04e3ea39e271e8b1112b26a60f8fc141187211781399f",
        "transformers/models/bart/convert_bart_original_pytorch_checkpoint_to_pytorch.py": "909d47e456ceb7fa7762a791f1ecc129a395d0fa3651c387251891754709f747",
        "transformers/models/bart/modeling_bart.py": "a0df5e711e54652ea3996b97578ed5335be2eaf742eceea9e4d25b64db690b40",
        "transformers/models/bart/modeling_flax_bart.py": "20909ab6e4589ec6200eb7acadf8df2f4238599b3d61962ab9f3174d6a797998",
        "transformers/models/bart/modeling_tf_bart.py": "a47ab0749ebc0d3e15e0059d556afc4b3d140a0e92b2a05251d7a3c270a814dd",
        "transformers/models/bart/tokenization_bart.py": "7ea1d908067098ce10a05024eae9c31b0adb5ed66457590f58cb1522eec7acf8",
        "transformers/models/bart/tokenization_bart_fast.py": "87e0c8c8b07b8a2ed08d350517bf2753c7b97cf54431409768f2a41ea308ef51",
        "transformers/models/barthez/__init__.py": "ec85e0ea8919a09d743426115a7d06be859652f194376ede230ec2cc9e425460",
        "transformers/models/barthez/tokenization_barthez.py": "2348cbf0f31d3efc5bfee2e1ec846a5674a7cf3320a3f752c7c27fc01fed1a58",
        "transformers/models/barthez/tokenization_barthez_fast.py": "0c00b6fe268da61809085d594071540c70cf5b8eddf0908fcf1cf7d2584c4d8e",
        "transformers/models/bartpho/__init__.py": "43498038f24641a1c78a075a8cb839fb64cf3b0f4d5b0e6e21142599f861f03b",
        "transformers/models/bartpho/tokenization_bartpho.py": "6f18141b4538ce0cc124a6a96bbb27c377da70ec328f5d9825e3c2fa3c100e7a",
        "transformers/models/beit/__init__.py": "cd5555d3c48c5b292cddf5c552cc92e632b6f9d6462cecaf7199a9e11be75a96",
        "transformers/models/beit/configuration_beit.py": "e282bf21f04ef78ae1d2a90b63085d5b7aad855a4fc9040e320e781d4efd1755",
        "transformers/models/beit/convert_beit_unilm_to_pytorch.py": "3ddaac968c3bd5b258422a14db5539ad61235d2402e33fdd3a756029f3f15982",
        "transformers/models/beit/feature_extraction_beit.py": "0bdc1c84a2eddcafffc33a8e9035ac6cad2130fcd59fd1d9b66e4a3c8e4eab6b",
        "transformers/models/beit/image_processing_beit.py": "dfebd1d42212764c30d201db9a67f3ba4129d74f2891f7d8e3a3e184f6599d2f",
        "transformers/models/beit/modeling_beit.py": "3fe8f15f8ac93e80addb1cfa8beea7a7ae902b589d0e7666777c228d956d6365",
        "transformers/models/beit/modeling_flax_beit.py": "f7fc6414def1b622ebc5b4a18695fc120a58f24b8e288ba2f8e95189d98d5002",
        "transformers/models/bert/__init__.py": "1d612b8a449191f00a8cce6e8007bbd4edfaf84cd0df025dbe060212b5c8e04c",
        "transformers/models/bert/configuration_bert.py": "390d44e6baa4cf745ca5e3013b5b326d1ed50a829e7c8f77f32c882eb6dca2df",
        "transformers/models/bert/convert_bert_original_tf2_checkpoint_to_pytorch.py": "abb440ff84bd3a403115d9a619457f2dff6a298a11b212496d03001f1b1cb115",
        "transformers/models/bert/convert_bert_original_tf_checkpoint_to_pytorch.py": "79226ced30503c17d904f026049ecbf092aa29605ec2f58ab2755b92598790d7",
        "transformers/models/bert/convert_bert_pytorch_checkpoint_to_original_tf.py": "ea7212b027603bfb0914588ba679061ac993a82f58a7e8330cf0ccf8469f5570",
        "transformers/models/bert/convert_bert_token_dropping_original_tf2_checkpoint_to_pytorch.py": "92c8a969c7151d7307ac6acd269ff30077a6ce242f60c31c1bb7f3228d340d0c",
        "transformers/models/bert/modeling_bert.py": "3493bff5da90fdcce98dad5c84aafe4d3ce1c550dcd93bc99289309953559eca",
        "transformers/models/bert/modeling_flax_bert.py": "50c454331befc2ef2823390b7d58d758ff58e3b5a89593ed64510bca9b06fa98",
        "transformers/models/bert/modeling_tf_bert.py": "35b4bec3f41d961379d3d0dcacfbdd605ccee1bcdf1d244cbdf1cd17491a7d01",
        "transformers/models/bert/tokenization_bert.py": "2ad453af477a846e2cb9261ab7d75b05bb1118b56885738074ac5138fb1f4e4c",
        "transformers/models/bert/tokenization_bert_fast.py": "16802eb6932d9adfc3efb67cd91b4172db65f029793f645db7f1c520a513da6f",
        "transformers/models/bert/tokenization_bert_tf.py": "d735b3cf714fae1e735aa446ed8558ff02150b3cc1f2234647a306c78f247b77",
        "transformers/models/bert_generation/__init__.py": "d9752f49578f9dee47b298f39fa97f3e89ca7d9f565e3441b9bf5b7af3aff11e",
        "transformers/models/bert_generation/configuration_bert_generation.py": "ceb285d797c7158c23690c5107474e8d05985681e5d4365f43dd1dde091a9a55",
        "transformers/models/bert_generation/modeling_bert_generation.py": "6443e475d8ff25612063fdd5e65b357bb9a80eaafd2851ca13a06f7e8a4315e2",
        "transformers/models/bert_generation/tokenization_bert_generation.py": "acdd5524e2e7fa7c3c014ddebfd0d779742cd31cf312deeab7f788e94b4c1895",
        "transformers/models/bert_japanese/__init__.py": "ea9ad03574b62787165ea02a92a0f2c4d9b3c7ebda150b4e8c9422a3e6547388",
        "transformers/models/bert_japanese/tokenization_bert_japanese.py": "8f55fe92d24d12847e3325de9c5c6733576d4af42132bd5507c422ac09208a07",
        "transformers/models/bertweet/__init__.py": "b171363707a85a9f1421a264b9268b4b0e04692133a56c017b7a5e81e73f2a3d",
        "transformers/models/bertweet/tokenization_bertweet.py": "6609b6218f78a919e5a6d455c9cea26f22821be169b6619a44faedf1e85698d3",
        "transformers/models/big_bird/__init__.py": "ac18970cb70049aafdd63b5523a973b09048af275753f089507748918e3d2d0b",
        "transformers/models/big_bird/configuration_big_bird.py": "d5800cb4b5dae2b2b87ca50219c8fb0203357da028282ecedd4825065fb51102",
        "transformers/models/big_bird/convert_bigbird_original_tf_checkpoint_to_pytorch.py": "a965f3255c402ddff4018cb53844dd2bb2ee5591480ad4a2aafdafb6fd38cc4d",
        "transformers/models/big_bird/modeling_big_bird.py": "0224ae2edaedf623be8864859f5dbbbf59253d7ed40d1d98e19b6a36626877cf",
        "transformers/models/big_bird/modeling_flax_big_bird.py": "78f556fba5700fcb202582255f8796bf411535a227568b095bf0adaa5cb3a46b",
        "transformers/models/big_bird/tokenization_big_bird.py": "81d0e7c996e0e497329891ef8d193b96001e941e219bd84433696844bdfd9f9a",
        "transformers/models/big_bird/tokenization_big_bird_fast.py": "6876cc9041526c5233d8335df713493ce8a3ca88d09c817594048525f6d931b3",
        "transformers/models/bigbird_pegasus/__init__.py": "15d41fce48e9a9801fd369a97002241681a837c9bd1b07e0cf8bdbff0c582474",
        "transformers/models/bigbird_pegasus/configuration_bigbird_pegasus.py": "3ccc0c82fb9d276bc297d8d48f501ec649e78c623cc3905d39d33f3abf666d95",
        "transformers/models/bigbird_pegasus/convert_bigbird_pegasus_tf_to_pytorch.py": "59cedaa0dbedcf1b7e0cf8bae792a5df40a00e0abf869d3ca6c2126fc756a4b5",
        "transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py": "e5d43a09c782e13e65f127a9b76fd0f197e3e76ac336a9d14cbca5cd1564d5b6",
        "transformers/models/biogpt/__init__.py": "1b0a67f1d07f05cd705e566af6cee0181c00dc3bd047a731d46058a8f95320c8",
        "transformers/models/biogpt/configuration_biogpt.py": "d3c5761afcb0d28427b925d22e066fb7718d0c66788e79c7e55e9e41642a8d48",
        "transformers/models/biogpt/convert_biogpt_original_pytorch_checkpoint_to_pytorch.py": "e73358cda132ed03dcf7d2c21d37287d7482237b6bd29ce5229169c13d5980dd",
        "transformers/models/biogpt/modeling_biogpt.py": "bd897123d23da4abcd994038aaac39e1173cb7291755b9aa918eeaff21ff3aae",
        "transformers/models/biogpt/tokenization_biogpt.py": "496e3e28227ca6264f84064aef9857f8daa4c8037d798915b787e08457ce4d50",
        "transformers/models/bit/__init__.py": "721969b47e3e954bcc4612751e47f5b3b06b309724ca18bc2b70e085658f8ff9",
        "transformers/models/bit/configuration_bit.py": "801ad3aae1035868c13a1c2c1783b5ef561eb07a6a46ccb822b75220d72e70ae",
        "transformers/models/bit/convert_bit_to_pytorch.py": "7e17ae998448550c19a19096725d1bb5987b2e16a775a11e0284ba8ad5269309",
        "transformers/models/bit/image_processing_bit.py": "5ffa4af281ad455bcca0a3b6a26e0638be36af646d1d21a108570d4c4c881915",
        "transformers/models/bit/modeling_bit.py": "5f061a4d96b4f4cb5494b3af1b3f5bb34ce5633982e49ce6d2414fb47acb6bc1",
        "transformers/models/blenderbot/__init__.py": "473c12a2e789b091363b7ad0beba56aab2f69fe8f8f872387c6ea2203d9c0d82",
        "transformers/models/blenderbot/configuration_blenderbot.py": "77d6a69a9fde84c62c2e5de1c3943c94ad2fbc769940ad595629c568b862e6e1",
        "transformers/models/blenderbot/convert_blenderbot_original_pytorch_checkpoint_to_pytorch.py": "f3a4015984dec89bf131439fc6a9861f0a439de69d7ea6c4192ba3318c37cae5",
        "transformers/models/blenderbot/modeling_blenderbot.py": "28ec11cfafaebeb5b21c29d8990314b62d658aa58d6b20aef131311d0448b936",
        "transformers/models/blenderbot/modeling_flax_blenderbot.py": "72f4b83f3abc07ad561cb28cfcb988b52079c18fe37cd260cba0d50e1ce87ee9",
        "transformers/models/blenderbot/modeling_tf_blenderbot.py": "f003559be027ba02c6486a5a6092d04726e0f869cbc428a1f76143112865b23c",
        "transformers/models/blenderbot/tokenization_blenderbot.py": "2e7e0e09fa58a1863823cdc2300ca58b4c3350aa468763f01107201536635348",
        "transformers/models/blenderbot/tokenization_blenderbot_fast.py": "3ca4d2ddf7da79842c8aaf780a45cb65834de0e89a212063c6c56c7e0a4606c5",
        "transformers/models/blenderbot_small/__init__.py": "3edb1a5ea502a7b6fde42b237563c5309bba772d9940129a5364f693513cf4ce",
        "transformers/models/blenderbot_small/configuration_blenderbot_small.py": "a27d89c8119460f1f9ab58534fb2803e7383725bee27fc3a3497d1401c19f73b",
        "transformers/models/blenderbot_small/modeling_blenderbot_small.py": "11010559e05218b5e28e4a7d3f0480c6b5f0cd4aeed3fe2de9dd5795674966ff",
        "transformers/models/blenderbot_small/modeling_flax_blenderbot_small.py": "90da16ff1c5996e8809ed092e65a24a8187240d3def1aed4544b000cc00ed73d",
        "transformers/models/blenderbot_small/modeling_tf_blenderbot_small.py": "b9e32c7b7bf0bb89aa0dfe692e93918ca347a4f6567db30c256c22949a226ae3",
        "transformers/models/blenderbot_small/tokenization_blenderbot_small.py": "76e5dc12506b7a4f28af3776d5a285237a879cd6c865f25a672199dbba93fa32",
        "transformers/models/blenderbot_small/tokenization_blenderbot_small_fast.py": "839f8077ba06b684dc6a60791c744231a87d3669ed886b2e948d37763217f466",
        "transformers/models/blip/__init__.py": "b2a9d7113efc1c0f3ae05e5eef36d792cdcf987844f3caec43da90b88e0e2c07",
        "transformers/models/blip/configuration_blip.py": "ed05fe6fd9b632d5885a60b30aec0cd4de319a609335bcb0d1778fdd520ee0f4",
        "transformers/models/blip/convert_blip_original_pytorch_to_hf.py": "eef2fc1cde04b09324509b7be29da7ac556fc112e62a6778dca240c6611e1a2d",
        "transformers/models/blip/image_processing_blip.py": "1b06fb4b55609768952d815536604752c2d731c9dcd9ccf5114da1091a11f567",
        "transformers/models/blip/modeling_blip.py": "8cc3ec2c400bc9d52a64c39c7fa98f010dd0250ece2e1e85b426aec765c77913",
        "transformers/models/blip/modeling_blip_text.py": "d8db3cb1246c1ce1ed57e2ac8b1cbaf17f88584bd6db5e6b5070d9eafd4aaee8",
        "transformers/models/blip/modeling_tf_blip.py": "a309077945f3f99c7514d377e6f34e69ef9694ca993b8307281e3389da419be4",
        "transformers/models/blip/modeling_tf_blip_text.py": "889898727669a8986836b7d47313f1b68913fea3091a02f2cf5840700599fade",
        "transformers/models/blip/processing_blip.py": "bef01be284d6e9844616508d5d84528160892aa4531f2981fc056a9ab6cbaca5",
        "transformers/models/blip_2/__init__.py": "b00d830267675d8af0f3f493d4588f31df2898753e57601b22f1d10163a4095d",
        "transformers/models/blip_2/configuration_blip_2.py": "0ae5e81604cb8c48c981ab93f0d2bf447ccdcd7931d7b9941a2cc6d66e4b2899",
        "transformers/models/blip_2/convert_blip_2_original_to_pytorch.py": "789bef3445ba1445d91ace96e8e62d885af4b39d6255d6abf40c77f05d45f995",
        "transformers/models/blip_2/modeling_blip_2.py": "015ab850e14977f4e0241849068a836d90fbc2911988366028d8842f986abdde",
        "transformers/models/blip_2/processing_blip_2.py": "a2d2ec7538d598da25504f133c007488c806e4878d851477dc4045f8a9a6dde5",
        "transformers/models/bloom/__init__.py": "9d5d9bc56241c7dc77a1ae5289d10907d5c09d12f0bb52c3aa2d1b15fcfb7f84",
        "transformers/models/bloom/configuration_bloom.py": "e4117c8b82bc8f70029a4167ab988696c3e77a1854c6e927dfbe8ef403a0537d",
        "transformers/models/bloom/convert_bloom_original_checkpoint_to_pytorch.py": "5ad3c5b200b8edd8460d6e9d1e6e4f0b849a66067ab45dee99315df108b0fb54",
        "transformers/models/bloom/modeling_bloom.py": "d76b428c4995e959797dde3928bc4fc5597dcbc816993e69d0cdf090b162d7c3",
        "transformers/models/bloom/modeling_flax_bloom.py": "cc15b01d923a381b3d4b587d2524806849ec90f2a96bc8c79f90113a16cb5e9c",
        "transformers/models/bloom/tokenization_bloom_fast.py": "aaa3c63540bc31f7c15ee2f121ea146e3cb953c6d1e4d8a1e827d016e5b8cd40",
        "transformers/models/bridgetower/__init__.py": "14afd7ca2ceb575433832ec5fd06e1fe894a9158b42a3110f95402a92fbdbc9a",
        "transformers/models/bridgetower/configuration_bridgetower.py": "6ffa07761eeed40d275915039e9ad22688dc8c0752ff5818c3d52ddb34b5fa42",
        "transformers/models/bridgetower/image_processing_bridgetower.py": "02d47a506757a384b002ccf801e1bf5d1a2ffcee74e3e532d19ba53fc94ca523",
        "transformers/models/bridgetower/modeling_bridgetower.py": "4db52165c57e7063262dda087a8f50a7dd3bbff2bb0200a1051bb2bab03eb85c",
        "transformers/models/bridgetower/processing_bridgetower.py": "bdf74ad49c79c58533dd319fbd8137d8c761c21a438089e3e5b2867adf4f07c2",
        "transformers/models/bros/__init__.py": "1f0011bc375ef34f16aab4558d3e42c6769c18e429cb1a55645d4427bc2c0944",
        "transformers/models/bros/configuration_bros.py": "553c748094142507a96459983fb1cf88b68bc74e0a773dc2cb1800aa428b2c4b",
        "transformers/models/bros/convert_bros_to_pytorch.py": "9316431b3bc8631cfd85b233cc939f3a3e6d8b18e2e5e7dbdbcf38aeac2863a0",
        "transformers/models/bros/modeling_bros.py": "501897dba521ce57d796c7e1848c4497e9d8926647f0d83f76dba30a84dac2c3",
        "transformers/models/bros/processing_bros.py": "15052ee5ccc71ef4336753f937d1a17e366ee1c999c3f9982ae5f454d8eb079e",
        "transformers/models/byt5/__init__.py": "d3a62141df1314d6dcf65539ab311165475c496205c4e78139aa9087a4b8582e",
        "transformers/models/byt5/convert_byt5_original_tf_checkpoint_to_pytorch.py": "2c489b1cf7650dd29dc81e971c1e6cee91d1b2a079a90c5458df771fc1bfab99",
        "transformers/models/byt5/tokenization_byt5.py": "322a118e713905ca373a075b29c8df619ec13029b5ca6bb9c9dc19506af30b95",
        "transformers/models/camembert/__init__.py": "b755145f66686e941258ebc1ae39ec840108d045650f09e07711fe1883325d35",
        "transformers/models/camembert/configuration_camembert.py": "1b110c0d846acfd3d758897fcfd594d3fb1c781ac81883622b1e9a6ddd29a20a",
        "transformers/models/camembert/modeling_camembert.py": "b05f9cf51ad1e902395ce87c16bd8f913f5bca2f727e161e18fb7f514b3a1961",
        "transformers/models/camembert/modeling_tf_camembert.py": "3b77da7eb4c54bc0c8bb08a7559871cf83e2b144078cc1de3f95a87b95ae91d0",
        "transformers/models/camembert/tokenization_camembert.py": "0ff08386f01709b010fa5d89410f87d8b3638e792080fe6ebe0b1b3257596b40",
        "transformers/models/camembert/tokenization_camembert_fast.py": "838f171d34a504437df695a1f2ac9887bc3225390c24f77fc7ac54768c84cf30",
        "transformers/models/canine/__init__.py": "3b6b94e15a4af6da9f9f233df8ab24b02788a78eaef5170be5f2759b878dbe23",
        "transformers/models/canine/configuration_canine.py": "f2801ad2825c444eef3d5b5046cc6fb171f409e962dd031b253ae4eab40035bd",
        "transformers/models/canine/convert_canine_original_tf_checkpoint_to_pytorch.py": "cc9e950e9139f08e3e9ed3970d408a3d85cf9e785692e61709f7a30dc86bf636",
        "transformers/models/canine/modeling_canine.py": "36cbf5533547fc1eef7b9474f07393eb091cbad0c945ece7177291d8f31bee6f",
        "transformers/models/canine/tokenization_canine.py": "6cb40fb2f4e993c185b87debb1447aa3497a7fd2ddbdbe12dceb341fea054107",
        "transformers/models/chameleon/__init__.py": "6fc58ea733152cfdf81129199c29af3b881cfa418514bd185be1118d940181f5",
        "transformers/models/chameleon/configuration_chameleon.py": "12fecae1e7a709b0e56605e10fcb7f8a19c756790af13534709794232e746862",
        "transformers/models/chameleon/convert_chameleon_weights_to_hf.py": "461f5ca56fe2390813c5d85518156f320351467e1e54c7570a58f3f56f5bbf96",
        "transformers/models/chameleon/image_processing_chameleon.py": "7647c5913f754926fff40c8bf32dc430223e267d2e8e01b08eff9361bc48aea6",
        "transformers/models/chameleon/modeling_chameleon.py": "fc45b52c95df5d911c656f88b1f4f26e75e835d96bb087ba11f3a903eda42f64",
        "transformers/models/chameleon/processing_chameleon.py": "8215ae16064b4cf6e928e050faa9b53bc2609aa9de08f5955bb15bea3e33baca",
        "transformers/models/chinese_clip/__init__.py": "2905cf28933e76c7b2f12c32c43ec24526a8384121b953075837adf717033c64",
        "transformers/models/chinese_clip/configuration_chinese_clip.py": "9f9745dba9edc2d4aace1b1e0845334a2c61d3d827cc5cc2d4fd2630cf4dd2bd",
        "transformers/models/chinese_clip/convert_chinese_clip_original_pytorch_to_hf.py": "fb46e755c757c52b66ca09328fa4b584818255ba446deddc33b028b211c7e591",
        "transformers/models/chinese_clip/feature_extraction_chinese_clip.py": "ce776ec8ec89f90771e0c0b908f6fa30567e5ab6f93cb807591874c5fa142d1d",
        "transformers/models/chinese_clip/image_processing_chinese_clip.py": "14ab450ad2fb8f9e9e311f1c43bc31c12ec6a6fad6da75d44e440100220cf934",
        "transformers/models/chinese_clip/modeling_chinese_clip.py": "c1e7bef2d2b438458dc49887b1e420a0facf13c050d7c0188f0c2453bc3aa116",
        "transformers/models/chinese_clip/processing_chinese_clip.py": "96c28bcaa0c93cb639df4011c6de49909df3c04d3b719c8e2ee9932de852a1f5",
        "transformers/models/clap/__init__.py": "32bc0f3bfe167a4fead0ba7bdf977306fe47c8e3b8dd6f0878693872ebba1d8e",
        "transformers/models/clap/configuration_clap.py": "1e8f3ce4d4bc1316ed64da09f5d0ec4542be4b97443ff3aeb3542aa0443f1092",
        "transformers/models/clap/convert_clap_original_pytorch_to_hf.py": "16a1e85406172337d463ddf8d9acf0966f737d23fb41d4bca7ebbd43a444fcae",
        "transformers/models/clap/feature_extraction_clap.py": "f30bd44a08231e270906d9d30c5e7a52c57e27636f7a5bb5e8f93b50c6a29bda",
        "transformers/models/clap/modeling_clap.py": "110c4bf4c1b56bad46e7bbc356532145a493f1f97bd2ffb4aa0aef3c508014ae",
        "transformers/models/clap/processing_clap.py": "032a3998ae5972f12f704a7d0e11ce2c5c5a449f60c133518718bde9648765d9",
        "transformers/models/clip/__init__.py": "555256a916c33740146bb06b24c69ec6329726d277360b029913504c033868cd",
        "transformers/models/clip/configuration_clip.py": "373b86a1214b486bbeef45f8a483ef8043b015bbb6ca24ba51775149f7c7514a",
        "transformers/models/clip/convert_clip_original_pytorch_to_hf.py": "10e75594618139bad7008751c8d0ff2a8dc6d5959fd268b281ad507001fd43c2",
        "transformers/models/clip/feature_extraction_clip.py": "86045f0feb3d0e823bb730cb009d045b7ad26e463d74e886aa818294e8918813",
        "transformers/models/clip/image_processing_clip.py": "0d342dbbd1e3db1905e302e6591b9222ae2aaa691c3067c3ec0869add7c6e8c6",
        "transformers/models/clip/modeling_clip.py": "ee6c3996aa6c25c9051bba1961200e58fcdc3ffda7f83120e83e63b2194ff3c1",
        "transformers/models/clip/modeling_flax_clip.py": "e2e69b9bdb7a8b86e7a914770d9ac693b5f535c695efc2fa6fa13a8b41a49765",
        "transformers/models/clip/modeling_tf_clip.py": "4c4a26e20a00de5b79947f17e0de8fead9f184b6c91c78866679b5e73379686c",
        "transformers/models/clip/processing_clip.py": "c57a7845f968a961f52b574508bf358c6bda3a8c02350dacd02535bf3d8294ff",
        "transformers/models/clip/tokenization_clip.py": "aae82ec3d77c1fe627aed034f1fa2e51d8d333f4e2d7ac79b8c04a6f4f793bb0",
        "transformers/models/clip/tokenization_clip_fast.py": "201f5fc9d076bd89b99653f1f8d9a6a4ee6822015cc5bbb6159b9b5abb35e9af",
        "transformers/models/clipseg/__init__.py": "0bdaae42afeb91e01f026d8fd82163f550c6ed931d1fc43f9745a9f0b61ee05d",
        "transformers/models/clipseg/configuration_clipseg.py": "75e4e71b20ee8abd522579a24dae90222114a253cae09e7fd519e4738ba75dab",
        "transformers/models/clipseg/convert_clipseg_original_pytorch_to_hf.py": "918c8fc5da5db6dea74b10fae6d5d44cc6cdd313f2cb38df4ce38c6d0f0e2f46",
        "transformers/models/clipseg/modeling_clipseg.py": "242460ee805898f89621759ca28db9e3f67d0c7ac97f94541eade4a4116b25b9",
        "transformers/models/clipseg/processing_clipseg.py": "766eeefba4b91e0d484c0734958cd7449b2c891f762ce32459b9d1ee9e1e1f31",
        "transformers/models/clvp/__init__.py": "b8bb113ba3ea914268e427f1208ef05b800dd86f78e044304bf1289c0a0ac0c7",
        "transformers/models/clvp/configuration_clvp.py": "3e6c6bcd3a5747579f9fb39df89261dbd5b6ec1aff8b13ba95b5412526fc4b79",
        "transformers/models/clvp/convert_clvp_to_hf.py": "d5661ffefc23d42790fd553d88caaeec6aebfcc9a502c68a10ad4ba2393ac8ce",
        "transformers/models/clvp/feature_extraction_clvp.py": "78462e7325b04c200bc7e16747b851f41194c30dad812d418bacafb913388394",
        "transformers/models/clvp/modeling_clvp.py": "5b4f4f305fd6395c56c000a3d0eba256124c6a112d20d4d2041390ec224b1fec",
        "transformers/models/clvp/number_normalizer.py": "956d4c8d163c3c30168d62c0f92d8593e2d559aaa4981542002985dbbeb9569b",
        "transformers/models/clvp/processing_clvp.py": "ba2daa42dc6d4c1a09ef649c954a862c7d78c3a44d0df7849eb3396f6276c384",
        "transformers/models/clvp/tokenization_clvp.py": "74d6eb5c885872aba6fefa27019ef1b31bca8a6bb5b68e827430eee53e7ed170",
        "transformers/models/code_llama/__init__.py": "4b5c69559e9c2d9c4dd400e644da7b742b282902a76f7f93c3e1e41e31dc9c16",
        "transformers/models/code_llama/tokenization_code_llama.py": "44a09fab32093cb00d7f8bab8a48013d6398e2b04b243dacab260134bebc509d",
        "transformers/models/code_llama/tokenization_code_llama_fast.py": "c5ec0a6c105b0bae1e68ce8fd49f425a8ea97c85f1fea8d1fa33b028687bc3c5",
        "transformers/models/codegen/__init__.py": "b0f17b0d9af04a7766e6a8ae1c84a6d9d1345954b94c525a150c0e60a4c6ccd1",
        "transformers/models/codegen/configuration_codegen.py": "c1c024994211cc6383fe74316851e922d725ca2d45e67c2e8b5785f77ae7a15c",
        "transformers/models/codegen/modeling_codegen.py": "73839bca75e109f75b19096dd6ea86bf8ca4ce4052793992b55ea2aa94f3c20c",
        "transformers/models/codegen/tokenization_codegen.py": "cb10e5194642a4a29be12cd33b003881cb10efd68c7c7193dff7530d9d07fa8e",
        "transformers/models/codegen/tokenization_codegen_fast.py": "a41c590c9769dd7716e4ca71ab9d1b734cc50550b3e595bbedacb7bda3c159e0",
        "transformers/models/cohere/__init__.py": "19ee23a91076e83b0f6711fff86bd79c76ad2d6adddb8f727fbde5d104468d77",
        "transformers/models/cohere/configuration_cohere.py": "f6bf78504abbfe4819a0f1d0b90176303499d6ab8f436dfa920d36abbf86684d",
        "transformers/models/cohere/modeling_cohere.py": "0870df52fb8ef1092508a54ad0ef3f73b9c174751338949ea2d5231968c245c5",
        "transformers/models/cohere/tokenization_cohere_fast.py": "8a8d663b93fd0121b4e1ed6007c32a8b22b4226b837e39178951388e251158c9",
        "transformers/models/conditional_detr/__init__.py": "13e04498854bfc721d2eced9b85c003b521495549f46919e503b93c56533dc69",
        "transformers/models/conditional_detr/configuration_conditional_detr.py": "b55961d7b0baa416d3f1bc79bd6883fa4e23f0302c702da50d4b036f56b81a30",
        "transformers/models/conditional_detr/convert_conditional_detr_original_pytorch_checkpoint_to_pytorch.py": "a4408edcf568a2a6627169f9c9c6df4e0ebd0b4a2271b6d28a0bf9e5f542c083",
        "transformers/models/conditional_detr/feature_extraction_conditional_detr.py": "a291d765e6ddfba70c2673ba45bac07665589a790dccad6ea7f7cf9474d22eb9",
        "transformers/models/conditional_detr/image_processing_conditional_detr.py": "3f7c68f0681423e01a3ec2192238ba23ad75c88de504f8520580652d05d91e78",
        "transformers/models/conditional_detr/modeling_conditional_detr.py": "bfaddf44ce3f107bd5f6a7d941bf81b2da940cd310ffc9558b7de6e88d9fe986",
        "transformers/models/convbert/__init__.py": "a3b773641d8f3cca2ca6ad2822b35ae7668ff49ced776a6c5df4e20ae8ba6061",
        "transformers/models/convbert/configuration_convbert.py": "69f77b987ecbca84e7495657188a8539d263ff3a41ac542227d7dae4b5ace455",
        "transformers/models/convbert/convert_convbert_original_tf1_checkpoint_to_pytorch_and_tf2.py": "bd36721a11bdbfba38ac3b8ff7ec4cdba817d44ce509d6bb4a7fc42d3f67dc69",
        "transformers/models/convbert/modeling_convbert.py": "22604d0fc71c5517652e2f1dad414c8a91b5ab5e9388d188ebff83e400f9580f",
        "transformers/models/convbert/modeling_tf_convbert.py": "100b188d441848c015478fa289dcb5ce98b083289b6c317c61049d319d650d73",
        "transformers/models/convbert/tokenization_convbert.py": "d7520563d3f588634f88d8d57c56db02dcb614f4f8336dc5bfd85e9091a8d283",
        "transformers/models/convbert/tokenization_convbert_fast.py": "b94bf2c9ea2821a3b70231b5b0f0b8bff087b785d6d82ed5fbbea18cdcafd718",
        "transformers/models/convnext/__init__.py": "9b715b9780741cd47e01478b443ba224e105cb3f32a908c85d71f07cff6a0dc7",
        "transformers/models/convnext/configuration_convnext.py": "67d2f0f3227811067976db76d0a84444ea822cec0cc4de303a0a06428d433646",
        "transformers/models/convnext/convert_convnext_to_pytorch.py": "87c5897a1d3618558c624abef4c771ca205bb2659024548c84dcc21ebc5423ca",
        "transformers/models/convnext/feature_extraction_convnext.py": "4f214ca1c857625377bca1fb51dd275da833c46862a3605f99ae287dc791ff30",
        "transformers/models/convnext/image_processing_convnext.py": "a09c6443665a2d0929a0ed7a850ee420c046a111967259730f8c5e9b497b3c82",
        "transformers/models/convnext/modeling_convnext.py": "4795fbf9c3a46525947752e18e86b7f55302b1acbe5f5015b2326997d6104df5",
        "transformers/models/convnext/modeling_tf_convnext.py": "a14acbeb3371151fb8c676ca27cc90f55c90d4133cba29a4608182f38f40dd54",
        "transformers/models/convnextv2/__init__.py": "e69275f610792c68600c7cddbcaa552c2bdec9f031f2920cbcc1b19ed6b17198",
        "transformers/models/convnextv2/configuration_convnextv2.py": "2e81b4fd799c44c4b55d2efdb45792568c8d419f6ad52f8b0f33fcfbd1fb544f",
        "transformers/models/convnextv2/convert_convnextv2_to_pytorch.py": "62cc25e54c0b3f4b74b42f0ed9bf308b1d9b78d68cb4fcbb6ab78a142b8471c8",
        "transformers/models/convnextv2/modeling_convnextv2.py": "9a8f8150dcb50a4c103d44f593d366c5893b0fd408eee4d2d3af3864743522a6",
        "transformers/models/convnextv2/modeling_tf_convnextv2.py": "54266b23d617e9981d95156a19edad40f2d382de35bf641d87c6ffd6d634e5a7",
        "transformers/models/cpm/__init__.py": "f52993d272f90e01a35f198f690162f4618f5d6ba11627360d7d86b05f81ca74",
        "transformers/models/cpm/tokenization_cpm.py": "9f7a12ac8c99ab13262b11ef72e9d6c8275e3d15e3e097f735ee7f660870469f",
        "transformers/models/cpm/tokenization_cpm_fast.py": "90f0557e241e964c0f388a9f7d07c9861fa2265408932d87163175b6345c5107",
        "transformers/models/cpmant/__init__.py": "dff3fb791fad21a8f599ab13aa4d42152eecf68ddef193f77360d6c71e8c3b9f",
        "transformers/models/cpmant/configuration_cpmant.py": "76c1cf9c44badbeadbf542cec00d762b755892efc7742c7911a639997063e0b4",
        "transformers/models/cpmant/modeling_cpmant.py": "15ce09704b225f7d79dbb6273026295f5658b3c1da56f06adbe6d04421e463b8",
        "transformers/models/cpmant/tokenization_cpmant.py": "de88b876baabc9f5d484cd90e057043f6b2009beedcaf9a39455f0c154ef2517",
        "transformers/models/ctrl/__init__.py": "b39f3c897130e12490fedaaac926bd158f17b0337c4f65f3e1bd5237e08eeede",
        "transformers/models/ctrl/configuration_ctrl.py": "c81e47c45f0428f330c4f9debbbb3c7932ddac1c3f2af88635e734141f466f06",
        "transformers/models/ctrl/modeling_ctrl.py": "97aa0bf418b3b4d8be9db9e3731c369d792a8375e61951beb9a78458668a05ec",
        "transformers/models/ctrl/modeling_tf_ctrl.py": "701e6de96806146d6490def158e1420c27e89e07b6a95dfb08933f2fbe91c626",
        "transformers/models/ctrl/tokenization_ctrl.py": "c5cfdae06d5e8cba8e9c07486a320be1755b0233604711850369e7b1bb584ab5",
        "transformers/models/cvt/__init__.py": "cbe693cce24554ee311acb2f329d209523ce0014e5d1dd69ee740ba41d2ec774",
        "transformers/models/cvt/configuration_cvt.py": "d61b3c53004c035b13eed823e5f7e061dde24b8579ccd5f696a202300f274385",
        "transformers/models/cvt/convert_cvt_original_pytorch_checkpoint_to_pytorch.py": "ce879dd12d0b164a8abf73abfbc3b9d769a3795068e1d67b6e09ce09aa8e5381",
        "transformers/models/cvt/modeling_cvt.py": "f261ddf5b5166d960d4d7802278441ef365013149e22c9ecb7209f8989fec250",
        "transformers/models/cvt/modeling_tf_cvt.py": "5a17712e820afe43ac57f9799412c47c34bbf0538931101426c61dc3825ae07f",
        "transformers/models/dac/__init__.py": "a6b89b488713be5d02c09254798fad248eef4eaadf8a742df1c1de1a0f2b8437",
        "transformers/models/dac/configuration_dac.py": "134db68a7528218c363568e8fc839530b7dacc7a898a4cbf2ea1d3d083b19214",
        "transformers/models/dac/convert_dac_checkpoint.py": "69bd97a09104e55b2eadc0a5ca266a43a4f9ed225cf6fdb90c453c7b4055ef44",
        "transformers/models/dac/feature_extraction_dac.py": "84a8b7cffba66c8d692cb8ce6ce1a1a9cb62ff0d4db7f870eab3086ce4dd00b5",
        "transformers/models/dac/modeling_dac.py": "29bc984be3d86db5fd616d9adeca103617f89a362d15ed3865aa5602ba633b88",
        "transformers/models/data2vec/__init__.py": "916bf980e752a40ee2de552e9dbe1fd80e354afcbf3c4ccbb103ac856134b2bb",
        "transformers/models/data2vec/configuration_data2vec_audio.py": "c9395e88f0cac9e37ed2b2f966a85889dafc9dd68ab910917926a3824b1249c2",
        "transformers/models/data2vec/configuration_data2vec_text.py": "8f63f578615beb919196ed0391c4bfe7b3e33e764c96d9ed43cd37a5993a249e",
        "transformers/models/data2vec/configuration_data2vec_vision.py": "517217e798afde3258eb5eca64229d4615caaafccbd1ce7320bec35c8e99a0cd",
        "transformers/models/data2vec/convert_data2vec_audio_original_pytorch_checkpoint_to_pytorch.py": "76f713abc0bd665e1ac5cd2061ca98693593a94c60c2f7b53bbc615cc796bbc7",
        "transformers/models/data2vec/convert_data2vec_text_original_pytorch_checkpoint_to_pytorch.py": "7abcb33f8eff4b043691e64686e4e8769a0d4b85ad155537e17a06f1d05a7d2c",
        "transformers/models/data2vec/convert_data2vec_vision_original_pytorch_checkpoint_to_pytorch.py": "a8a8d5fa3a8880bfba8b5ee6e3240b5bff7749b3e91b1427bc78eecb5c55c505",
        "transformers/models/data2vec/modeling_data2vec_audio.py": "d0ee49bdda978516a17d195355c77dc6afcc65b9c12dd03f5189f90f89c11649",
        "transformers/models/data2vec/modeling_data2vec_text.py": "dbe55445f4cee96db5b58aab2bc032caf212eb4151fc6067008d9978b75a7add",
        "transformers/models/data2vec/modeling_data2vec_vision.py": "b17d7f43b98694afdb4bd6a4e36088bc2cc9254575d16c0f64e61be2f31a45e4",
        "transformers/models/data2vec/modeling_tf_data2vec_vision.py": "fdac49753b4216c4ad41830daae976bd9ce130f5bbe0e41e8d6cd7e54eabff18",
        "transformers/models/dbrx/__init__.py": "9f7e82f815858c9f70920040bfbeb8b0692c24538bfdf90c1357ded5c4e6fac8",
        "transformers/models/dbrx/configuration_dbrx.py": "5b59d6b851e2c50e993f8c71dd0e2fd5c2980b84fcd34e5af30e222552244e00",
        "transformers/models/dbrx/modeling_dbrx.py": "3acce2ff1bd2aea5e8c9356ccba617823cd40fa38b76b1ac4dee520c3fb33b26",
        "transformers/models/deberta/__init__.py": "e9ec007c9f32045c97bea05f069d7d40312cddf4e01b0a749be7141d939559df",
        "transformers/models/deberta/configuration_deberta.py": "c09d744c7353bae4562244dffa490ed869413d4b2766838a30f6007e6cac8e03",
        "transformers/models/deberta/modeling_deberta.py": "8ceeae36954c38db433bc065606bea04ce37ceb5a0f0d59d860546dacd1d32d5",
        "transformers/models/deberta/modeling_tf_deberta.py": "a14f82d9526b037ba8e7d60d36cefdf3b8f14ebd5619cefb5b75e23204a304b4",
        "transformers/models/deberta/tokenization_deberta.py": "f5b3ad9a868704f4a92251ddf1fc3e7d8e163d8b6abfa6916bdd304b5c53750c",
        "transformers/models/deberta/tokenization_deberta_fast.py": "fe2cb4f03245cd0b2bac44f5449280a7a9469762b1645a50ec12c4e265e66862",
        "transformers/models/deberta_v2/__init__.py": "22c185a8f19bffba0410334242c3bf2010936b6b499753a3296a23cad63e5c7c",
        "transformers/models/deberta_v2/configuration_deberta_v2.py": "15bca20575e9c178c808c4d4d8c402d27431c4f1a45c0c6b2b920e44a223365a",
        "transformers/models/deberta_v2/modeling_deberta_v2.py": "6f4d5bae16717b64ab6870136c7499751835415c2afd1b78ac6935b7f7ffc8bc",
        "transformers/models/deberta_v2/modeling_tf_deberta_v2.py": "14a783a2a8b63b1084c58b848ccfa57c67b7ed54cb011042c352d4bce808e302",
        "transformers/models/deberta_v2/tokenization_deberta_v2.py": "6aa7a8c30345841708f6c29c08268578116636467b2d3c6a9181c70f583c2811",
        "transformers/models/deberta_v2/tokenization_deberta_v2_fast.py": "ab08100e357493fddde34460ce552220306ac113b5bff75bab0b5c7f65a267e3",
        "transformers/models/decision_transformer/__init__.py": "f4c34ca90235ccdc2e5f3848f135c02cd1e1594b98d9839da0ec7bda5de2a3c3",
        "transformers/models/decision_transformer/configuration_decision_transformer.py": "94bc70bc061420c9b8425decc4be11325045cdbb5dd3693102f1aea8d3b33fff",
        "transformers/models/decision_transformer/modeling_decision_transformer.py": "2d5135bf3dc3d43f3a93f85a4e152a5505805373a6fb8ff8d1e2d3b5378e5239",
        "transformers/models/deformable_detr/__init__.py": "9b862b200d320022a302a3f48f99e00b82700aace87d9f243f609dc2e941eb3a",
        "transformers/models/deformable_detr/configuration_deformable_detr.py": "c811d97b446c51982ca56bfbd739eb93024ade771e058ce06bb1f363334b94dd",
        "transformers/models/deformable_detr/convert_deformable_detr_to_pytorch.py": "cadb0c163e2ba92fbc7f10cbf70a23a8537e3ec723589efdad571541093fd6cf",
        "transformers/models/deformable_detr/feature_extraction_deformable_detr.py": "1b061a4fa07af85bb625b97c0802e875becbcf882bf634917ead3541f2d073b6",
        "transformers/models/deformable_detr/image_processing_deformable_detr.py": "1abdd077261122bea71d7ec8f4ebb5f0488d5eeb91c04b58309714916a92d1f8",
        "transformers/models/deformable_detr/load_custom.py": "1af0de1fcf371d24fcfaf1f95e5e63711f554bf7b4192cdb0e822648bba0f6b0",
        "transformers/models/deformable_detr/modeling_deformable_detr.py": "a7acd1344e77c5bd42cf318261cd70f02608113c5739e53656c97a8e5159411b",
        "transformers/models/deit/__init__.py": "bebbbafca05d16df7efaa927415c4130471c4fd2023da3570fdfd85b7f05bd90",
        "transformers/models/deit/configuration_deit.py": "f4ba2933b74b29dee388a5688dcc9b444e4a7585c7c5b0196d86869a31f0af68",
        "transformers/models/deit/convert_deit_timm_to_pytorch.py": "ef05a38660a94bdef6ad8ba421166c7e155f925bdb765f2772516a891c1bf366",
        "transformers/models/deit/feature_extraction_deit.py": "d63fda574a00654a1f498246084151a3458d77fcd51178e3dd21654d04ae5751",
        "transformers/models/deit/image_processing_deit.py": "f05baed56d475a50272064ac53ae002a98aa012fba1bc9492e361a4af75eca85",
        "transformers/models/deit/modeling_deit.py": "4c6d08fa018431eff31d8d5793e7555d02d968a880e16caf2831af8e2df67da0",
        "transformers/models/deit/modeling_tf_deit.py": "5ff55e238c56ce1e1430241695959faa199d90fb310c9d4c3c5b1f4323b37c27",
        "transformers/models/deprecated/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "transformers/models/deprecated/bort/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "transformers/models/deprecated/bort/convert_bort_original_gluonnlp_checkpoint_to_pytorch.py": "f5a6389c1f80e3e59e5551fa0b313d931a07afdbaa2f97f9356dbf3a2af35b1a",
        "transformers/models/deprecated/deta/__init__.py": "b1176137aa527d3d46f15634e2cea33676412a0c99ac1e03b2b06c00fb3c470f",
        "transformers/models/deprecated/deta/configuration_deta.py": "1937d33ce68fd89cdd34a41af73837090e7640fb903a4a3153d54b73eb99b76b",
        "transformers/models/deprecated/deta/convert_deta_resnet_to_pytorch.py": "12edf1a6cb85c29faf93238f1e1023598225375cef9bd4e2ae918c4eae46cc6c",
        "transformers/models/deprecated/deta/convert_deta_swin_to_pytorch.py": "456c7b0ccb793cc0683a140cde9a0e20b9880093c7116847f6663b0de6535438",
        "transformers/models/deprecated/deta/image_processing_deta.py": "dca48c2463d362141e643143a3cab58c3dfd396c94a698299af5db9f1ed0701a",
        "transformers/models/deprecated/deta/modeling_deta.py": "e9177a2d40e6101e4dd53f8a9c82fa7ee223e5fd0ca6a1fc7ee5232b8ed5dd52",
        "transformers/models/deprecated/efficientformer/__init__.py": "bb8280e1bc8382846443dbae3468240363eda488740696554ce6c0d1582297e1",
        "transformers/models/deprecated/efficientformer/configuration_efficientformer.py": "4058814e615053a3fc565960859e634294750ed8679bdbb295381fef3dee1cc7",
        "transformers/models/deprecated/efficientformer/convert_efficientformer_original_pytorch_checkpoint_to_pytorch.py": "d678b4c328518d36c5f14e0167f15753effd273cb8dc730b288def1a5c8f8c57",
        "transformers/models/deprecated/efficientformer/image_processing_efficientformer.py": "6bdb434ad6e0f74f3d9d35f1094de98d6046e8707a25bc36b27950cd559d0ee6",
        "transformers/models/deprecated/efficientformer/modeling_efficientformer.py": "d36f525e66e9ebd1549f5de6f4e7684c78af2007bec7e464154b64eb6c982d69",
        "transformers/models/deprecated/efficientformer/modeling_tf_efficientformer.py": "b51b3d2e3c5ff1b7f507ee8cc2950fb948a7cd68a4db8933407e7429ee7c723c",
        "transformers/models/deprecated/ernie_m/__init__.py": "57a0b6d6213c00a612a43356e057e7dc81a22a9ebd4f8ae8d8b15c4577349aae",
        "transformers/models/deprecated/ernie_m/configuration_ernie_m.py": "6c64545d32fc35d2447af64d0660c187f681fd1c1134bf06d6b7dd358316ebdb",
        "transformers/models/deprecated/ernie_m/modeling_ernie_m.py": "7e573dff51ee32b0a11a81dcc786aedc89446edf556960d8636f72692986dc37",
        "transformers/models/deprecated/ernie_m/tokenization_ernie_m.py": "a0629d3e7b51e6c8d4dd7af16da44dc925fbe9b41a48b94558d4e02c97e65c12",
        "transformers/models/deprecated/gptsan_japanese/__init__.py": "f1ad53fcf06437630acc90d24d525a9f9912927c289f7711b5489ca0a56dd926",
        "transformers/models/deprecated/gptsan_japanese/configuration_gptsan_japanese.py": "4fc6ee1cc8c7dd7167c7b0575e2b3a339693bd62f0c2795e4dff980f2c92c0d3",
        "transformers/models/deprecated/gptsan_japanese/convert_gptsan_tf_checkpoint_to_pytorch.py": "b321784c26cb401c99866e55a881605dfcd0e33226982b9af1436309824fe6df",
        "transformers/models/deprecated/gptsan_japanese/modeling_gptsan_japanese.py": "25b0674c0725c9f1d01e45b244c7c45719662bc23921e9b170f89d9d2311c9cf",
        "transformers/models/deprecated/gptsan_japanese/tokenization_gptsan_japanese.py": "cc8df9e922ea9dee592c1929d6c6418e9f0c08e3f7559fffcd556c9798b20db5",
        "transformers/models/deprecated/graphormer/__init__.py": "96d44494c5a8bb48d1779d13e74347a09a1251bbcce48adc4f8d4470543b995d",
        "transformers/models/deprecated/graphormer/algos_graphormer.pyx": "6ff4259b584a0879c0ab1ea838b182f4b922bc05742bf0194468174fd32605ab",
        "transformers/models/deprecated/graphormer/collating_graphormer.py": "2917b0fb6a7dffb85e2d37e501803a74e6e8aff1f1cb8ef220ff0714481a8f55",
        "transformers/models/deprecated/graphormer/configuration_graphormer.py": "673342044663fc6d52d65837328bb0bad89278ef46e3bc85a1bd785865d737d8",
        "transformers/models/deprecated/graphormer/modeling_graphormer.py": "6376986e05f9bc8601ec57ccf23464bf6c5944b7681d9b92e5a06d7ac2d7a97f",
        "transformers/models/deprecated/jukebox/__init__.py": "f7ac8bbaefb23817001dacf5ce1bdce115b022faa48f272290c6be19715c5a6f",
        "transformers/models/deprecated/jukebox/configuration_jukebox.py": "fa02eae2e29da9d8c25ae57d65b0a1b148851842346b9f2cb79a1aa4f4e2c462",
        "transformers/models/deprecated/jukebox/convert_jukebox.py": "44180e3dbc0832fff8da6505258c51bf82001999f8700ce34ea8eb308ec7b558",
        "transformers/models/deprecated/jukebox/modeling_jukebox.py": "3b4c41262dd4c8c17c023d13c9761b37fdb0b68b878f2f6921d31b5147648994",
        "transformers/models/deprecated/jukebox/tokenization_jukebox.py": "af561c286d8e90f58029dae2436057817f8c06c4076dec9c72873968a2c2a5a7",
        "transformers/models/deprecated/mctct/__init__.py": "69a33e095b0cc84516a861c7e710209ea52ee81e43ef7d17fe54e8ec2329a3ba",
        "transformers/models/deprecated/mctct/configuration_mctct.py": "3a6af191ab4fbb27103919ae2105b39c01ec8b6d2717d08cf871ed1d6ca1d603",
        "transformers/models/deprecated/mctct/feature_extraction_mctct.py": "26c692136d0d7aa057f14c3ed3b6391dd51c42d6d866a0ab4cdd7c5aed81e2b2",
        "transformers/models/deprecated/mctct/modeling_mctct.py": "622504d5539328c1faa0693dbe5a8a7f843c631910149050b9df5b257805eae8",
        "transformers/models/deprecated/mctct/processing_mctct.py": "124a247637893e0cec4b1ae23cd980b6167a5a03bf890c8532940a5c3792ed4a",
        "transformers/models/deprecated/mega/__init__.py": "8bff5d1ea0e5e91649d7379b863f299f7ccf960c51a84ca7c2c33f9a3f5e58cb",
        "transformers/models/deprecated/mega/configuration_mega.py": "d26dc5b2ff4aa9c6440a2ec36e08ddcfb9e274aa9ff0c41b75f32c60c94c17fe",
        "transformers/models/deprecated/mega/convert_mega_original_pytorch_checkpoint_to_pytorch.py": "46a62b5ef40d09afa64a517d2f46b236f76b75a01ac88b04217a49fe3f1cec51",
        "transformers/models/deprecated/mega/modeling_mega.py": "f9f2d06e2805b68963bd44b4562b1b4ff63bfeaf6a8b2604917b0cfa674541b7",
        "transformers/models/deprecated/mmbt/__init__.py": "d020a67ac0b018830d1657f6a03b0bd2061a092a6c7c00b5fdb30e5d1700805e",
        "transformers/models/deprecated/mmbt/configuration_mmbt.py": "995912607a5736729bbc6889ff430e17c57f96ac2ed25e2b761c080d3585bbba",
        "transformers/models/deprecated/mmbt/modeling_mmbt.py": "9acfdf6bc1ba5b0de4ca4ee3a8b78075b6ba93613a54c06af36ccccf91af14a4",
        "transformers/models/deprecated/nat/__init__.py": "d4a81e51802cf18a6ad6b660035b52fdcab418d8d320dbe3c9c75047e9b43fbb",
        "transformers/models/deprecated/nat/configuration_nat.py": "a3e9e27c33fd22f7edbcccd57a85c6194c9cc1427ec28c752ba4157789296a29",
        "transformers/models/deprecated/nat/modeling_nat.py": "1b68207c9fd12580482006e3bc9bb60da01d804cdfef8721a95bda35e9ef7124",
        "transformers/models/deprecated/nezha/__init__.py": "a7862e47a166bc649e0a78806896935ad2fff64ab331f9c678a018b24696c9e3",
        "transformers/models/deprecated/nezha/configuration_nezha.py": "85fa46eed62a1077dd74c159e0d8ba8740d102e1ba530344b2697198ae7ad9ec",
        "transformers/models/deprecated/nezha/modeling_nezha.py": "dfb62e872dbaaa4a27ae3edd8d4c3db60253690a79c85d5f571f1cb41c974a8e",
        "transformers/models/deprecated/open_llama/__init__.py": "289d7524b9b4fb2b71da366311582024c0be0718e494f26a2d5176166d4e923c",
        "transformers/models/deprecated/open_llama/configuration_open_llama.py": "e4ef2bdc55dbcd81388071aa9e1623ecbb52615ba3017291e192a402c4c628b3",
        "transformers/models/deprecated/open_llama/modeling_open_llama.py": "50b2c325b440acb5ecb2395ffcd64ee1db52282945f3bbb87e6d3cd8aa515b45",
        "transformers/models/deprecated/qdqbert/__init__.py": "c43b6da5fca091b92db4db8aa37a56e9ef99d3f3304db8f9b8809e8975a0a69c",
        "transformers/models/deprecated/qdqbert/configuration_qdqbert.py": "a98c7f57ce6a93883fa372fe3b188b39baa7743f37e24d23d1b0e341435c7d3f",
        "transformers/models/deprecated/qdqbert/modeling_qdqbert.py": "5e31ad17c881f08ea57ef2f43d02ba7155916d8dbeefa2e9fd12e2f05fb2ed9f",
        "transformers/models/deprecated/realm/__init__.py": "ff191b96a4a09934ebc8f2bf73437fba070c55873cef553123684eb24be8fe9c",
        "transformers/models/deprecated/realm/configuration_realm.py": "914c70550d00f7d86bdb010500b59fbe0a0324aa743a9c468e5b38d90fb25595",
        "transformers/models/deprecated/realm/modeling_realm.py": "36d1e9a4b13c88aeab3301a3a9e15144c98614b926f8a73ee788758a3aefb869",
        "transformers/models/deprecated/realm/retrieval_realm.py": "71e6cd4dee3731be55375c54cd1d777b06ef9069e56799e52631928f47b0a167",
        "transformers/models/deprecated/realm/tokenization_realm.py": "b07391e2d9cb16b65a8995e15e1aa789b89901a010beda702f5f1b26f5ab8fe7",
        "transformers/models/deprecated/realm/tokenization_realm_fast.py": "799efafd53e18eca9d1041d1af4ff862ddc72b6e72d007ce943a2180f7fbefdd",
        "transformers/models/deprecated/retribert/__init__.py": "23968cc29d85270e33a0bebdaa5b24da4ad08e924c608878dfa5f8ed8c5432ef",
        "transformers/models/deprecated/retribert/configuration_retribert.py": "ee58926b83289d055e2c4cf6565c6e6a9660964e99fc2cf21b98bc3718b63133",
        "transformers/models/deprecated/retribert/modeling_retribert.py": "b45e12776958dff874f8336a590a221572b1c5b8df4eaaacc4fb499ca2c49ddd",
        "transformers/models/deprecated/retribert/tokenization_retribert.py": "367422a8dc346eb9a46688ddf2073abae742612323b036a24e78be3d45e1b1df",
        "transformers/models/deprecated/retribert/tokenization_retribert_fast.py": "84891bc428ca6e47db95f600c8413a54e7fe97b6849a05cede6c9143dd7b821a",
        "transformers/models/deprecated/speech_to_text_2/__init__.py": "16b3b95ad9fa5339f1e43cd51f27cba5da3b88391e0691605c2e1b1d75e0c71a",
        "transformers/models/deprecated/speech_to_text_2/configuration_speech_to_text_2.py": "1e9255ba76c5529db790f6410abf4ae6c217295a76dfc89c472bfcfd819c9822",
        "transformers/models/deprecated/speech_to_text_2/modeling_speech_to_text_2.py": "6ac2765253ba37e1ec2e33b57a0eab1425ad7f651b1fee4d801ee5b0f181d2ee",
        "transformers/models/deprecated/speech_to_text_2/processing_speech_to_text_2.py": "ec0594dff39e8321f037196e10c4878cbcc119f61c8379be4cd1eaf551d8253a",
        "transformers/models/deprecated/speech_to_text_2/tokenization_speech_to_text_2.py": "4bb6e20e63eba21e374ba8806c0d1c209c8256a6fa7c6ea2b5891bb08d8271f7",
        "transformers/models/deprecated/tapex/__init__.py": "950bad298b706d4f33b4fbdad2dc919e757ecce5b0eabc641b2a0e512baf9d4a",
        "transformers/models/deprecated/tapex/tokenization_tapex.py": "30fb81d49927acef5663f8fe1e0cbc25618d2af728c010eb8e1162f9b08600bc",
        "transformers/models/deprecated/trajectory_transformer/__init__.py": "5e75c30a6e1e3da9e742a9d09cc9f5169aaf9aaf7ed4bd3f9937a8a8e6ccf3ed",
        "transformers/models/deprecated/trajectory_transformer/configuration_trajectory_transformer.py": "a87de07f422786b96eb4a510340e3e3aba96a7bda7fc76b807a8c0fe4672e795",
        "transformers/models/deprecated/trajectory_transformer/convert_trajectory_transformer_original_pytorch_checkpoint_to_pytorch.py": "b143d6352bf2e3a218afc785132c6a2eb696f7469bbb3cb84a7aeddee2855b7e",
        "transformers/models/deprecated/trajectory_transformer/modeling_trajectory_transformer.py": "b6cd4b06a2239c2f60079de8afd493711253004ed46927599d81e88788ddb6ae",
        "transformers/models/deprecated/transfo_xl/__init__.py": "e48511ceb6534d31652da3d49f647512b17c4af43d9c5f5070d33c10d767b728",
        "transformers/models/deprecated/transfo_xl/configuration_transfo_xl.py": "537ceb0d502435b99275cc8b467195bc7128e8109930e3592981e1aca20c1a2d",
        "transformers/models/deprecated/transfo_xl/convert_transfo_xl_original_tf_checkpoint_to_pytorch.py": "a4643988d29d0838cf8a514123f7703a6065e876b8a4e92dec6baae26492841a",
        "transformers/models/deprecated/transfo_xl/modeling_tf_transfo_xl.py": "653c46833b9b04a5227a8b532be67bd53bedeca28ef52f82179a663ad01697f5",
        "transformers/models/deprecated/transfo_xl/modeling_tf_transfo_xl_utilities.py": "0e5bf767345db961419d96479fc45e81b5b8e5778279cb980b3cf3642ddb0d7b",
        "transformers/models/deprecated/transfo_xl/modeling_transfo_xl.py": "b6a5041734d2bf019ee7915f21e4375f9749a2f414c86d375e1b80e4f580ae5c",
        "transformers/models/deprecated/transfo_xl/modeling_transfo_xl_utilities.py": "2f59782bbb23f2bc17cef867efff912b651b3a762d7c3505d15745af82fc9f10",
        "transformers/models/deprecated/transfo_xl/tokenization_transfo_xl.py": "75746e09972a51d8dce9c48502f19ad1b31970623b4151fbba52163a53a7c703",
        "transformers/models/deprecated/tvlt/__init__.py": "472a7f91c25d837b2a8c52a0c915598d700c529fc4a60f422f618b4001c3d24d",
        "transformers/models/deprecated/tvlt/configuration_tvlt.py": "b8687a21ef8dbbeb9fe7df3b2cbb4506fa44a9df2b2c48c5cf390c288a25e9be",
        "transformers/models/deprecated/tvlt/feature_extraction_tvlt.py": "331eedb8626f2bed589d2ee08182fa8ff7a6ce896ef0bf07adc7b90133ed3d1d",
        "transformers/models/deprecated/tvlt/image_processing_tvlt.py": "d6bf6812cee23f580c0312de901cd766ae823432727f927ae5489a10ec39fe44",
        "transformers/models/deprecated/tvlt/modeling_tvlt.py": "850d0fcb14bca0e8e2a24b8bb4c0316358cd48bf56a0a987ee4e9106b9bab1cb",
        "transformers/models/deprecated/tvlt/processing_tvlt.py": "a42df34236a9c5d864aab97541d27b99790439218da283fb91350458a52bfe71",
        "transformers/models/deprecated/van/__init__.py": "5062a57a918ea4eb959ac6fa3267acb3a90f6b6a8fe2b2f37f327476c7500e7a",
        "transformers/models/deprecated/van/configuration_van.py": "42937ea761e0d02e7d89fd894841b8ee3ff37a9c757f82a90a02016202e108e6",
        "transformers/models/deprecated/van/convert_van_to_pytorch.py": "50c6a2a63b41ebc38f8fa390ce84b2aae3e50641be21b378ab5159bece752f18",
        "transformers/models/deprecated/van/modeling_van.py": "63034fed85732a9c94452437b5a8a388e0434e5174f3a844713d9f106a906931",
        "transformers/models/deprecated/vit_hybrid/__init__.py": "2ddd143a5dc5e32f98688e368e4ef29bfc2f4c5b30146263fccea3a5279753f1",
        "transformers/models/deprecated/vit_hybrid/configuration_vit_hybrid.py": "57026980c6b597dacbf91c7d8c5f8f382fe6cfaf72f3cb671ea812e37d506b5d",
        "transformers/models/deprecated/vit_hybrid/convert_vit_hybrid_timm_to_pytorch.py": "353fbbd991c711a41b9a6b07821f7f508ee07ffe3403291f7fc716f175eca504",
        "transformers/models/deprecated/vit_hybrid/image_processing_vit_hybrid.py": "848d5ce2632936ea6892facfc8b5c5b4310aa649d4f0c47459d9d43e91b47667",
        "transformers/models/deprecated/vit_hybrid/modeling_vit_hybrid.py": "db637520e0d8a471e3d5c35aa99f9a0ae921f5b562247b776cc368daa250f554",
        "transformers/models/deprecated/xlm_prophetnet/__init__.py": "39891c2f98e16c711a2cbbce01dd2ff82a69c90c5bb91ccd1336920c1857c4a0",
        "transformers/models/deprecated/xlm_prophetnet/configuration_xlm_prophetnet.py": "75f6bac3746f38464bc52f4601d40e29a245d6f4fa19cfb0d3a6bc12e8e0e529",
        "transformers/models/deprecated/xlm_prophetnet/modeling_xlm_prophetnet.py": "117e66ccd3d461f5aa70de41f98aae097bccfd213b4df65c6edcec96fd563c12",
        "transformers/models/deprecated/xlm_prophetnet/tokenization_xlm_prophetnet.py": "1e90fbb0a98069e94c5140f036b0321e004b862588dab9c36b19fec851637446",
        "transformers/models/depth_anything/__init__.py": "476c76c619f0e32bcec237225d2a432969b3f5f0681ac6fba21dd693986f418c",
        "transformers/models/depth_anything/configuration_depth_anything.py": "bbd0614702e6dcb643476c5cf6d1c739a352ab48716749c296e49cea0c97624e",
        "transformers/models/depth_anything/convert_depth_anything_to_hf.py": "adede3d49fc6072c16785bf478c45ef45bcd4969cd49bebea497fce767d96588",
        "transformers/models/depth_anything/modeling_depth_anything.py": "4b2745ebdcc60c40d64436cd2efd43cff46dedde14fc34cebd8a0eabf62ec6f6",
        "transformers/models/detr/__init__.py": "c08de29060e0ab0603e6e4b1174b0a3da0134235bd83f8326ae20c473ec59408",
        "transformers/models/detr/configuration_detr.py": "1b47cbd1499b60f0ee9b998359911921cfad5d9db8e0ccde92a3988c47ca4b9f",
        "transformers/models/detr/convert_detr_original_pytorch_checkpoint_to_pytorch.py": "93517ca68571223b2a414509bbb089976063df1d48ba2be58138b9e18fe688a9",
        "transformers/models/detr/convert_detr_to_pytorch.py": "d58fd3cf65927726c7b1c0cbfa2b85e6c246d8d8b6a36fbce6e9da24bb5aca4c",
        "transformers/models/detr/feature_extraction_detr.py": "80cc86d7aa4d24aa229889973b2aa2e7cf611a3dfb3981966fb6684f1f387792",
        "transformers/models/detr/image_processing_detr.py": "73f6a8658ea78bb29b7b8fc9e9bd9748231570c9b45ad581754677d0aa471dc0",
        "transformers/models/detr/image_processing_detr_fast.py": "0232837aee63c24f02b69dc13e9a0178bbe0c7e4063871390ca0ad02f72be361",
        "transformers/models/detr/modeling_detr.py": "d98e9f0898ef1d00d83e0393dfd2f81c760d076262560d3e88d69eab070e8371",
        "transformers/models/dialogpt/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "transformers/models/dialogpt/convert_dialogpt_original_pytorch_checkpoint_to_pytorch.py": "669e7d4e62c1284b3ec75faab9965ea80461a52ddc4e79e6813e27088d33b076",
        "transformers/models/dinat/__init__.py": "c202f21a28115d7e28e16877ce964b1afd0d9eeaf33b81b8b76b1c6c4580bd41",
        "transformers/models/dinat/configuration_dinat.py": "9f80d2f43e6eef22bf56cbf0366de8a439fab65e223e889510b319aec3f99fd4",
        "transformers/models/dinat/modeling_dinat.py": "5f2d05eb88d104de395b21c1866cb89c1c04a3d612dd5e78151de0789f830ce7",
        "transformers/models/dinov2/__init__.py": "6cd3239a68f3dd4c2c14acc095a1a0d9892477c3cbe5b14b9c82b4daf14e8650",
        "transformers/models/dinov2/configuration_dinov2.py": "f6fae9c8e0f7769a44cb952174b7b93cff4848ca31f2c20f7dfc64568fb50762",
        "transformers/models/dinov2/convert_dinov2_to_hf.py": "5295ea2db2c9f2c17d2d4149d93814ff90c865ee958999885dd58498385550bd",
        "transformers/models/dinov2/modeling_dinov2.py": "890b8c4ef922d2da3c440bc9e4eb8146009f04ea2d8de5df5f467e9033fc0a41",
        "transformers/models/dinov2/modeling_flax_dinov2.py": "3f020aa452fc12ee898dec2d9bd1d5e00b2f75887e6116a84a77a9f62302f86d",
        "transformers/models/distilbert/__init__.py": "6574b18c0786f06bd4717ee3f9eb8f999d98245a9609d79ab9bd286b6bf57941",
        "transformers/models/distilbert/configuration_distilbert.py": "2ae3373b580c7593317e05af29600d329cee5d6e2022eec4b891734174ff8f4b",
        "transformers/models/distilbert/modeling_distilbert.py": "57640c064e6613b40281ef657ccdcc45403917f6bac9be95477f6ab799178d28",
        "transformers/models/distilbert/modeling_flax_distilbert.py": "7d82ab3c6a1741ae64eca45062a43c067a29ff976ea4289168040b01a71d2a4a",
        "transformers/models/distilbert/modeling_tf_distilbert.py": "08b2bf7a87aae2a25cf6adc7d9fcd217f5aeb7d4944383092c2e3c4f5cedf0ff",
        "transformers/models/distilbert/tokenization_distilbert.py": "7abc19c560f059f5733372bc6faeb3e31c0da29b5246638c843674a6f25cfd40",
        "transformers/models/distilbert/tokenization_distilbert_fast.py": "a0ed426a76a61d732e1ba7891fc2cec1104480adb20927bcd251767c31b3e73a",
        "transformers/models/dit/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "transformers/models/dit/convert_dit_unilm_to_pytorch.py": "184327c1cd62304a1b8f05cb3b12c965aae34aabc004e2245007e04a9f469f2c",
        "transformers/models/donut/__init__.py": "281df1b6a57d3bc8fec72af0211dae8e7f5f0cc29456d8d5000aac672cd412fb",
        "transformers/models/donut/configuration_donut_swin.py": "ae31a07af7fecffb19ec1ad523b083d3ef08d21dd98b18f105fb228269708ff3",
        "transformers/models/donut/convert_donut_to_pytorch.py": "948226de3ee8c8961adb1cbea626776ef5041ce48ff66434c7f31986a3e204e6",
        "transformers/models/donut/feature_extraction_donut.py": "8c14a90dfa220a0fc85abe20729848731b3b0c0efad099c7e95ea101f6a860f3",
        "transformers/models/donut/image_processing_donut.py": "557d16be6ea4b4de22fa5f40ceb3a9d11316c486255bef114eaea80f252ba769",
        "transformers/models/donut/modeling_donut_swin.py": "864cac6f6e865842c0560a4e82890c2df0231afdedf127214ee099d2fcb4792b",
        "transformers/models/donut/processing_donut.py": "106be13245345f566c61c267cb390938b25b4916c2c7c60ddcd7fd248defdd36",
        "transformers/models/dpr/__init__.py": "f1d3e673db3e3f92c3c480b20f613c8d665d4204412a96b1c42b2f22128879cf",
        "transformers/models/dpr/configuration_dpr.py": "758e2b4e827e3cf4de0c448e7f091868d66f7207e0613cf7e683d171f5034a1b",
        "transformers/models/dpr/convert_dpr_original_checkpoint_to_pytorch.py": "5ecc46e45060e3af841e50ec32ae30db50bd5b8c25f1167a199bf1e5ca0199f9",
        "transformers/models/dpr/modeling_dpr.py": "32cf97a50065213e3e31ae6f3ad81e767b0bf6428227c175f2dfa2888f319c00",
        "transformers/models/dpr/modeling_tf_dpr.py": "19fd8d6b1c752e87234af85a2f14a4391475ed16d019b67b26f7ae6215441027",
        "transformers/models/dpr/tokenization_dpr.py": "778cd1a376e7688e467e96a8f9227b45e9903d01c0104de726df420f050769a7",
        "transformers/models/dpr/tokenization_dpr_fast.py": "c2cc2c4a6dcd5767666d039d2e7a6491511b9be12e2159ba9d41d9c88bc09ee5",
        "transformers/models/dpt/__init__.py": "0050ffc31b8f85c0bd28b25af5eea50c047c97e88a87039c5356c0d10225ffdb",
        "transformers/models/dpt/configuration_dpt.py": "479e77a6df884699b6d6fb6de1e6a3d064e2af31b705c739099b08663547fd35",
        "transformers/models/dpt/convert_dinov2_depth_to_hf.py": "45246da75fc2e8d1bf8d7e15fbd7ac00c84a5d72b0cb978884c4d2ed87a109a6",
        "transformers/models/dpt/convert_dpt_beit_to_hf.py": "5ecd5101c0108ad54a5328f21184f16206d8dae750cb215b9ceb670e110deb89",
        "transformers/models/dpt/convert_dpt_hybrid_to_pytorch.py": "48bc6cc51a6be5d6577be433bfac6c997059220f08ca14e8a28aa34b9a6d8c16",
        "transformers/models/dpt/convert_dpt_swinv2_to_hf.py": "2c7d1a396b9e087a9597c1eecff30b76842ab28e42f13821eff02b531c6f1988",
        "transformers/models/dpt/convert_dpt_to_pytorch.py": "7b348ab24867b545fb57e637f7a3c0edae578667587c90d03de7213e2cbf2ebe",
        "transformers/models/dpt/feature_extraction_dpt.py": "66005c48a3435f4fc5b2dbfde2ca75afd8e9afdcef5c22cfc2f21e93be8592ca",
        "transformers/models/dpt/image_processing_dpt.py": "1e0d72c8078168f21d4de18c8097e2d570653a270da22fbedbd7396526831353",
        "transformers/models/dpt/modeling_dpt.py": "6250b52c14a4546510cbd06687fb43f804ab04d57c8c0108853f7bbd34240290",
        "transformers/models/efficientnet/__init__.py": "644d65ad88ad31ed8b696aa9592585ee5f3b273325e58d9bacca21f14dd61565",
        "transformers/models/efficientnet/configuration_efficientnet.py": "b2b66b3d93c86bc87600b3e3859fa73a50c590be1a48e36ec57dd60a076fa199",
        "transformers/models/efficientnet/convert_efficientnet_to_pytorch.py": "7b635ad71bcd73bcfd5efbc8eefeafd55dae156afcf0c49337724f291e46b2d3",
        "transformers/models/efficientnet/image_processing_efficientnet.py": "3b1af70b167befc6d91a91a1067e08173dfe6df4b6987dd102ebc7bbcce08217",
        "transformers/models/efficientnet/modeling_efficientnet.py": "f3926d5169f78c78625ee12561c074679e80c9b2cd4bd58353a203babdbb9b93",
        "transformers/models/electra/__init__.py": "a06c700f853e83811c7417077d7339acf53492a144819ed97d24ed710db48981",
        "transformers/models/electra/configuration_electra.py": "d580656d66ee9746f4e37c7266602312b0f61d58ba46596b671c609309af95b1",
        "transformers/models/electra/convert_electra_original_tf_checkpoint_to_pytorch.py": "f06ef24e3e134de70555fd4e3c57aa16e3d2bb2ceba277f78127a2410784306e",
        "transformers/models/electra/modeling_electra.py": "254e398dd9dccb8228b52734791638ae37bd7276b1a7e7294fc3884f6e591378",
        "transformers/models/electra/modeling_flax_electra.py": "4b94e451b8c5fbd18d3b17a219f5d38dcded9c8355d7c47c08b2c57f7d00f735",
        "transformers/models/electra/modeling_tf_electra.py": "5c478fbd14531c1d4dd817da84285302375bb7227ce16dd2631b32f023e602ae",
        "transformers/models/electra/tokenization_electra.py": "afd07b7fd10b3b4b6eefefdea23be02a62594420af6c3a89688b5d8c4f455377",
        "transformers/models/electra/tokenization_electra_fast.py": "ccfab3b2dffa757e5e885811da256c66ecd8212f8a4def01283921ddfb0f4d0a",
        "transformers/models/encodec/__init__.py": "64bfaedc33d105fced0e31a080abe19d449988b735eacf962472ef1a568a9701",
        "transformers/models/encodec/configuration_encodec.py": "6b0545589c8d7d2e27467addb64922c37976905fd40d365e7eb7f0701c02e974",
        "transformers/models/encodec/convert_encodec_checkpoint_to_pytorch.py": "ec8b611b9e8b781c07fd61734f90afc1c7ec832d6f2217aead01d6a67312df5f",
        "transformers/models/encodec/feature_extraction_encodec.py": "96e61dd6e1afbd00bf98362552c9ccb52067fd2d1d85b6b3609f73606b90d4a7",
        "transformers/models/encodec/modeling_encodec.py": "a23ced8d83917f18de93ff0954ce053575857d72744232d2ee54021c16f52a83",
        "transformers/models/encoder_decoder/__init__.py": "6d1d723dbbaa2875185dac48fd0b83cfa71c0525a90abd131e13c1337967b6d0",
        "transformers/models/encoder_decoder/configuration_encoder_decoder.py": "f13a83aaf6cb8d6c3b906b7d910bbb4f39e7fdb50bdb207fda56f4182c70e2fb",
        "transformers/models/encoder_decoder/modeling_encoder_decoder.py": "7e2c927d6eb138e5785dbe62626180ebe9db27eed194846647104bdd3535b389",
        "transformers/models/encoder_decoder/modeling_flax_encoder_decoder.py": "303add8f3293737acd29f23461e77b2e8e6d8068859df98c2bbe08808f5c12bf",
        "transformers/models/encoder_decoder/modeling_tf_encoder_decoder.py": "cbcc33e5fff9725fadf1b6c4d2117bbc190da1fe3b16ebeac2b38efac00ce099",
        "transformers/models/ernie/__init__.py": "841794725616b61eea66948f04ae5c5e78163189d1cf6a6d2b490be199f634d6",
        "transformers/models/ernie/configuration_ernie.py": "90e961e65fe8479cf3e71e65acd748b7939f8370909b5c4c94374e6675310397",
        "transformers/models/ernie/modeling_ernie.py": "6dd5836a2c584d09c3bb36eeafe94b792dc7cef1c884f96022fba88f7db64aef",
        "transformers/models/esm/__init__.py": "1159ab9953df9270c5d532a7a889ca66dd5d3c95096914dff51651c16ddb7d99",
        "transformers/models/esm/configuration_esm.py": "04122d1002da3e3da69b75dfb0c828bb0c2ea008a1abfb84d63799d3ca7fa3b9",
        "transformers/models/esm/convert_esm.py": "c7b073e659015cc409fef619d3e2f7ff3eb595c4d143d7252320b9584917d8a8",
        "transformers/models/esm/modeling_esm.py": "03e3784d40a04802164f62ccc611b8066f7fee71cf3a661c6582f1889ac68c1d",
        "transformers/models/esm/modeling_esmfold.py": "3ebed5764512264529cfc979cdc5e97a4b6c2b0e2209545aab904b519d9e3475",
        "transformers/models/esm/modeling_tf_esm.py": "415073c53ab755cebee5dec06b8e33084c52982696709461887300e780f80672",
        "transformers/models/esm/tokenization_esm.py": "1c3e895f0777de84b0300beeb206802a96fe9053db234a4f5f3dd394bc92077b",
        "transformers/models/esm/openfold_utils/__init__.py": "5f2daeaaf16c2c2f00c7e38e71ee4f82804389980426024faacfffa794815946",
        "transformers/models/esm/openfold_utils/chunk_utils.py": "728dbdbd760269387783a3cf4acbdbff91b278f5d5b9d3242125479004434f7f",
        "transformers/models/esm/openfold_utils/data_transforms.py": "178c0600d46128b77a30b1ebc20d88c69a82c42244c7c6854b1a8076c5ec04ca",
        "transformers/models/esm/openfold_utils/feats.py": "4471fae537254a5708f9fb863f5e9feb1aff428955d1a1915c4594abed1ba085",
        "transformers/models/esm/openfold_utils/loss.py": "c18d8e36a6ee46f58ca268e4a5f3f07e86bb76a08edaf16433e92635f8638afa",
        "transformers/models/esm/openfold_utils/protein.py": "47b76212fbc83ad258dbc07effa4d231975698b158e0d3b068ccd0980834c7fc",
        "transformers/models/esm/openfold_utils/residue_constants.py": "16d3e5595c1e69c9273df9a2e170ab47aea416be04b985f2c2fc7420463c280b",
        "transformers/models/esm/openfold_utils/rigid_utils.py": "27ec505782ab9013701d1e134870704fce6939829ffa727bf0eb3826d8896f11",
        "transformers/models/esm/openfold_utils/tensor_utils.py": "7324a78616986ddab84aac96c80177a8679458f7d62acb936164675fe876d6c1",
        "transformers/models/falcon/__init__.py": "f9f4254c6668929b9d83ecf2050cc5b4e11c1df1d2b817bfda547cba62e7a2e5",
        "transformers/models/falcon/configuration_falcon.py": "3aed7f766368fa7ac034e52ce418158932ace90d5a78ce86f34ce279eee6b11b",
        "transformers/models/falcon/convert_custom_code_checkpoint.py": "5cf275a30463467a3f635003e547a83c4e28a3a6be49e411f70f6ef8421492d1",
        "transformers/models/falcon/modeling_falcon.py": "2d6fe8821f57e6c93d48d9b893a89a52c277cf1171a60fd337f2f9145fe1915a",
        "transformers/models/falcon_mamba/__init__.py": "4fdfacced50e560b93e2600a7d7663ad37dc930d43d1eada709ceadae5a20f0d",
        "transformers/models/falcon_mamba/configuration_falcon_mamba.py": "cf9b86c7aaf6e9f0ee2303c952e64b21a6e0f036f1af66f9f97838750d860dca",
        "transformers/models/falcon_mamba/modeling_falcon_mamba.py": "a47835b24b75c32ff411f9f013a0665aeea50bb4a6e988d0313b955048a5f65a",
        "transformers/models/fastspeech2_conformer/__init__.py": "242744e9c746f2c4c37691977fbe336622d16bada6cd9b65c32e71030385ab30",
        "transformers/models/fastspeech2_conformer/configuration_fastspeech2_conformer.py": "a2b83e8bd91ecfa0706cb2ee2d151464bb67d08e2b76f3fb9634312bf22119e5",
        "transformers/models/fastspeech2_conformer/convert_fastspeech2_conformer_original_pytorch_checkpoint_to_pytorch.py": "f93a091e9c08fb1a0b2ccccb61da85ac12fa8fa9ec48f94d6e4437a5f4e027a6",
        "transformers/models/fastspeech2_conformer/convert_hifigan.py": "442d4f6959e5d5c2f1f1cd8b758c9c36d8bb89846150ceff2ab5f6985e56c823",
        "transformers/models/fastspeech2_conformer/convert_model_with_hifigan.py": "c13e294068041d5168588d4b6fbd4beff8baba37cdad2303198b8319be287a1f",
        "transformers/models/fastspeech2_conformer/modeling_fastspeech2_conformer.py": "9fd883345914d78b81a3fed30ee25bdb1bf57a7fb7dd5be63376b940b95a9ad1",
        "transformers/models/fastspeech2_conformer/tokenization_fastspeech2_conformer.py": "9a9aeea3c5b01fc63a7c3b1e532545bade8484e30d53b85c1c442ddc38cce13b",
        "transformers/models/flaubert/__init__.py": "c7c45843ec8c10d98e3a72ab8d1aa47f2e30be0e68ba8334fb01debf597a7ece",
        "transformers/models/flaubert/configuration_flaubert.py": "191c72f1b0dd962153a023bfe032f295b59d83e93f230ce388315bf0cb801ee7",
        "transformers/models/flaubert/modeling_flaubert.py": "2cfcc9404610712d512e49e98cff7dfc51b7d911894e1bc4137ee1ceac5ed2ad",
        "transformers/models/flaubert/modeling_tf_flaubert.py": "aac5584fb0d18d41cf344adaef904785f0d4ee87700dace651b96273216df164",
        "transformers/models/flaubert/tokenization_flaubert.py": "ed5441bb1869cba0fe9d27dbd60a6cb6c79b6a7069f7b96c73bcdded0066231f",
        "transformers/models/flava/__init__.py": "a3bb4f1a589d865b00717d80f2a356d5c838df82b1c870e0c4d911657cfd1e8d",
        "transformers/models/flava/configuration_flava.py": "ccba5a25bd622bf0e8a9ee89923b1214873a3c4b9afc281610a46eab23147f57",
        "transformers/models/flava/convert_dalle_to_flava_codebook.py": "88424cf56fdc2a4dc72b480a4ba8b6ca010c7b2ca6582325d7c2c36905d10216",
        "transformers/models/flava/convert_flava_original_pytorch_to_hf.py": "2e2950a5b7baa9e3763ffb9796369eeb310fc7f2a87a9a11bf8baf084028d100",
        "transformers/models/flava/feature_extraction_flava.py": "980d6e027dbdcaff4f57b8185dabb3d154c024381ca65f433c7bc7f7d11dfffb",
        "transformers/models/flava/image_processing_flava.py": "849c5210268333844919a9dddef39d1e9ee6e0a40db5c46c8cf120d8da086c73",
        "transformers/models/flava/modeling_flava.py": "4667a4171cb7b311990f67b1b0d671e8cdfe5d05a8038641bfdeac00f231af52",
        "transformers/models/flava/processing_flava.py": "7e3f6e16531ead51859c1f615755c9eb5737abcdaab2d8cfc2659474c88be3a5",
        "transformers/models/fnet/__init__.py": "21dd6784d8bd80afbe7334c830c31f3fe131fdca2d0700a126b10ddcedd8e7b1",
        "transformers/models/fnet/configuration_fnet.py": "bc6c37fdfa89c8e39b100308b1c6e918464091740cc5731db8c828578b8b2113",
        "transformers/models/fnet/convert_fnet_original_flax_checkpoint_to_pytorch.py": "b36849671c599e58d8f9a404e52e424fab4bdb261bc07dbc2b108c2abcf31cc6",
        "transformers/models/fnet/modeling_fnet.py": "0e8f302d3e673da8dbf72f7de8faf496331127ce32ec733b0271bae086c59914",
        "transformers/models/fnet/tokenization_fnet.py": "3fee29cff49b93e64d392e8f9bd8fc17f9f0997e4eeb22fa2c2e8bc11e68c9d6",
        "transformers/models/fnet/tokenization_fnet_fast.py": "08f4f6c8f24b05fdaba29620702d4708ec8ae44c8f9c7a4096092a212793f53e",
        "transformers/models/focalnet/__init__.py": "8aafe50de9a0452b6db24b8f599f329c7ee1623d1102c56c816d6812aae948a8",
        "transformers/models/focalnet/configuration_focalnet.py": "c44b0ee996927d2a1cf40044bb0c083dbbd397591be148d435c32f63fe78271b",
        "transformers/models/focalnet/convert_focalnet_to_hf_format.py": "c41a28a7b2b8ba77cf6b009b9a5bfb053407a5b26469459ab2bc2cc3c756fca2",
        "transformers/models/focalnet/modeling_focalnet.py": "56264e7a7304bb2837a1acd2f4164920bbee94601bf5548a7a3141c6f3c29691",
        "transformers/models/fsmt/__init__.py": "a606e1a0750b370793b7bd9e8e5e7bfcce69e5d3c59fe1f2d2b981aeddfdcb1c",
        "transformers/models/fsmt/configuration_fsmt.py": "730c247976f88aaa95531415053321ff370ede7072e132fe040fe7a9de867e6c",
        "transformers/models/fsmt/convert_fsmt_original_pytorch_checkpoint_to_pytorch.py": "056b67f745d002e586a7c93dce7b394adf4e9ffa2cdfde4448d824697cbacb68",
        "transformers/models/fsmt/modeling_fsmt.py": "3bb261b8a3bdca40a1bff118c33f8417fa916eeb619156e62cb3bf39b1921eb7",
        "transformers/models/fsmt/tokenization_fsmt.py": "6dd93016097d914968a1b0a69e95e940de9bb14987e71945b7b25edc061e4571",
        "transformers/models/funnel/__init__.py": "35ef0ae8116db90f68e3185977a526f04aeccc6c73726429d52dbccb11b5d39c",
        "transformers/models/funnel/configuration_funnel.py": "9c754f1b9da5b851d7331e5359bd2321628532f878fd651d58912f1f47dca3a8",
        "transformers/models/funnel/convert_funnel_original_tf_checkpoint_to_pytorch.py": "778f98bf9f6b29a22b5c8c97a56e12dcb20ffe71233efa6d3b88b3362b9014a1",
        "transformers/models/funnel/modeling_funnel.py": "cf5acc34d3142fcfc480c2853714f38d185040e5421dba517ba10ecbcb83b3d6",
        "transformers/models/funnel/modeling_tf_funnel.py": "076c3357576e7cafcfb4161a5424d256636d3e0e25eacdfe520f76c9183a50ca",
        "transformers/models/funnel/tokenization_funnel.py": "15eaedd12c9aaedec7b0dc091aa697739110ab6adb6291f33bcaa7c4c9813d45",
        "transformers/models/funnel/tokenization_funnel_fast.py": "ea8acab33edf1998dc816e4b257a3c43008be3e71e6954b416b826aa76a236f1",
        "transformers/models/fuyu/__init__.py": "5bac783a319cd47d8a915aa4a0b754762cd98d461649a5c632aa01ce5c3fa9b8",
        "transformers/models/fuyu/configuration_fuyu.py": "b490ad4d5d625a5eac1af2dcdee7c38032aad9dfdb4841e58931a110bb852cf2",
        "transformers/models/fuyu/convert_fuyu_model_weights_to_hf.py": "73c038aa2518e3b31f3de106e75f2aa1fc45773badd267b712d14d8b3107bfa4",
        "transformers/models/fuyu/image_processing_fuyu.py": "ca21fe0149775817583e6acd1dabdf5f01ca854cf51a32d4e9d1d81762e45dce",
        "transformers/models/fuyu/modeling_fuyu.py": "a250d8874735f5561bb496478f5f00157780260415d10163bcfb0fe5f3a22626",
        "transformers/models/fuyu/processing_fuyu.py": "b8c367d8b4337fcd296ef5ae79fc1a9d74d6173deb37a534e0fae588ba906433",
        "transformers/models/gemma/__init__.py": "93d7783bfe1dddd8082e3b2734fc2b0b3da59a0af27d7cc126f90d58806a46b0",
        "transformers/models/gemma/configuration_gemma.py": "7609b40407b75f53c27ee5a5c36389b12c61b53a80c20ecd258f66e3dfc70523",
        "transformers/models/gemma/convert_gemma_weights_to_hf.py": "502a3225de305582a58a428c2b4fbd1911406be0a6dceb4bb7ba122635ceb8f0",
        "transformers/models/gemma/modeling_flax_gemma.py": "62704fc3a32c0ef36df505e93d68655d124c67a94e57e1d76b1fed237be9ab02",
        "transformers/models/gemma/modeling_gemma.py": "8280c4c13a96c5813432140d73ebf5e0731938b7718a332ba92e67dd6af80216",
        "transformers/models/gemma/modular_gemma.py": "1f75260245fea740c956f76e92d22e2ae496d7d35648439b154c4d1fc4592b5b",
        "transformers/models/gemma/tokenization_gemma.py": "f47617ca3ba0f4da0b250d1a6e2db81f373e4eab737aa8203164c51c6910f77f",
        "transformers/models/gemma/tokenization_gemma_fast.py": "6d3222e3a13f3d70e64700fc8501b4008e874658fed3763b8ad58503ab5c9501",
        "transformers/models/gemma2/__init__.py": "dfb2b04af8b0a223e6c70c978812ebf61450015a421ce76cd1c441b11f0ceede",
        "transformers/models/gemma2/configuration_gemma2.py": "af7beca93d2f73bd06e5ca3e51adacb605e11a57667dde8df481c47d2c04dd51",
        "transformers/models/gemma2/convert_gemma2_weights_to_hf.py": "0e9e06017ff3679182b3c6cb5a652e73b3dbc38a4d39421f14a399dca3188bc0",
        "transformers/models/gemma2/modeling_gemma2.py": "bf533cb3256578b92be0fa5a772360bacbb8d1e91e8083ec0d427a7a76c58555",
        "transformers/models/gemma2/modular_gemma2.py": "1a6fa585b9d9146421c6a27a23c292ac5ac53cbf37cf031a166e564fea147d24",
        "transformers/models/git/__init__.py": "d92d7c2f00e0c5791177892ccdb90055b105a9f9c614886201140e39545da063",
        "transformers/models/git/configuration_git.py": "e8e81596212927156f5681bbb72f87792797ff14bb4b7745b0bd2c5f9fd8fe53",
        "transformers/models/git/convert_git_to_pytorch.py": "579329f81cf2e3d0c39142cc58414115462ff5704ae29ec34840ebb27a8377d3",
        "transformers/models/git/modeling_git.py": "c39c819a3b039f51c290ed7b28a0f957ee02d5d59a87c693991bb42ccb735d53",
        "transformers/models/git/processing_git.py": "4664afd5ab97bc1802ae71539f91164344d48b00702835229f642734c72cc3c0",
        "transformers/models/glm/__init__.py": "7c869fc3a1407e56db786fe710cfd53c9c8c2479eefcd6d61d31e3102200bc8b",
        "transformers/models/glm/configuration_glm.py": "a029fa6aacfae65846c017f3271adb948bddfae6d471dddf0e8346383c88dccc",
        "transformers/models/glm/convert_glm_weights_to_hf.py": "5ff27e57f775fe4028ca7cd9701ca713d2a2963d4364b692e4dfbe5cab3a891b",
        "transformers/models/glm/modeling_glm.py": "8f7c32354ae9cfdc65aa60b54c6856835fa62d5b18e0bcba3f47b64e9f16edb6",
        "transformers/models/glm/modular_glm.py": "b0ce384e11d35c2ab24e30d9cb83c672e6ddd7c3d67dbac2336c58760b0cfd65",
        "transformers/models/glpn/__init__.py": "d6e5ffa40a95d501ce8b47742f8dbc52ea4c01c14163a39648313a557ba0c4e1",
        "transformers/models/glpn/configuration_glpn.py": "7f220f5375c8de2a75f0c4f2a216bda5b1aab3872a7d1bf564eee6ced8f74e72",
        "transformers/models/glpn/convert_glpn_to_pytorch.py": "8befe025fab3edeb618f32e9133f36ada8e4852be95d42e5238e378c575ccec3",
        "transformers/models/glpn/feature_extraction_glpn.py": "4b6eb72c5787551ca6fe32adf0a9133a38ed035fc1a804675206d2144c603cde",
        "transformers/models/glpn/image_processing_glpn.py": "274a27382e39470c12a76e9db8fee072ed25c14e54adf0729cb37c26bb0b7757",
        "transformers/models/glpn/modeling_glpn.py": "bebf1aed977d3199a53d16de58b6fa0c78c861cad561951f7954064ded540a35",
        "transformers/models/gpt2/__init__.py": "1befa975d2fdbb7af675de6456593fc3d5b91c2b61854b76c389d0c92ea47a37",
        "transformers/models/gpt2/configuration_gpt2.py": "3689eab68d1e20b31caff38976f9f7b12484791321d84a4ff7bd791b205cad01",
        "transformers/models/gpt2/convert_gpt2_original_tf_checkpoint_to_pytorch.py": "dea942f918023fdc7753e997425503ece105deae3e6fe105de78deaa9ed7fb03",
        "transformers/models/gpt2/modeling_flax_gpt2.py": "eaf01e2f54b01e5614c53c0799f1d71182eebd32682d1ab9ce5fc6c149b93e21",
        "transformers/models/gpt2/modeling_gpt2.py": "cfdc7f878b98873daaf442b1aba6b46dec38b8e78099998b60ecd723e269618d",
        "transformers/models/gpt2/modeling_tf_gpt2.py": "7cc149e4e507e19423a7d5e15db35e0eff95606267a7b4e41c18fbca25a644ac",
        "transformers/models/gpt2/tokenization_gpt2.py": "e7e13dec555c9315d894fbb31b084c6ef23c551a208cd6e856ec6413be8fe83d",
        "transformers/models/gpt2/tokenization_gpt2_fast.py": "17a2e4ca1bef6bd11000d03daddaba5687e3064fe38f369a18554319ff8d2d4b",
        "transformers/models/gpt2/tokenization_gpt2_tf.py": "3ed834d5fd5b5747c0bc8d492babfe144e2554a50f2225ebc713eb7fc33b9205",
        "transformers/models/gpt_bigcode/__init__.py": "97208a35404fa0d2afa08fc9ed0e8177093cd48bbc6a2b84244a6839740937d9",
        "transformers/models/gpt_bigcode/configuration_gpt_bigcode.py": "f4d6c37e07abfc998d6d52e0cefed108c423e49859403ef994454f618553d153",
        "transformers/models/gpt_bigcode/modeling_gpt_bigcode.py": "6055941040611556bae08fad90c1dd85c212240b221a35855de2a4ab5bba900d",
        "transformers/models/gpt_neo/__init__.py": "06b8125c3a113721fc449cec7075cb06f58f0797d37b91261162fef1ad99371b",
        "transformers/models/gpt_neo/configuration_gpt_neo.py": "d0b9ba61ed86f8d3f970f91a2a957cb3d4dae05bb182295643c59e05b0274fc7",
        "transformers/models/gpt_neo/convert_gpt_neo_mesh_tf_to_pytorch.py": "a9eae9dd4a8a86db3ca5f1ed34d049df4629c97fd0b237dcdf7b9b45a6eb4645",
        "transformers/models/gpt_neo/modeling_flax_gpt_neo.py": "c60c04e548b115a9fdc036fd49c39df037041fea3522ef805f56cd90c5901440",
        "transformers/models/gpt_neo/modeling_gpt_neo.py": "7b5ceae7b0ff3781102fbec12c89a2d4e6f51bfd6b38d05642637862484b357f",
        "transformers/models/gpt_neox/__init__.py": "b282d851795ab9c5080f0c6c18041ce7173b5cdef4dada66de62c78381603770",
        "transformers/models/gpt_neox/configuration_gpt_neox.py": "d567d3dc7694c6eba110b4d0c90c25c61b9430d4d830c526c122770607b91658",
        "transformers/models/gpt_neox/modeling_gpt_neox.py": "0a90fe6a9f4e870679ee5469221596d25b7dd41d7de535a5cec9abaaa966fdf1",
        "transformers/models/gpt_neox/tokenization_gpt_neox_fast.py": "0bce25eb8f0d9191db97b48fc82c42388d9a923322d03fe1fb53d0c4e021adfd",
        "transformers/models/gpt_neox_japanese/__init__.py": "e892f5975d8c1aa05cde659dc1790500e8c1c099ef2383dacbcb4a02fb6f1f1a",
        "transformers/models/gpt_neox_japanese/configuration_gpt_neox_japanese.py": "c907b977380f0f2bd8ae41d09872eaf8b045d741e0f6a90c3f16f95c708a7b8e",
        "transformers/models/gpt_neox_japanese/modeling_gpt_neox_japanese.py": "01c6cc5b90847e16b62cb9c819fe01cee6da588ee6181e15cd4c3d268dde2f79",
        "transformers/models/gpt_neox_japanese/tokenization_gpt_neox_japanese.py": "fb60e88092ec8202b0d743a55240da594fb4b76a658d3c68948323abe50f3c99",
        "transformers/models/gpt_sw3/__init__.py": "a898fbbc5f044b7ec1c2c29b244d73576acf51d98cdefc7c99c90816e5ab2525",
        "transformers/models/gpt_sw3/convert_megatron_to_pytorch.py": "08104343429bf78a35546889d976dd678beb3e2164c276804905f1946556c117",
        "transformers/models/gpt_sw3/tokenization_gpt_sw3.py": "3a2442ddd83d563cee3df90d8d6b876ef9344f6cd3efde312b8334e22f5db335",
        "transformers/models/gptj/__init__.py": "c77f66e72d618a4af278846b190b7d7bd7b1b23669d85425c90c66276cba85a5",
        "transformers/models/gptj/configuration_gptj.py": "e541e84650c5cbb68f9d539b336035b71a095e622cc14fe1f5701f7e4c51a509",
        "transformers/models/gptj/modeling_flax_gptj.py": "55a613af1428b2a908a8771b29c0c58a74ffcf76a87f07492dab1602ac634653",
        "transformers/models/gptj/modeling_gptj.py": "84b8e3cb06d68a22f0b571633110774268c4d5d15495f269858061dbf684917a",
        "transformers/models/gptj/modeling_tf_gptj.py": "a85d3f3066b6d75effc15b658bfbae219a81e86208105915536b71a705549c74",
        "transformers/models/granite/__init__.py": "1890ebf6494f4997315db5e301dc0a30cf2707de9502fc551883f637f15e4c94",
        "transformers/models/granite/configuration_granite.py": "20151bcfc6009410d4131670382dc85ac2c3b2e463a18842cc09a9164e0fb1b4",
        "transformers/models/granite/modeling_granite.py": "3559e59f87b75b0970f9de924f8aa81984615de550e517ebb284cb23b0a5cc79",
        "transformers/models/granitemoe/__init__.py": "fa5c8666e13d56715cf5297f8ba538e6dec8ec41595d4d87fe0f0817ede701d9",
        "transformers/models/granitemoe/configuration_granitemoe.py": "551ea9673595684d8ddf744b860ec957e74151d5e49b3bbf340c5c7e2f5775c1",
        "transformers/models/granitemoe/modeling_granitemoe.py": "db878cb98edffa7aee02cfa350d5dbe9d621b944a2bf48f3be7d1ac9d02e8755",
        "transformers/models/grounding_dino/__init__.py": "2056bfe4b4cc3185d5023358c479e349aa8c7330a0e1238dca57056a9dbbda72",
        "transformers/models/grounding_dino/configuration_grounding_dino.py": "154eeb15b4a3b7ae3773fff1439d25839fc778a33963148828a7e5f84ba52118",
        "transformers/models/grounding_dino/convert_grounding_dino_to_hf.py": "5374f6f858ed62ff6e9cadfafe2035ec87f0c3b9165985a93db542eaeebeba74",
        "transformers/models/grounding_dino/image_processing_grounding_dino.py": "341dade3934df950a899e3f1d4ebd951fd32175c1245301eedc6fbb51f628378",
        "transformers/models/grounding_dino/modeling_grounding_dino.py": "ad48714a4c7fb91ba1782e511250b4ca84241aaa0b7dbe730e61b97a32619842",
        "transformers/models/grounding_dino/processing_grounding_dino.py": "973161ee60aa7fb4c3cd257673f45de10607fff266897faef557c7d36883a304",
        "transformers/models/groupvit/__init__.py": "0dc7fe431716629da0571a0baca3ddbf31d464f8be5d1d42be78b48bd754d860",
        "transformers/models/groupvit/configuration_groupvit.py": "de4df1c72d186a040798e81c3609da06c1dbede3abe542515f0e3ab199a12b13",
        "transformers/models/groupvit/convert_groupvit_nvlab_to_hf.py": "f6043191c8d53423f996f579e126db4ac3a390a0873917288b0ab681c7336023",
        "transformers/models/groupvit/modeling_groupvit.py": "0213e2c371d14732fd213b3cefe1c42848d8af94c515c1f93bf5065b2bfb4586",
        "transformers/models/groupvit/modeling_tf_groupvit.py": "32fe1bd4e874a74b166d6d2e7802f62e2869108694d6c5fffa35a8a09f230d77",
        "transformers/models/herbert/__init__.py": "4a9f60408aa55216476aeb2e68bd8c1580ea256e2fbec5462db56bc91fa4365d",
        "transformers/models/herbert/tokenization_herbert.py": "8e937fdd2bfe9880fcbb5474776b6c0ed3963bf935603ce142b783a612f96e55",
        "transformers/models/herbert/tokenization_herbert_fast.py": "4084dc27270c350b9422e98bfda9f598dcf9e5f2400e45bd4ba8dd0663bdf4a3",
        "transformers/models/hiera/__init__.py": "e6ba089d7c9c596c61af3feb00b2bf4a1efe21cf60c942995f7007eefb7e0052",
        "transformers/models/hiera/configuration_hiera.py": "20870e254048ee861eb2bafce85d5a0f7e43f5f1fb5cb85c42d625d7945fec13",
        "transformers/models/hiera/convert_hiera_to_hf.py": "985b3008591aaaaff4b092453866767901009c5e188a398525ec6b63a5bd1b77",
        "transformers/models/hiera/modeling_hiera.py": "509573e36c9fe2c4855f27319d03aefd2c4f7edfd9728c249fc7689d1832745c",
        "transformers/models/hubert/__init__.py": "e80fae2aaaa3726848601a5c2e19d88c09921b35931b337aeec729379a7daee9",
        "transformers/models/hubert/configuration_hubert.py": "ab6676dd3017752f86990abff913ed3bc599a0c5137a45ef07acfd828559fbd7",
        "transformers/models/hubert/convert_distilhubert_original_s3prl_checkpoint_to_pytorch.py": "e04384fc4e012086d57ac3e63422f86d53b903dd70c4ca4085f01d38ca530f38",
        "transformers/models/hubert/convert_hubert_original_pytorch_checkpoint_to_pytorch.py": "d2ebbe946e50a282281741826780ebd206938e8ea2751a9d955667b4c87cd3e1",
        "transformers/models/hubert/convert_hubert_original_s3prl_checkpoint_to_pytorch.py": "42ec2f86c572a9c01708f40dfa97b219cfb50ba1a393a77e85ae0ab794d8177c",
        "transformers/models/hubert/modeling_hubert.py": "e13c26081f049ed95751f7ca87c5a6a00ec8d9ae9f6ef88ae2ccd73550053497",
        "transformers/models/hubert/modeling_tf_hubert.py": "30521bf14a6c7deb957ad60a4dfbbae9d34803b789accfb540677fb0e8dcc3ab",
        "transformers/models/ibert/__init__.py": "57add2d3d7d5bd55428d8e2532f54bf2d1e55ba2a3aceb720ad8518ec2f17a12",
        "transformers/models/ibert/configuration_ibert.py": "7c57f4b477172b709ba7a05839cf7ab25befc523df2a7ecf691ad8a1d1be8502",
        "transformers/models/ibert/modeling_ibert.py": "77373147ee41a81475fb85b3b8edf31db51d814947b01e653f4af0ef02756e4e",
        "transformers/models/ibert/quant_modules.py": "22d53be82231d1771908f391db5773f7d27d939acad9fcdf7d0cf48c90ae3663",
        "transformers/models/idefics/__init__.py": "5ebe3773aa2d4e6921f079521444d915a10edb539c8e4c3f85cdc9665c382a78",
        "transformers/models/idefics/configuration_idefics.py": "205e8056d60637142a020b928b6a9358c47d908b7ce7edc4b8bd6b704ba3b481",
        "transformers/models/idefics/image_processing_idefics.py": "d3f7e3d4a7fc58dc96a2149eb822091cfea375d1da09fcdbd8b2251316ce8ef5",
        "transformers/models/idefics/modeling_idefics.py": "dd783589e111eff1ec1bdc157b371664fd2f3840bf4252d57476f1b29db0f6d4",
        "transformers/models/idefics/modeling_tf_idefics.py": "8d067186a4ed1177f09fcc993e21c832acf3f50964726ac0497b482bf8edb7fc",
        "transformers/models/idefics/perceiver.py": "b86bfc147db067e34ed4421a15c948d6793052a69303b8b43d2f57c58ee2be7d",
        "transformers/models/idefics/perceiver_tf.py": "ad8a97bfd8fa6e6af837264b015d4c855322888315ed167d09a7f26cfb5873d2",
        "transformers/models/idefics/processing_idefics.py": "a806b6494a33e990ea22141580d7ed94fbafa65fb59522bcc09f8ac5c2e68409",
        "transformers/models/idefics/vision.py": "11543994eb5d574d202bfdd302e2c8e3351e1dbc38cd5d5175935766a5175e24",
        "transformers/models/idefics/vision_tf.py": "29ffcf7a7458d6f865040eb63ef8ddbd40f24132888b7d17a81fdb30137532bc",
        "transformers/models/idefics2/__init__.py": "a901e64931255b8fade6541597324950efa6f52af64567ec453a7a57461ec009",
        "transformers/models/idefics2/configuration_idefics2.py": "adb5090b2029993cf290ed8aada7a4c2f24c4bd74b4773eddf6c5cc181c2981e",
        "transformers/models/idefics2/convert_idefics2_weights_to_hf.py": "de777f575a8d4efec37a165940b2c078a874d3ceb1be310236e581bc99856cd3",
        "transformers/models/idefics2/image_processing_idefics2.py": "44026978c37788d68be1826d57fe804d5625bdae61fe954547f6d18072f73166",
        "transformers/models/idefics2/modeling_idefics2.py": "aadd27a451c1e0cd6244841db40c840a605687568fe2ce6bf62ab6e307268277",
        "transformers/models/idefics2/processing_idefics2.py": "fc35d51f15a08136bae8a941ea7b3415dcb2ff925ed16c3acadf535719458570",
        "transformers/models/idefics3/__init__.py": "4ec4673b204528098f13a899157272b80c7bad36cc366d80fb9d383f8c6ae73f",
        "transformers/models/idefics3/configuration_idefics3.py": "7f28a1d91826f3ff1af6b1f772b1a434a8097b68aa57cb10d10970f1242b7c2f",
        "transformers/models/idefics3/convert_idefics3_weights_to_hf.py": "c7e55eda20dfe132fd8d772998128904c3c3560aab7cc11c32b708169fd15830",
        "transformers/models/idefics3/image_processing_idefics3.py": "ad0068b07cff75ce2ab122e7b791f5867fb16e3d2df91fdf89c9d8d47e2f969a",
        "transformers/models/idefics3/modeling_idefics3.py": "5ebfd9c10dc360a334edd2e1a988fd9a4b464432e389990d6f15e6aaca4ebdfb",
        "transformers/models/idefics3/processing_idefics3.py": "b38118587e3bcb80610aff899b0cd008c20c69a54d53b4f4c7eef9a70067da5b",
        "transformers/models/imagegpt/__init__.py": "41d15aece92f0031283c4957e4caa3b915f5c332a61a93ddb07a7e13a1a7dcbc",
        "transformers/models/imagegpt/configuration_imagegpt.py": "7806bdb5189eab4d88baa2cedcedae1acb6d914fe17575417faa06dad900e7a0",
        "transformers/models/imagegpt/convert_imagegpt_original_tf2_to_pytorch.py": "04ca8a3469f526fe2b9ed3fd7c6e42d321bf945d4c63fd21f72bf442de2b8e93",
        "transformers/models/imagegpt/feature_extraction_imagegpt.py": "882a50e2d537566978e0a80ee3791826fbfe45c655c5ef2d73bf78831524b6e5",
        "transformers/models/imagegpt/image_processing_imagegpt.py": "6a999317973b00f8942e18c14c2521414eb257abc569953117bb0a14ee3cd847",
        "transformers/models/imagegpt/modeling_imagegpt.py": "363d2effadf9ebac649d3a314d24c1f98f99cda74ade03e1acb1d789554997ba",
        "transformers/models/informer/__init__.py": "bfc350244b4a6eb5565d065aeeeac0ffca83595a064a7e5b24d8483d83b160d4",
        "transformers/models/informer/configuration_informer.py": "c9622a4e50b25f441c41136eaa4b6c7e84abd841ecb3d7dee157fac8cef33af8",
        "transformers/models/informer/modeling_informer.py": "dd7e083d5ace2688403ec862b12482ba48cf42bc984888dbd9289cd4a57ea5a2",
        "transformers/models/instructblip/__init__.py": "1e3bc01ddae598715f05ef9b1cffd438e81e80c73806c1cbc3948dbbc8452ed4",
        "transformers/models/instructblip/configuration_instructblip.py": "0fcfef984118c676e8e8b0ae964c4cfd4ff0212f312e6b69e492575d570851ba",
        "transformers/models/instructblip/convert_instructblip_original_to_pytorch.py": "8aeb2da41b231c7ce34336c084f26f848ed90525c20e86bd9e3b4af66fe09bf2",
        "transformers/models/instructblip/modeling_instructblip.py": "a746048b34f3136d8a20a657849bc0bc7fbd86224780aacbc961e32109d86e06",
        "transformers/models/instructblip/processing_instructblip.py": "a81b96c73f96598710aadbf4d08b42c4b46f0807ee22ae8644a4ba73356523ad",
        "transformers/models/instructblipvideo/__init__.py": "b1338facf6aaf1ffa282fc70e4177d4eef7f6cf3030e0d9f98793db238cba70d",
        "transformers/models/instructblipvideo/configuration_instructblipvideo.py": "fbf229acb32714f37117f70886b8b886f4e06a0a30b9b19fbd9bda4a3a2be9a2",
        "transformers/models/instructblipvideo/convert_instructblipvideo_original_to_pytorch.py": "17af4768b885631ec4ca77aa0232c6eeae6388f132d1b31317c435a85da1edde",
        "transformers/models/instructblipvideo/image_processing_instructblipvideo.py": "16d5da9f4c7977d7c0647b9aac0f12390bd42f3bd3e33ae1554b8b81c7d4ea02",
        "transformers/models/instructblipvideo/modeling_instructblipvideo.py": "1a4a3d3ae75c65a4d034b0cd4645356751d4c46c38b0fc36d14d5d199d9a8a17",
        "transformers/models/instructblipvideo/modular_instructblipvideo.py": "d4b86fea7771a7366c743fb718982ca2c3b6ec20c2d8cfc3ed583cbba2240761",
        "transformers/models/instructblipvideo/processing_instructblipvideo.py": "6cbb1e57c635c9fd2911162235a23ea71885e41d080c53f8dedb86df39e63986",
        "transformers/models/jamba/__init__.py": "683d6c382334463936237661fdf121df17a8b7d115604dd7de72a2f2b3fe2b22",
        "transformers/models/jamba/configuration_jamba.py": "804ba2839175aa3e240f9915d93bdef90dde73da3c1e6f65d2821870eaa539a5",
        "transformers/models/jamba/modeling_jamba.py": "c3405d44f5eb14c31ebf04003711247ff2a8c5df63d573474dc797442aea31ce",
        "transformers/models/jetmoe/__init__.py": "3d0fea001923f4a5cbe402e35a81ee61271c70a0effdad397043f468dfaf10cd",
        "transformers/models/jetmoe/configuration_jetmoe.py": "c48a95c78bcedb9cd09016f987bec1491bf01b68f1d284f00ef10a788684522c",
        "transformers/models/jetmoe/modeling_jetmoe.py": "df6fe787c05b3b9b0698c910e813a1ab7d948c41265ba0cc63b740f6e9a42fc2",
        "transformers/models/kosmos2/__init__.py": "97e7ccfbec3298cad5bad5c5bf8579c45ec22a62e488615c7000cdf5b85cb0b5",
        "transformers/models/kosmos2/configuration_kosmos2.py": "01ccce520c8d45d1af5329a9a8940ae06c8126369cfb8c5953c07e903f4bcae2",
        "transformers/models/kosmos2/convert_kosmos2_original_pytorch_checkpoint_to_pytorch.py": "dde8efea151dea2af3167992b85548e84bb53555a6b497f7fea97687d3f80079",
        "transformers/models/kosmos2/modeling_kosmos2.py": "477dada98136ede7903c70428cb01b3e5fded868f37fccf004943beb3b7fd67e",
        "transformers/models/kosmos2/processing_kosmos2.py": "b0dda69776f5b3e29fa9240f0facd4344993b782038498170352cd6e5598ce63",
        "transformers/models/layoutlm/__init__.py": "4e83530c916dc7c1a252e7ef8d53b00462c156ccdbb6e3f0411570d06c99cfba",
        "transformers/models/layoutlm/configuration_layoutlm.py": "2e4f85f8937b1b87065a5e0b3a3103f3ee6a6aec449aabd0a8db4babf917b27e",
        "transformers/models/layoutlm/modeling_layoutlm.py": "278a43390b43b2543a6fac3ab73e60c501780d478a5d6beca8402bb8f3cf743e",
        "transformers/models/layoutlm/modeling_tf_layoutlm.py": "b24be8b0acbf88b1ed17341fe7e34adce35266cdc2f13249db1a55c55d9cca22",
        "transformers/models/layoutlm/tokenization_layoutlm.py": "f819677e15dacd92ce6840a63c57af8867ede2052a6cdb6a90227bcaf2e870cd",
        "transformers/models/layoutlm/tokenization_layoutlm_fast.py": "7947e17cd770c813fa62f574266f5456c1cffba3c057315abe0782398a9d8136",
        "transformers/models/layoutlmv2/__init__.py": "1db7c562d73b378edbb52ab3ea61c123cced94752d885da0dcbe404781020159",
        "transformers/models/layoutlmv2/configuration_layoutlmv2.py": "d1a20609abc4a73d2bf6d19270be28717d856d9e53ecd42a606ae34484c0fe3b",
        "transformers/models/layoutlmv2/feature_extraction_layoutlmv2.py": "33d6c30a92812c8e696b1a2be22a1ad898c40e1487f4da7e3d36e01e1d95f4a2",
        "transformers/models/layoutlmv2/image_processing_layoutlmv2.py": "bad0f9f44b2de09bf2651f3a0b7af05b888a7d6c6b3b051c2ebaa9d21aee6766",
        "transformers/models/layoutlmv2/modeling_layoutlmv2.py": "6c812797c6749a93477769bad754a19eed2e1753ec752f3bac16f42ed2f3fb48",
        "transformers/models/layoutlmv2/processing_layoutlmv2.py": "c72841abda5862635839f2b6735de003e7f5716ceed5fa7490ee850bb27d0df2",
        "transformers/models/layoutlmv2/tokenization_layoutlmv2.py": "3ede136eca9f2d0efa528c555c1376a8279eea66fa1a63b0f1a2a2925cecf8fd",
        "transformers/models/layoutlmv2/tokenization_layoutlmv2_fast.py": "bdc305afe43c55f3a48f10da7d1a0a1b2e1ed1b06a29d3d78a6e0668f5ade2fa",
        "transformers/models/layoutlmv3/__init__.py": "ecb5d565d49d84bb21923c1f5e2d1c361b20ae116c7a7c0de380cbcd6654ab74",
        "transformers/models/layoutlmv3/configuration_layoutlmv3.py": "9cc892a7b3b46c29aee9d29d66c77621322c69ff2714645330939971737ef89f",
        "transformers/models/layoutlmv3/feature_extraction_layoutlmv3.py": "8d6b26b22da6ca6d2679e9359475aa7eac65260309758ddc81f43fe004846eda",
        "transformers/models/layoutlmv3/image_processing_layoutlmv3.py": "faa7816c676024db7ee6a2ad5c72ce48563313cd9bb875417b4dccbd0d5db61f",
        "transformers/models/layoutlmv3/modeling_layoutlmv3.py": "36383b3f3b2d29b2f26e99fb7984e0374a64a15455a7f42e23cadc973a4c139a",
        "transformers/models/layoutlmv3/modeling_tf_layoutlmv3.py": "4b5cff33155840cba3fc8c537f4ff8e5f2286274c40e16d768fee0c773a7098b",
        "transformers/models/layoutlmv3/processing_layoutlmv3.py": "4a1b6f0666631876e9add075e2fd90b088158abfbbe201274c61f3bcbdf5bc22",
        "transformers/models/layoutlmv3/tokenization_layoutlmv3.py": "e923eef18c6f755283aee2afa66b5468014ab2cc02a65043ec1eacb4dfd22404",
        "transformers/models/layoutlmv3/tokenization_layoutlmv3_fast.py": "d0717cf4e371f539ca15c95f09da0e0d83f9f84d26c80a8d82bca9e936d30658",
        "transformers/models/layoutxlm/__init__.py": "008be3ceea913c55c5b965f19ce969f690576884f9673c7b7f0b60d8a2951130",
        "transformers/models/layoutxlm/processing_layoutxlm.py": "0421746f9ea84ee95a6e1cf8e59f305d69791175516de23eca9a04e3d3d8cfb9",
        "transformers/models/layoutxlm/tokenization_layoutxlm.py": "4190dffcc8a0232223509619d0e10170823aeaa00edb45173b4496f912107ae2",
        "transformers/models/layoutxlm/tokenization_layoutxlm_fast.py": "9501490728a427c83b7b42854216548aa8f8b289ba843183466083c3ebff7f87",
        "transformers/models/led/__init__.py": "e81f7a88655ab91697794fb8ac43b141574570d1e84ca9b466a93f0634f30e5d",
        "transformers/models/led/configuration_led.py": "fd826c34e55e46d2894807df6e2b63a215fa65d2e25e2ac12d1999393d972833",
        "transformers/models/led/modeling_led.py": "db724f958dcf56489e0d7c5c469b7a58e73cbc0d441c586d656cd8cffeba0b9a",
        "transformers/models/led/modeling_tf_led.py": "3198cc4867342bba9ed436ad55fc33a71ca7531cf05b790dbdc59556ce7252f0",
        "transformers/models/led/tokenization_led.py": "13e6bee9c15ace25bed840bfc4f4c30fd6cc71e179e96f8b58df0d0d97911efe",
        "transformers/models/led/tokenization_led_fast.py": "cb6813e3c973c13789d3d03d365636de7bee2462a35f79ceddffb75826f7d5ec",
        "transformers/models/levit/__init__.py": "2cd214127fc6384650a34b0fe0764532edacd994676d72dfabc43645eaa176df",
        "transformers/models/levit/configuration_levit.py": "1279a39a9ccf276d9b3db2aa235906bed93f47b95513baf1cfeaf5e764f196ae",
        "transformers/models/levit/convert_levit_timm_to_pytorch.py": "4cdf3b334dc2415e0b45bd231f4482353b5fa19f2b18fbdb2e0ca4102d7890b1",
        "transformers/models/levit/feature_extraction_levit.py": "9764476eb6e0f4ccd1a8aaff12b3a8fc0ba24aff771a3f8eabac34bf6a7e233c",
        "transformers/models/levit/image_processing_levit.py": "0a3b38af9b0c05f185f6e9fde527bf248966bd3ff2474f28871cbe4b26d113f3",
        "transformers/models/levit/modeling_levit.py": "800c92e5fc41d8c5b500fc4815b7e6138da42920e92eca47055354727c12843b",
        "transformers/models/lilt/__init__.py": "a86149c4539b6876fe8f16f47f0cf418135ccdb09494ee24421d6eda1b945be4",
        "transformers/models/lilt/configuration_lilt.py": "042887b69151e8d984389c59f30588beacc3f5713ebf06a20ee735e90c3882e4",
        "transformers/models/lilt/modeling_lilt.py": "ce29c0d463357eef70608b31bc88aeef6e387cded57d0fd4ca90a09a7a7869eb",
        "transformers/models/llama/__init__.py": "0d8b747ca00b644ed0ea5e475213a9d05456c6d8d4f0318d0c80c81e6618f822",
        "transformers/models/llama/configuration_llama.py": "de225c7f7e3c52d2d848805c777beae79cb6164f50484a83894fc6b8b53ea0e9",
        "transformers/models/llama/convert_llama_weights_to_hf.py": "d11a220cda7c675c47f44f5e403f326000d26cfc5285d75312067c84da86b5fd",
        "transformers/models/llama/modeling_flax_llama.py": "295ad8ffd45b8179df8e3cdc04e309dd6923be4191e4253209999c7528cd80ed",
        "transformers/models/llama/modeling_llama.py": "733e7625fec5abcfa416ab9b866cb91875d41007f2e31c3e90d2ae0111ae98f7",
        "transformers/models/llama/tokenization_llama.py": "e77968e24ccfc4e92af9e33221b790477b4d264cb889baebbf3eb4dc7c9356d3",
        "transformers/models/llama/tokenization_llama_fast.py": "52ec7e10a051e5bb9b7f39af2ebca5c7e7f5e138043b458eba5633fc7f34ec1e",
        "transformers/models/llava/__init__.py": "d4a04fcf4f60faa43d55a3667e14bfb18a6ce756af6e5e3630499bb2071a7028",
        "transformers/models/llava/configuration_llava.py": "28e391c5bd57862544e7f08ad0ed75bc021e476532f45a70a18223193f1e8a89",
        "transformers/models/llava/convert_llava_weights_to_hf.py": "e0784d4f8e8edac4745cefd01d05ccf36d614ff854e0e978f39ad096e1bb20d8",
        "transformers/models/llava/modeling_llava.py": "93558ba65040e4aa3ad08ec228acd6cbbac88616efb5af12b1029368df4d5dd5",
        "transformers/models/llava/processing_llava.py": "7f37c41a62129ffbaa7ec99d25eaa2533215d4a84a8ab8df098c471554584210",
        "transformers/models/llava_next/__init__.py": "b756feab7ac225430b4ff57791d3b0f3f91ca6661f5782c59dc2c0cc8b95e7be",
        "transformers/models/llava_next/configuration_llava_next.py": "7c8d3b700dbf41469fd0fd6313e53c693365294dd293a28f22f72ac3aabb3db7",
        "transformers/models/llava_next/convert_llava_next_weights_to_hf.py": "5a90be8ef6384ed9591a95bd30223cd8750871097d969b14653fdc9b37c9a9f5",
        "transformers/models/llava_next/image_processing_llava_next.py": "d5e7d356a79c9e7fae5958c433aaad20f1d12b0a38053f71a061007f1d390ac0",
        "transformers/models/llava_next/modeling_llava_next.py": "b959cfb5aea004a4a40a26fddd1de9ed31ea1555d01512afb3276712d7548bc2",
        "transformers/models/llava_next/processing_llava_next.py": "4324b317a62686af9d1058879c9db2276f5b00c9461a5afd8abb399e58247304",
        "transformers/models/llava_next_video/__init__.py": "931d6605b1895ae8fc9ab1d780288bb922b8b28228547da10c4daa1483689ea8",
        "transformers/models/llava_next_video/configuration_llava_next_video.py": "981bbc6bb53eb7f08c32d28fb9ea8ba5103bff5ea4faa007d7390fe0dded9160",
        "transformers/models/llava_next_video/convert_llava_next_video_weights_to_hf.py": "fb69274e9f751054cc077bcd5cf1a86885bdbb5b3bc805efd57c92986553a49a",
        "transformers/models/llava_next_video/image_processing_llava_next_video.py": "7298a7f0cf2eee79d529d22a8a2acf92da0ed29537d73f6ce7fe49ac10a5427f",
        "transformers/models/llava_next_video/modeling_llava_next_video.py": "b3ee87cb7095502fc880c6d8b0864ba73b74e25bc25334cff47e737ed7a32f5a",
        "transformers/models/llava_next_video/modular_llava_next_video.py": "c121b53c5a0e696c9979eeebc8e2db4e739875958907c990d730e92e2f74ca75",
        "transformers/models/llava_next_video/processing_llava_next_video.py": "b07406b8f28f5946dcb3dd776781f2f9717b1c77152330ed652108b919a131d8",
        "transformers/models/llava_onevision/__init__.py": "f0d689f8e15335a26c5b10a5d6aa4ecd2315e3a9e5b17797dcadbe9c19e7569d",
        "transformers/models/llava_onevision/configuration_llava_onevision.py": "35927e7edf888fb449f9090a5d53d3a59913fbdb3e97b6a29be2d4e419a1211a",
        "transformers/models/llava_onevision/convert_llava_onevision_weights_to_hf.py": "67bb453f50118160d6594bddce7c36a37af42edc0c26833dc9d9b08970558304",
        "transformers/models/llava_onevision/image_processing_llava_onevision.py": "d8d259048f80945d1846eccddf2dd5f07a3978e483845b41272ba5dfafbe0d93",
        "transformers/models/llava_onevision/modeling_llava_onevision.py": "9e7a4a8f12618a9b0a35696cd553b13f081c8a2de4ecf79c821a62cd21b19b16",
        "transformers/models/llava_onevision/processing_llava_onevision.py": "40c41450f3eb28e4c419e162dfdb9863dffb2e5178f54082ade4323d1364ac0d",
        "transformers/models/llava_onevision/video_processing_llava_onevision.py": "347b3ee1287b870833a18eb9003190daf43eb59072fea4b07d83a8adebedd9f8",
        "transformers/models/longformer/__init__.py": "d6508dac1b3776e59bc79d642994c1e1a7cb5d3885d504f12b46b6c17887901e",
        "transformers/models/longformer/configuration_longformer.py": "b3f978f5eea29a73a508f92a72a88930569b925a7e3b4a4694862d71f76cb2a0",
        "transformers/models/longformer/convert_longformer_original_pytorch_lightning_to_pytorch.py": "6edfb4ceca881ac0fc58e362ad32c7c38e198c825ff8dbcc5e52f0220e6ba899",
        "transformers/models/longformer/modeling_longformer.py": "1babd92b28dbf81bbe0545b528abbfcfd4bf08cb72f57024841776771043dece",
        "transformers/models/longformer/modeling_tf_longformer.py": "325655a5009d106e88617d40b4d0c0990a6b5ab556cdf58a2f9c3e2af5c46212",
        "transformers/models/longformer/tokenization_longformer.py": "b7ae2857bffc589303f1bdae46bd521fd39a04f75d65707100ab166c7a460ab9",
        "transformers/models/longformer/tokenization_longformer_fast.py": "3d2ec8f68e563c4c93080362464d161d470e84a0f2739c2857e1818225fd2de7",
        "transformers/models/longt5/__init__.py": "5e8bd1f8a82557ef72dd8419dae3c9994dd35e0702900c1e55202d83a134cd71",
        "transformers/models/longt5/configuration_longt5.py": "542b4cfd0cd2a8fc5cd7faa7a27bbf350d11a60d7fcb5e64ff4b984a425b681c",
        "transformers/models/longt5/convert_longt5x_checkpoint_to_flax.py": "6adb79ad98cfdff9a5211bf589c24edf0c50c6ec05604bc2cf86c5af6b1e5b89",
        "transformers/models/longt5/modeling_flax_longt5.py": "eef84358704622ddafe71f70698ff8815f384f192a16128e9988c1cbc5a28fb7",
        "transformers/models/longt5/modeling_longt5.py": "060857870ec69fc5940c2071b27150f737dae5d96f33df9730063c46f11a6661",
        "transformers/models/luke/__init__.py": "4b76b49c3514c5d34d9bf8691c69ac78c736af6e7ef164e50903ecc826232de0",
        "transformers/models/luke/configuration_luke.py": "0f55213c3b517eb5e76cb4c91466fa89a9938ef15830b11d51f54ad374ae4223",
        "transformers/models/luke/convert_luke_original_pytorch_checkpoint_to_pytorch.py": "a5f9c37c1bc90d1c822c12dd72c6a565a295d35684cf45b5a20d99dfae214c3b",
        "transformers/models/luke/modeling_luke.py": "b5b4ccb89c6ec50a16545a6caeee25acd9772f40ac6bb57f55cc50383c0cf24d",
        "transformers/models/luke/tokenization_luke.py": "c8571806dd03b4e73ccdd2f6dfd91c902f8a82e0eaaf2d0d5c6d3237421f31b4",
        "transformers/models/lxmert/__init__.py": "3d72659a0c81973766c959b63bafa44df705b9435822883b8b66c8979c8da7f9",
        "transformers/models/lxmert/configuration_lxmert.py": "3a2bfef2be9f4ecbd71b6a6718ffb3b3e5e12617cdeb79a3a90353e20069c179",
        "transformers/models/lxmert/convert_lxmert_original_tf_checkpoint_to_pytorch.py": "3ece62368f75623dd72e412e5eb3f62852d28d68582723fed6fb6a332b752ea9",
        "transformers/models/lxmert/modeling_lxmert.py": "60b47d3bcaee4be4757f652522a828127448bc83a06fc3d5cbc9eddbcc48752e",
        "transformers/models/lxmert/modeling_tf_lxmert.py": "5c631a2f08f77c6441af16ed849b0555816b34e3b16cc3eec47a071e66852d17",
        "transformers/models/lxmert/tokenization_lxmert.py": "0589d883b0352af33cf6b016cd9a4774a69153ee1fb3afbae2bb50ff25513284",
        "transformers/models/lxmert/tokenization_lxmert_fast.py": "fa61cc2385822c9a17b7c9d8bc94626f23987c9281c8f5bf6ba9d057f2f5d4f3",
        "transformers/models/m2m_100/__init__.py": "eb8267771e8ccb8cbe058b90b4ca276e283c45cde2142efbef3fbe0e01d7213c",
        "transformers/models/m2m_100/configuration_m2m_100.py": "a31cfd7793d98b045d3abb305dd8c035d76739a690c0a50033d07238ff7a71f1",
        "transformers/models/m2m_100/convert_m2m100_original_checkpoint_to_pytorch.py": "c4d1bc344db4a1d3af7bc675cca3c31c9af912ff23337d0dfa626c26a7ec5ed3",
        "transformers/models/m2m_100/modeling_m2m_100.py": "32f3a82f890651818fe5b5cb638d3f823c07841797dcf3feb3adb7ac5c1f739e",
        "transformers/models/m2m_100/tokenization_m2m_100.py": "09346796cc604e94b7295503147fc3e02e14b201b672e41f89eda51f3bef1ab9",
        "transformers/models/mamba/__init__.py": "c6e7bb5d47a3d065722bbc99acfe7c88c62e2586144ef99302efe901022a9f65",
        "transformers/models/mamba/configuration_mamba.py": "4c491c38144a6712a01106f73d07b5a6a3cacb1de344bb74696d3773e4f3a830",
        "transformers/models/mamba/convert_mamba_ssm_checkpoint_to_pytorch.py": "04ae8cd6d604c0bc2833b344ddf766d01469647f0bbc24c6bddbec79ef6d6990",
        "transformers/models/mamba/modeling_mamba.py": "987c464498682e7edc79a86330e7540033eef539f32b349d4ff07db114b1c9a5",
        "transformers/models/mamba2/__init__.py": "2d656695d8010682289a432603322405d0e4ebf6b039dcb38b7436860df8e3a7",
        "transformers/models/mamba2/configuration_mamba2.py": "2c87a455db521178a910620252a101fd99584b4c0cfcd702d22b41415f548270",
        "transformers/models/mamba2/convert_mamba2_ssm_checkpoint_to_pytorch.py": "3dad86b0aeed3f7375b8f6330efabd037f41a85216360200705910ffd122054b",
        "transformers/models/mamba2/modeling_mamba2.py": "467d6fdf926e8ebc72eba14598db8dff1c490b5e768aed57bdc215fc81d5db37",
        "transformers/models/marian/__init__.py": "13169cecec043e60c0fbfb77eebae16cfdd74f67e42fe3f6af2b0a30a82f3f75",
        "transformers/models/marian/configuration_marian.py": "ba0a2ff8e074a12007085826ac9145f1ea8a124a0ff23e8b1c6f8c4779daa49b",
        "transformers/models/marian/convert_marian_tatoeba_to_pytorch.py": "2972f7d68362e56b8b376e5fc2eacbd6e8c3c08b684189fe1664ce1763d74d43",
        "transformers/models/marian/convert_marian_to_pytorch.py": "ef15912d29c572ac6712b9d61e83a4c218c4be0adeaf5260354e9b843c185ed6",
        "transformers/models/marian/modeling_flax_marian.py": "b0c270a868013074324dff5370564a23b8d745ffa012dfedd0f742d680f358b8",
        "transformers/models/marian/modeling_marian.py": "40c44c2d1e5300bbe4e828c1450a179be502d9f816f507583783f993386a9d05",
        "transformers/models/marian/modeling_tf_marian.py": "bf060bc284be53ede249f5a66a4585dc3a3d613d107e6c7167e873a56f68b174",
        "transformers/models/marian/tokenization_marian.py": "c28ec7cb6b91cc53ff857f380e1a194ef594797b5686a1b9f81c6670502c83fd",
        "transformers/models/markuplm/__init__.py": "70ad3bb0414571a25743ab6cb2de47d7d0105af9ec031df73858fdaac0c0f50a",
        "transformers/models/markuplm/configuration_markuplm.py": "232ea9f4af427f46e0b4d2161dfa462e9ddabf63014ddd48865211dcda9cc351",
        "transformers/models/markuplm/feature_extraction_markuplm.py": "a18ade3bd4a91702d93022cefe044e42d871fc38b66fb1a2dc4e11a0f40f24c1",
        "transformers/models/markuplm/modeling_markuplm.py": "89f6e64ec74c009026568cb07caa1a42f3e16241cd484a7dbf501c2d88ffa831",
        "transformers/models/markuplm/processing_markuplm.py": "78fc95a45356eedea81647316c4006e32fbf86ded6cd658b9a54e6785148a09e",
        "transformers/models/markuplm/tokenization_markuplm.py": "5b9fe60a5b83ec2eec331b9a9b37d259b297810cc24cf8c0ff12cc82176c284f",
        "transformers/models/markuplm/tokenization_markuplm_fast.py": "640b9e2c7089ab0a1efe3399d0231b4772be2651411051e8ac0d094fc13dd539",
        "transformers/models/mask2former/__init__.py": "d08c46e5a6364e0ff3671c3f944558776ab89d720b0d8de075ae2384643fefcb",
        "transformers/models/mask2former/configuration_mask2former.py": "b696a2a0f9682c2bbbb94f79b4ba406528e17bc76712b9f6f71fd9b4f6e19e7f",
        "transformers/models/mask2former/convert_mask2former_original_pytorch_checkpoint_to_pytorch.py": "bf86be553767107c592c0ca43a7e4082a2d767dc85673858e0252ee1cdd71d41",
        "transformers/models/mask2former/image_processing_mask2former.py": "29a89dbc108274128a4f67fc7000c84dbd9be33314bb7bf5ba188730f5d384a8",
        "transformers/models/mask2former/modeling_mask2former.py": "2a6760e6a69defa622d03fd404da5ad63474624e0913eac98c1385bc4df8757d",
        "transformers/models/maskformer/__init__.py": "572472236924fb0aacc4fbc87f95e87227c813c834b926b4175e38b3bf5f1332",
        "transformers/models/maskformer/configuration_maskformer.py": "0b4f600203f7787f5a14907514622c71f1b97e8aae99fa2f27b2161a2e5555c9",
        "transformers/models/maskformer/configuration_maskformer_swin.py": "111ee4ed64aa257be094b2ebd248757a67ad354d243aecebad895c52cf1797f5",
        "transformers/models/maskformer/convert_maskformer_original_pytorch_checkpoint_to_pytorch.py": "faaa5f2026f3c251aa84c35a4b7ea9852529f9a33faa458edeec3a31dea7b64d",
        "transformers/models/maskformer/convert_maskformer_resnet_to_pytorch.py": "2e12881efc2a48f4d5ebf51e813fbf1be771b12a66c265fdc7f0ef7daf469d17",
        "transformers/models/maskformer/convert_maskformer_swin_to_pytorch.py": "ca54180ffd6e4a60992f3f8fb7121cec8db0092902f970e06df31a7cced5b38e",
        "transformers/models/maskformer/feature_extraction_maskformer.py": "30c3d0b906361272b8be2c43bdef88f8f205a820d640d61879574062f218f076",
        "transformers/models/maskformer/image_processing_maskformer.py": "acf351b0ebb6c0a3709d63c7b347f659f4b57188331be8da76c18f1988742bdf",
        "transformers/models/maskformer/modeling_maskformer.py": "8b3ad9b01b94fed66c2784509bf4578d1530676e27c3b3364bf1f67557fb120c",
        "transformers/models/maskformer/modeling_maskformer_swin.py": "86937533861818c970cbf3ab935ac989eaca6f667a9aa5a2384a976a84cb6907",
        "transformers/models/mbart/__init__.py": "623239df7225acb2044b9c7a53b4b8d600d18cf946b69ca7877c6ef7a8488f58",
        "transformers/models/mbart/configuration_mbart.py": "b7540f4c56d2bf9ff6ebdc256d2e856f4067912163d634e7a2cb00cd59a3e878",
        "transformers/models/mbart/convert_mbart_original_checkpoint_to_pytorch.py": "c555bd323fa377b5ff3089890a04b9d80a24d4218f7fe13abbca6dbc6d612bca",
        "transformers/models/mbart/modeling_flax_mbart.py": "98e1d94d01c74a471e5e94df402934b1328980b63ca8088f4e2db9cf59c61acc",
        "transformers/models/mbart/modeling_mbart.py": "1d25ce11a5d9722566004375c2ed68681b10a8562083c1e5c9233ca1cf04b97f",
        "transformers/models/mbart/modeling_tf_mbart.py": "384cb902024b52b0768d33cc048843b30f8c2ee45e95a98422dc974ad25ac8fb",
        "transformers/models/mbart/tokenization_mbart.py": "732c49a43451fbf1b106652a6b1c17cd60b948e9a0be549222c0ddb45f0df31a",
        "transformers/models/mbart/tokenization_mbart_fast.py": "d62788bca91f0ed2997bf84739a64d6d2b7a7f354fca52a860eb4d2374faae9c",
        "transformers/models/mbart50/__init__.py": "e5e910092f4e90bdffe542579eeed9e5c55e0a2efaa55800c47902f2a43c5ca9",
        "transformers/models/mbart50/tokenization_mbart50.py": "20d4dd1a73bf601781ee659da41824cfc3c7fa9ad038a77574ff76a9b06c2831",
        "transformers/models/mbart50/tokenization_mbart50_fast.py": "e1740f4f99d730b1250b07c77f2e2e4e89567b65660f51dc5dd5491f48d0de80",
        "transformers/models/megatron_bert/__init__.py": "b32ae24364659ab42eb3340c469994683fe2d842bf4dd958e2dfea762bd97a15",
        "transformers/models/megatron_bert/configuration_megatron_bert.py": "89ec0573303f8c48e981ac75cd0f53d12545fac2f4a77845c2d207650566f4cf",
        "transformers/models/megatron_bert/convert_megatron_bert_checkpoint.py": "540303d4c15d546f30f5c42445f9a564212f68c828a3e972148f5d7ae9c3e4e0",
        "transformers/models/megatron_bert/modeling_megatron_bert.py": "6b3ac5e242058b8cb28abfb951b70620356e9fd61589369d8fcebaaf467be176",
        "transformers/models/megatron_gpt2/__init__.py": "5b270597d7147afa17201841efaa8ab6735120f324d8ba130e49a47c07cecbd3",
        "transformers/models/megatron_gpt2/checkpoint_reshaping_and_interoperability.py": "57b831bd17ab6a77ecbdd22cf60d10fa6004939905856d40617d0fbe1ebd208f",
        "transformers/models/megatron_gpt2/convert_megatron_gpt2_checkpoint.py": "50f2d70a3178162c67c3f832ea4cf14caeb88a8c68fc4231c1254eea8282aaa4",
        "transformers/models/mgp_str/__init__.py": "db034a6df5b14855f9c4744bf2913a8d6277a0f1661d3df4702169d623d2fefe",
        "transformers/models/mgp_str/configuration_mgp_str.py": "531bda6249ff8c6e62828900ddd93e42bb54caf01319b4ef83ac3307c9d8a516",
        "transformers/models/mgp_str/modeling_mgp_str.py": "759a2f9aadb559c0f91729172670947e25dfe829df106fcd61144ee183d1a18e",
        "transformers/models/mgp_str/processing_mgp_str.py": "761d4c275ef2359768a2b1bf322df543bc1aa939f2468724face1cda4fe0d034",
        "transformers/models/mgp_str/tokenization_mgp_str.py": "088cfdcab2a1d953ec72456d609d29ca71603e1c1863d5eec896ac98a0fd98aa",
        "transformers/models/mimi/__init__.py": "bad37b3bf6600bee6915cfd244bf93a112addbdca361419ee599a96472ea52bc",
        "transformers/models/mimi/configuration_mimi.py": "6ed141cddbef3ff7cce411cdc9fb81bc4e29c3e442c08d48afab9ee449a6c764",
        "transformers/models/mimi/convert_mimi_checkpoint_to_pytorch.py": "69e0882c57594da6a97428febd47f029ffff7f1082f6ab99463d63d4b6da433f",
        "transformers/models/mimi/modeling_mimi.py": "c4d3e2a5a522102c5014fbbf697a256b2bda8ce5afb51cdf40bc43245001ba15",
        "transformers/models/mistral/__init__.py": "19dde5f0967e3b17bc7efa98287d415bf188e0fbdce2c632f3dff987d868b052",
        "transformers/models/mistral/configuration_mistral.py": "4ba74189d39a574c91f4b916fea00774b2ae95853e321204dddc6bf38f252c43",
        "transformers/models/mistral/convert_mistral_weights_to_hf.py": "77da35dda16876ec46605430bc3e46c3e1a17e5b6aff9e79b92de01f5550838f",
        "transformers/models/mistral/modeling_flax_mistral.py": "336162a3ab65eb71347c04e0d3befe0b02e84f588d57ba595a6aaec4dbce4c02",
        "transformers/models/mistral/modeling_mistral.py": "df64a2c58cb5e31f238ba406209f60106ee103b36d948f3196ea5a0da59ddb31",
        "transformers/models/mistral/modeling_tf_mistral.py": "c048d315f0ce169db3dfee456f9dc3f174ca56c2df4da69b06fbd15dd4a98caa",
        "transformers/models/mixtral/__init__.py": "2beaf5321e70cd195b21fcd3afd3d2a6f66a64f5302207573021012bb58e3e7e",
        "transformers/models/mixtral/configuration_mixtral.py": "c04a6892617107faffa06be7299359dd62274b2e9f3c18dc58a602fe9aa2311e",
        "transformers/models/mixtral/convert_mixtral_weights_to_hf.py": "584c6271a948c2465c72a5b2463514d8b06f6cbe9c33aca2386fce6f2eaddce9",
        "transformers/models/mixtral/modeling_mixtral.py": "262319007985e3778677eaaaa052161178d45521a4de748e8e29ac542a502832",
        "transformers/models/mllama/__init__.py": "996aecbe24e4c25c154ac4d3bf67262cf25219b1519b6d218ef6d8be881ea2a3",
        "transformers/models/mllama/configuration_mllama.py": "2ac1137cbff44fb7ef5fe1e4b206f9a0b65a7a93c0d65ae2ccc8e5e74aabf365",
        "transformers/models/mllama/convert_mllama_weights_to_hf.py": "cc0288b580522710b8d4e217ef73b56c9147a2c3719384f466c7d7867adf66d2",
        "transformers/models/mllama/image_processing_mllama.py": "09ff91b5961578e225659c9a0fb278eb9cd4000e8fabea7cc0a22c42d3f8fd63",
        "transformers/models/mllama/modeling_mllama.py": "9ef94e46ce55fc2e4503568a4124f06e280bab5f222bab94f6adbf60d713a2ef",
        "transformers/models/mllama/processing_mllama.py": "6716501a3331fa8aa29c3da7bf9e51274ff5a4c577ce75777d31e32d7b0fee25",
        "transformers/models/mluke/__init__.py": "3e3d06063214eaf61d844cceeccf0edf9739263e22bc82060222c00613782bb5",
        "transformers/models/mluke/convert_mluke_original_pytorch_checkpoint_to_pytorch.py": "1ba67de3ed7f0228a549353de8f4a35ffa5d805231f9bfdb93cc6530a5f94ee1",
        "transformers/models/mluke/tokenization_mluke.py": "69d8c9775190991aacb2504944c68b9dc0d2ef60936bd481dc426e303086e578",
        "transformers/models/mobilebert/__init__.py": "d465142d93317642cad21d1a3d1075313ce458fa9377800896cd250f8e1638f1",
        "transformers/models/mobilebert/configuration_mobilebert.py": "cdf3e0aaac31f3f2f92340c7374b3ed01fd2593dcb136f026cbcbe7a2d9b86fc",
        "transformers/models/mobilebert/convert_mobilebert_original_tf_checkpoint_to_pytorch.py": "3115bdb28aecc08a384625aaecf55599a66c626e30244735f8385c2f3b2c0d15",
        "transformers/models/mobilebert/modeling_mobilebert.py": "03acccaed3f996c580ed288f36f9b3bf807b39dceaf5c95b8274eadd99914da7",
        "transformers/models/mobilebert/modeling_tf_mobilebert.py": "7f9b5d50ebf6af007b78552a7dd6ff099b54d786c2a072b99ac929ff628de627",
        "transformers/models/mobilebert/tokenization_mobilebert.py": "9829f3f925a464e54afa4622cb2c87555fe483c8d93cd230865316e0a499c479",
        "transformers/models/mobilebert/tokenization_mobilebert_fast.py": "629e4570f24d59676a938d43eb10eee3880df0e59dd238f5d3805d0db19aa9d8",
        "transformers/models/mobilenet_v1/__init__.py": "dd6f84f3b9ca697f29d812d44bfee0241dbd89dbb9f8b60f0577444f361eedad",
        "transformers/models/mobilenet_v1/configuration_mobilenet_v1.py": "e9065f4bc01d6ffc33f8e3aa6b18d1b70d82e56853a7b4d575016f2a606c2dbf",
        "transformers/models/mobilenet_v1/convert_original_tf_checkpoint_to_pytorch.py": "913f54ca827465fa46dbea15846f1336cd7c4777138175272b509c0bee7b2183",
        "transformers/models/mobilenet_v1/feature_extraction_mobilenet_v1.py": "828474002f8885632b425bf348aff465e8f8d8960dfa8b304863505a720e10d5",
        "transformers/models/mobilenet_v1/image_processing_mobilenet_v1.py": "c360c825d51ba11f982409d99a2ff09d5014cf1c03438e468473a237f85b52ef",
        "transformers/models/mobilenet_v1/modeling_mobilenet_v1.py": "37d8f94192fee9a906e117f8309933b0cc738973d942cbd3470accd8ebcb8ae2",
        "transformers/models/mobilenet_v2/__init__.py": "949109d02894ac8e9a6dda19c0263f46049d2f5a59a98be3f8f43bc483411ea2",
        "transformers/models/mobilenet_v2/configuration_mobilenet_v2.py": "d094eec5e067c7056e23f819bd333c04c1e200012aff9f025e857df3cda69eac",
        "transformers/models/mobilenet_v2/convert_original_tf_checkpoint_to_pytorch.py": "989561cd808cbeeb7092b50b7b0136186b153b13ac5b8c238c4f17cd35a55889",
        "transformers/models/mobilenet_v2/feature_extraction_mobilenet_v2.py": "fc8515bf2a0c06cab2982a21f82566a2cc19e27381a6a14995aa147c3f164371",
        "transformers/models/mobilenet_v2/image_processing_mobilenet_v2.py": "64bc2c4ae6833284c418a2f66bb467dd3c312f59a4a253f0227dc3c30f70b087",
        "transformers/models/mobilenet_v2/modeling_mobilenet_v2.py": "6a325b679893f21cac07af8be7136ef19904bad603c30b74d3ed09917e9215e1",
        "transformers/models/mobilevit/__init__.py": "dbc7374960466d1e4c7a42450c48e201e894e5b785dfbe8cd20c47848d2f32f3",
        "transformers/models/mobilevit/configuration_mobilevit.py": "d2facfad2812dc080d8b19505bd744da64772370cca913b09474a925fcaf7f7f",
        "transformers/models/mobilevit/convert_mlcvnets_to_pytorch.py": "9e9863e0333c1b8dc45145a14082fa4d81d607ce791a6648f4a3e4f262d75fc1",
        "transformers/models/mobilevit/feature_extraction_mobilevit.py": "9dad87d356ca22142cc821dac8f6956ac7b91d11919a63bbcd50c3b98efa523d",
        "transformers/models/mobilevit/image_processing_mobilevit.py": "0155a1a651d832cccf63ec7ca5928714c0e5762fbf26058f95a11b7be97c6ed5",
        "transformers/models/mobilevit/modeling_mobilevit.py": "321a7dddd962d61b292d799bdaa2b811c021d71fc5b055320acfe9deba48c979",
        "transformers/models/mobilevit/modeling_tf_mobilevit.py": "520bbaae5e420fd248d93829369e885a5e96135792830db574d0fd0a02b9b8e4",
        "transformers/models/mobilevitv2/__init__.py": "e3c71b431b02c97da83724f2e7e6981c815fd4edb99666c78326268d3274a428",
        "transformers/models/mobilevitv2/configuration_mobilevitv2.py": "05a9c2bff05e48c2f1f1dfce8fbefb241aa19637af28879327c66099b7aa3325",
        "transformers/models/mobilevitv2/convert_mlcvnets_to_pytorch.py": "ce5f051909cc0e1a0de4f82d64bb47bcb58316b2f6c20e806ae44e9a8ef389c7",
        "transformers/models/mobilevitv2/modeling_mobilevitv2.py": "7c4260fd74d84361443d1bd423d20b1f7fc818f7d86b3561cb27e414eca3642e",
        "transformers/models/moshi/__init__.py": "b96e28a9329975b994459682ff1c301d79d810cc8b26b30424095f6d4cd258ef",
        "transformers/models/moshi/configuration_moshi.py": "0ac395d9beb4b601606a17f6792c917131e0703ce411634a224aa2e9704298ef",
        "transformers/models/moshi/convert_moshi_transformers.py": "e36b1b2e12cd236856456ac14896c5287ec3187c23c68467ec34f5c286a17a2a",
        "transformers/models/moshi/modeling_moshi.py": "855f633309a18c63f90ed2d497f29d3553e228782b9f2e59e85986756d002b96",
        "transformers/models/mpnet/__init__.py": "cb01d2466f90cbe902a0bf7db0b1c43a31d18693b7244142f49d86c1968c0e54",
        "transformers/models/mpnet/configuration_mpnet.py": "a55f01e132da32a73dc88e9868ae15fd9a573fdf99684b6945b6cf4e9a415b1b",
        "transformers/models/mpnet/modeling_mpnet.py": "87dc5f515da84a965f04d37f89033693732f801e53a118290aa77839ec5df1fe",
        "transformers/models/mpnet/modeling_tf_mpnet.py": "7472cc006fdbed5facf3c825e27419071b5fda64b50ce9c06e3f16ea1ff2958e",
        "transformers/models/mpnet/tokenization_mpnet.py": "e6aecdebbab1b266a4b595de35568e2011c3a6db4f37c136244d2201f15376d6",
        "transformers/models/mpnet/tokenization_mpnet_fast.py": "0d4c75c069517e1c69a453c77ef4faf04158f4c04b75ccb384179b05d713e654",
        "transformers/models/mpt/__init__.py": "99e4dcba3bd51e4a9c80af8fa70e1403c2ceefe9fc9bd02691943acf475ea122",
        "transformers/models/mpt/configuration_mpt.py": "6b66ab26e84a32c8cf55ff26e920f7718748d4a645d2b594caa88f3d357b6e4c",
        "transformers/models/mpt/modeling_mpt.py": "cde44cd8fd4c13290c90cc261b7464d156aa820b7461776aaca5c0e0d1513d44",
        "transformers/models/mra/__init__.py": "9433ee995629f5e8f886cc88565b53c70e946daa2e147fda330924ed47e8cfb5",
        "transformers/models/mra/configuration_mra.py": "e917bcabdf699faa2da13f2ade661c212247855857fe6a5e2ef22eecdf9de007",
        "transformers/models/mra/convert_mra_pytorch_to_pytorch.py": "2e1695950e2af3c82d7b083e81e45867be3cc50ddbacb2e1c83228f8e19649d2",
        "transformers/models/mra/modeling_mra.py": "a6cb9bb99c648d7ce036fb78494d986afd31f30006d4da0755854979d015eb81",
        "transformers/models/mt5/__init__.py": "ab97f4016be5c94d5e4239343970a9319e0e337a8d0eadf93efe91bb1ad641e2",
        "transformers/models/mt5/configuration_mt5.py": "304782c40655658bc8258f8d0b2219a3f918312ad3bf1810ae3ef816476a5a51",
        "transformers/models/mt5/modeling_flax_mt5.py": "9dba28a37b56cd27bde373732e5642eebe127e4d2857958137468ded3c5c2979",
        "transformers/models/mt5/modeling_mt5.py": "0dc5850c1a226dda4cff0eea86b8335e011e769d975014c44359095a5114eac9",
        "transformers/models/mt5/modeling_tf_mt5.py": "3534bced5c9472e7e295f4b5edad95378b82c7476f62cc0b04d013bfa80146c4",
        "transformers/models/musicgen/__init__.py": "fc1f774bf9c633c4b2bfbe74115f71c11d000aff463c007e1be530b28c744cb3",
        "transformers/models/musicgen/configuration_musicgen.py": "8f219ccbd96c811a95f44c6d4a0546fb2fb940e419062df28897009db3a6e6ce",
        "transformers/models/musicgen/convert_musicgen_transformers.py": "932e2771e1d9fbbf06029d0be2f63e7055ec67a946be46335fd93c306519da44",
        "transformers/models/musicgen/modeling_musicgen.py": "caa306741ce8f7170be7fcb2a5b4bf2a8ec6a519e00aa4ee4c6ddb6e1b961346",
        "transformers/models/musicgen/processing_musicgen.py": "038d34f14a89dd69b89e2c46f86211e9be5497565c576367ab8641db656c3034",
        "transformers/models/musicgen_melody/__init__.py": "bf71552eca04d93121fde01a60a71bf2fd75e073e8f5164dfa9e53492e1e0ff2",
        "transformers/models/musicgen_melody/configuration_musicgen_melody.py": "9d0567af521a4cad7b18c94fb11b777342af67a08d21540181f288208155b8b8",
        "transformers/models/musicgen_melody/convert_musicgen_melody_transformers.py": "b9a5adc0c08b99209773b7343caf538a7289781b068c37d1c265d51c7fccc628",
        "transformers/models/musicgen_melody/feature_extraction_musicgen_melody.py": "d3e80c8ee1a11b824c78cfb8e306b7693a3736987efdc8d9b3b9379e173a71f1",
        "transformers/models/musicgen_melody/modeling_musicgen_melody.py": "85a60c4bbb8b9e891b042b6db63c6677b5f110d98b6d6318d2fe50cf95a27709",
        "transformers/models/musicgen_melody/processing_musicgen_melody.py": "5b6744a5e98f3e15f5d18813c26d13df3bf2ef567c43127f2d2a33e99d345002",
        "transformers/models/mvp/__init__.py": "1a3c59d12df8b2a4147a2ad8fb482785782bf51f2bda8515e24220ec28ebc064",
        "transformers/models/mvp/configuration_mvp.py": "43cb1b271fbb54136e7db7165133b375ca78ca5cd77a688e13069fd92d95350b",
        "transformers/models/mvp/modeling_mvp.py": "29e2a7b22a5b2e978dd1af5aaf58318a2b44e65358d2403b8d42018b9042a52d",
        "transformers/models/mvp/tokenization_mvp.py": "26547a9795d3e54e1e53fdb41516faf6d9845ef7b125ad5df3c9a82778f18f71",
        "transformers/models/mvp/tokenization_mvp_fast.py": "3daf19686b43adf86b58b9c1f453ec3b6386535df51359791c4012db936fe9b7",
        "transformers/models/myt5/__init__.py": "a2aac64391af1ef1a317ae90f9de0841ea6c25af9a1232a0608d88e2cf7e14cf",
        "transformers/models/myt5/convert_myt5_original_tf_checkpoint_to_pytorch.py": "9bf0561e2be149b2003f8df13955fcd9e371775cfcb8e125035ece4acefbbb4f",
        "transformers/models/myt5/tokenization_myt5.py": "4238ff2a1d08445e45b1ad38831d0a46dcb7862d666a7110299145917cfff117",
        "transformers/models/nemotron/__init__.py": "9e80d9f00d980157bb134fc88f8ca6db859c3ec58dbf7b9fb5f981d14fec1a05",
        "transformers/models/nemotron/configuration_nemotron.py": "f7e33a6b9fab6be5154a4f5fe86fea2c2ddb4a1df3c68336d2b6281fcac2dda0",
        "transformers/models/nemotron/convert_nemotron_nemo_to_hf.py": "05df724a116e8acfcbae98430297eb7d4fe673a4bc3a22f0725474f371a85ebe",
        "transformers/models/nemotron/modeling_nemotron.py": "060ebdc4d99fc8fa829427dfbe38be8a6ec66aae3e6c461ccda4c98ce9d4ba3d",
        "transformers/models/nllb/__init__.py": "b4ceff15d984ef33909baf06a1142246dd636d87cf79af640b6e1025248c8081",
        "transformers/models/nllb/tokenization_nllb.py": "30e1cfbb126912f529cee527b4e71e77fa87efb0c65a5613639f461764d0c0df",
        "transformers/models/nllb/tokenization_nllb_fast.py": "1fea212445a131218d986a9a29dbd12bf7deaa4c6b7a43556846de8aed3c287f",
        "transformers/models/nllb_moe/__init__.py": "0630123cb44327e994f1c35707e4fd2b32f2a9eaa8604aa29e5298ae3532b79a",
        "transformers/models/nllb_moe/configuration_nllb_moe.py": "6f2b34c5d88844acfc5ba3575a68143a1e15f6571eb7fdca1597cdf9cc633fee",
        "transformers/models/nllb_moe/convert_nllb_moe_sharded_original_checkpoint_to_pytorch.py": "73d65a6fda95ccd1129345367b124d6a80f0510a3f43b6697191d58998ea4d04",
        "transformers/models/nllb_moe/modeling_nllb_moe.py": "a35ad79ba1d79de253da85aa040465078833901e82cc84bf56b36cf076a5adee",
        "transformers/models/nougat/__init__.py": "d9c4b0e34c9ff93f355127a56b61af5acf8d49758790e6bacc9ff704eed04826",
        "transformers/models/nougat/convert_nougat_to_hf.py": "dca1c6f664e29020d7f3c84a6d107cfda550cca76585e3f5fd388ec9dc10a08c",
        "transformers/models/nougat/image_processing_nougat.py": "29490257bd95ea2d01855c6c5158f7cf535712be9931df2e660fd23c6a8fd528",
        "transformers/models/nougat/processing_nougat.py": "eb9399efe5ef15e884c058c48baf590d8f77d70e8dbc74c71a8f448b1095c4a5",
        "transformers/models/nougat/tokenization_nougat_fast.py": "80f67bf9e921012bb728a3e83d43aaaefc4be72edb6034559d334eb8e81cc055",
        "transformers/models/nystromformer/__init__.py": "aa9e9c785b7264979089ee7d81d3b870ca085fcc90871773baa926ec7f625668",
        "transformers/models/nystromformer/configuration_nystromformer.py": "3d2c127d834944cfecbdc52dc904ad2666b951bed4bede52c6da85b04ec371a3",
        "transformers/models/nystromformer/convert_nystromformer_original_pytorch_checkpoint_to_pytorch.py": "f0ae48185a2c304f8b0258c52ee4dcd3da1c7b5230c590dcc70d4a3c7b1a9aa7",
        "transformers/models/nystromformer/modeling_nystromformer.py": "354d6894166037f913cce54ef3e3dcc7be06785ece59cc0b83321ae9c823760d",
        "transformers/models/olmo/__init__.py": "fdd36540bc4097093862df5d8f1b6b2d7cbdd1b7a7f0b531e0bb43f30651e615",
        "transformers/models/olmo/configuration_olmo.py": "aaa63c005e9338460a9faabe28a2ae141f5613f23aeb8f5dcaf581a7e1403e1e",
        "transformers/models/olmo/convert_olmo_weights_to_hf.py": "488f752a7fc1fe6d287a5da4b89d8b50c1aa7da3592f8438b13db276a3586651",
        "transformers/models/olmo/modeling_olmo.py": "4b4ef082bb274cbf46312ab380dd82bf741e263b99fddfe85524213f20037f83",
        "transformers/models/olmoe/__init__.py": "051228bda129aaea182ab0b05fe2981333a5b03e50ee2d6cc88f070b99c294c3",
        "transformers/models/olmoe/configuration_olmoe.py": "d7bd567cf22e0d0708e4dba8cac87df93452a70424af61eb4e783bb9ee96e160",
        "transformers/models/olmoe/convert_olmoe_weights_to_hf.py": "bc3d299f20d577ba3217b9c8a9d5836b9309650ce0530b47dbd35a4129eb8bf8",
        "transformers/models/olmoe/modeling_olmoe.py": "ca6fbfd81b559a830eb8911daacf525e451deaba712016d73f3cd3edf667b297",
        "transformers/models/omdet_turbo/__init__.py": "29a33f8c2e5fe8831a652ea11cdc3983c1daef312822553506ac38027c3f575e",
        "transformers/models/omdet_turbo/configuration_omdet_turbo.py": "3233a20660f0fafb2e4b4b5b96974b8fe856f19710993ef203054165da9ed1f8",
        "transformers/models/omdet_turbo/convert_omdet_turbo_to_hf.py": "c9e750f41f9d0036d0a3f6455cb6fd9e10060b84ae5bae36e309ffaea1b6c169",
        "transformers/models/omdet_turbo/modeling_omdet_turbo.py": "c0f1630ea018d759b81d55c10dc46b99e0f76af54a262af151e186f057a3cc29",
        "transformers/models/omdet_turbo/processing_omdet_turbo.py": "d23627db91eb18b5e70a173544a71b8163c7e270a332a1a927627c6520628878",
        "transformers/models/oneformer/__init__.py": "d47181d12cd514b62df2ed29c098046a7decc01961d131559ece9995c0f790fd",
        "transformers/models/oneformer/configuration_oneformer.py": "2112aa8f18eb4b7c918e718be900f3cfa17b077cc19a090b6b0aef46473b805f",
        "transformers/models/oneformer/convert_to_hf_oneformer.py": "c81592d12135b064bd52a0b35f611d6e1022216bc10ae992070bad27c550145e",
        "transformers/models/oneformer/image_processing_oneformer.py": "6a8dcf52f42fd413b4e5b64a27cfd084e2bcdb75544cadde3e6cfc87a4b2a853",
        "transformers/models/oneformer/modeling_oneformer.py": "987192d416243546b0a3464bc3014e53c43d182bd9e37122377e79487ebcc392",
        "transformers/models/oneformer/processing_oneformer.py": "6a1b28f1f18c2c66f4efc41f63c4f9a356c38f939aa6da0c6c8c624c824633b7",
        "transformers/models/openai/__init__.py": "3883b698bb8fb597a60e98da0eba3ceb8a8b11f4777691d1066ec2f7a800f1b1",
        "transformers/models/openai/configuration_openai.py": "6b6c8f7cd750f9c4310a99d6809e52ca4a4b67a692e43fb505671f516a0ed748",
        "transformers/models/openai/convert_openai_original_tf_checkpoint_to_pytorch.py": "595ca26f007581a29b36a26e6e26bf99b87e37c432e1aefb5bb5c0ae84f0d320",
        "transformers/models/openai/modeling_openai.py": "a038d17e1b22fab0fe17ba7884eafd0b2b89722caedb9c1819017cba1399e62a",
        "transformers/models/openai/modeling_tf_openai.py": "8eb21e7cdb985f12898509b58f00c758e1c782eba0493779303662cd3bf27999",
        "transformers/models/openai/tokenization_openai.py": "a3272be0d5fad76d20d830bc0c6ba863fea8f7277f1125c75a48f0c0c44dc4d9",
        "transformers/models/openai/tokenization_openai_fast.py": "481c2fb61b061e0b443acde79c056e4342889640f30fb586f685eb035858b478",
        "transformers/models/opt/__init__.py": "fdd814b0a98a9a0719fcdcf6dfde7271939e1cb0921f0a687d8a584fc46c64a6",
        "transformers/models/opt/configuration_opt.py": "78fc0912437d8cdcb8e50de214c891f53333353357fb73d8a2b4614db7f528a9",
        "transformers/models/opt/convert_opt_original_pytorch_checkpoint_to_pytorch.py": "34801082816979667264243accde04ca565da23b08426db0b6f388b8c64a8fae",
        "transformers/models/opt/modeling_flax_opt.py": "1189e99ad110ae17fabcb4f8272c9677c57be8dccac4d8859f4330db68315de6",
        "transformers/models/opt/modeling_opt.py": "cb1a8a514e9723fd9b376ec8308abe1c6da8524f2e94199bd611df3abeb42cfd",
        "transformers/models/opt/modeling_tf_opt.py": "998adfffac791406781c2c8fd5c742bd383bd47da59333c09ee769fc574a5cc7",
        "transformers/models/owlv2/__init__.py": "62a55306296d5aea64805e637cd8e35737a8f0084c5c561e77a12981636c7979",
        "transformers/models/owlv2/configuration_owlv2.py": "66cdb9cff9d4c27a6048fe05b2c26047377ae54409d7f9461ba7e265a1d91f2f",
        "transformers/models/owlv2/convert_owlv2_to_hf.py": "ac5d3693d5d64ecc1fe0fe1967be9e901ddb7baa51b0524bb5bb96689a72c776",
        "transformers/models/owlv2/image_processing_owlv2.py": "f15b2942d876fd00da07e4ac27739011c11b004f23cf451f88c725ce8ef0087e",
        "transformers/models/owlv2/modeling_owlv2.py": "3acc7c4d149b6aef4bccea6648c23d7eb7766bb3d3eb1fa63cb572815a50c2a9",
        "transformers/models/owlv2/processing_owlv2.py": "5940190b99cb22a54bb1e1f5a1db7c177da61d957647689a19ed5e5aafbd74c6",
        "transformers/models/owlvit/__init__.py": "913e29ca9086a37ead661615e26a07d11d0582a787b851f8040abe91cebf3c38",
        "transformers/models/owlvit/configuration_owlvit.py": "935f2deea8e1089e0fca2c2b8d12d3e8b87535b20f8f8f0fc991ac67ecfd86ab",
        "transformers/models/owlvit/convert_owlvit_original_flax_to_hf.py": "b687f335971544ec1f62857ba55eaee74026dd3166f979ae244006c0dbd14fda",
        "transformers/models/owlvit/feature_extraction_owlvit.py": "c8f3bc15b530dd869b29bb15fe8ccaa48afa262c4ef649d5c3578c2077a20ad6",
        "transformers/models/owlvit/image_processing_owlvit.py": "cf7453106cb9671128164779ff2e18af86306ec0d53cce2ae6a1a50c597b7970",
        "transformers/models/owlvit/modeling_owlvit.py": "58bac4438c076ae8bf65d82e219ab61bdba7f339f555a7d7819473b58efb089c",
        "transformers/models/owlvit/processing_owlvit.py": "d27499655f07b589b2c1a09f52a30259869da803b742d322f12f89b7fcbc6a2d",
        "transformers/models/paligemma/__init__.py": "648762f69b77ac8d8e3616efd518b1edeeba47de3e2b76924f9ed6e063c6009d",
        "transformers/models/paligemma/configuration_paligemma.py": "700dd907c3792af3de998796c098cdef2c064a3691eb0e2d6f48001576266170",
        "transformers/models/paligemma/convert_paligemma_weights_to_hf.py": "951a7c162ec2c1a7aec9212845695c74202dd9080f2797088e805b9bc9946db9",
        "transformers/models/paligemma/modeling_paligemma.py": "7e1aa2eaaf73d9c93f206484fdd733393d2987e8c43a07b7345acaf369495736",
        "transformers/models/paligemma/processing_paligemma.py": "0b5fbefe2b88622c0768c35589e1aaa2eb97002d31701442705700329da6f824",
        "transformers/models/patchtsmixer/__init__.py": "96b63c1296b698695bcdc254c4074b5bbd9a0872a5d7b3f3273313682495bd4e",
        "transformers/models/patchtsmixer/configuration_patchtsmixer.py": "3354ae28b7ea8ee5dc052141f2072f8bfa303d991f5b5c69927fe7b7713a0e43",
        "transformers/models/patchtsmixer/modeling_patchtsmixer.py": "94012056a8ee78929be7d4e0ea21f2115eb40231bd38ce7ac35ffb825de71ed0",
        "transformers/models/patchtst/__init__.py": "6bb499ea1f0b1291fc1536deaeb1e90e75904e99030eb6b7e3675b8fd11f2989",
        "transformers/models/patchtst/configuration_patchtst.py": "d676968071a635e12f0437c79a8b8065e35d6f4b10fbbb5a5173cb496e9f5f68",
        "transformers/models/patchtst/modeling_patchtst.py": "af11696868a92a429c9924775db5d23e97522750ad834f46325e247719930df2",
        "transformers/models/pegasus/__init__.py": "8fb8efbfb391b8b101f6408e79d21a75a4fe35a4854b4335fa61458caec89cbf",
        "transformers/models/pegasus/configuration_pegasus.py": "bed54aab0964d218273e5616b949f8b3294dca4748069b668de3ddf9ee68c319",
        "transformers/models/pegasus/convert_pegasus_tf_to_pytorch.py": "f60789a30340ba465cf45136384ab4a57422eb29f0f64fb6345b659884b1a548",
        "transformers/models/pegasus/modeling_flax_pegasus.py": "2f5d87c07d066e2398e25ac95d7aca8fc92711a5f607712f0197b564af28200b",
        "transformers/models/pegasus/modeling_pegasus.py": "0ec17e818bec4835a3077eef6accc6fbff4cdb580a5e74152869eb997884a9ed",
        "transformers/models/pegasus/modeling_tf_pegasus.py": "dd8fab61181fa4a9437247e6564c19bbcb5c9da93a5e5e4f78daf3488134bb2b",
        "transformers/models/pegasus/tokenization_pegasus.py": "cd1c9538ca99ba7b0abc4a741eae1921d3fc7f094c012381fdb4ca93f4cd68f8",
        "transformers/models/pegasus/tokenization_pegasus_fast.py": "ee0b762e93590b3aa9acdd29c319988acd1dd4b04a8ea81bd8efe5dd058291b9",
        "transformers/models/pegasus_x/__init__.py": "109c07d062793ba9d1e62586701ea465f878b65b81d12ec34c70075f3996e99e",
        "transformers/models/pegasus_x/configuration_pegasus_x.py": "e1a0cd11c701b3b2845e64ba2f1bc460cb128740849e396d2dafc4ee2f6abb15",
        "transformers/models/pegasus_x/modeling_pegasus_x.py": "b347cfc154537dcb5c15ef524a1b5c69f57f8139e9381f3f15a98e188cd58aad",
        "transformers/models/perceiver/__init__.py": "978a1357b2d40614799b4b18ee27cb7636e3e19df066a6f1b4e7ec1cf4ab522e",
        "transformers/models/perceiver/configuration_perceiver.py": "e0e7af53d123145a6d091ca0bbdfb57950bbe985d8fcf48b34ac9df051e02aef",
        "transformers/models/perceiver/convert_perceiver_haiku_to_pytorch.py": "afd9dbf2d591d7bd12efce94f3975a8231456e0c0bdfbbe6a5d3aa53e0cf7a74",
        "transformers/models/perceiver/feature_extraction_perceiver.py": "d255bfaa1e4e36d530af401133d441f618b303beb02fa7e67a87c3ae16c8b172",
        "transformers/models/perceiver/image_processing_perceiver.py": "5cacd75d73957ef93307e09f936cfb760301597a1ea750c9a06a4a1715043860",
        "transformers/models/perceiver/modeling_perceiver.py": "0c0b86b3bca0eba308a538007f203fb000cb846ea4204c8d46d0aaef5c60b586",
        "transformers/models/perceiver/tokenization_perceiver.py": "821625407be23f53e3771ba29f7a11d5591c1f93aff701c8f0312874b407236c",
        "transformers/models/persimmon/__init__.py": "c6b1b73ff9d6156368bfa9b31f12b2444e0cef366c5eefffe21f78f0b395e7f3",
        "transformers/models/persimmon/configuration_persimmon.py": "882261d9b5bd8b7241499f87ffb974c15c7b3406a13a9ff8ae5dfdb5ed4cbfa9",
        "transformers/models/persimmon/convert_persimmon_weights_to_hf.py": "17734571b0960fe531170829da1f8dbfbf3f334a742c42cfab8adedf464d2235",
        "transformers/models/persimmon/modeling_persimmon.py": "69cece7ed82325f3770cd4fea3b9cc7086f41971bcd1de6b0e19302f88c22c89",
        "transformers/models/phi/__init__.py": "a8c5b22519f53e79f25fae3b54ee31ac96d1ee19538b0bed124c9054310a1f1c",
        "transformers/models/phi/configuration_phi.py": "1dd555cf458c643ff36207df1998a61eb795bdc7520a099512f50c7f935b83f8",
        "transformers/models/phi/convert_phi_weights_to_hf.py": "5eb8e0b599ba199431d35ad9d2ae7683a7b86a3c99865f27d3640d721003e814",
        "transformers/models/phi/modeling_phi.py": "c605fcb58c2a534701e73abb11ce99ef92716924242e54023354f44b23781119",
        "transformers/models/phi3/__init__.py": "35d4808278581d153991c3cec3cb2e972268ce08803f53087cf7c22e3d6cca95",
        "transformers/models/phi3/configuration_phi3.py": "aa1f19cd559f2c8ccfe91a554ee52e4459f5236948d18e505c05807f8765f4ea",
        "transformers/models/phi3/modeling_phi3.py": "5fe05441155bdd285f3fd63d64233f0ccca5beaae2c60b27863278efffac6e68",
        "transformers/models/phimoe/__init__.py": "c066ac3f2b2ed041ffab4406699997a902f9ec6c5f667f0d4ecbc1d88e94daba",
        "transformers/models/phimoe/configuration_phimoe.py": "0a15dee72e70050be4e276e8f66e1ca8ba7f9fcc65873a41e991baaeeef570dd",
        "transformers/models/phimoe/modeling_phimoe.py": "80784a2d52d7c37e8382315756c38a00a09e7aa7b8b0266f4a43fc663f3a68fd",
        "transformers/models/phobert/__init__.py": "243000a06e853a9375a399201416c7928928f4db228a8162f9901e02047bf676",
        "transformers/models/phobert/tokenization_phobert.py": "9c0141bf67e33c1099d6bf33d4295ee56ae139e4c6cafca46af3a29bc1dab7bd",
        "transformers/models/pix2struct/__init__.py": "5d6cd2efdd6fb4736f8dfcaf166112e64e2ddf4d7b1b3bc837fe863f01b6fd7c",
        "transformers/models/pix2struct/configuration_pix2struct.py": "1181cef339d760cc31b0914403969576c0790baf820fabc7a67d095e8e29ccad",
        "transformers/models/pix2struct/convert_pix2struct_original_pytorch_to_hf.py": "9bf4bef68c723783d069f45b59020ff86d0d503ad3ab13a6afc2308873423ae5",
        "transformers/models/pix2struct/image_processing_pix2struct.py": "2468c9bb120060393ed363182d3d996489381d6d3de5677399d8bdeb2407a321",
        "transformers/models/pix2struct/modeling_pix2struct.py": "850b079e5533428c37f95d9c65000c5bb1e35f339bf0cbdafbd78b95fa24f1e0",
        "transformers/models/pix2struct/processing_pix2struct.py": "9fd9e064c79c2216b9935e49be16039452b85d34ae53b23d6501e2512bf64782",
        "transformers/models/pixtral/__init__.py": "579e215670bcc725fbd9b9f3ec583c0ff9aa32dcd967474614e613b333495a39",
        "transformers/models/pixtral/configuration_pixtral.py": "dbef48fcf1c93c452d1a8384561d40471c84f641ba6643c2d82687b9d9097cb8",
        "transformers/models/pixtral/convert_pixtral_weights_to_hf.py": "e7577d9acfe7fd2d91343ef6f598e6ca356f360d62083dbf83ebba01e8e7a516",
        "transformers/models/pixtral/image_processing_pixtral.py": "f5fda02ce5755c58d2d450d29158ff044420dc72322e24402b6b8e0d97dbf0de",
        "transformers/models/pixtral/modeling_pixtral.py": "bc7a6726a5f6cfdc79986cedb5b63375b61ccdc807e4ebe5fb824290346584ef",
        "transformers/models/pixtral/processing_pixtral.py": "7c48bd369d2e9ebb1ace7e4eb144786a3d91ac96136a6eda69fce4c2c26a0880",
        "transformers/models/plbart/__init__.py": "c9780466db215dabd0f3ef8639f877b113e8614f144bfa9d47189af05849e07d",
        "transformers/models/plbart/configuration_plbart.py": "0ba712db235e97aa09cb853dcbaf3664099c0ea702d8819e663de2e4a8ff3c8a",
        "transformers/models/plbart/convert_plbart_original_checkpoint_to_torch.py": "04e5cdb9d352af5c5ebe61e7bcda5aff8c9add0f3d9ba2789677508425922c1f",
        "transformers/models/plbart/modeling_plbart.py": "edabc427a1b0ed9e178439112e1cfc0388b54625de0979fe0f59e886b885f7dd",
        "transformers/models/plbart/tokenization_plbart.py": "c0a9ec48b5b0e048637eaa445dddcf5d3f849028c871b56fb1faa55bd81d8e65",
        "transformers/models/poolformer/__init__.py": "10be5a7f786fc29c970b3b3facd4e7003cf8e3c35a92ee424622da13ea965bde",
        "transformers/models/poolformer/configuration_poolformer.py": "e00805a2e292345ba564b87ed166e075de1b1d5f32e0995f876f476c59dbe98b",
        "transformers/models/poolformer/convert_poolformer_original_to_pytorch.py": "56f969ee3bbb92bdac83535d5ca99aeaf6060018ece2c5613ca86014a3c94699",
        "transformers/models/poolformer/feature_extraction_poolformer.py": "2832f8b60ee1c70cd029898673a8cc65fcde0fd5024dbd34a0d7db7a3223ce69",
        "transformers/models/poolformer/image_processing_poolformer.py": "a6d5c7dc219093c94e1483613bd90dde1015c7755674fc1beff6dc81341375be",
        "transformers/models/poolformer/modeling_poolformer.py": "373c36028f34273f6af17433a9681d3ae6c7095f249acc656e4d66657a669f53",
        "transformers/models/pop2piano/__init__.py": "ea6b413c4b71434e3bfe965a1f7c677db462af2ed5473c3e1a48d3cbabbe6938",
        "transformers/models/pop2piano/configuration_pop2piano.py": "09293b743bdd99c36883fe71c1421b4a07125bf64ecb96c03133ede21d87de6a",
        "transformers/models/pop2piano/convert_pop2piano_weights_to_hf.py": "e41e0044217c94259e5b67ec80d7b4960cb99e662f2e634f405ca0e4ede48fe0",
        "transformers/models/pop2piano/feature_extraction_pop2piano.py": "787c80eec8cffad918e105c74c6625f374429c2128360710f537faad277d3dbf",
        "transformers/models/pop2piano/modeling_pop2piano.py": "86f08aebae4d45e83ea31bb95a95a4c7020e74d69afcbd5849a9dc348d18d62e",
        "transformers/models/pop2piano/processing_pop2piano.py": "426a1b291fd9dd1a3feadd764d731a8a57aa507d6502319563a9f6c0e7afcf06",
        "transformers/models/pop2piano/tokenization_pop2piano.py": "63782b52cdbfe18be0503c430217b88410497b4472019abfa1fc75d63c353390",
        "transformers/models/prophetnet/__init__.py": "e70e291fb5f1de0a7d7424b2e0e5a07e847aeaf5041978a567654c9cd30d1dab",
        "transformers/models/prophetnet/configuration_prophetnet.py": "7529ea4f1bdc7157ea05fd87b4203c7be9b49c9f6ada2f20457ca76999a5bf00",
        "transformers/models/prophetnet/convert_prophetnet_original_pytorch_checkpoint_to_pytorch.py": "36c578390d8ce509a0f91cc13a15b9f3c3cfdb33090035f0704d6f14803d14f1",
        "transformers/models/prophetnet/modeling_prophetnet.py": "4bf1c315d6bad6b4e18ca2c681a518ffc60e1d806f558aa81b76cc4f9a764e27",
        "transformers/models/prophetnet/tokenization_prophetnet.py": "272508b2b42c6eb492d6b33add57e2fc22188b2527238b3e549553f23bfa41c0",
        "transformers/models/pvt/__init__.py": "9dc984410c6b9bf04c248cb66afc14fda2f83841deb702556b78d4ce7d7c5fd7",
        "transformers/models/pvt/configuration_pvt.py": "c6b13012310fefbe537c66d556cdce84423e3f01db6e31ec2c74d2812a13d34a",
        "transformers/models/pvt/convert_pvt_to_pytorch.py": "04ba186c40a6bef2a759042a323337ce59bc94c8d873a2fcc6b718c22a2781eb",
        "transformers/models/pvt/image_processing_pvt.py": "86afb974701ffad78ea91832fe808912d943bff9f663ccd6a056069a662d14f7",
        "transformers/models/pvt/modeling_pvt.py": "60a37fc805ed0946d3981a0175cdf98e2061fa31b6694ab09b4381317b7721d5",
        "transformers/models/pvt_v2/__init__.py": "8ee53345c82acd0008e4c1d46f2870077948790793934e4547d9f7610156010a",
        "transformers/models/pvt_v2/configuration_pvt_v2.py": "fafbbeed883e85527a4b9152caa293a97f0cef0d1c0cefd2f24d9410a610cba7",
        "transformers/models/pvt_v2/convert_pvt_v2_to_pytorch.py": "3aa613601d5bb2c121e02f80c02146d150c37045996b54aee64524ae7fd470ea",
        "transformers/models/pvt_v2/modeling_pvt_v2.py": "8902ffe3c9ffc460da937fbb0364c32e2c5811af2df8709dccb92e06156796bc",
        "transformers/models/qwen2/__init__.py": "aa84d39d3f00fa9120e645ddb675f4360908b337b1fb7e71ba5d8fbc9dda6f8f",
        "transformers/models/qwen2/configuration_qwen2.py": "a4da735ab575c3f73a50e5f493e355d1ab271ff3f27fab384294f6cd992ea03f",
        "transformers/models/qwen2/modeling_qwen2.py": "4568d588b45dd28152d97c37300a5e227589bc70b9fef5224af29977ecf6abdc",
        "transformers/models/qwen2/tokenization_qwen2.py": "cbd85127aa186116bfe14ca84143d4fc196cae74cf2a8101ca2090df37a54a61",
        "transformers/models/qwen2/tokenization_qwen2_fast.py": "34bd108c4b37ea1889528d32bba5f7fa4a7be0b0238a82b2a097aa9f185db18f",
        "transformers/models/qwen2_audio/__init__.py": "22d780080dd5e84f517895af2e69d94e2a1f504dfa0c10d5bec5f66f7615f0e6",
        "transformers/models/qwen2_audio/configuration_qwen2_audio.py": "0c4b5dc4ec042e66ee898e7e186af155da10b6821650cdc2ee5dc5cea5014cf2",
        "transformers/models/qwen2_audio/modeling_qwen2_audio.py": "46af59c4c7710a437f2ed197c6f720d4a13191e97fa5b57bca7894cbdcfc44e5",
        "transformers/models/qwen2_audio/processing_qwen2_audio.py": "7bc627bef5c89486e59ddca2194589c526cd61e073102ccf2ed6cf3e3adf21b3",
        "transformers/models/qwen2_moe/__init__.py": "4d35908fd524ba3c2630bb7c703816f28be01f4529ad49e868334bbddffd771c",
        "transformers/models/qwen2_moe/configuration_qwen2_moe.py": "c13a485fd516eb1a586b5112304c44280a71e5be8a3efef7cf85302edb2b762a",
        "transformers/models/qwen2_moe/modeling_qwen2_moe.py": "cbe519cba783a4f3f2909396c66687b703a1f88c7ec4fc31909639abca382391",
        "transformers/models/qwen2_vl/__init__.py": "ac517c2b1629de76b77cecfb595310fd7d4c3a524b09fe5da7dfd5fa0504206d",
        "transformers/models/qwen2_vl/configuration_qwen2_vl.py": "bf438ac476ee78f6c320267c95be473523a2557f87a1b6ac34d86c9d4f47a4cd",
        "transformers/models/qwen2_vl/image_processing_qwen2_vl.py": "f1c087f3ea190305c62a405f6415bfee75d8464e8d22d9fd8a50b44e512efe07",
        "transformers/models/qwen2_vl/modeling_qwen2_vl.py": "10a3622b3282e6f821b91b5f42bcc14c766ec4e29ea3dc0184fc659005e827f0",
        "transformers/models/qwen2_vl/processing_qwen2_vl.py": "bd0ba61fc0485535813f0ec5588967f0b9159f5b1e6b5dfe06c9bee600e251b1",
        "transformers/models/rag/__init__.py": "a26330b697135811d8299bedf0d2316c00878480a66167de4e0882ecee14f3c8",
        "transformers/models/rag/configuration_rag.py": "9d9b8a99873d5b138a82e7f78aad18125db6b27a0f46522253b804a74651e751",
        "transformers/models/rag/modeling_rag.py": "cd7746f1a567d10a6feea8f645c599efba4e76f85d97c52ba3fdc7485a96668e",
        "transformers/models/rag/modeling_tf_rag.py": "9094329205e5747773cd787654abeea7bd848849fbff9d375bffc96902ffc97e",
        "transformers/models/rag/retrieval_rag.py": "b8b6dd5222c1d2e2cf0e70c6fb58512d937c3db66f9690ed22d7b200583eb108",
        "transformers/models/rag/tokenization_rag.py": "0c7bde913a4bd4a5bfc08b56fd392c8ae6f99c7167eea4f0703c92a5fc8799e1",
        "transformers/models/recurrent_gemma/__init__.py": "81413e2913c6783fdbf9a9253069fda036e749d67cb700ce4175312f6cd6908a",
        "transformers/models/recurrent_gemma/configuration_recurrent_gemma.py": "f048e421e4db9b2ecb303b65d60d25aa17eacc24d36a144c7ab3c97d0cdf5734",
        "transformers/models/recurrent_gemma/convert_recurrent_gemma_to_hf.py": "8d91a46761663455ac657cf7ee07fce8d8cb4456e02d32ba0be64eebe242864b",
        "transformers/models/recurrent_gemma/modeling_recurrent_gemma.py": "7d912e143c9e872b6d16bc0d2334f959333b883bd1429547845ec06cbf5f2fb9",
        "transformers/models/reformer/__init__.py": "7650e0c91df01b69c22588384bcc7a947642c4551e19db71d0b2b62a8439c9d2",
        "transformers/models/reformer/configuration_reformer.py": "858b2a31b09a143bbb65d3e242c8bf21d4da28ae5e5e7da3e393d205655966f9",
        "transformers/models/reformer/convert_reformer_trax_checkpoint_to_pytorch.py": "a7060f44d9af124d054696d1e77fa93800871aabf79f37b1bed94768005022bc",
        "transformers/models/reformer/modeling_reformer.py": "665f5aa355d27ddab073dd93acdbbb551b04db68d8043221c35c75c0a50f02ae",
        "transformers/models/reformer/tokenization_reformer.py": "dcd056014ec1da42703677a06b77c1e18b3e13854329fe7b9df7c6be1d0faf1c",
        "transformers/models/reformer/tokenization_reformer_fast.py": "d3a2e1a8389f1a657d66ba55d1a482f6b15ce51cf77bcf7aa381cc3b9795b946",
        "transformers/models/regnet/__init__.py": "4cede8fdd1281b933ee5b6d5a34d06b1ea6b824ef5590b6abaa1171537b333ee",
        "transformers/models/regnet/configuration_regnet.py": "aa77127d27891df7f3378913b71c1f7c979624d91a35713f6b03084a12b432e3",
        "transformers/models/regnet/convert_regnet_seer_10b_to_pytorch.py": "3c7d5e3ec68d831659bbd616a1bdc54db5999319cb2a837d6dc2422152b6a582",
        "transformers/models/regnet/convert_regnet_to_pytorch.py": "9327ca6d8fa4c256a3f95b179cc6496706aa64f6eec91f8c539f251431bd17f6",
        "transformers/models/regnet/modeling_flax_regnet.py": "d80a3b78e0d6707b9fa59a0d6c60b815b5fab59544d9b7d65ab65231b3c670c8",
        "transformers/models/regnet/modeling_regnet.py": "cd0af4b63ca9aad7685995be8466ec3505820a8ae8d33ed69404eb0e842078cf",
        "transformers/models/regnet/modeling_tf_regnet.py": "89cb987a0a86e5189a0b7a9a8e5cd777b0140846360659c5cb339acae92cb7ba",
        "transformers/models/rembert/__init__.py": "4ca6f0be84cf23011c47e3b1c016464687f4761afc2da5cc89b8ca5acbbb1fde",
        "transformers/models/rembert/configuration_rembert.py": "f9a44affb480ce03fb95c769f866a358b81289cf4a84affcefc1a66546e5fca4",
        "transformers/models/rembert/convert_rembert_tf_checkpoint_to_pytorch.py": "fc5c1aa4106793fc6fd503dbcbf3c69c5bc865f19ef6fa28725014c14dd57b5d",
        "transformers/models/rembert/modeling_rembert.py": "8003c0e34014f69329fa8b371a99a46a86bf6707e56333caa7e8f9d629545d99",
        "transformers/models/rembert/modeling_tf_rembert.py": "681d1a0c22a679b3c70f97764beea65e3a4d409d78c3317e039305373e23327f",
        "transformers/models/rembert/tokenization_rembert.py": "07cbb004c3ec6ba6ec3b3a22a7fec865321376996fd8ab8eccda7652904f77b2",
        "transformers/models/rembert/tokenization_rembert_fast.py": "77332dbefd04002ec784cf0cb654af1a8c35fabe684d6acf856d15002020cbac",
        "transformers/models/resnet/__init__.py": "e34135b1c8de42f7f20f1c1e6bf4e830dfd09811e01e68dee38fb726d938e1cc",
        "transformers/models/resnet/configuration_resnet.py": "3abc3d411a6dfeb360faf3dd395646b0f64cb1c863c9318de809ab73c2e50e35",
        "transformers/models/resnet/convert_resnet_to_pytorch.py": "7d56abfa27e4ffefec10d91989303ddf021a12e9cf3089e5a749a60dd1f928e4",
        "transformers/models/resnet/modeling_flax_resnet.py": "b89333d858155e6e9f7f08e2a2b08792e3db091adaf1574dd6f6082d1b888316",
        "transformers/models/resnet/modeling_resnet.py": "8ccf8c31182271ff9644e83373ce59ca53bf5518ddf3ddd217e2047b89aeed5d",
        "transformers/models/resnet/modeling_tf_resnet.py": "6ee47b4f1e9146de101e946b456c21113d5cc19f84d4fdd640d1ce4343bc6bf2",
        "transformers/models/roberta/__init__.py": "766206a853bb2557791a20cd4d8744ec940d3fe75bef930be36e3287fb768d1f",
        "transformers/models/roberta/configuration_roberta.py": "60f1528a4046e9e172a601b54d0e23f7a071f59a6e5f5f0d22c98082bcfa34d8",
        "transformers/models/roberta/convert_roberta_original_pytorch_checkpoint_to_pytorch.py": "e6c5f93ed52c7875971fbf314c15ea1acaf39fc62db6b66cb8dd04d07f425a2e",
        "transformers/models/roberta/modeling_flax_roberta.py": "073e5580a2b05a75559911721c3d75520ec896f83038b20c6c623494190c1edf",
        "transformers/models/roberta/modeling_roberta.py": "2b171c5bedbca2450b33b25d94a231c0fdb9d25d91b78f5bf3638af459fa8c60",
        "transformers/models/roberta/modeling_tf_roberta.py": "12029fa4113c55e5dfb8890fd90130b599683ab6becae6fc5ff42bcf1c4e4dac",
        "transformers/models/roberta/tokenization_roberta.py": "e05b76316846e044843b6c89d1affc8da514f7c231207da82daa2b868b690b5c",
        "transformers/models/roberta/tokenization_roberta_fast.py": "3b75bd3fc8bfe66f93991b8a7fe7a04203eb4e4a0e1de3b5e416c75ba0359727",
        "transformers/models/roberta_prelayernorm/__init__.py": "bd325132a0b1593625631fcc8f9f6564521b2928027981f20e80ac7b2b058233",
        "transformers/models/roberta_prelayernorm/configuration_roberta_prelayernorm.py": "1313f97ba2589c381b6546309ba2d7cc4e00e7ca72c53c7e5c52d260664d4604",
        "transformers/models/roberta_prelayernorm/convert_roberta_prelayernorm_original_pytorch_checkpoint_to_pytorch.py": "0d684db83528fdd66c5928c920fccdab1018f4acd69405a7a6037113cf2aa564",
        "transformers/models/roberta_prelayernorm/modeling_flax_roberta_prelayernorm.py": "93cdc27ff169ccb82e5c81ed24948ca63eb2b95cf2fc675d143a6e9159a3b1c2",
        "transformers/models/roberta_prelayernorm/modeling_roberta_prelayernorm.py": "b0b83fc2a48cb70fd9c603b6f8b7293e4c57f0d028eaae220a885192b3851ae1",
        "transformers/models/roberta_prelayernorm/modeling_tf_roberta_prelayernorm.py": "2132c93688f0ed14a25f6718954c1c66b91b324cd2bcd97f00705a59413a624b",
        "transformers/models/roc_bert/__init__.py": "c36388f0e7d265de334a57cc166d5fe2ecb958c6640f4f52063a19764aa5f67d",
        "transformers/models/roc_bert/configuration_roc_bert.py": "6da591b4340d498835e218abafb574057e37b1bffd5b5746f9529cf42a612749",
        "transformers/models/roc_bert/modeling_roc_bert.py": "8877e45624584045a0598939c163300bcdc691e74c69302730f9e76074b3b75c",
        "transformers/models/roc_bert/tokenization_roc_bert.py": "d31c80a7cb5c85d6b870e51cfdf839d6b0a50139f0f3ef9ff92b502edfeda401",
        "transformers/models/roformer/__init__.py": "7642580e179bbc413f664b6b48ff5d395aaf9f763ba61bc6d197da8738e6c299",
        "transformers/models/roformer/configuration_roformer.py": "1a105d7efafbabde2991a1ec86c78ee1643ae717ff64b9550b8b8ea5b02570c1",
        "transformers/models/roformer/convert_roformer_original_tf_checkpoint_to_pytorch.py": "4d2ebeafd195d83257a1ff689c58a1060bd75dd9f4f1a974fe426eb52f1cc044",
        "transformers/models/roformer/modeling_flax_roformer.py": "bed5ae6723c17d3cc1865563cc9b5e99b4834e883060efc09bd1b18cf865bdde",
        "transformers/models/roformer/modeling_roformer.py": "36cafc00e1a77dafa9554878d3196e8c89d2d22cc0f1653edcb422d14b33d128",
        "transformers/models/roformer/modeling_tf_roformer.py": "5e49896914a63dd390737ab9ab7d36f625a59b0743bbd614af93ab5221e72ecd",
        "transformers/models/roformer/tokenization_roformer.py": "5e14ac505bcb9f6b54237f2546770790e7215be43b149b9455202e8aae5fc993",
        "transformers/models/roformer/tokenization_roformer_fast.py": "e6f9a8dbd744edb1f41b22f10dcfdc321b99dfb66f5b7fe25f6104ef14b241fb",
        "transformers/models/roformer/tokenization_utils.py": "d1c887d77a96da409ae66cb5acfc1fc00b925d7fa31b33749f37a6bc6bce071c",
        "transformers/models/rt_detr/__init__.py": "c5f99c3dd4c3539b28d4f46a571f889e4d8d699fcd2e6c836f22b15d9ed89f75",
        "transformers/models/rt_detr/configuration_rt_detr.py": "e14c80f2ca087cea234fb41f35114648849a9a23daab309ab420c7d57e457169",
        "transformers/models/rt_detr/configuration_rt_detr_resnet.py": "f23225561fd15d6fa84db88c25053d105ab7844c2e0dbc8ea6c4c6d47d4e1e09",
        "transformers/models/rt_detr/convert_rt_detr_original_pytorch_checkpoint_to_hf.py": "2f6b449cfa7834d2655ec23e7c106989bd1583beaa2f7c4df8e2efadde36f49a",
        "transformers/models/rt_detr/image_processing_rt_detr.py": "5bbde971f35f059c3eb3c6f819e8c2893291883c5019f23ac25f87b3f8e81279",
        "transformers/models/rt_detr/modeling_rt_detr.py": "90e6ff6ed2c51177aef18dd99c74a6a374eb5f613ee564718944b648a930bd7d",
        "transformers/models/rt_detr/modeling_rt_detr_resnet.py": "702106f6330af2a87dd7b12f689991bb1d07a70baa8b0e1eaf71a5d61d9b2077",
        "transformers/models/rwkv/__init__.py": "b4c3f66ea313894e8ebd77c409efc038e7a946cffa9431e636c6db9da9bb972d",
        "transformers/models/rwkv/configuration_rwkv.py": "6f78ebc9564eb2b0117166e0a975b49a0fafbb0adc0e45e3ef4a2e26ef9a733a",
        "transformers/models/rwkv/convert_rwkv_checkpoint_to_hf.py": "57a979324621422b2fedb0382d46fdeba28319202ae3c764d9528189efe2483b",
        "transformers/models/rwkv/modeling_rwkv.py": "578f8117e203aa3e9bf279dc7a7fe02c25d3dc80f189ae4336c6bb57f6e76dee",
        "transformers/models/sam/__init__.py": "971df5035ac11eecb542c3d61afc542d7cc7993885312dcec36502321adca8dd",
        "transformers/models/sam/configuration_sam.py": "fed33241641b06c76cb64891a73ed310503ecfc340087e7decbb34b3ee79742b",
        "transformers/models/sam/convert_sam_to_hf.py": "4deaf6daa3a198dd5e4322a2dfcec72f428206b8ab9cf9ebd5ab14e01a1b4249",
        "transformers/models/sam/image_processing_sam.py": "9037d7ecc0aad54c2a5d82eb57b794c3ddeda5f711ac0e8410f5f6b54d8e56c6",
        "transformers/models/sam/modeling_sam.py": "a337ce746139b5891242a4e27e09e5444caad9138ebdb355cd69fd1c39d498a1",
        "transformers/models/sam/modeling_tf_sam.py": "439077ad52748c45731881b980b0ef79442abb3ca2ab1dd532445a55bc9a55b0",
        "transformers/models/sam/processing_sam.py": "52d84bd5886d29b4bf8672d4a16144668648136a0ea9e0463c3e51b8fc91fb3f",
        "transformers/models/seamless_m4t/__init__.py": "390595d2c6f637b7b7159a4cb7d8c728c8d89a58c56a821f13a2e36214f3133c",
        "transformers/models/seamless_m4t/configuration_seamless_m4t.py": "c005f6bbec8ed4dd86fe091dbb87deee1cb7871c7048a571fb5919d014735f66",
        "transformers/models/seamless_m4t/convert_fairseq2_to_hf.py": "010ef99105c3d18bf55e7e72fe67f7161ac74a10243baeb0aa0fd8fa8f77ab2e",
        "transformers/models/seamless_m4t/feature_extraction_seamless_m4t.py": "23b95713c051823536ab56c8b00495635e6990373a64ee9725ba9be455491117",
        "transformers/models/seamless_m4t/modeling_seamless_m4t.py": "e72ee579e929e857a820a75b46e1747bd31acbcd6bb75f5a66cf9f7d8c579eb0",
        "transformers/models/seamless_m4t/processing_seamless_m4t.py": "3ab3ef0c9900008ba85a0972c6dd59e07f7dded9be0325f73b10dcbb81a6a6cd",
        "transformers/models/seamless_m4t/tokenization_seamless_m4t.py": "79b17ea3ecdfab6730a6ba60da9febcece3ea472d2321948c0fc20ebf40ae047",
        "transformers/models/seamless_m4t/tokenization_seamless_m4t_fast.py": "fca4e4875cba68600763818ee49e404eaa992580afc9e94c45ccdfa0c8c7de80",
        "transformers/models/seamless_m4t_v2/__init__.py": "70f6bd600cb46b660104ba52d3c61903ab4e732de42c3a72f2746b52a9edd955",
        "transformers/models/seamless_m4t_v2/configuration_seamless_m4t_v2.py": "f8198b0f9f861387f8535bb3f5eeb7183480aa9c67388a2c744a975d00d328ff",
        "transformers/models/seamless_m4t_v2/convert_fairseq2_to_hf.py": "ddfb96d881a826934a546084f585eb59b5d9bdda24a3a71f40bc8b327e70c9c8",
        "transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py": "44108332242cc93b79217244ec6c7949bf2867aa3b48fc68a1b654ae1eaaea40",
        "transformers/models/segformer/__init__.py": "b789e74bacd132dfd65ab50b0ae2cb953b32c32deab0e5340693fe28192538f2",
        "transformers/models/segformer/configuration_segformer.py": "c5711afbaa5fa16254247fcf8ff369c07db63d57a33c5ccaaa16fd688fa67827",
        "transformers/models/segformer/convert_segformer_original_to_pytorch.py": "2713a9103049fc8407365bdb5c00e5320f4f050c0f752808e326dcf248f684f6",
        "transformers/models/segformer/feature_extraction_segformer.py": "c9a45c9266e64f28753a8c373e71cbb235b831445a5aa75d853cc6f8f55ccb09",
        "transformers/models/segformer/image_processing_segformer.py": "d7ed624f5e06d7535fb779287a1de719dce55b52b55d4506b83806e9d25414ae",
        "transformers/models/segformer/modeling_segformer.py": "843ff98ca2fc6b673f11cfe4af438bc418582a0b58a613711d8d4a3625e55586",
        "transformers/models/segformer/modeling_tf_segformer.py": "3e73e7f0e5e0689f3819afd79d633ef39462836293d7ff5117e2b0a809fe2109",
        "transformers/models/seggpt/__init__.py": "13f3e6ffc7bebf4b44c1ee4426e30e3d6f5fae64b525dfb847d7b6109d0848d6",
        "transformers/models/seggpt/configuration_seggpt.py": "1ee65ded193f4e9ef59046e2ff2ae04324e4ea9d9eb5cc3dc041a13f5949bf33",
        "transformers/models/seggpt/convert_seggpt_to_hf.py": "0592c1ad39c22cc2e06dc4596d493cb1f968d51fe3a4c4b646ef741b0a50b71c",
        "transformers/models/seggpt/image_processing_seggpt.py": "d5350e5a4432e5bef3d48f5a9ffdfbf6f0beb3ba8ced51c9d797fa01c435d027",
        "transformers/models/seggpt/modeling_seggpt.py": "0cdd89d2097a0f2f7d9f349971dacc22f3e040aca0f19b8a7eaf5c2a2a30365e",
        "transformers/models/sew/__init__.py": "e1b1720300aeb9ccb8350fd0aed94fc22f8afa3980bd4efe3a64045a0d87b5eb",
        "transformers/models/sew/configuration_sew.py": "880084916a9b0e3aded46b5dc572c34262743db581da1e41119410f6aa31140e",
        "transformers/models/sew/convert_sew_original_pytorch_checkpoint_to_pytorch.py": "48e593e2be3b9e9f332705ba7dd5aab6009fb900078d751552030767a4930830",
        "transformers/models/sew/modeling_sew.py": "0dff1deebdc3804fff4c2593d78d9d7320da315a67ac9145e6908ced7dec7f51",
        "transformers/models/sew_d/__init__.py": "8eacda4ae4b2c22c94373a270361de8794c556b21a068c6fbb6a374d51881922",
        "transformers/models/sew_d/configuration_sew_d.py": "b5cc09eb4eff4ee225633e7072801f6ca438f80229dbf97180f3fc08270326be",
        "transformers/models/sew_d/convert_sew_d_original_pytorch_checkpoint_to_pytorch.py": "e42cbf15f66bd7eeca826bbc8a99844d0b77dc14f23c58d7f77b6e68f57fb51c",
        "transformers/models/sew_d/modeling_sew_d.py": "03e0daa4bf74f00b91f1c41f32429d61ac3a82c2fcfe8aad85a2438707a68b57",
        "transformers/models/siglip/__init__.py": "12a366c6c0f2b0e8a74dcdba5622d7bd671a3e3ac6f94bcd6359f6e07e5f774d",
        "transformers/models/siglip/configuration_siglip.py": "9c441271fe1091be81a675e428fe0b9cbd65c2a26242cca7e0a0366611b7197b",
        "transformers/models/siglip/convert_siglip_to_hf.py": "25694cce319c4bf3a0204eca1a5557d7259026c569586ed7deb2c2a1791427dd",
        "transformers/models/siglip/image_processing_siglip.py": "498e6799da03ef65ebcd1cebe2c2a921eb6951aecaf0e645da88ea4f7c580d13",
        "transformers/models/siglip/modeling_siglip.py": "28ff4f412be8cb9c2398bd7bedd47685d1f9c806e6fa69e1761a6d7f3e7c2dcd",
        "transformers/models/siglip/processing_siglip.py": "c7903d08acb3373385d2e757bcc550e213050426c0747f969cb017aa8a7be739",
        "transformers/models/siglip/tokenization_siglip.py": "bc96250830d3f20e4647f848737dd9b5cf3de359206b8dad92d05d64cd00bd8d",
        "transformers/models/speech_encoder_decoder/__init__.py": "f7cecdcc1b5e11b432d08618e3707f24aa25c3605bc97e8ec7db3fff11f475a4",
        "transformers/models/speech_encoder_decoder/configuration_speech_encoder_decoder.py": "ee1cc213bdcb7076e2ab76f8a53b0c752c23b65e22cceb68644fa5755b3c071e",
        "transformers/models/speech_encoder_decoder/convert_mbart_wav2vec2_seq2seq_original_to_pytorch.py": "4fb4e53790c46ee315800b4ad31c258c13841a31c64f367a35d8fb57e5d549c0",
        "transformers/models/speech_encoder_decoder/convert_speech_to_text_wav2vec2_seq2seq_original_to_pytorch.py": "c326971362027fb601a1a2718b85b86bd81bc63196ef3c2974ec4908f06c2c70",
        "transformers/models/speech_encoder_decoder/modeling_flax_speech_encoder_decoder.py": "6b8e83f0067904e72aee3e609d39a5c82613f4f9b4a6670853df912fdf57c30c",
        "transformers/models/speech_encoder_decoder/modeling_speech_encoder_decoder.py": "a718f154c0251d1c63078caa8a8cb047eff7ecf94d249657547814a29768ef61",
        "transformers/models/speech_to_text/__init__.py": "7ad471b5aca13c0e281a5544408eb1da75c3fb1fae4311fd17143983c90fc3c1",
        "transformers/models/speech_to_text/configuration_speech_to_text.py": "3188e70ecc9b1b75b3881c65df18a7a4d45cae251d35c7026a8cf5f0ad56c550",
        "transformers/models/speech_to_text/convert_s2t_fairseq_to_tfms.py": "bfee5a48fc2e08a0adab053c811123f700369e6d7867deed83ac10dd2e3b828b",
        "transformers/models/speech_to_text/feature_extraction_speech_to_text.py": "7cf533625827902bf69b382d65596f225d66cf187fed688fb07cfc009d5ecdf0",
        "transformers/models/speech_to_text/modeling_speech_to_text.py": "b11be8bb5b036fbb902195f41a3da1275a983df8b848b7222821e9e12548bdcf",
        "transformers/models/speech_to_text/modeling_tf_speech_to_text.py": "a96b8f23a5ff752e39dad55ed7d226c2192c2a3dfdb7172826ac7331d2186cee",
        "transformers/models/speech_to_text/processing_speech_to_text.py": "952472a74f3ea705c7986b2e30afdcff5163f4db8bdeef3642d1caf04be948e1",
        "transformers/models/speech_to_text/tokenization_speech_to_text.py": "4ac51b0238d9666f12cdb4e828ec48908f945f7ac7c874408d3c1868432afc21",
        "transformers/models/speecht5/__init__.py": "c23ff56fdabb2d7c3fe98ba88ed93970998cf7839ab53afd3bfdf51222e1ba2d",
        "transformers/models/speecht5/configuration_speecht5.py": "d74cc8dd4b0e4b62de49da94ed7a0fcf5b19b2c52f37aecd33263ec675130ccf",
        "transformers/models/speecht5/convert_hifigan.py": "08bf46497fdb8a68e6fe1536ac4e7931a36f4d48d3b560faa82b6a34c697cbb2",
        "transformers/models/speecht5/convert_speecht5_original_pytorch_checkpoint_to_pytorch.py": "03202369e89b7b7d34d986514f699aab5622f3e88fd63ec086ce6ac58323889d",
        "transformers/models/speecht5/feature_extraction_speecht5.py": "95c2b1dcd6885f1d0f1884d128fd2403c4992bbe647754a7f0f3472c19fe493d",
        "transformers/models/speecht5/modeling_speecht5.py": "0b679766a2eac322d1952ecc04b0365aa1be4db0355b022b99bfee711d6893aa",
        "transformers/models/speecht5/number_normalizer.py": "7319c451d1d22125b9780a35e5c2ee56465aeb9ccc16e305689f3300e402b000",
        "transformers/models/speecht5/processing_speecht5.py": "b26a8576a289429f559b51437e68fb12f25e0192923c1eaed8064c7ec8ec41ad",
        "transformers/models/speecht5/tokenization_speecht5.py": "6d205b4d637edb24e0913f889669466f327d7d5ca89c7e72f8eb8e03e98d8cad",
        "transformers/models/splinter/__init__.py": "7509a06353423578bc70775eb3351d5e37b5a5219d4d1c6c26e7c22f7c195480",
        "transformers/models/splinter/configuration_splinter.py": "f9f9fde331c132d1d835309b08b5cb890dc980e0ccbd2068bd8a3033df155b93",
        "transformers/models/splinter/modeling_splinter.py": "ee72390c679828b7656bdf32bbef358e7b6a036a13cefbc51051cc9d25804766",
        "transformers/models/splinter/tokenization_splinter.py": "81a367437a75b7a823305d1847de5d7f0d725e300b06216e688770e50e5e56b2",
        "transformers/models/splinter/tokenization_splinter_fast.py": "b7e81b57d39394035e650fd72e2579198a69f6a656f62ed596568b29fe3bced2",
        "transformers/models/squeezebert/__init__.py": "6e9e39c67742608527c2688bb1bb1edd2331c7aa800adc860470442eb85e9200",
        "transformers/models/squeezebert/configuration_squeezebert.py": "1f0dff16d855748d12164c795d3591a16f8829144a551fb3f377c1cb1a499424",
        "transformers/models/squeezebert/modeling_squeezebert.py": "d5d2f5a429873326c21201d0578e755131de95f0298e047ac5ab234f88724e3f",
        "transformers/models/squeezebert/tokenization_squeezebert.py": "0d462b309981317d64e5683c60f4f85d6c19d293cab55db9cf3fe39b8b34a9ba",
        "transformers/models/squeezebert/tokenization_squeezebert_fast.py": "276daad4f27ea9aef299cbefa66897d9fb763b15031e2d867629f2e2b3a23993",
        "transformers/models/stablelm/__init__.py": "ae5cb7a3bea2417872b37dd6cd9063f321c0200554bcc90daf5f8762d786a9be",
        "transformers/models/stablelm/configuration_stablelm.py": "beb4a42aa6eb343d299903c266cc44d36864fcf3820a9ea0bea62c5ad335e7bc",
        "transformers/models/stablelm/modeling_stablelm.py": "45e0fb11ad07020b65b729ebbbc75e8d889f6a9d7e986034df167b1f1c881063",
        "transformers/models/starcoder2/__init__.py": "2afbae1b8d7a69dfe8661c57fb3ce4024a53169c38432f5794cb3e09060eba0b",
        "transformers/models/starcoder2/configuration_starcoder2.py": "936b565de892bd6a18b2e667b4ffed01091e852989bd4699ca2b0d155e41cafd",
        "transformers/models/starcoder2/modeling_starcoder2.py": "8304cc3e3206c58f464b5f0b611ad064edd6b0c973828b4df715b57e11f4c246",
        "transformers/models/superpoint/__init__.py": "17af3d3878e3b67d45df97b309f30fbace5a0d688c4d1f1491bc418eafcc8f08",
        "transformers/models/superpoint/configuration_superpoint.py": "a80d255931db3c429fd9a07d835aafb2d0a2db812594aa6695f392a43752a321",
        "transformers/models/superpoint/convert_superpoint_to_pytorch.py": "b4ed4feb2a96e3a2d8d619d62093ceb382a35b4b995a4895596f864ce5db2468",
        "transformers/models/superpoint/image_processing_superpoint.py": "3a6febcb96a548fb6084c5437c55c8d82c03611366e2c8b064660f9aa74d1651",
        "transformers/models/superpoint/modeling_superpoint.py": "ca9b64f3cf5561d60a6903b32ac1f4a8a2ce4902abac8c04f95db34bb5ca29fb",
        "transformers/models/swiftformer/__init__.py": "65f7f808a2f24c21b56dbe0e2f583441a0a024de8ea99c9701d1b960ddba4028",
        "transformers/models/swiftformer/configuration_swiftformer.py": "164288c5a966aeac3f3d5fcab99563a67786a0ae951f948068ee638b785fcca7",
        "transformers/models/swiftformer/convert_swiftformer_original_to_hf.py": "7f7584d502461d6e8093c7eede7dfb4baf66f76c602027ec6d860a0ef89b9fa7",
        "transformers/models/swiftformer/modeling_swiftformer.py": "8dd9ed9af54f6fb72b7beb443c16bbac79fb60a1d03d226f5b8904b031c1a6b8",
        "transformers/models/swiftformer/modeling_tf_swiftformer.py": "37bc7b1dbb8a1afc4e7be59efa21306cd56c759fbe7bcfafa26d8bd0b28f5133",
        "transformers/models/swin/__init__.py": "d0ace02f02f5b6f3e5a809aeff716882a48cfdd347c777e074e31076b21e080b",
        "transformers/models/swin/configuration_swin.py": "6a898683a0458a07dd5478bed581c43ef654c25e4c23d6c4c37871a780f9b7b6",
        "transformers/models/swin/convert_swin_simmim_to_pytorch.py": "df9681758fdd1d54ae995bfebe5eaa4bdc2e25e36ba964f9124313be8f3355fa",
        "transformers/models/swin/convert_swin_timm_to_pytorch.py": "504e57c644cd2598d32b07cafeea48f9b3aa6701397c88108c90d2a0f2a44fe8",
        "transformers/models/swin/modeling_swin.py": "9351b4b5773e6814a664d0a96f6a769918a0a005cdd6c739b8729e1599fc5291",
        "transformers/models/swin/modeling_tf_swin.py": "f8f78ffa3a4013d814088df3cc8fafc5ef25f873edc3e2d5fa7f9c9f26a696bd",
        "transformers/models/swin2sr/__init__.py": "e5ab205cf6533f311f8768664d673cced60198db440284b34ce191dfbfd4fb0b",
        "transformers/models/swin2sr/configuration_swin2sr.py": "166885594e2d79c2da3916845264958861388bcd3075231393417a0e57cee88c",
        "transformers/models/swin2sr/convert_swin2sr_original_to_pytorch.py": "c6fe03917327e24781464f252da1b92aaf750dd40c9f8abfdb95ae74f098872a",
        "transformers/models/swin2sr/image_processing_swin2sr.py": "e996d569b6649a6187118c1d2754b1bb071899e5d7f651777a58463f5cca3725",
        "transformers/models/swin2sr/modeling_swin2sr.py": "1d414d510b4b570218a73420e749e53cc7f8986cfdc54f7bf3b4d8ad278b16ca",
        "transformers/models/swinv2/__init__.py": "1843d32fb442d78790adcf1da5d188aafd38eb3e54e84c9912b63d703ba1176a",
        "transformers/models/swinv2/configuration_swinv2.py": "3d0ca4805481e3e317dbfc2314eec473f1587b6e523c6452dea6b53fa2b57f61",
        "transformers/models/swinv2/convert_swinv2_timm_to_pytorch.py": "120e40487c38ebf86e6270e7f9009d55726749bfd4e507f3ae4b57fff9cffc3d",
        "transformers/models/swinv2/modeling_swinv2.py": "66c3d22b63b4b478055ec6e0a609fce48ebdbf7a29076fe13a2606d56cdc243d",
        "transformers/models/switch_transformers/__init__.py": "23b98c3a701096b41095a588ceee9ac5c9a7e3a939159b868e9f725dff6a5f9a",
        "transformers/models/switch_transformers/configuration_switch_transformers.py": "bfc5dcc831b28b40c82d5d91ae4c5fbb4235594764b703126dc16f7f11d59497",
        "transformers/models/switch_transformers/convert_big_switch.py": "c233068c75c0a95a2897a7d9421746fc0bf6523c7d103a19aed1c2f117432e4e",
        "transformers/models/switch_transformers/convert_switch_transformers_original_flax_checkpoint_to_pytorch.py": "00024d90f72bfd31e33cdffc4549ce74161b6d873a18ea97760763871f45672c",
        "transformers/models/switch_transformers/modeling_switch_transformers.py": "38cbc359087530866bd35d67ffbaacb1d7bb3ad9d3b5adc327542c9615e302a3",
        "transformers/models/t5/__init__.py": "d1bdeafdefade94de70c7cdcda1f3c5cfb1cbd40d10a7cefc7f2b496c714b40b",
        "transformers/models/t5/configuration_t5.py": "7e341d0f265cdcf4b9f17db120ce41396dc84538cd19020881c3f3ff923ebd8e",
        "transformers/models/t5/convert_t5_original_tf_checkpoint_to_pytorch.py": "2c489b1cf7650dd29dc81e971c1e6cee91d1b2a079a90c5458df771fc1bfab99",
        "transformers/models/t5/convert_t5x_checkpoint_to_flax.py": "3cb81f7b9bbf81c16305db829807ae29a0d6e158c9b4fe8a2acc78cc8457f21b",
        "transformers/models/t5/convert_t5x_checkpoint_to_pytorch.py": "1931741581c30c3065dad718807722aea1ce23628e1366240c6e1e9338e1fc0a",
        "transformers/models/t5/modeling_flax_t5.py": "009fcac59b80bcf7814c5ad72d20c0581ffad61d09a8b3391ecffdf4abc30d27",
        "transformers/models/t5/modeling_t5.py": "b98cefd7c49fbef729748e27213f3e6f573f9ddc026250d7c885bee93e349de0",
        "transformers/models/t5/modeling_tf_t5.py": "291361836dd69410c67161ff53d303f5d7489a1f2f6f924f1a37cf37fc34dc8e",
        "transformers/models/t5/tokenization_t5.py": "5fd05f19e10e2d72a43800c74641fc0f6443ee5266a769def75c0445b2131b64",
        "transformers/models/t5/tokenization_t5_fast.py": "f1771cfa71caf485de2a232b3a8f468020f7651b75f0e375b189b765d5d3ad8e",
        "transformers/models/table_transformer/__init__.py": "e55273cbe385cd9b4cc8e236bcaddf639162ef1a07154db7ba30ec3b58b0c4fa",
        "transformers/models/table_transformer/configuration_table_transformer.py": "dfcff10dc5d47177dd16990d7a3d292adcba48d8a608b1569b30ce101b6cf8cf",
        "transformers/models/table_transformer/convert_table_transformer_to_hf.py": "170efe05f104962e3f424e005d9f6c35f8a2b73e88270c9318f76d086964060f",
        "transformers/models/table_transformer/convert_table_transformer_to_hf_no_timm.py": "f40de1c1d4166b285cf11a31516a4ba0fca18691c3b9582178837f30e90b9d82",
        "transformers/models/table_transformer/modeling_table_transformer.py": "906d9c8ccf451ac8d5c42a932899e5397d9751ca3de34b3acd4f34205bf5d3e6",
        "transformers/models/tapas/__init__.py": "8b26f92f861582e6fc6005e9f3d2ec1e3adcf3584fb53934c6851b45907fd682",
        "transformers/models/tapas/configuration_tapas.py": "63a7dd3de7c129d9256a9c6799d671363621e224e0360bf7cac140db20ea135d",
        "transformers/models/tapas/convert_tapas_original_tf_checkpoint_to_pytorch.py": "2baf5d489fa1e176e2621ff8a5ded45fb284ad74e1c7c76d0ce45a8827012933",
        "transformers/models/tapas/modeling_tapas.py": "8ca6f6f804b41948d80e49d34467d9a0207fa4210cbebdbce42c6d73fc7c10e3",
        "transformers/models/tapas/modeling_tf_tapas.py": "6a286afb612f5edf5b42cc322ce951e017dda9e4ec0f1e2ee282239df57bfdea",
        "transformers/models/tapas/tokenization_tapas.py": "c57e80041a9cd5988078ddbba8648a48f7fda29b42d6f6404d7c1a7f1507bcfb",
        "transformers/models/time_series_transformer/__init__.py": "4860a39de6c32de09938545c4a37a88cbdc8808b96e0bbbf947c315fb5d66ab4",
        "transformers/models/time_series_transformer/configuration_time_series_transformer.py": "023815c3a62309a6029c92624ff579fb96e064c12f4199e5209e8c06b5df589f",
        "transformers/models/time_series_transformer/modeling_time_series_transformer.py": "b2a501e3f95d220fe879bf342b4cda4913b8940484ba9b310e1031fa708ac871",
        "transformers/models/timesformer/__init__.py": "0279a870f96e9ee2007a1c09ec4612b8a242cbc416b6b14bb03fbb36a03a754b",
        "transformers/models/timesformer/configuration_timesformer.py": "dc55f8aecf20f2fb02444fcdf06a61209f886f6a7289480f8ce38b6bb8dec4c6",
        "transformers/models/timesformer/convert_timesformer_to_pytorch.py": "4e339f3db102e2855be6d94e814da6f60dfa3818b30c41239b46db719cfa32af",
        "transformers/models/timesformer/modeling_timesformer.py": "fb92c8b1b2a8b1f3917fd07a2667466771ec1e5d3cb9569acc36056b6ade6c20",
        "transformers/models/timm_backbone/__init__.py": "ae7f72d705e270fd60e88888fed496bbb7e7b79abfc7a85fbb783dc90be8bc45",
        "transformers/models/timm_backbone/configuration_timm_backbone.py": "a58ce34285952e4c54192704a0cf54080993808781158c360e95ce4bf64e5ec8",
        "transformers/models/timm_backbone/modeling_timm_backbone.py": "45644f95358643ea3388130d5020a949d6905a2596fae863ed13efce37a678e2",
        "transformers/models/trocr/__init__.py": "0629c014c6751b043c78dc1ef0c277382f61744c4e6c552e776853ac77914f64",
        "transformers/models/trocr/configuration_trocr.py": "58b57156bf87c3c2ee985ebb2e4a5caaa84a3212988d5fd711ce4e271b410f0e",
        "transformers/models/trocr/convert_trocr_unilm_to_pytorch.py": "14ee94e8be750d80710b1bda957455a6c7d965628aecf1d957eea7260b7889c2",
        "transformers/models/trocr/modeling_trocr.py": "f71f53d91fce3bc08cd07c4ee8282b451ec12e197ef1f6d1d7a43af39b4262ef",
        "transformers/models/trocr/processing_trocr.py": "eee078ec2af649a8c15bfe0c85b744989ebe9ad7ca9ee2a5f0f859cab2248d66",
        "transformers/models/tvp/__init__.py": "7258d4bb0cb4b53b2f757b1d64e4e5f0182b4f2f2c46bb821561540e86c8faa2",
        "transformers/models/tvp/configuration_tvp.py": "2b7b840aaa9c7fe48f383b145998d780e49cadac31a756ab8e38501259879821",
        "transformers/models/tvp/image_processing_tvp.py": "2ad0c6e0cbedac1483ff86cd22e026537cb192ce91af6b8ea3045ed709cbd6c6",
        "transformers/models/tvp/modeling_tvp.py": "d17ccfc1a23bc2eba5a4404219412c25c7d38095957593bd8785215c3834bede",
        "transformers/models/tvp/processing_tvp.py": "73d9c445930e831b2ef302d0f0a849f1bdfbfcb2d445e5114e8b9803418ce978",
        "transformers/models/udop/__init__.py": "7a8a5839790c19c53d0e1a6c05548f991106e6719017b311752802bc7c136fd6",
        "transformers/models/udop/configuration_udop.py": "e30ffdb8cc61d5ec6aaca4c7a9f9949038ee37006cd1c5eef1591cd65018adf0",
        "transformers/models/udop/convert_udop_to_hf.py": "dc790c771577f4c6811cecc81d09c0cc19c0ef2c68cfb665f3ba6ca66391af74",
        "transformers/models/udop/modeling_udop.py": "eb6f99eed070418273b7cf53dd0d336e7208287e5961804badb09824027dd75d",
        "transformers/models/udop/processing_udop.py": "2ee8bfca58a3e574fcfa81da2429d80567890db827d767ecb70c3340933ecce3",
        "transformers/models/udop/tokenization_udop.py": "435ff32017a954fadf38dc6dfcea73e064bc0289ad2bf6ab5e4099ef8c6f7ffe",
        "transformers/models/udop/tokenization_udop_fast.py": "d0219e25cacce12b052629da662994eae043e3bf1307f02a03aa25f1c763a48f",
        "transformers/models/umt5/__init__.py": "c1c29b91d4bfb2eb99090b39d8ecf49417a021ad100d23d95b643e5c1a4cde7b",
        "transformers/models/umt5/configuration_umt5.py": "a8498d6a83ef796d72f2e11d83502c34ce29d1b080c62006bec7214af6a7e346",
        "transformers/models/umt5/convert_umt5_checkpoint_to_pytorch.py": "71207a4e86cbc56a1e34da8f5cf887e1838ac23d238bda612bc800e2fcedfa3a",
        "transformers/models/umt5/modeling_umt5.py": "40042c4b818bc9a0c0c73ce7de75cd38e82283e64064b2ee12e2f40308973df9",
        "transformers/models/unispeech/__init__.py": "bf55e5d8a36ba2c165bfe7a9f5b5cb88c2f50bef65862ba5b51f949a507c5c65",
        "transformers/models/unispeech/configuration_unispeech.py": "6f194c72b9b2255cad5a782f20e6bbbf3eb3bc48aa23b7d5b9ddb5abb95b9aad",
        "transformers/models/unispeech/convert_unispeech_original_pytorch_checkpoint_to_pytorch.py": "f52cbc44ab294bf99be2b4e5e2df4896a35a3225d0cf7d404eb59115f339c610",
        "transformers/models/unispeech/modeling_unispeech.py": "06007b8da419e17c9f7f1ede8aa04a3939ddfc156b47b75820ee9a34122eda08",
        "transformers/models/unispeech_sat/__init__.py": "a7519359cf4b53e3758c7fc8dc46391de11939e160533b874a5125a53a42ca70",
        "transformers/models/unispeech_sat/configuration_unispeech_sat.py": "581e5c4c325d4a510822c33e355187c72a9be56308448e0e8a057be3f1e760bc",
        "transformers/models/unispeech_sat/convert_unispeech_original_s3prl_checkpoint_to_pytorch.py": "38b3884b003cd8f841baa2133ef7d1edb3f6dc5c741b1bdbd9cd926c22a4fd76",
        "transformers/models/unispeech_sat/convert_unispeech_sat_original_pytorch_checkpoint_to_pytorch.py": "6aa9a1d009b5136ea27d11edf0cba38dd50ef421e4559eb38aaa0e22bde7ebea",
        "transformers/models/unispeech_sat/modeling_unispeech_sat.py": "a8708875b448cd2d62fde48ded03ba28b931965e8bba4e05e066f41d65ee55b3",
        "transformers/models/univnet/__init__.py": "9afbd863bced1a2ad2b47168689de4b047f662de91088ef6c670613f2488486d",
        "transformers/models/univnet/configuration_univnet.py": "eb1dbe90d586e00877912a8dfc1a4c7262b979db93e0be05b31a7449b70ee089",
        "transformers/models/univnet/convert_univnet.py": "47682a5dfcfc3aadabc08514d3557b4ffa12a03186d80e067adcbe47cd189f6e",
        "transformers/models/univnet/feature_extraction_univnet.py": "b27015750e429455ff4b0eeea60bd6cb326ae1b50d45e95141ac5c5b18072200",
        "transformers/models/univnet/modeling_univnet.py": "b00c89fdfe1f6d6c68f35ebcf1d6c579f41fd532ae6bd88e6c0d4024a1b3e28a",
        "transformers/models/upernet/__init__.py": "cf66afcbab4ffd6a4036218f039442c53ffdc8fa743df10395f5232fdad0b173",
        "transformers/models/upernet/configuration_upernet.py": "7f9dd7053f50429ab0ac95381cad696d6eccbab09d759b4bed2b747c1ccd6d8a",
        "transformers/models/upernet/convert_convnext_upernet_to_pytorch.py": "97f089a17c0034413dae6e66c291f06eeb08a092e637c8cd1a3c6c8fa5a166b9",
        "transformers/models/upernet/convert_swin_upernet_to_pytorch.py": "94757c484fdb667c4ea3ecc4276d52da7638e3db8f55cddba5c97624628d1230",
        "transformers/models/upernet/modeling_upernet.py": "83775897019df324383cd0a48b552e93fc58a0c37904b1af8045bd2920bf0882",
        "transformers/models/video_llava/__init__.py": "80e0793ac0dd57e6209ac89132de420dc3c29ed3f5af997c561fac29ee1a10ab",
        "transformers/models/video_llava/configuration_video_llava.py": "1b34f1e2b5b92f50bb862373463667d51b4300c320991eab909983ae2d5d379c",
        "transformers/models/video_llava/convert_video_llava_weights_to_hf.py": "dae6e415f7474d173ee813cb606d40f360da922d040674a49953cb43245cedea",
        "transformers/models/video_llava/image_processing_video_llava.py": "30cdb57e1445e246a1d7ccc84b174dc5aacbd4d418f1a628e67cc18837132c18",
        "transformers/models/video_llava/modeling_video_llava.py": "6359622b1555f4cb570dbc5a30b5f4a4776494c1c127fced3daa02daa880c477",
        "transformers/models/video_llava/processing_video_llava.py": "243496a1698756ed2ad3f72d20b5196d3d6a84bc501e428a73359595482c7286",
        "transformers/models/videomae/__init__.py": "ee63cb6e3df63826c703cfdc8413cd55411b0919b80703acdc5f5f1ca2928702",
        "transformers/models/videomae/configuration_videomae.py": "39934da605114d60540bd9abf19ba128fc8c5f0cfe0f917ff0176821cf7eb604",
        "transformers/models/videomae/convert_videomae_to_pytorch.py": "aeada74f66497a4adad46dfc90cd831ffa8ebdc6410d014d81b0af1f798a6636",
        "transformers/models/videomae/feature_extraction_videomae.py": "1e0e709858646e772a4779dfbed7af57a9ac69412abcb05fe26b4ee1a2026132",
        "transformers/models/videomae/image_processing_videomae.py": "12a2df53ba4a7b2a3e3e0910e4fcf8c6dbba5923af5154890fd72613f0dfc4a3",
        "transformers/models/videomae/modeling_videomae.py": "f24da57face6be0feb70c26c59a1a8d4dbe636d8c6d14648f7a3bdf668c9be8c",
        "transformers/models/vilt/__init__.py": "c752ceab5456ad1cef975668ea76bee911823f7da821003e0eb4397ccd64d393",
        "transformers/models/vilt/configuration_vilt.py": "addd847b7e429cd4173a3581793340659dae8290808b02b50e9d3ece3b3d76ad",
        "transformers/models/vilt/convert_vilt_original_to_pytorch.py": "3c4d48202d14c66cc434ffcbfc4bfeda63b0dd0e3737b1e9a20f88f2a40dfd87",
        "transformers/models/vilt/feature_extraction_vilt.py": "742d0697073fac35fbceaa7c07146dcda2e8810188e08e028d00a0c54ed4391c",
        "transformers/models/vilt/image_processing_vilt.py": "a7c61614934c3cd5c5dd404cdd7b88292a60991434b9c514a9dbc5ba0ceab675",
        "transformers/models/vilt/modeling_vilt.py": "f3a7e37455abca683df599ba439ce8ee5ac9d51dd6be32ad4b3f16c61c1c7923",
        "transformers/models/vilt/processing_vilt.py": "d2239a97c742684ec90909598db275fac1c6c690cf660524328c046f11511764",
        "transformers/models/vipllava/__init__.py": "113c74c98e0e7a6780cc1a0590e73293e7175559f1001e01cadba489223ac514",
        "transformers/models/vipllava/configuration_vipllava.py": "55b66f8aca9f85665f542fed3bd5525b7bd4a1ead790fbd4ad9dc3284d6ade00",
        "transformers/models/vipllava/convert_vipllava_weights_to_hf.py": "bbae3e94e5c313424c1a190660912dcab3a1de0a5e26dc520c2fdd0b4f267367",
        "transformers/models/vipllava/modeling_vipllava.py": "92bf06de9f2b2b776be9544e8162100f26e8d815c800f80d7e608d4a5a2cf5d4",
        "transformers/models/vision_encoder_decoder/__init__.py": "21142c4bee01cfe726e81f7bad2a1e0bad99d65d709ecd17543670067d4a0485",
        "transformers/models/vision_encoder_decoder/configuration_vision_encoder_decoder.py": "eb1eed75304eaecbca38ccb5d8d0ad6cf6ad636a9aa8e25a548186c72dee3c3c",
        "transformers/models/vision_encoder_decoder/modeling_flax_vision_encoder_decoder.py": "02da13cea523a255179fe3413ddce173680d45a0c95cf47dd9e1948fd7d99928",
        "transformers/models/vision_encoder_decoder/modeling_tf_vision_encoder_decoder.py": "af3ed23dc230a460879eb75993eba2c7d86c18e22e51c3a066321fafd535c716",
        "transformers/models/vision_encoder_decoder/modeling_vision_encoder_decoder.py": "1913427a06ddd480abf18346cfb604408014fbe6fbf171d4852be3ab8356e37c",
        "transformers/models/vision_text_dual_encoder/__init__.py": "9142ebb58d887b67a281d9fadf19e812a4549662a6df50fd994089b3817ad8ba",
        "transformers/models/vision_text_dual_encoder/configuration_vision_text_dual_encoder.py": "6b048cef9cea224f4f32486ebcc5d86b15be0e84b0eec3515f52a8ce0f6400e2",
        "transformers/models/vision_text_dual_encoder/modeling_flax_vision_text_dual_encoder.py": "2082707a3b45f085990abd57c16abb1b4fe1d2825127697901f0e913308414b1",
        "transformers/models/vision_text_dual_encoder/modeling_tf_vision_text_dual_encoder.py": "31648ccdd2592e2078b8ba87940b8be2287e02ddc2db62866af575c70e2ac7c0",
        "transformers/models/vision_text_dual_encoder/modeling_vision_text_dual_encoder.py": "b064104b36dec2a0a19c8ad68d7b17a6a1363e98db5f27d8bf07534dff44c87e",
        "transformers/models/vision_text_dual_encoder/processing_vision_text_dual_encoder.py": "5b1c3e4a1741c439162bbea17098c7aefc92a7eb96d32ad3be8a96a2ea2f872f",
        "transformers/models/visual_bert/__init__.py": "0b62ff443453b27a162c2f8578ddea0ee08aa9a7f6b9fe9b680c9d814359e0b7",
        "transformers/models/visual_bert/configuration_visual_bert.py": "9a175d521418dce3aaad34ecaa1d16efb6faa08fcc9348a9bd247b337d0a48d8",
        "transformers/models/visual_bert/convert_visual_bert_original_pytorch_checkpoint_to_pytorch.py": "8da29588fc6b161df4d99d26b8a9d0a2fa632e57a7ae84f54705de5c11958794",
        "transformers/models/visual_bert/modeling_visual_bert.py": "302650f7853f0c0e4c1e2f243857a48f552109a5e576038ba89f9abc53579981",
        "transformers/models/vit/__init__.py": "d54095937fb6f599c481746cf9894b3203abc5b9b2b78cc36e2dda5aa65dba5b",
        "transformers/models/vit/configuration_vit.py": "f30a9e66694c5e9a4cb2ed2ca11873ee7726ea28b74b82304fbf6884fda0c5b3",
        "transformers/models/vit/convert_dino_to_pytorch.py": "fe5191d2a0e7ca3071af406dc626f1c694b0a3bd736ba88ab7e089d9c297a472",
        "transformers/models/vit/convert_vit_timm_to_pytorch.py": "bd93ec71e299428f0e39569510c528cb91c033b289156e2f1bb0d2ab29d5a7f7",
        "transformers/models/vit/feature_extraction_vit.py": "47e5bf1cd3b26d2a4ac4a18a7e8e220c1e33193447796d5cabedbd8b09db565e",
        "transformers/models/vit/image_processing_vit.py": "3ef6438c91099182c145e0286cc238d3b78d1a0de51a3203a6a343480d545646",
        "transformers/models/vit/image_processing_vit_fast.py": "35419512f1508b003c88e2797825aa30a5f0f23e8bcb70b33e045c0a0b2fded8",
        "transformers/models/vit/modeling_flax_vit.py": "2ac4ea96c7b96f97ae46061786b5e836a08dbe8d0b10f046b94fdbd2e34ed32a",
        "transformers/models/vit/modeling_tf_vit.py": "468ae434a764debcee280234834d6b11c8841a985931d3733e4288c69c544165",
        "transformers/models/vit/modeling_vit.py": "6683fd999a848c0242b81b9457e749b9b19b9463a39948a401d3961003a0d8ea",
        "transformers/models/vit_mae/__init__.py": "eea3d315663f89c10cf11ed3ff4266a9c90247f281ad6e8f60b93232314d8899",
        "transformers/models/vit_mae/configuration_vit_mae.py": "75939329ce2e5d0a053d1233c8c0fba44bc2b49a30e2bf7c7a75c8c0b8ddb5d6",
        "transformers/models/vit_mae/convert_vit_mae_to_pytorch.py": "363e18e4b4bc1fbc5bc9635e2c4f559f4345c9749041811c8f54103333751dd8",
        "transformers/models/vit_mae/modeling_tf_vit_mae.py": "1c22707ef820f9c8476eb33830ac8a3248466aa55e8c66f9fe80f96a8033c66b",
        "transformers/models/vit_mae/modeling_vit_mae.py": "0a6fc32cd13c9bca8bf9ffa24c62b66fd2014d31fd51d71740a6e3aab092f339",
        "transformers/models/vit_msn/__init__.py": "eede962395b4372dea489614331af9ebb2edac1db04efa192420eb74769b28bc",
        "transformers/models/vit_msn/configuration_vit_msn.py": "5fffc480db532f27ca1caadd89f54cd86b6d142091c0ef374c922d93cea48ddc",
        "transformers/models/vit_msn/convert_msn_to_pytorch.py": "d71063aaf6ef885906c618bfc6adbde7a47ba99a4510174a3cd39061bf92a080",
        "transformers/models/vit_msn/modeling_vit_msn.py": "ad58f31bd449af2df836a5b79ad21ce66cba25c5de199719c9d7faaa53cdd82d",
        "transformers/models/vitdet/__init__.py": "2653ce8ed2256da6714be9268e1d1d12e0874016d1ca8e466dbe3f298f02095e",
        "transformers/models/vitdet/configuration_vitdet.py": "2980f0aa2e841a4aa782a1a07d122e82183924433ff047db2b85b0664da92ead",
        "transformers/models/vitdet/modeling_vitdet.py": "355c95baedbe0f202936c58f72ecf1b3074421b302e693e60e69d9425f38fbca",
        "transformers/models/vitmatte/__init__.py": "bd6f9245e2de54da3c4e1f3e5ede13bf7cc181bb171ff474bfbd6b4e11f88558",
        "transformers/models/vitmatte/configuration_vitmatte.py": "2e2dba2292e5f8f06858c8ea3602068d9e9f4c65f048a7dcab66953b28625247",
        "transformers/models/vitmatte/convert_vitmatte_to_hf.py": "d7172d9bbf279822de94f32a1897a9c52caae6c68a800e1bcb9093cf2c513ef7",
        "transformers/models/vitmatte/image_processing_vitmatte.py": "5f53e9db986f3886d8b8bb04de47a252114baa1fc175d84a90b1a7f48042b787",
        "transformers/models/vitmatte/modeling_vitmatte.py": "5949da9f0115b8e3d58f75fbeec289ec714245a5c0bfd19ec99b1f0a6137bb85",
        "transformers/models/vits/__init__.py": "be5c3083c35e0b046feabc79cf632e1f0b2ca8b490402b7e0f776314a5a92bc7",
        "transformers/models/vits/configuration_vits.py": "0ae079dc8da429f32f6ac1ab08673aa94720872fa0729af86251285f608b3b8f",
        "transformers/models/vits/convert_original_checkpoint.py": "37aad1cc168994cc51c13eeedf7914c892b2fb87c54d64c3ea7bbf4534ce1add",
        "transformers/models/vits/modeling_vits.py": "637b9bb69a3fe969f4d2ad95b975cfe648079c935f0a7b4eb9f8905d7c2813e0",
        "transformers/models/vits/tokenization_vits.py": "95052911559ec43b5b0c3f3535fb5f4f0974df556c74fca9f2a2adce5a83307c",
        "transformers/models/vivit/__init__.py": "ae3026159977557bec73f1e9f032f3f92e3cecac1708f83ebf5d4a2ec8499164",
        "transformers/models/vivit/configuration_vivit.py": "b3a93457d2ab29aeaad1f4f318d8cc0f124bb3280d98ec03b0f97ebfab22cfac",
        "transformers/models/vivit/convert_vivit_flax_to_pytorch.py": "ee5a8f2eb7c2dad391312ebd512ca764695564170fbf52e3ceded43baf19bbdc",
        "transformers/models/vivit/image_processing_vivit.py": "7abab730ffa32748d3625b9e168d8fed39bc9b75c0c753d17b65c80f743900fa",
        "transformers/models/vivit/modeling_vivit.py": "067c9171b4da530cd1384e599f24d5c2db67707ff2d0c68f5b9dfac0c9465cfc",
        "transformers/models/wav2vec2/__init__.py": "d8042f2d61cd2772aa6551652e847e7f32bd22982bd8b2204b61e6174ba903db",
        "transformers/models/wav2vec2/configuration_wav2vec2.py": "4021be8ac66e81b5845e50e9c1b3c62f76780bce5d57f336b597f8efbeab5478",
        "transformers/models/wav2vec2/convert_wav2vec2_original_pytorch_checkpoint_to_pytorch.py": "7775a1b10af9dc109512910d48ad0dd3e9560a4b67ba5da94f2c7d3b69f5295f",
        "transformers/models/wav2vec2/convert_wav2vec2_original_s3prl_checkpoint_to_pytorch.py": "c6d0bb83d7f38e98cdf997ae93632386b26c49b9fa86cd63853e5ebd9bed3543",
        "transformers/models/wav2vec2/feature_extraction_wav2vec2.py": "72a03611b72530ff9a7d595ba1057034d01b98576baeee641af3db1a377c11a6",
        "transformers/models/wav2vec2/modeling_flax_wav2vec2.py": "5f2b989d714cea89bdba19b195e02e838497c85b71b218a653061c0238c38131",
        "transformers/models/wav2vec2/modeling_tf_wav2vec2.py": "283d58114b579eccbcf9474d16845dba9e3e7b5163b7fbce153d2ed1b0f33e7a",
        "transformers/models/wav2vec2/modeling_wav2vec2.py": "d912d2238a95ea29399d4e47319bcfb202e09a28d53423d39168fea4528a7904",
        "transformers/models/wav2vec2/processing_wav2vec2.py": "51df5d13f7a015d8ec3ac3ec036815ab4718582eeea5f708916127b0548d3a7c",
        "transformers/models/wav2vec2/tokenization_wav2vec2.py": "c6038bc9fe6571948635567fb0408acd82710cf811746de3a464d5e8ef210c25",
        "transformers/models/wav2vec2_bert/__init__.py": "e2426e174dea8d88e2d290d1e365fe139d8ca91eb47c089d966aa5b212e13f28",
        "transformers/models/wav2vec2_bert/configuration_wav2vec2_bert.py": "d0be6095049d94e6d9a1454532b318937f741fe270c7140ade727aa598aa9f35",
        "transformers/models/wav2vec2_bert/convert_wav2vec2_seamless_checkpoint.py": "254e08422ff77607ff8ff7e82b926fa7109b93464c15b13dc00680f9646743db",
        "transformers/models/wav2vec2_bert/modeling_wav2vec2_bert.py": "6f531d1d163cdf038fac71a917474eb00809662e474f97f5766821ef86ea1d2b",
        "transformers/models/wav2vec2_bert/processing_wav2vec2_bert.py": "7c3e3acd03ad9c5e0e8d8fee14d1979bd95babf3c24987defbdbe55e242b4327",
        "transformers/models/wav2vec2_conformer/__init__.py": "6a9d459ab3bc870e3cb0c92598b326f969502a8f2ee9a0a1827bc6df32d7bf22",
        "transformers/models/wav2vec2_conformer/configuration_wav2vec2_conformer.py": "9e83b3fc77be929fadbece620aadf0fc5107c238db93c1fa01cc152c4353b3de",
        "transformers/models/wav2vec2_conformer/convert_wav2vec2_conformer_original_pytorch_checkpoint_to_pytorch.py": "809bc34ccca98b877008ce1137837b661f16d599c89366986bf56d3b8b9aad0a",
        "transformers/models/wav2vec2_conformer/modeling_wav2vec2_conformer.py": "854b131b636324d6e141ec69d9261c143ca5b0e1d32438947ff5f0c3bb8262d5",
        "transformers/models/wav2vec2_phoneme/__init__.py": "136c51c958b2cc221257c5c4ed8435831e56971f7f002a0f0c1e996449bd6d6a",
        "transformers/models/wav2vec2_phoneme/tokenization_wav2vec2_phoneme.py": "905e951ef202eebdd37656c76b251b58196aecc11e8bf870aa1cfae5ef69e428",
        "transformers/models/wav2vec2_with_lm/__init__.py": "77f96f93c40089ae0120a37b77f532dc7751aab0e9fd92474c367e9e41cac0f0",
        "transformers/models/wav2vec2_with_lm/processing_wav2vec2_with_lm.py": "bc1b9dac5d80c0d46ead2cdd212e3a9784f6ad786516f156a4cb130c938e679f",
        "transformers/models/wavlm/__init__.py": "3eb23663b346684ac8db301da96be572a937c6943955ed07ea4dee3abc3f5bac",
        "transformers/models/wavlm/configuration_wavlm.py": "bd4a37ef71e1ab5e3f198bd0613f7bce14f5f193c1172d3ca7b063a7663c78bf",
        "transformers/models/wavlm/convert_wavlm_original_pytorch_checkpoint_to_pytorch.py": "7586485fcab7f8943e2e48608318db3163e38b1bbf66938dc17a9046ef489a34",
        "transformers/models/wavlm/convert_wavlm_original_s3prl_checkpoint_to_pytorch.py": "a4c5c500271ee5480030ad6e1ddc08ea4b288ab143afa1b438447acf5c856053",
        "transformers/models/wavlm/modeling_wavlm.py": "4dd0d04bb62041b02fa861daf09d1f84973e567f1f8364464c6dc1fc61d1817a",
        "transformers/models/whisper/__init__.py": "7bcec2fe5b914e7d40150889330014872f6667338763e171cb99d37e434d39a8",
        "transformers/models/whisper/configuration_whisper.py": "c4165b93b0d8d921df310f53344128c40b3b7538db7177aae1c4f7d6c18d55a7",
        "transformers/models/whisper/convert_openai_to_hf.py": "7b513a9851d4c05e28dc1bd48703726be3f9c864461dc3c2c1d9e2e08d0e750a",
        "transformers/models/whisper/english_normalizer.py": "313275e8e86cb69ad1d97f28c1f10998e36a9284871f2cf3b4435e8e61214813",
        "transformers/models/whisper/feature_extraction_whisper.py": "92a7d57aa3791e834e8efc12455ae49f044c6c19a1152d8521ffed08e139e2d8",
        "transformers/models/whisper/generation_whisper.py": "19a1c4bf8c0d92550f067e3bcf47b731a81ab91e7d1a12dc5db245e1efcce6ff",
        "transformers/models/whisper/modeling_flax_whisper.py": "85e615d685fd55f33ab33d941c56a78beeb24538148569f28816f66919f22894",
        "transformers/models/whisper/modeling_tf_whisper.py": "1a4e6331e77cf0153ac7fcde1b7a3d29833a9c61f20ae485a7301cdfa20133d5",
        "transformers/models/whisper/modeling_whisper.py": "6587bfa49a9f1214e6d6de1b27d23f0c9e9f79c157f90970ea398441bd01ac09",
        "transformers/models/whisper/processing_whisper.py": "fdfd49c4cfeea1ee4a27d0ae0cd853b55a89725706e27039ed1b9862f8b09922",
        "transformers/models/whisper/tokenization_whisper.py": "c3d76b05c67548d673560b51521a819d18f881d2494269c61313d332ba17f327",
        "transformers/models/whisper/tokenization_whisper_fast.py": "3a2f2924cb9bc99f66ecae65f595565f680fe0ff53412a83ec9fded101369f2a",
        "transformers/models/x_clip/__init__.py": "1cd8e9bab8b9046e6a1aac2e8620183b75857ada7d69c9479b7d457d8cca9cc5",
        "transformers/models/x_clip/configuration_x_clip.py": "560874fac7108a4bb40500561035a2bed7146c95a28f814511a398fb5453442c",
        "transformers/models/x_clip/convert_x_clip_original_pytorch_to_hf.py": "5b35def082aa4b3e018bbf0422f440e82dd088b2f873e4a90118201e3216b6de",
        "transformers/models/x_clip/modeling_x_clip.py": "353756d769f7d79c112619ec50238efbeaf17b930567efecac805978bbc2f7fc",
        "transformers/models/x_clip/processing_x_clip.py": "beec2e37fa4d6a03cc7ddbc626b49b850553b2538704c185818576c43f411ecc",
        "transformers/models/xglm/__init__.py": "c8239f89d047b1e0f06e875e1baa0d95da038b7b916fbfd6a2da25cc8d5e3637",
        "transformers/models/xglm/configuration_xglm.py": "14587c9577da62930c5e5dcba41dcc818ec19b42602fd8d1306be609714f1cee",
        "transformers/models/xglm/convert_xglm_original_ckpt_to_trfms.py": "f5f8d73f8d273056e223d1f4555eba06eaa4f4942b3e100511108e0581e5ffb8",
        "transformers/models/xglm/modeling_flax_xglm.py": "98ef292746704aadd8172c44539fe265b1900fff1b2d8259cf4f40cc1ead6448",
        "transformers/models/xglm/modeling_tf_xglm.py": "e7cfc58fdb4780a240f58b0d93e3234de42de218ab56176012e5ad76361fcea1",
        "transformers/models/xglm/modeling_xglm.py": "b5b760d3004d623943cb05f5c587c5779f6adef0c2fa57683a02550c884b148b",
        "transformers/models/xglm/tokenization_xglm.py": "a08175f6105a343dda2079e3919463873ed8d35ef6834858cdd7c7e372dd117a",
        "transformers/models/xglm/tokenization_xglm_fast.py": "ec289c97c2259e8abf45bc0ad77ea185080188bebeb5fd21def8f189f5300331",
        "transformers/models/xlm/__init__.py": "049dfd2faa1ece68d8d1d52fd2908228980207ebafa3b781ba52478e7e5d208c",
        "transformers/models/xlm/configuration_xlm.py": "1564accd175c013cf03a30d85217e4865931cd4792f31d28de93e056a0bce5f9",
        "transformers/models/xlm/convert_xlm_original_pytorch_checkpoint_to_pytorch.py": "594176650b70cde8d81ad179e13a126a17a7211bc017182d519e5c933425f477",
        "transformers/models/xlm/modeling_tf_xlm.py": "b4c1f74e7f14433cce87bf3b1dbc046d0d57f377530855d894eeee78abf4c77e",
        "transformers/models/xlm/modeling_xlm.py": "495dfbf5679ce7eee0166ef69639f3c7ffc6ae81e8478d523ae3177ff4e1a1be",
        "transformers/models/xlm/tokenization_xlm.py": "80b5409849a1ab006473a8352542a46ad0fe6e416313d9821bfcfd3261ee21e8",
        "transformers/models/xlm_roberta/__init__.py": "1014fabf2b87ad87f517d196049032a7e8e1a073c53ff8704fed9f4989a8a300",
        "transformers/models/xlm_roberta/configuration_xlm_roberta.py": "eb0c1e997be711b5ca6376c445b5941093050aa0104c677f71cd38483acfb9ec",
        "transformers/models/xlm_roberta/modeling_flax_xlm_roberta.py": "3a3b2d1f6591ea88a88931af513e87c04bc9c643b1db88833767140bc3f2f014",
        "transformers/models/xlm_roberta/modeling_tf_xlm_roberta.py": "96d41878c613db3eae167eb512e07337b77cb9f993b4ea31ff059231c0c30285",
        "transformers/models/xlm_roberta/modeling_xlm_roberta.py": "445eeb66df7c591babb729c0271e80c26faeda7902e5bc1efcee82336617dd69",
        "transformers/models/xlm_roberta/tokenization_xlm_roberta.py": "bcf72c2995580f2592780e3c9fb3e425993988034a227832ce99330d5e9da1f6",
        "transformers/models/xlm_roberta/tokenization_xlm_roberta_fast.py": "88f8112669d214fa886dfdbdb1ac5913ef99180a4a2dfb06c7556ac43e127cff",
        "transformers/models/xlm_roberta_xl/__init__.py": "d6469baeb597adbbc640d7f2bc4a05900bb1af7f985f7307b49fbd279d03e396",
        "transformers/models/xlm_roberta_xl/configuration_xlm_roberta_xl.py": "25d89a5137f924c349891701e307e652dc9cf1624bd13cd7277b64b60e8d4778",
        "transformers/models/xlm_roberta_xl/convert_xlm_roberta_xl_original_pytorch_checkpoint_to_pytorch.py": "cd56ba6b3c7dadddf70f72641f6baa27a5b6d13a2c2725a2f5e2e6dcb36d7395",
        "transformers/models/xlm_roberta_xl/modeling_xlm_roberta_xl.py": "d4268e216628394502b80566baa52766b5b56282d7f1b7d00c9f4a21b2952f22",
        "transformers/models/xlnet/__init__.py": "a108a363cdcaefa2cb2aeb2b1224c81e65e9ff8ecd788c05a1b99869637e4c3e",
        "transformers/models/xlnet/configuration_xlnet.py": "30e9cc5502474ec527afe3212665fcca4bd04f91a1ea6eb43bd3318157ad94ff",
        "transformers/models/xlnet/convert_xlnet_original_tf_checkpoint_to_pytorch.py": "bda6cf0e033f8a666c4d5aa552afd8aca125a56844a6235ff319334a19a01faa",
        "transformers/models/xlnet/modeling_tf_xlnet.py": "2ecc864524d1d009cf715770c246e1597e9230cc9e5a5ed032c107e18e46aca8",
        "transformers/models/xlnet/modeling_xlnet.py": "d334afc90c857322e8f7ee1ad65ddf911437729cdc420710b50693fa1c4c0f2a",
        "transformers/models/xlnet/tokenization_xlnet.py": "4905cc1456cde728c3d3cff1a00b7997546ebfff9ef5cd98b3cda85afd0fba7c",
        "transformers/models/xlnet/tokenization_xlnet_fast.py": "505472b523235bebc867fdcab7c69c9b668d3a9ef48be9ac2626df047388f52c",
        "transformers/models/xmod/__init__.py": "85ce9c0146bcf894241c23df8323a7a9b5ef27d743fc41c6525e6d4db07a0adb",
        "transformers/models/xmod/configuration_xmod.py": "a83d9e4d4b9179c7dee28a4fcb2dee1283a752a53fdc1f706ca9043ab9e0063b",
        "transformers/models/xmod/convert_xmod_original_pytorch_checkpoint_to_pytorch.py": "c85480b578f16c0cbab97060d978a745b9375521013ac5a3d6e80185536b1a34",
        "transformers/models/xmod/modeling_xmod.py": "c5fdf05df2c0b476b9dc193721be8368159f35611976476fda7de940445af0f0",
        "transformers/models/yolos/__init__.py": "956b933adef2525a9dce8379acedc69c8d0ecf6ea11e0879e015b77ce989babf",
        "transformers/models/yolos/configuration_yolos.py": "f5603cf3eabba0ef2f6adddfd2726bef650e6c34c9a4c4231428f500201d64cd",
        "transformers/models/yolos/convert_yolos_to_pytorch.py": "74367c94976887c1448ba8ae8d43c6867afe7a36dc4c6408211501d9ced603c7",
        "transformers/models/yolos/feature_extraction_yolos.py": "d1e6cdd417b8cbce82db2c8ddab310f406e0b840e3710edf91a6eba29529c1cb",
        "transformers/models/yolos/image_processing_yolos.py": "307cb2527a3a39cfe884871a6560d08d46673c8a8b4a9a9697df29d1dddb0a84",
        "transformers/models/yolos/modeling_yolos.py": "0d5fcd8eb8c11ba478380288803eb035936f2d1d4705798db6dbceaaccb2232e",
        "transformers/models/yoso/__init__.py": "36338150ab91b5ae26fe30b33666349d3ed14f9dd99d787eb9c3a3a74081ef0c",
        "transformers/models/yoso/configuration_yoso.py": "2ea1c617802ee554d85e01b0d17f4a02595d1be6ea8ea138f29bd0315e62031c",
        "transformers/models/yoso/convert_yoso_pytorch_to_pytorch.py": "5633ce48b20d7e489a1f1f0cddd4cd31d0bc857877335cb284843db78573aa4d",
        "transformers/models/yoso/modeling_yoso.py": "056c0fe09f8e1525ba348044685853f38a12f7f013c5613be42eaf8a061f2619",
        "transformers/models/zamba/__init__.py": "54e3c0c4f4a4035af7d289226c0dd504f62953434328e03cd028a9c77dd08fe6",
        "transformers/models/zamba/configuration_zamba.py": "afd99dda32bd5a332dde904d394a746885203301f32b049cdfcc057a8d2158d3",
        "transformers/models/zamba/modeling_zamba.py": "a9553f81bcdd749adbcb5333e84b8aa6be7d192d3db6f18b40f97109194ec04b",
        "transformers/models/zoedepth/__init__.py": "7864ad00628f92c9fd6e797b27a51d3257a07fded79b49211a0ad02791eea4ab",
        "transformers/models/zoedepth/configuration_zoedepth.py": "485507fd342091c14933f7f8f369c16c46b32bf40460f9831cb18cdb6851382a",
        "transformers/models/zoedepth/convert_zoedepth_to_hf.py": "493b45d831ae66f160486a5e0e3f2e35045a7622d0d21d7b1efa0a0c3e537454",
        "transformers/models/zoedepth/image_processing_zoedepth.py": "69c0577457fce27475d22201df361aa3472353479cda6d7c71ade5b0978d5eb5",
        "transformers/models/zoedepth/modeling_zoedepth.py": "90979b8f48739a7cdd0a48db070156e96f9fd8a8c2963b496700921d36ce3d9e",
        "transformers/onnx/__init__.py": "c002cb6384cf38ada23eb15c7d97ff5a21264d1014e9d0161c497119d7b1af9f",
        "transformers/onnx/__main__.py": "259f5999e46c9c38adc133166fe7454fc5bd00498ca0c28b4374af6f20a4634c",
        "transformers/onnx/config.py": "ccf0e00bf1d22e631ea8f91c2effd8f047db7cb2c40cba8faefadf402472865f",
        "transformers/onnx/convert.py": "65287d8d013a07a702c619526ca2c7c4d9a3e3c1e45d7765f8717b886b59cb99",
        "transformers/onnx/features.py": "192bb0663efad131f10240e625844eb78dcb6b419a63e6c0d7d8f66c4f976152",
        "transformers/onnx/utils.py": "dfd530fc690506c4dbe99bcc2074539c8dbcf5a40385cea1c1f11aa5a04613ea",
        "transformers/pipelines/__init__.py": "c9eb9b8607c1d1ffae6c3e5c43113df2041b29cd589bc5f07beaaa3b871fd473",
        "transformers/pipelines/audio_classification.py": "ee5ecaeea0daa7d3896a0bf528344eaaf8ac9b2c979811db62351ca9e1614b04",
        "transformers/pipelines/audio_utils.py": "b1c60297563beb6ab28ca27720163db42cef716fbe857c55f66467154f53b1be",
        "transformers/pipelines/automatic_speech_recognition.py": "9c3ee553503e0bf4abe6337a15e11ed0de6bb561aa72656abb25585d48a8373f",
        "transformers/pipelines/base.py": "3844bf319503ce11aa993662dbb5f16809b34f2d44207083b62343f5f3fd7d81",
        "transformers/pipelines/depth_estimation.py": "a66a3713ac3a3b3824f936bf0f259841981747aeacf257a3b5310d75bb12507b",
        "transformers/pipelines/document_question_answering.py": "0790003e0977ae663678fb4f7959ab1cdb7f7928ea33d9dcda5e7471469d6bd1",
        "transformers/pipelines/feature_extraction.py": "02bfe13e58d8d456bfc40b11617e1c082b2cd6f7fe882e6eb8a607a77ade8ddd",
        "transformers/pipelines/fill_mask.py": "b764b023a47ef23767879fd710d30e5c61ea920d92eabd4d116a641db9dce372",
        "transformers/pipelines/image_classification.py": "788f7882822202aa2c27d6ad9266017e3d204fe80c4aa73f2935fcd027b38685",
        "transformers/pipelines/image_feature_extraction.py": "2889f7ca5740513c4599a97e48d17b08f91cc75877abf28cbf28d4b07cecc7da",
        "transformers/pipelines/image_segmentation.py": "ae8014f606f4927743ee789a8f3a55bc9c7414c7ce97f6daa8d48eb2c46aa9bd",
        "transformers/pipelines/image_to_image.py": "54707b12540862b0463d0b03e50b53674a78a625c9febd77294e1f91681b2e6b",
        "transformers/pipelines/image_to_text.py": "a66f578178680b65d608176d7aee71f5cf5004022bc068921613b7fe2ae362e9",
        "transformers/pipelines/mask_generation.py": "1d1994c7e1fda65f39828dbab7bd1387b96c3d0bbf9c37671e08bad8590a2feb",
        "transformers/pipelines/object_detection.py": "c21b0635217c33fcc992fb318bf9939c2d78e7a479926ca2469e6efb7cd1ab5a",
        "transformers/pipelines/pt_utils.py": "0fe70514a01a56d9f78da6463ca16bf94dc9177fd84791f790ee100f58eba906",
        "transformers/pipelines/question_answering.py": "2499f25e9b0a91934a099863eb1cc161f0a5722beab975590415e7d3c76a3de0",
        "transformers/pipelines/table_question_answering.py": "642d8ef9d4aa472087c29c782ec33d28efdc1d896f81cb514f3b1964cef52af0",
        "transformers/pipelines/text2text_generation.py": "72f21177cd0b9ddf0f89c900bcf3bc9ba7272dd8b427b6a15cdba2e0a9a02805",
        "transformers/pipelines/text_classification.py": "c766aaa4f4cc1e797197b51a0a217bb2f35816f19841a2d715c934c23b911243",
        "transformers/pipelines/text_generation.py": "bfbc9082d9b152561687e467b709fcb2a455035ec4aef4987f0e4bdaa2fa63a4",
        "transformers/pipelines/text_to_audio.py": "d5a435d93473a11f1de4510c09fdc57220e88b8007385535397745c5f6f5eb8d",
        "transformers/pipelines/token_classification.py": "8741b339e734c001287e71ae92e78b70ff101c1d78af76f89def546855697127",
        "transformers/pipelines/video_classification.py": "1fb52d8f65015634486e5989945f3a92847c2d88fd34c81c1f6e0be10aefb297",
        "transformers/pipelines/visual_question_answering.py": "399fca2c1df91458caa742834fcb5d94dc9288291b24ca91654999acc1f4f0d0",
        "transformers/pipelines/zero_shot_audio_classification.py": "cb18c19ddd5ff7d1a8258384e759fc2615223119a4a2d322167fb6b8b9d2b0fa",
        "transformers/pipelines/zero_shot_classification.py": "7c1a81efe68db0a0a4d2728c40fba218555be875b1cc0a7c2be81e83cf7e17d4",
        "transformers/pipelines/zero_shot_image_classification.py": "31f4324b73f84152ab139597c677e8b0d1d1529d890d438e540db97ee7a1286e",
        "transformers/pipelines/zero_shot_object_detection.py": "9ef69b02f1d3de7beefa0777f7ad9a42c6121da432c3b4900c9982b0b943f2c8",
        "transformers/quantizers/__init__.py": "842a6b427a08db4f8ed4548c491803f8ff7f34a13337b9047d8ebafc1ad0c73d",
        "transformers/quantizers/auto.py": "1d1c6592ce3c0a9d9dd357533feaaa5ab593b103149ee705aac2782b406b0b83",
        "transformers/quantizers/base.py": "d5569b329b416163bda027fa8665b3f431e530e1944a9e952d9a97371caf4203",
        "transformers/quantizers/quantizer_aqlm.py": "92109bf264364f4b583f0089a80ef090eebfe7d4760a1b471e7c1027385f0017",
        "transformers/quantizers/quantizer_awq.py": "14cdbb446c476b345320dda8daab65e10e9bd74b44f853462a510e23c6a84087",
        "transformers/quantizers/quantizer_bitnet.py": "09e98359b42bb054a56b2fd52b47ee985e4428fa3a42c084cc98a191b0bc3d98",
        "transformers/quantizers/quantizer_bnb_4bit.py": "8b32a0f8d898ca9801692b26e6d0968e6e3d3e3172c7cf3a43fac07b0cc6c7d4",
        "transformers/quantizers/quantizer_bnb_8bit.py": "284e158fe975805ce62f574888ea42be01053ed83abf706c6b5270a12a5b9dd7",
        "transformers/quantizers/quantizer_compressed_tensors.py": "2caa1224ebe91faff605dbf2ddac00c3f57379c4b1c095cb6af437fc75503fca",
        "transformers/quantizers/quantizer_eetq.py": "12e2b316192cad8609b925c1320999a2d3e24e98c86122c4afd9a0ba3289f32b",
        "transformers/quantizers/quantizer_fbgemm_fp8.py": "8b601df658f88d9b708ddde70d180b5f2e48df9a9862022db99f00c0d490952a",
        "transformers/quantizers/quantizer_gptq.py": "cf5aaab1abc87eb592ee63343b312e11c51716304cb074ae0a0f01a66bff21df",
        "transformers/quantizers/quantizer_hqq.py": "fbd18fe8c3eab510dd2cbba77599a9824a698d667d58558500ed77c42b6d0c7c",
        "transformers/quantizers/quantizer_quanto.py": "1fb85f802f2767f3ff4968dc488f9bf5942d0468468c60bd8082b9e602003783",
        "transformers/quantizers/quantizer_torchao.py": "d6f93a1b212996c1705ea3b2eb849697bdb607bb19800ae2b1aa9e4ee9660f88",
        "transformers/quantizers/quantizers_utils.py": "e9b8267fc98bc68c3a817a274c55fb3cb7ea16c7faa65523ec339e5e75e1c0c3",
        "transformers/sagemaker/__init__.py": "7cab4a0076a6cff08b2fd8cf1826b613ed67f119ae4bee7ca86b7366e29cdea8",
        "transformers/sagemaker/trainer_sm.py": "ec6b0a2ed8dd31f2a9f7c3b01c3ed1701b25ef8e4e3b01c0681b3091f2e47ec1",
        "transformers/sagemaker/training_args_sm.py": "e199d08484df3304f4cb663632f908d753c407fc9f4d7e59ed6acf2add155c3f",
        "transformers/utils/__init__.py": "ba269a29d5c49a3b7c6c56f68f174827b11c74b8a18b119a40f334a8abd50628",
        "transformers/utils/backbone_utils.py": "05924e6af9e2c03283933fdfef20fe9bc6460d4c7e962e45c2a559b498e6deb3",
        "transformers/utils/bitsandbytes.py": "2f338ac1c1d6031c5966ffbb4ecf50d2f94462f1ddd7c69f7d58156e24774f3b",
        "transformers/utils/chat_template_utils.py": "4f19330d8852825a1139440847e2567bd369630f2fa130abfcbdc58b40f49bf3",
        "transformers/utils/constants.py": "b19b14c0e9c0dc26ed375b2fb3d62868d2d34ec01cf5155a213b20a5ff0ae222",
        "transformers/utils/deprecation.py": "d571c42c4134b2a424ac1fc586d05cc008c793911370b542b0479a9196bc25dc",
        "transformers/utils/doc.py": "d680194ff951a8b96f23eb4bf4109dff08553af18237576e6fc6f967ce67dc60",
        "transformers/utils/dummy_detectron2_objects.py": "9fb3edffbb1b54135fa2128670e01107e65c3dc2516e31007282dddaf4d79dd5",
        "transformers/utils/dummy_essentia_and_librosa_and_pretty_midi_and_scipy_and_torch_objects.py": "9faa58e2cef3088237773a3b12377446f8876bfa4c6ad7ae0c4c1b6c782c4d46",
        "transformers/utils/dummy_flax_objects.py": "fa23874008d0531d92d3f969500d9110741450b526a31da2108372063337c67d",
        "transformers/utils/dummy_keras_nlp_objects.py": "0155adda8ac80825178bbe786e46afbea3f360ef753e3111f85954640c368d97",
        "transformers/utils/dummy_music_objects.py": "d65c4879b61439d1c958c43f4f921080f81c3bfc29ffc60cfc719cdec92e1958",
        "transformers/utils/dummy_pt_objects.py": "bc422e0e3eeeccf6ba841e4ba36452f07644a1f9af907c6b75b80aa2a3ba6ea6",
        "transformers/utils/dummy_sentencepiece_and_tokenizers_objects.py": "0603cbafc5b3f00fb5ecaf3ac74e0ddb508a5ed58d40b2445b1d9ce1a651a9a0",
        "transformers/utils/dummy_sentencepiece_objects.py": "a41ca434d83d20f0deb2154e79ac38b311ef826b776f2f57e2b210b73d0e3588",
        "transformers/utils/dummy_speech_objects.py": "f5e166d5c8ddb1838f068033f494e03f7e4183c585d82f4067fcb5845a4a65d4",
        "transformers/utils/dummy_tensorflow_text_objects.py": "e37574200da46fd82db8bd12d4e2f5791145c734302a0e293e3315b97501e6a8",
        "transformers/utils/dummy_tf_objects.py": "abf1af2f8b42b652634a9b2e2db06ddee230ff8c5d13d794d15d31eebb2546ae",
        "transformers/utils/dummy_tokenizers_objects.py": "1d6fde51797057754f5f17d21d25f7978b5a38b6eb6a393388650a4f1f0f0ad1",
        "transformers/utils/dummy_torchaudio_objects.py": "f40ed8e3ae37fe14daaaa64a94bf8ee76e30467ae636d383c62b2e0dd3bfee45",
        "transformers/utils/dummy_torchvision_objects.py": "209bad4bf1a225108fbba7d42787a37b16911cc069b5d179ffd2a65858d7a2f6",
        "transformers/utils/dummy_vision_objects.py": "d609e928b4001b9ee89948b88b67cdba4c968a2f41654d56da885bdd0af0e190",
        "transformers/utils/fx.py": "af050e5bf1546fdddec5aa7a53a3c8379c591d4e7d7ec7d08a162cd746dc9f43",
        "transformers/utils/generic.py": "75d535461c98e90fca41fef518b5d135633c0524c6cff4ae668a008eb90a338a",
        "transformers/utils/hp_naming.py": "bea70e5dc0cecaa6c8496a3cf8295425438155b64cd61d3c11cca64f0711b617",
        "transformers/utils/hub.py": "4f5d458a159ce41ff26bd087e8aac5e2ce03973288bbbf1a35731579fb88c4fc",
        "transformers/utils/import_utils.py": "9d7f63effbd7c8dcfe69e7f34cae0d164db9cca2d5f4d887405ae0f3e2ba455a",
        "transformers/utils/logging.py": "8e131b102a420da30c8dde8b1190bb432b37c2916db266742b7742541e592c2a",
        "transformers/utils/model_parallel_utils.py": "5db194f48945179f4afdaa654715065674df219f66a5b2e898aa90d3ca284dec",
        "transformers/utils/notebook.py": "96d4b133cab3419e060651b9c6092d84f2e165f8622993a41c388f35e2a287f3",
        "transformers/utils/peft_utils.py": "270e8c8ef54bb50edba28a2dd332ba5ffc6a465fcf00e877945663d40d86b9cf",
        "transformers/utils/quantization_config.py": "e866ef639458c4f3a927db4334c6734d4ec0e0ab0fd45d3b572ccbc4dcbccc99",
        "transformers/utils/sentencepiece_model_pb2.py": "5e242cf6e304bac7c064feade8806e4d35fdca5ecb88ec89122ec86fe5b39aad",
        "transformers/utils/sentencepiece_model_pb2_new.py": "22cfe530953c3259971939112fe52df610d627012661e5de74f0873c56aa9703",
        "transformers/utils/versions.py": "0be4eaaf8a864871fae328080424a8f2003a6b3cfb0dbce1f3375cff28cc917f"
    }
}