{
    "id": "torchvision-0.19.1+cu121-cp310-cp310-win_amd64.whl",
    "hashes": {
        "torchvision/cudart64_12.dll": "f86bc7f6043b5441f9686862403db35ea2006d87381a359deea3599804c6b83e",
        "torchvision/extension.py": "d00e1e7d0e95f1195070c32d0e92bbe152011e90efe2272392439cf84a243c7c",
        "torchvision/image.pyd": "fac79fa2a54695e9763aa706e0e854fd8da711de4bfe8bd4a915d49e553bf15e",
        "torchvision/jpeg8.dll": "54005247f4a9c7dd149ca17727850acf1b568b9a49588c29cab27747d05c688f",
        "torchvision/libpng16.dll": "9cfc6eeee22b3b182911708b5328cfeeb4010a084154fb0bfa1f0ec5e02bbdcd",
        "torchvision/nvjpeg64_12.dll": "3a855fa0717c1cd2a97a3f626b5d593ab860fe6b4fdc1b20260f38651d535ffe",
        "torchvision/utils.py": "99e830b90c221331fa911af890b67a14503032aa78020c89978006583439cec4",
        "torchvision/version.py": "10d86699080c82512ed592a36070635d6aba24ce7998d4ebc2162870eb68234d",
        "torchvision/zlib.dll": "8dbfd6ef7374a831158bddccb79e3d5665e9625c81af557f15b4150b7877f687",
        "torchvision/_C.pyd": "1f3f1b3a3404f1be3f9e78df117e8334512c6f0aea3d438c9eda75ce9f42a5ce",
        "torchvision/_internally_replaced_utils.py": "8e7107d948842900947f506ad9f2133cac7183e67248938d215a2788487c8466",
        "torchvision/_meta_registrations.py": "feb3480040c59073268181a6f7cdbe5a04a6840f68d8a549a5df03b285254269",
        "torchvision/_utils.py": "91c4a7e8fdd58efe503e01c736636ee7d321f8d2dbe4c0e5631bc390d256ace3",
        "torchvision/__init__.py": "cd747a10a42625758c364ba596561b25d4bc22138b36a25a65acf853bec8e1c3",
        "torchvision/datasets/caltech.py": "e659800c8d0a426c067000693266a2bebdaa6393683a07381e10c5f79db9b3a6",
        "torchvision/datasets/celeba.py": "8444bec47b6a81b4da830494b0e9c0aef299f98ab05b0d0a368f70bc26ec504a",
        "torchvision/datasets/cifar.py": "d87564a917567a4b3abc73cd954d4aef4ace0e6be0200c0e0eee5107f99e443b",
        "torchvision/datasets/cityscapes.py": "4bc0148edb5e565512ed2886035579249af1eac3050a249dbb85ce79ad29ed6c",
        "torchvision/datasets/clevr.py": "be58963920eca3bc115f936d7f059238ae2c2fe87403450feed72d0227bda37a",
        "torchvision/datasets/coco.py": "7df30c583e2510496030f6f557debb3935354624add8c3e4960877877bc63a34",
        "torchvision/datasets/country211.py": "fe229cf40681a069bdbd64ddf59d886dd078843d8a8f32a8f57b1af1e0ef95f9",
        "torchvision/datasets/dtd.py": "c42c6b8773eb9f3e937740f6ce9d0b63836ea6a50df6b8a14e46f583c23b988b",
        "torchvision/datasets/eurosat.py": "85a19e2d4ca92452a8750240502dccc7209d77f9c0447358fe75a96d8d80e98e",
        "torchvision/datasets/fakedata.py": "06a19588fc8845cbdd04da4686c3e5fe2b2bc71393b6514bc8a9cbc7305640ff",
        "torchvision/datasets/fer2013.py": "7757110e79eb3cff0cf83c5e82e08b9c5eaf99030ed900bd2d7e9993ca4f7eb1",
        "torchvision/datasets/fgvc_aircraft.py": "225904d38f75f0967ca1ff1bc1f48fb6f7e461a7eb04850651ba60de2b1f428b",
        "torchvision/datasets/flickr.py": "911cefe87262cfc4c36bbfd247d81cd774b59ffe25a02cf98a47bb5215784b72",
        "torchvision/datasets/flowers102.py": "a6406aa83a8e23811ffce07927cfcff2cd1daaafd895d63592443485cdd2d0da",
        "torchvision/datasets/folder.py": "c52f697f7e38af924ac6d35831d593bc247d34d8311967d4e0ec39c4988b4ef7",
        "torchvision/datasets/food101.py": "8e158a18caaa9083031eafdd4287103a06161dd67aa582accbd70307b30f888d",
        "torchvision/datasets/gtsrb.py": "4d531eb09de3cd5935b60e1e709ca2ba7e654343ca87b94c6562e465b9156d46",
        "torchvision/datasets/hmdb51.py": "9c07cbd9399930d02ec6fea13755f78cd3fe0e604417996ce589e31e8eb84c8b",
        "torchvision/datasets/imagenet.py": "7eda99dea7d106e2fe7c00171633702b337dd8a753fef4be3d4a8896715431f0",
        "torchvision/datasets/imagenette.py": "d49c4a891e48b590ae399a284a2772da66b7dec8143346055c8d6f6c7497e25d",
        "torchvision/datasets/inaturalist.py": "4560f7a87e7fe35d66e93a6789e52e8551ae59ffc8cf9a88bd60a4b970952404",
        "torchvision/datasets/kinetics.py": "48c8272c9eaa6aa99d5faabd1b216048f7d98a3e0f746fce3d72caa15f8fb85d",
        "torchvision/datasets/kitti.py": "ab4a2d49a9d4ca04c5ab83f64f7c4a7edd46bfe04f417c3ec4d34c7ce9833b37",
        "torchvision/datasets/lfw.py": "dd759dc44b750fe33ecc6e29b2fabc64252f291d64b1043489721fa3cd25a6b0",
        "torchvision/datasets/lsun.py": "a4e3d62c29d0058de56d4cc2591fd8b1184565e101daa168016c67b904ff97ac",
        "torchvision/datasets/mnist.py": "2b2932f9ec7e0071393577b32f3a9bd4aa7dcd30396ea4bb988d0549fa5885f2",
        "torchvision/datasets/moving_mnist.py": "8ae5fec8d9a48bb6f2a7135f202a1b89f66169db492859931af15de3424fac8c",
        "torchvision/datasets/omniglot.py": "cac673b7dbd0ede0f68a4a9018812f7d155c92eb20d89465e1df2b4021743c45",
        "torchvision/datasets/oxford_iiit_pet.py": "dd16d4fd4c6f56a89f9aacca54c5857fe76db5fe771a96e774def9d7ca1b56c2",
        "torchvision/datasets/pcam.py": "f2d59b25cc68ee52984d3a08485a4bebf3926f179812a53642c698e8e6234693",
        "torchvision/datasets/phototour.py": "c8443f5f56c325003eef4235c7b3d3cbb17e9829fa52b5bbd2e6d4fb3dc053c8",
        "torchvision/datasets/places365.py": "8b3349afa134991deda081b8509b3cd8675cd4587f6b91492956bca95a5ecd3e",
        "torchvision/datasets/rendered_sst2.py": "fe0ba1bb7d39a00b71087f0a715e2b5303f909406e7050987f1fbe96906344af",
        "torchvision/datasets/sbd.py": "79eaeea9edb0557b15501bdc1662a8736a9e6c9833ff7438d2a715b4af2fc668",
        "torchvision/datasets/sbu.py": "19602e5b3092dfdc241fbeff3f2dc42aed9e8fe4e27c36b11b28aea7aed12c5c",
        "torchvision/datasets/semeion.py": "0cbcdbefa8a19a382d0333619d5d099ed4e3c2e580d6c7f4784705063f682482",
        "torchvision/datasets/stanford_cars.py": "444cbda008d560de632124422d00fc7a0d06301c7731951b61e17be9e402748f",
        "torchvision/datasets/stl10.py": "30671f1e1f6f53320fad3b607180ca8dec0c8f0e2bd75bc92c91a284b3fe8514",
        "torchvision/datasets/sun397.py": "c886eb287e827ee27797cca3406b1909a91018f71b2313466fa87ae1b4020d4e",
        "torchvision/datasets/svhn.py": "9cffbad8ac4b90b0fa9fce25c39960c9b947c911560b93588812e81a07880f96",
        "torchvision/datasets/ucf101.py": "cccf4463a0a5a9dbede393d9c8bd1d66f9e52e7fb9a32083eaff76e1b10d94f1",
        "torchvision/datasets/usps.py": "bdaced30f535f289ceffbb565d458d43442c3cf628c4607eddaed8880de962bb",
        "torchvision/datasets/utils.py": "45f4f4d77065ba46ca22fa7d2c6f032fff85758b1c1a489e188e6f0bdb6e927e",
        "torchvision/datasets/video_utils.py": "8146b373d82fe30805b89d4de3b7b67385a2f3a1d6851f4ed3d1dcc15ada78b0",
        "torchvision/datasets/vision.py": "e4debdc6216c35d8aa8d5ccff903f7f8fb6cc0350db0a49ecb2fc5cd74c3b7fe",
        "torchvision/datasets/voc.py": "ec68735725378966c1cc5c9bd73763fbdc710922e640276284f3bfa3ce5276a0",
        "torchvision/datasets/widerface.py": "506bc8f7b9ec042989846d0a28dc4ec0cf6290b181b9a6a65128e5cade23c33a",
        "torchvision/datasets/_optical_flow.py": "7b103549f80735dbc4c5e387ac2a0c9d051f842a3eedcd0ff7b924a989b67511",
        "torchvision/datasets/_stereo_matching.py": "b88dc4cefc4981c6c8f7bb17922ab051dfd469f66ba4be7b40c7d0ee42b2e180",
        "torchvision/datasets/__init__.py": "22c45737579a4f213b59bebb06d05a0e066402e917a9889b95bce2278943e9a2",
        "torchvision/datasets/samplers/clip_sampler.py": "111a7d7343b764640d47794b5ef6575a37c99176b26329bc6e161f3a6fcc34a2",
        "torchvision/datasets/samplers/__init__.py": "c97f170f787e5704c2a2a17d21d42672e19b959c6f5dbd8422a73994fa975ed6",
        "torchvision/io/image.py": "18d4f240cba8e867eb268d68908303ac40d4b53dd8300acca6d94f7a2bb40997",
        "torchvision/io/video.py": "13c81a5dffe5e5e91428d118ca3a32ea9648b9a1ce4420956a9a737802663392",
        "torchvision/io/video_reader.py": "461b8af8a72eb650ff0723e4343fed1c7fd0548c03b1da962f3f82d0a25cd043",
        "torchvision/io/_load_gpu_decoder.py": "07798f2d77ab2585ea887bfd14eda5691ac64652245e28bb0ac0f427c27f4b05",
        "torchvision/io/_video_opt.py": "9f93cbe215c29ce55a2c39527cbb56ccff322b8ca9c166f2bd085b487aced0fb",
        "torchvision/io/__init__.py": "bcd166a26ba3bd84aabe8f84fff46dc74d67e5ef09345d5ce2f7b0a8bf6d8bc2",
        "torchvision/models/alexnet.py": "5dc95d3f652e3a474e51f7718ad192f2a1f32c7efc372ed50b34f32ac6962135",
        "torchvision/models/convnext.py": "98c2f75c02c6bd019edda6249b3e9d6c2ed6bacee7b595abec85628568cb57c3",
        "torchvision/models/densenet.py": "5b1bde723f1bd3d532d858caba7ed96da8290e61e597c2f673719b33cd3622fb",
        "torchvision/models/efficientnet.py": "b56e81a6c04fae884de9bd68d7fb074a2912a2a0eea504607604444e26237006",
        "torchvision/models/feature_extraction.py": "cf411674abcdff3f959b3536da0adceb1b88960072993c57b026c2837cfae02d",
        "torchvision/models/googlenet.py": "02d5dc90d5ca7265a10f2a28cd5b2f6f754f23ea1d976b69b62633eca5d4df00",
        "torchvision/models/inception.py": "97db6eb703bb28d55ae677dd975ff97feea527343e352382cd73c0ac320b7800",
        "torchvision/models/maxvit.py": "9bc3df87b31871800dc70c6201a53da559b379698e0768d3a4b4a2b948ec1d92",
        "torchvision/models/mnasnet.py": "3d3485e037216c582d39c85df648283ca09c7ca1fa342e167c76b96efe23679f",
        "torchvision/models/mobilenet.py": "6a5ac427092d99755c0a9854f21d84009657d1874a7dccf8b4910e746d815c1f",
        "torchvision/models/mobilenetv2.py": "7958a5db7c8fe1ff830548632adef799aa3ce33122179634d701cdc21f0709d3",
        "torchvision/models/mobilenetv3.py": "835525d5192884f1e15dfb1e720dabd16ecd56512055473b5ffb93d5bc71ad34",
        "torchvision/models/regnet.py": "35bb00dd13bb91aee4f5fc18c95679c2fbed254ba15eac97efa68622822e8c61",
        "torchvision/models/resnet.py": "01759697b5e5912429502b2ff2509a59e0ee61aabe2b238b5e605ed11f2bbf9f",
        "torchvision/models/shufflenetv2.py": "5441ac4cd35376a76ef26ec8eb6cd0b892bfe429044fed18e22c58049f90042b",
        "torchvision/models/squeezenet.py": "0e16be722df9d0a535e43d0b4bd374ee4c3a32536ebac5074819c2f3712bcbf1",
        "torchvision/models/swin_transformer.py": "f90f4a775ab3b03eef2f7bb5dfb4383281d24f0cc0e9015cc1e685d330969949",
        "torchvision/models/vgg.py": "42df6be6c16863ea0f7703f80deeb58ea4957bd5d464b5cae3bafdc950d0df73",
        "torchvision/models/vision_transformer.py": "184fbff9d9452503d39ce35ee2aaf360e629fb06af3ceac53c2a3d92b337f558",
        "torchvision/models/_api.py": "449baba6994afeaeed79e5259ea94cb934f1028aea20484472e432772873177b",
        "torchvision/models/_meta.py": "d8d488202a2ae0c0f33d9734d03946253807382c1305239b4937914e1dc4d2d4",
        "torchvision/models/_utils.py": "5fbcddb84f747e47a4f038ee933c8434e719d22a29d374742c8c42fc5b806b39",
        "torchvision/models/__init__.py": "e9095325fbe329c526309bf049aa5650d1576dfd95a35e5d551701b8d49a624a",
        "torchvision/models/detection/anchor_utils.py": "4d029638a0c500bb13998c3f04c1880e54fd98d421ba49a09cd745b918cde3dc",
        "torchvision/models/detection/backbone_utils.py": "041295c42c8063d43c25838b437a006d62717239f91c06cf7807036fee49a150",
        "torchvision/models/detection/faster_rcnn.py": "ae1323ebc290e2e0de14a4f7d0f572db196a2c6e37bbab40ee2f5ee0c10cd795",
        "torchvision/models/detection/fcos.py": "dea8b8e029d4bde23b5b752eeeedfd7e0ec7e7ed894f50bdedd1207523912e88",
        "torchvision/models/detection/generalized_rcnn.py": "9cb563da8f32afa056d4c375daedf442e15bbedb1d96511b5256cd1fe74ef86d",
        "torchvision/models/detection/image_list.py": "233163c4868c77215ab352073c1800b812b789824e7abb791f31aead8262b4d9",
        "torchvision/models/detection/keypoint_rcnn.py": "95c32b90fd3e8e9af75b34b0c2b86731cf9073098e21041b15cff0da71773441",
        "torchvision/models/detection/mask_rcnn.py": "1d9cae58d74ec3c58874ed39fbca1b5040f5034095b85779136d4a0b3cc27c51",
        "torchvision/models/detection/retinanet.py": "69663fffdaf3f2bd1b4f62ef9743f99655b6844e36b3abcd3a58da4c5e21a8e5",
        "torchvision/models/detection/roi_heads.py": "7ff2dd7baf491ee80601a8865a1eae809f565134fc7fb227c4faf2fcc6718196",
        "torchvision/models/detection/rpn.py": "cf87b3be0d574bdb8dabfde32185f32119ec021b860a5679009e4fd0d0f388df",
        "torchvision/models/detection/ssd.py": "432596ec88a1a4d1b8fd259e568d7e5f927d90326b6ac77bf78f801c8703c506",
        "torchvision/models/detection/ssdlite.py": "0d190dd3b2cfed64cab7a4395883ab690477ed49f1ed722207bd1476198309c1",
        "torchvision/models/detection/transform.py": "828bb498618fccb9dc57664c1e44d3930e943b47d4a098a2e83af63743cd03f6",
        "torchvision/models/detection/_utils.py": "9bd6e8c2a8ee62247d03b1c8ef02402bf92016b51894a4ae917384c2e52d4690",
        "torchvision/models/detection/__init__.py": "0f872cdf7f19e01427e53817d882ae242f530f6aedc36b2f50366500b47e9702",
        "torchvision/models/optical_flow/raft.py": "a3dc09de3647f445b0265edf41879649d7973cc298399d19c26fa185c7aab959",
        "torchvision/models/optical_flow/_utils.py": "3d172e53e201e842f784038b8b20b9abe341ce5bc829f85217f04ca651dbcdf6",
        "torchvision/models/optical_flow/__init__.py": "bae44501dbdc0e86dd01b636566c4467bfc22c7fdfe7e2519024ae251923e116",
        "torchvision/models/quantization/googlenet.py": "3fdd9c69ca0a553578703a1a36445ebcbc7575a187e4390f7d4c0f0ccb8e5ced",
        "torchvision/models/quantization/inception.py": "4d7cf6851a52be1eb360fdfdf0cb174d840c9ea6209d89eae70c86eb1af93619",
        "torchvision/models/quantization/mobilenet.py": "6a5ac427092d99755c0a9854f21d84009657d1874a7dccf8b4910e746d815c1f",
        "torchvision/models/quantization/mobilenetv2.py": "836cf71cf434317142b8c5794e92cf45d3bdf66df00bfdddd2e9146a75da247a",
        "torchvision/models/quantization/mobilenetv3.py": "97d8350302a2537e572aea1b5e8f943dee4ca91282d6480def18165a29b8aabe",
        "torchvision/models/quantization/resnet.py": "6b3be7d6fc1e6cfdb6aabc9818d8052ccbe21a31e4957397ef17780b6720814a",
        "torchvision/models/quantization/shufflenetv2.py": "ee4f4c2d12f38cfdef91ef9ed008bf72703e8f5e4a190ab9c8372cfc42d7520f",
        "torchvision/models/quantization/utils.py": "223f3c97ab68c8ef0c422d70e75d89b7ec90d90f612bbe7e67648e8c8cd2e99c",
        "torchvision/models/quantization/__init__.py": "60e26662a5904df3f93f6ca9b5e64d29038c5b85440765872656284a549a2f56",
        "torchvision/models/segmentation/deeplabv3.py": "324998126d5d17869f4046179857f12c072a8a8893e6e58a60649709c708621e",
        "torchvision/models/segmentation/fcn.py": "990d568b84bd8f91ba3906cd722bb137055b27a7bd9a24f32168fa9941792700",
        "torchvision/models/segmentation/lraspp.py": "cb1fdbdcf26c1f97b41774ea8860e11276d70864dd357da2231b0abcd7a7334b",
        "torchvision/models/segmentation/_utils.py": "c857b205ae7f3f2bf5510ff637ae1731181362cc627f0cc377e5513febe62063",
        "torchvision/models/segmentation/__init__.py": "4cb2f64929aa134f072e2bffcb2216c88cabbdfdb168eb198b49ae0effd8e557",
        "torchvision/models/video/mvit.py": "c482b89c23ae2565d08e85fc373728bb0cf24e4224705ba0df28aed1ae7e0e4f",
        "torchvision/models/video/resnet.py": "24e3fb1437d439f4103fe8c4614bf34883abf4869ec65d8bde2521fabceba7dd",
        "torchvision/models/video/s3d.py": "467fa2ca93f5de3ac44c06a9d50778358ea4929603b925e31a410a6433b17a62",
        "torchvision/models/video/swin_transformer.py": "33be0fdafe2554a33ace0c287859ff9e3a69641da5fa0023b8656fcf31122a95",
        "torchvision/models/video/__init__.py": "c471d1e5cea43f470c0d7724ed79d7ab5f6224bfd47a6731837382d3472a13a0",
        "torchvision/ops/boxes.py": "2efad6e4f8f82b94d1140a63ef4cd4c7dc6e299d12262c60bc070f664d1bc140",
        "torchvision/ops/ciou_loss.py": "4339bcf42f367a15fe62f6013cb3d13e16c965daf78ad8b3c6ec6b4fb30b8bda",
        "torchvision/ops/deform_conv.py": "0ee228b050cadedb18e5194753b99ecf9c75a74f0841a8bd586d78cf74b48335",
        "torchvision/ops/diou_loss.py": "e8879b5a531873fd989db1b7ea78835e0335eafc5a8d22917e2bac12e509c294",
        "torchvision/ops/drop_block.py": "6642333356f7bf9fd4ef3d1e6afcda36937b201ab437864dc30bd602b8aca708",
        "torchvision/ops/feature_pyramid_network.py": "26db399b35095f711aadc01053930351ed1ae52827e588d4b2d696d894298041",
        "torchvision/ops/focal_loss.py": "952e45aa02c5b832a5a66d2c939575560200e8b14074951741a3e2df99c40e85",
        "torchvision/ops/giou_loss.py": "c41fd19444b6f24fc0ea21f656a5803c1424893ff3904c1db51103191fe75493",
        "torchvision/ops/misc.py": "9e242728fba27d0cd55c05a79dfe93915b207adab27ad8d9ea5ab7c22dadb19c",
        "torchvision/ops/poolers.py": "b1f81c656876748a3d518e37ec29e9007771a8f421baf8cd3d8ce120a94020f1",
        "torchvision/ops/ps_roi_align.py": "ebf9269c4eb3ff701967537686b4bfb8addc6eecea6618dd336ac2e7499f614a",
        "torchvision/ops/ps_roi_pool.py": "d89ae3270cd5b4478483405e6e40a719fab8c440f03020fe5e1f75e66bcd7322",
        "torchvision/ops/roi_align.py": "8ce04e7dca58e51709909e89f1517e38c4af05a61633164b2abbf539ce8399a8",
        "torchvision/ops/roi_pool.py": "70deeb48241fa54cc44ef3fc4a33c3975c9f5e36f183d23eb579c76ef00ac9af",
        "torchvision/ops/stochastic_depth.py": "f53e19bbf05a7a629969f4a6470acf095af969a187f2d9b396c40064efb5ffe6",
        "torchvision/ops/_box_convert.py": "82517ab2e94bcdac3f286dfac20d021d6b7479feb6067923a246ea42705432c5",
        "torchvision/ops/_register_onnx_ops.py": "838339169ee7ff9653cc841c517bc472ddd816550c3cd5524107c13fe2747904",
        "torchvision/ops/_utils.py": "c45acb9cb84a0c7886d93377f6d51663e3096cb10f91ae9d91a55524500defef",
        "torchvision/ops/__init__.py": "ef089b1b1705d491c3be248db3d3bd3f095cf1d84c4857d9a34c335634c59c06",
        "torchvision/transforms/autoaugment.py": "503f140654f875608841a343503401b5cd28b0c1c73d096e2ebeec79926be1c6",
        "torchvision/transforms/functional.py": "7bf7847624c84d2ae153668d151a7c8aa7a77f21717afb20ae614101928cfd35",
        "torchvision/transforms/transforms.py": "35e169a3ceb159fda1f2f333fef5e96ea57d3f346844e129e8694dc70f684d94",
        "torchvision/transforms/_functional_pil.py": "ef4a1a0ac084d25c07729ecda1923633d39b8be44a53f271b4fd83e071fad875",
        "torchvision/transforms/_functional_tensor.py": "126777b1025afe63818b9c556b92b041faa88ca0c0bab80e8508044512f1aa8a",
        "torchvision/transforms/_functional_video.py": "73805b522dd8d8bbec928cc5772eb5f6988b05de5a72c8f1828818017998e4ff",
        "torchvision/transforms/_presets.py": "515c5c84d81d3cbfb88951e33b17079ddca092dc382bbea187110af24b35ce5c",
        "torchvision/transforms/_transforms_video.py": "b9bda0093e442e22bdd7c06af8fa7a9b3856ac0671963edb95fa6403c0e16f5a",
        "torchvision/transforms/__init__.py": "5823574c951b27587b61a37d51fac14afb7ef924f63c0578b0b2026d34be2f90",
        "torchvision/transforms/v2/_augment.py": "85ca6895abad452b110293983ececf02855add839674b3c69cf83d2ae75c146b",
        "torchvision/transforms/v2/_auto_augment.py": "af0cc74bb099beddabdb512e23348a5b8182aec35d758a284d15c5907ddb38ea",
        "torchvision/transforms/v2/_color.py": "a45b1582dde8e7dcbca77fc6c1e54d81e951db97169ef5c0b534b222fad902c1",
        "torchvision/transforms/v2/_container.py": "13ef13bd317fa81a82e9a2e794ae669e9dd5dbba103b1872d57ecf65f4000f9c",
        "torchvision/transforms/v2/_deprecated.py": "f684a4ef01db6086a3022ce0dfba0e1857160b91880b012e48718039319f1a41",
        "torchvision/transforms/v2/_geometry.py": "4a2a28d12b267d9f4eadff6a1d7e2284b154d500cbac733e27177c7879539c53",
        "torchvision/transforms/v2/_meta.py": "23fe533ffc86a3fbc7a71ef128360c22b973ba2bac0a3717457eb347c5b31145",
        "torchvision/transforms/v2/_misc.py": "43d3626c852e0cce7a7f3f090a4b23d8061a93a87492a9534f40342185f63f13",
        "torchvision/transforms/v2/_temporal.py": "16616dc2796ecd1cc9397e90f9cda1c5e3d05b4487029ebb72d2ec64b5adf053",
        "torchvision/transforms/v2/_transform.py": "8b72967d77058e2a0bdc55798b1d577ad2b570b1f2c3786eb485b077fc0d9fdc",
        "torchvision/transforms/v2/_type_conversion.py": "cd6c186522e6fbb324ff44eb4a82431d7f4a7a5f9fcb2dfac0695861f684beec",
        "torchvision/transforms/v2/_utils.py": "0a2b27b43cbb8f41aea2b82650057cd284bb0350fccf1cc50f700616ba72b424",
        "torchvision/transforms/v2/__init__.py": "bc9a8f610a06583cdfa565ad893bb4ff519907392b7681d6a503c30d367d5532",
        "torchvision/transforms/v2/functional/_augment.py": "6aad94777718d73aad74c85955c7a0bc691cb90f3ac14b7002c3bee9b5fdb3fd",
        "torchvision/transforms/v2/functional/_color.py": "f939e8ba0abc354a033e962cb9e70684646d0b4fb27a23690a6dc708af95f76f",
        "torchvision/transforms/v2/functional/_deprecated.py": "f97eda8135e9f899db169b29df1a15935799afb3b24fe7af06dd279542c0478d",
        "torchvision/transforms/v2/functional/_geometry.py": "4a714cbc1220cee441918cc66397beac3bdc9fc097c87bca4215f3241ceae408",
        "torchvision/transforms/v2/functional/_meta.py": "6ff305e1242b999355a5c37c5fef1e74ff82126436e3530a0d6a504c6e2999b2",
        "torchvision/transforms/v2/functional/_misc.py": "6b76b47d6410f17622c5550994476a30557029165b469a31b9383cf825152c8b",
        "torchvision/transforms/v2/functional/_temporal.py": "b5246492a3aa510d105e310d17cd85d7a125d7e274203a052881feb2cfdca42e",
        "torchvision/transforms/v2/functional/_type_conversion.py": "a187f82cc8220a5bc4670c1cdd66ca23b7c9fab445843ad54812a23c0e6fc62a",
        "torchvision/transforms/v2/functional/_utils.py": "dd3e62160abcc211d06e4eddba2cd89a8c6ca47ea6b643fe2fb92eeb6ef37c16",
        "torchvision/transforms/v2/functional/__init__.py": "2c6bba64dbdd19a0fb8040f8322ef1fb7112d43f459cddf1ada5446ffa7de1e2",
        "torchvision/tv_tensors/_bounding_boxes.py": "b7a1d32b5309d718a226fd2688c8c67b3428b44c3c81035439b3c53028741d85",
        "torchvision/tv_tensors/_dataset_wrapper.py": "a6071ab275701a241bd26984a8f908832708fb8015ef4df16c14705056cca3d9",
        "torchvision/tv_tensors/_image.py": "c08d05ae76c750ecda2329dafcbcafe67d931a6496c2387e1df5530b82d9925a",
        "torchvision/tv_tensors/_mask.py": "b28655e5a300b73956df659be760296a0a1d6786eeb60412f02f9e0888ab2eed",
        "torchvision/tv_tensors/_torch_function_helpers.py": "53bafe406da3295fca61e51027684a3e56112f0ab3ff1844b3bfcbd685e906f3",
        "torchvision/tv_tensors/_tv_tensor.py": "bfe7559be659b387dd4fa4d5700797eca9c0269b9d5547f9e55a9db50b60b611",
        "torchvision/tv_tensors/_video.py": "2ad707769b26f35ba1c78e75a0db3a6ea15eb94c3a1bd5e3aa5b4379424dbf37",
        "torchvision/tv_tensors/__init__.py": "ed404865bada5728483be64278ab43e7d89ff395ca9004389e38d2e918c47c38"
    }
}