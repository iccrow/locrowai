{
    "id": "modelscope-1.18.1-py3-none-any.whl",
    "hashes": {
        "modelscope/__init__.py": "ccadc8e6c33793c4c435adbfd670fb25c7a0e55a5e4701645e284fbbe9c4c726",
        "modelscope/metainfo.py": "2bf838c061e37cfa32d15a71f8b700b04e11b4279ea12c1a90301fae0b62a92b",
        "modelscope/pipeline_inputs.py": "3cca4f2f83e7841c7691b0ca04df3b432804f540763ce465506d4f2e69a249c9",
        "modelscope/version.py": "9feb1f690fc9856c32d1d83743e22bd6bc38f32012cee3262e0cba08ef597cba",
        "modelscope/cli/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/cli/base.py": "9b50c5945d7a2f42f2ae7d1836e163f01c868d5248a08d232b3028a1d2178d19",
        "modelscope/cli/cli.py": "6c2a329b2fa80709ec16b5832a20080a0595fa4390abc9ab51b741ceec724ad5",
        "modelscope/cli/download.py": "3ac89077f60844911482bb49a67482616a081d9567154e09c4771048129a9cea",
        "modelscope/cli/login.py": "ab35469c23ddc3c1f44c5fd2d8653637c47cc6c56e1008a4ff3f9f26e005a065",
        "modelscope/cli/modelcard.py": "cae57cde0fe58a23f73321941351921361cc672c216fd35330e1961bec867f2a",
        "modelscope/cli/pipeline.py": "6a16ab18e2567ab774d715a6e4eb3cbcd12e4ed4fef01e76c4a0a3dcd37cfd24",
        "modelscope/cli/plugins.py": "c478c13920aee04477c875dcba928a1dff129d940485e2f1996eafd3b94af040",
        "modelscope/cli/server.py": "36d7a9fa0612cd1f61a20c80c10cf63df46cd20e3a0f14d8d728069c3cdf9f25",
        "modelscope/configs/examples/configuration.py": "440c86757fa3570e5324288f7f25dbaee87ede92b41b29e9ea13e7e7471c6aea",
        "modelscope/exporters/__init__.py": "e4675590ab311094fc9d502d343a99fc15bcf44e6d624190993b519898a1db0b",
        "modelscope/exporters/base.py": "fd9d29b514b7daaedcdd90530d7cfebfbca17c298edf83cd52aa126eddc9057f",
        "modelscope/exporters/builder.py": "caeab8136382cf7822eab1ca258ef24ca11e5e480c7fc6fb4e0dd30427578a14",
        "modelscope/exporters/tf_model_exporter.py": "f7063388ad9af3c645948b4d031eaf685a8c78a204e345b74dbadaee7f9c8b97",
        "modelscope/exporters/torch_model_exporter.py": "a93c2a95c43875749c468d7d08828e37a04a679b9acea784deeac442d8a93128",
        "modelscope/exporters/audio/__init__.py": "3a481e084d5fd97d5cc45a6bcc69040b22da1962908983eff9b18055c8943da0",
        "modelscope/exporters/audio/ans_dfsmn_exporter.py": "79c6492e9285cc7b1353d016c233618d6539fb202a3f5b44a06b0ed97786c297",
        "modelscope/exporters/cv/__init__.py": "f96fd7ca6b6a4d02a332212c2b7901d1298421b3d972feb8b108136e363aa3ca",
        "modelscope/exporters/cv/cartoon_translation_exporter.py": "5888b7dde71db46a9ce9d626421e09f7955e9f30c86a76aa3d280a965beab6b3",
        "modelscope/exporters/cv/face_detection_scrfd_exporter.py": "e1f7681d6cb1461901216d034d7a954e833a73823c91d7ba7ba4e77113a814b1",
        "modelscope/exporters/cv/object_detection_damoyolo_exporter.py": "06280881d9a56a06cb6419998fd3ad394b1e664fc582e4ebd5425f492fe8aee1",
        "modelscope/exporters/cv/ocr_detection_db_exporter.py": "a63376f0080d4a58f53e39e15165d52edfd5f99e13d019d11d47f4c6e11fbf9e",
        "modelscope/exporters/cv/ocr_recognition_exporter.py": "eff5f61d8de5b6f7c8a9c69071bb14fc09f6eed7b7c85ce81accfe556be9b819",
        "modelscope/exporters/multi_modal/__init__.py": "72e9ab27c66a96efc3d4706c2996f427c1a210875d72a23916ffcb9153528ba1",
        "modelscope/exporters/multi_modal/stable_diffusion_exporter.py": "1061a27c880fdd54406e0e02ea339ed3f9196a554693a24783f82e8dc8a19fad",
        "modelscope/exporters/nlp/__init__.py": "f29b0bde6ba68028c4818d310fe568494a2472b4aba09b47ed56c2a8791ccb77",
        "modelscope/exporters/nlp/csanmt_for_translation_exporter.py": "120fac3f7b44aef5cde488c35f81ab780f160c5bbdacb7a443e202f7013b87f1",
        "modelscope/exporters/nlp/model_for_token_classification_exporter.py": "d83f95cac782fa454b9de84eb16dded8cf03e8d5ce55553367e0065b672c177f",
        "modelscope/exporters/nlp/sbert_for_sequence_classification_exporter.py": "7af2f99f9da8f2b5ddafc845ca2b7527a45b3461b9f89ad6e4c57db9585b3a41",
        "modelscope/exporters/nlp/sbert_for_zero_shot_classification_exporter.py": "9bf05b68e57154417073fa45ac2a3c67db0f42e933d4a9bd30d31e95067cf168",
        "modelscope/fileio/__init__.py": "45a7584d31a487e10581a14fd31c90f9790bd4a76e70a43dd3b6417cf266647c",
        "modelscope/fileio/file.py": "96fc720536c3fe99ac8214422558411db4d4bb37350e9588b8e6b0fb159669eb",
        "modelscope/fileio/io.py": "1302df995761404b3fcd6993b1cd2f2550085020f6f9fa5f456fc97f7464db1c",
        "modelscope/fileio/format/__init__.py": "1d201b6d74924955f9ca8ed2e747af0f310c6c3398733eba1fc0f5d7360f492d",
        "modelscope/fileio/format/base.py": "7f6a3f94cb5ccbc10f866300d6bd4addf9d2c16fc68a6966c82804dd1dc1c193",
        "modelscope/fileio/format/json.py": "0af22fa32494ca62bdf279481c9cafb51a86ecd05b57a3c002ba6196c269af55",
        "modelscope/fileio/format/jsonplus.py": "d9b08f5199ef5eb753501e3a0b553f85718bc142dbb2fb95af8b3eb497d9ed99",
        "modelscope/fileio/format/yaml.py": "7580a7b2dae4444b16ea53de2487a5b1eaa6accc1c738c1f9a3d47585a19ef6f",
        "modelscope/hub/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/hub/api.py": "5fb8b0743d65fc022b085e732ec1da3c28967ac4a9b4b79e331c56bf137475f3",
        "modelscope/hub/check_model.py": "a259b17c4c4a535dc216ad4582743e16fe3e349d9b0723b2ae2a23eb2c3e75e3",
        "modelscope/hub/constants.py": "8700589a0c9368a2d1d39433dbfe9cecedf99850760e34626582bb7459df1e00",
        "modelscope/hub/deploy.py": "6bbefd94c8dd5eb29abeb8fae4befca967d1e95c718a335e237b77f66ada6eb9",
        "modelscope/hub/errors.py": "54046909bd034d193f8a2bc3a200512559aec40d31d746ca6a7cb0db7eeee514",
        "modelscope/hub/file_download.py": "913bb774ffeafa2cffaea5ec0da2ef9dce2ef374c6145efbd8010463d9051a61",
        "modelscope/hub/git.py": "fa1a1d33263bf75554701327419a733391a6e869623081ebb1f56350b74d9060",
        "modelscope/hub/push_to_hub.py": "3bc8d8c319a1fecb1bfa79c8ab4b1a071caa2cfb2da8bad97db0e35a4f83b5ac",
        "modelscope/hub/repository.py": "3ce981aa4ec6a4495f80464be34016754dab75ee4d80041270f8468d872db7fd",
        "modelscope/hub/snapshot_download.py": "2b89443b54def43a4de2ad30cfbb5a1e4d38e20273f2ed0001d06d262ec3ac54",
        "modelscope/hub/utils/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/hub/utils/caching.py": "db26e898c80a1944d43a063b976fde60b44f68d211455cca3138e7dbea4f4373",
        "modelscope/hub/utils/utils.py": "15898d8a2c2f6b0156263b7e58d784670c8291c43f022480117dd6445d10e842",
        "modelscope/metrics/__init__.py": "e617bab701a14aadc8caf519f43da93be3bb1d5a533d984a98d15c667913b7c2",
        "modelscope/metrics/accuracy_metric.py": "317755581013d03630194191982065d6cc6f1e76a3166d6d497d0a61eb900ffb",
        "modelscope/metrics/action_detection_evaluator.py": "9a96d36893c0e72c58b9e55e7fbe20f031dd899cc3bdc1c1163fae64faedb7f6",
        "modelscope/metrics/audio_noise_metric.py": "e37f5cce09b3ba7f71ca424943489f267af94e2a27d682667f8cf84e5f728353",
        "modelscope/metrics/base.py": "34b12ee72e8a6414ef4cd5da3d138d24ea092f400f3751b653ba29e086bb699b",
        "modelscope/metrics/bleu_metric.py": "dff38649c769379628da9647d69868565c974001f47857f9c34d3098518e4ee8",
        "modelscope/metrics/builder.py": "1aa8b6e018fd698d713ff70608b5089517202f92fb051ffab39b034bf0200878",
        "modelscope/metrics/image_color_enhance_metric.py": "a79bb6b84ce4435c4c648591f4d275c34ff3b3bbe950fa9380c577b577bc8a48",
        "modelscope/metrics/image_colorization_metric.py": "062c6676ed0c095c84ebc4110a4f9802f6c24ef4a9c312ed65b59ba726bfc8e9",
        "modelscope/metrics/image_denoise_metric.py": "cb3c925cd807f559f12d0cdc7d6ed01cb010912d22a2a9fa12f9dc4a55130674",
        "modelscope/metrics/image_inpainting_metric.py": "1968db93aaee8adf0722033c2a3b72e0d73c3b2a97161196e4bd239ee0b91a68",
        "modelscope/metrics/image_instance_segmentation_metric.py": "22861fb243eb08794faced1f214649c7b93cfbd6180ed8bcaf6523fadb8fdb8f",
        "modelscope/metrics/image_portrait_enhancement_metric.py": "e0b037c8d04e5b89f3e6bc8e3b7a915c61b533b70db98a00359e0823dc52f9f9",
        "modelscope/metrics/image_quality_assessment_degradation_metric.py": "2668a157e59c04f51bfc46ab7bedf1a81e19803493aa441955135c7bd4603a18",
        "modelscope/metrics/image_quality_assessment_mos_metric.py": "10db0e86c10a5718a4afa2b7818e2ad668b52026f6ee8226ed1a5845832c1c42",
        "modelscope/metrics/inbatch_recall_metric.py": "c5d6bb11b708ce8d347a9739f3e62921e8182392b103288370c5cef184014a4a",
        "modelscope/metrics/loss_metric.py": "ece2ad33066aa3a86e2260dd47391b954bdf3a00638b86ec32a554fbb3d9ff32",
        "modelscope/metrics/map_metric.py": "2bb2dc20432fca4377842d657a9a5ab5666854a8eaaef30d08433730e2962c99",
        "modelscope/metrics/movie_scene_segmentation_metric.py": "885649ae5a31bd734a9c7fc0449f66a9514cbc47503859028534bba97ee0e0bf",
        "modelscope/metrics/ned_metric.py": "cc7203e8ef240ff7dc5901583d89778e07a2bc11ed26b7062fd3fea79a3f8280",
        "modelscope/metrics/ocr_recognition_metric.py": "f1a83dda8a7d9a4419662b6e10a3f7a2fe2e14b70c2ef59e7dc736bb97d0ddaa",
        "modelscope/metrics/ppl_metric.py": "ef51803f64d2b32e36394615705cda859ba0cf76140935be4bb44f03c0a8699d",
        "modelscope/metrics/prediction_saving_wrapper.py": "0a6e48ee7c01349b3ef7b34d3cb276fb4f7b0bef145175f2b75b53da6adf00d7",
        "modelscope/metrics/referring_video_object_segmentation_metric.py": "aa41e3a4aadead270c648b8f3ef091126ffc727c286af13378b5d482e0de9e7b",
        "modelscope/metrics/sequence_classification_metric.py": "664439c04b5bf4715f15b5ea0faba2fb0277f45548b216e3a3afdb7c56a40543",
        "modelscope/metrics/text_generation_metric.py": "6f4709a3f5db3c0fc9b3483129b07979ff4d0bbea6051e8bfa637b89da09c406",
        "modelscope/metrics/text_ranking_metric.py": "66f9bbf16bc333831e32664e769775c7bea2279ac8699991098cc3ab5fe4afe0",
        "modelscope/metrics/token_classification_metric.py": "bbd758f8cf29c9ca496991c567fb20a8c12eff8b2c47709249793f1f5a011c68",
        "modelscope/metrics/translation_evaluation_metric.py": "cfc920a0cb48fa034e243f907cdd6f2716e0ec2bb5fed198fe1cbb17fa339289",
        "modelscope/metrics/video_frame_interpolation_metric.py": "e5dcd335c894034d4de662676cce418c63cd6733453bf877b71b911a54fd07d3",
        "modelscope/metrics/video_stabilization_metric.py": "857ff2743db4548282918f8ec2cbd71b5e0bd55ff4edfd0b5a9bb260fcd01d91",
        "modelscope/metrics/video_summarization_metric.py": "33f1858157e78127c0a8f78bce58bbe1467910d181162caa50c3407e5c34a0b3",
        "modelscope/metrics/ciderD/__init__.py": "d02e91fe125b82e6e5f0642b897f7439094506d06f32771b40d00170deb8eae1",
        "modelscope/metrics/ciderD/ciderD.py": "b96cd77c97c3ac868266dd041a6e817d0884bf9edcd79d28b8c7ea4ac9f7d729",
        "modelscope/metrics/ciderD/ciderD_scorer.py": "765d0bf0ead5ad9ca6064d27b1a0f42c77afd534b976d26588bf52d70213004d",
        "modelscope/metrics/video_super_resolution_metric/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/metrics/video_super_resolution_metric/matlab_functions.py": "b960e68827611d04c0d713d7f48c0fb6234c30b8fabd34869ac878731262c10c",
        "modelscope/metrics/video_super_resolution_metric/metric_util.py": "94feb5b1e6c31a3f5fc3ef814106d38abd7c356ef7d2aff234c58a84def6de94",
        "modelscope/metrics/video_super_resolution_metric/niqe.py": "b8e7e297295b073585c6d85714bd74b36ee89316958af2350ad4108403c3f60e",
        "modelscope/metrics/video_super_resolution_metric/video_super_resolution_metric.py": "5e15dcd8be0783245a7f1ea90dae391ec0340f9d00f4a23894291a8b989009b2",
        "modelscope/models/__init__.py": "092c71e3b9ab3165818d21be9282df37a39ea1f5dbbb13a1a049916f7c8f7602",
        "modelscope/models/builder.py": "ea11780d75aefee680d67f0ca3fca0a53096bc7b273a7daace6fb45560558a90",
        "modelscope/models/audio/__init__.py": "a1008fc2b14be43b5210f80b1c5831bc333e38bfb244319a78504befa7fecba1",
        "modelscope/models/audio/aec/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/audio/aec/layers/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/audio/aec/layers/activations.py": "652dea582b7df595a43156a33a08ce7fe5a01046cb99321b32c20e33d436a528",
        "modelscope/models/audio/aec/layers/affine_transform.py": "1846d62060c6e06a74177d1927d0dc920076218780c786841b2c773d5857c326",
        "modelscope/models/audio/aec/layers/deep_fsmn.py": "fcb98010323c2e6931f65949538194cc4f656f31cda134008014a097b10d8810",
        "modelscope/models/audio/aec/layers/layer_base.py": "a8acd3352266750b44bfc71244ab0e3b499ddd3e5f9b03552f3f1444014e9c84",
        "modelscope/models/audio/aec/layers/uni_deep_fsmn.py": "1b773e72c737674dc283107e288fe39374288354138f8e4cc3fc8969dece2c75",
        "modelscope/models/audio/aec/network/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/audio/aec/network/loss.py": "aa801065e9bd5444a40b1bf5d87d074018d9cc92e0c40328f0258bd2282db2ee",
        "modelscope/models/audio/aec/network/modulation_loss.py": "9180b2f330287a3b59445324ceaaedf15cb35b0d27aac81ea326ae6439c65211",
        "modelscope/models/audio/aec/network/se_net.py": "6e5f04aacb52d1449f75320edfa07f2d907f61f9adfc9621b122f463cfc63cc1",
        "modelscope/models/audio/ans/__init__.py": "9fdc4ef913fc65976671653c00344a707a92592b5d7895fc6ef3b1e45e17cd9e",
        "modelscope/models/audio/ans/complex_nn.py": "e0efe33e559062d38f4aa90d5757a6098b6e513c3d535b5e80597f80d0b63977",
        "modelscope/models/audio/ans/conv_stft.py": "b03861fb1dff7f8abf46abbfcc75762c3260937567e98890d109f4d0458f47b3",
        "modelscope/models/audio/ans/denoise_net.py": "d5004f52183f106af228ccce7761d2bf40484cf509ba0511bca7ab62c35aa1af",
        "modelscope/models/audio/ans/frcrn.py": "7debff5bfe646c595f4efbfa103605f2097ac9f9203c2c440b313eeab66246f0",
        "modelscope/models/audio/ans/se_module_complex.py": "ed0e89a59b9007b4a960b33aa8c97723da7b9b3dede21a9abfa8d481753d44a9",
        "modelscope/models/audio/ans/unet.py": "55e3dda6901099380cc027f51ec44c996e787f4b96d0cf8553ee98d5bc533963",
        "modelscope/models/audio/ans/layers/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/audio/ans/layers/activations.py": "d7e822799aa30c2581638b642ca7b6eeda7500b63cf9ad9ddf0ea559bd4f2ef3",
        "modelscope/models/audio/ans/layers/affine_transform.py": "96e75eda35d7491f1eca34411f226d6bd36b799b619ab46e8c02d559a8f65132",
        "modelscope/models/audio/ans/layers/layer_base.py": "2b3e80b87f5acd5c92ee4b09360a4afa138638d9fd2b29910a95c9b89cc09ee8",
        "modelscope/models/audio/ans/layers/uni_deep_fsmn.py": "af78e7377c50af5eb27f769ca63cc78d2bdbe9134573416cb16c6c476563399b",
        "modelscope/models/audio/asr/__init__.py": "7eff7f6ace595e0d3fcbb27115c9c56447083fb1dc4397e8144ee31fa7b887f1",
        "modelscope/models/audio/asr/wenet_automatic_speech_recognition.py": "0d1ce6c3509185a27fe04418ef0bf64079fe7f5f7d57c8da41a145ccc75414c7",
        "modelscope/models/audio/funasr/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/audio/funasr/model.py": "cd90cb432e3f209ef5d3923d1273fb597c84fb4aca29f24fb083059b01a41c3a",
        "modelscope/models/audio/itn/__init__.py": "3ab1da28c16ea8611e3f52c16e3afc07f4048c65b938b9fd9de76212861de56e",
        "modelscope/models/audio/itn/generic_inverse_text_processing.py": "cc128e914ba1b61f545a4a50d849ad5778a0c68270e800998e01a600e2086178",
        "modelscope/models/audio/kws/__init__.py": "01596352be8d70e110ccefceff4f78f2746280b7079cf3dd9ed9d2d1bca32a25",
        "modelscope/models/audio/kws/generic_key_word_spotting.py": "66e1421c1cdfd40748c3fdf905da269cdc25ce0df03cba0f271e05d727afa80b",
        "modelscope/models/audio/kws/farfield/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/audio/kws/farfield/fsmn.py": "261fe21f382824e3e3f63b1e34d823ad684fba5f08fdb81d28fc90c41b9d678f",
        "modelscope/models/audio/kws/farfield/fsmn_sele_v2.py": "55a55c1c7b5ae4ea0b848538af52c93a0ab5b6af9901432ef77d49802d5dec36",
        "modelscope/models/audio/kws/farfield/fsmn_sele_v3.py": "ff869f307b289669b609e52757d52862ffb9c294c7af0c54f1c348c896360dda",
        "modelscope/models/audio/kws/farfield/model.py": "5078b712d6b1b4cb1fed2c847498f6cdc101008db24aeb6fc347a146c907b4ab",
        "modelscope/models/audio/kws/farfield/model_def.py": "87620006d2800c855d7577e7afbe5c4a3928ae10cc5ee8f9add8e2f1c9186969",
        "modelscope/models/audio/kws/nearfield/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/audio/kws/nearfield/cmvn.py": "342b51234c7fabac28862e514112e637d099bb91eab66d6f0d31332cf94915f2",
        "modelscope/models/audio/kws/nearfield/fsmn.py": "9bf6bde65ff309170337d0dbdbf537dd91fe15f22e0cc304b1e01dd1d0cc6748",
        "modelscope/models/audio/kws/nearfield/model.py": "b8961aa41836d2f74e81b9c60b74d68cff7e5d20fd541339a4d33adcae3f1960",
        "modelscope/models/audio/quantization/__init__.py": "ac34063a1fdbee0accca9e9f00278315c60327704cf19f77bc432735640e3c74",
        "modelscope/models/audio/quantization/generic_audio_quantization.py": "8d30701a73b89797771e3f53ac75b0685c5f8435c6275e67b58de26b5fdbd426",
        "modelscope/models/audio/separation/__init__.py": "836845bf1ee0b3f2bb28f132f535e9414e3078feb157212301e80be150e56548",
        "modelscope/models/audio/separation/layer_norm.py": "304d93358332502b24371de63448502c6f0c4084ab5ffef5f68556cf3ca8bbb1",
        "modelscope/models/audio/separation/mossformer.py": "290fd97be3cb8d9160d2338653028662b6fda76281b141767dd6ba3a3ea31c04",
        "modelscope/models/audio/separation/mossformer_block.py": "184ffb8959dff97e618e8490d31adac41166c769c28672e7939b44cc96e965a5",
        "modelscope/models/audio/separation/mossformer_conv_module.py": "54837d536d6f6630d10701f367db8fd9136886b78e90b3909265a08fabf52bf6",
        "modelscope/models/audio/separation/m2/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/audio/separation/m2/conv_module.py": "b5b82b7c58f236327127a8a2ebf018f3b7899a22f185b1bbf5374b9c8fbc5010",
        "modelscope/models/audio/separation/m2/fsmn.py": "97e88cb860bea84817b2b8842739fa1fe11309c2e5465e54a2d1f4036fc1027a",
        "modelscope/models/audio/separation/m2/layer_norm.py": "4e9c04df8482afee30f956674db35713dbe5c1165a860f1af0f0897b76d36821",
        "modelscope/models/audio/separation/m2/mossformer.py": "132088a3e46268ca301516c81e6880fa4eb8ea8a7847f20bd377c03d55d00036",
        "modelscope/models/audio/separation/m2/mossformer_block.py": "310f01b58783ca3f6570ce2a69c27096d2c86bdaae541ef514e4ae31280a85c4",
        "modelscope/models/audio/sv/DTDNN.py": "1e39830130292c6620869a2fcd40061b264066574253a8a483855c53f05ee880",
        "modelscope/models/audio/sv/DTDNN_layers.py": "f4e6a40a69ad5956b6ddeb178ab2783a31227bdabfefa20fffec79960ac06460",
        "modelscope/models/audio/sv/ERes2Net.py": "6740726afeb79b68ea8d0f74a4c63d601bd4377f06b1eda89d8aa22ee1dc2819",
        "modelscope/models/audio/sv/ERes2NetV2.py": "bcff9d6dd0061e73aa13aca4749a59de45462c4d9db4d0a64b1c69d73f5183af",
        "modelscope/models/audio/sv/ERes2Net_aug.py": "ff3d4204bc794a0a991d2f66f25c5aa873743ce80424483d34c392dd3afdfded",
        "modelscope/models/audio/sv/Res2Net.py": "74dacbffd998cba0bfceeeb6e2ade4f8c32fdfe61106415cbc9b00b506552e8b",
        "modelscope/models/audio/sv/ResNet.py": "54d455f785446d59a5011c93e4e54ba4bfb8180c5582c1b376123d945093ba58",
        "modelscope/models/audio/sv/TDNN.py": "5b5ea637431bd2254eb88d186f7e620f0a434179f2dfdaa668ab0f521046f789",
        "modelscope/models/audio/sv/__init__.py": "7a80d7cc4c8ce661663c3c5ca3fb8acc678ba373e726b7aeea5f6a3918c68ba6",
        "modelscope/models/audio/sv/cluster_backend.py": "df24e14d7c6bb68a40463b0fb60ccc0c50a4eb551ab7f509abd1466cef3aee3e",
        "modelscope/models/audio/sv/ecapa_tdnn.py": "b354b19fb4fdec61bdffb3f3db57c65ad7301a655e79de107674d6b487e6e25e",
        "modelscope/models/audio/sv/fusion.py": "7aa7ce95fa112d77a42995a35675ebea25403e2695a245e20de61238315caa19",
        "modelscope/models/audio/sv/lanuage_recognition_eres2net.py": "87f66cc42e5e2edab852867c20f377ffff06b1fab207d303bbafade12c1f48d5",
        "modelscope/models/audio/sv/lanuage_recognition_model.py": "578b8991d5fd28c990f63256adb6b1d3412f3dd9bd73002d0c099e4e8911e46d",
        "modelscope/models/audio/sv/pooling_layers.py": "ed96f9e36e47df151e27373d47e7b60169f6924f595c176b9c34b9e2ace7ee6e",
        "modelscope/models/audio/sv/rdino.py": "cd6d53a01c9c396114f3df2f2e36a5252fdd751c3404590875c1ed8e8a7a014f",
        "modelscope/models/audio/sv/sdpn.py": "eaea4d22f2ee865af683d9f139918f63afbd30d336f986188d683557c03b262a",
        "modelscope/models/audio/sv/speaker_change_locator.py": "a6fe7d3c6231961c59dcba6134e77e9439c053e30e7c026daed0a223e7c17f71",
        "modelscope/models/audio/sv/speaker_change_locator_xvector.py": "9681d652a4d6d26c67cc28bd0e63622d4e4bcaa2daf0fed7b5f08f8fc894b806",
        "modelscope/models/audio/sv/speaker_diarization_dialogue_detection.py": "d59cb92b7da25135b26fa7b8a1a9994594cc70fe60e9c32d82517f285135666a",
        "modelscope/models/audio/sv/speaker_diarization_semantic_speaker_turn_detection.py": "31c2c35f483f46b8f054ca53381a3bfd75aeaca6783e1d350786d603b16f541e",
        "modelscope/models/audio/sv/xvector.py": "ef5cc8400aed8b1a86111e9d71da04848365bb4e08ca86a793efcbb3d6aa5172",
        "modelscope/models/audio/tts/__init__.py": "24aa447e0085b4a005f67e3df6cd6fa519a0216d19da539b9fa8bcf56d758273",
        "modelscope/models/audio/tts/laura_codec.py": "cf924d79d9abbc7a6045df62b9be9aeff54e41781030037abf03fab8335ef9b8",
        "modelscope/models/audio/tts/sambert_hifi.py": "d222fdb279022135368c4736ff3c716c31426523ee434fb29e94e753377e551c",
        "modelscope/models/audio/tts/voice.py": "51f7e2bf4d4f05cf722fe92ce7f46fe1cc65dc66b17844475b9ca41bc2a3f085",
        "modelscope/models/base/__init__.py": "7e2cdac0826f073358223cb89c510df9a6ae322583803422343aaf670903a564",
        "modelscope/models/base/base_head.py": "f8036ce12752e30828985c291b4fe0678e1ea8e2446244880632ce44744e41cd",
        "modelscope/models/base/base_model.py": "857a7c53eff9ee7b25138f9d8dc984aa79a7aaa6f85afbe4a4884a1c413caf3f",
        "modelscope/models/base/base_torch_head.py": "9c7f07ff3018d2ee42ce6796eeb954c0256b304dd48dcd3b39d6fe766a1ef319",
        "modelscope/models/base/base_torch_model.py": "bf1267549924a664d3bf73c2bd4e5f11374a3efcbeb172e74742ab23a5597e3c",
        "modelscope/models/cv/__init__.py": "79faf1705375e8a5a962aee3ead3fee6ee9c7d9009650ea70714ded60eb1a566",
        "modelscope/models/cv/abnormal_object_detection/__init__.py": "7d86d0291b3f7ba805fb813a06799a1d6d2958ff7ddff9a661193313052129dc",
        "modelscope/models/cv/abnormal_object_detection/mmdet_model.py": "a380b7b71c20b3ebf4b6a683d34f77ca4654a48c6fd4fffd5631ed72942ad842",
        "modelscope/models/cv/abnormal_object_detection/mmdet_ms/__init__.py": "f1de5c7a5d7b96dfaa048ceeeedec27177e510e3a23bf3367a8c8748598f81e0",
        "modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/__init__.py": "d773fa7ebf28c777161dc34d2212d86a7d0993eab27d3f83bdcf0234a5b772e4",
        "modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/mask_scoring_roi_head.py": "e95a94900c16d7ff1ea1c16453f1e8c03cbe531d8be50ccfc5fc145c72fdced1",
        "modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/roi_extractors/__init__.py": "c1cd348cbefe931fa8df9087c36a8f524b9468d7c1a3a12abaf7f3d27a2cfbe8",
        "modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/roi_extractors/single_level_roi_extractor.py": "a17b70ab68086be60400a685098ef41d96286fe5c89dce63c06a9fc19169bbd3",
        "modelscope/models/cv/action_detection/__init__.py": "74da22659b81fc595d7e57198ff3bde4018742ee0044a31e3b081d1548265375",
        "modelscope/models/cv/action_detection/action_detection_onnx.py": "a6e788939971974471964b90cbc727ca3507d107d0fd9245232ee69eb0ac1ee7",
        "modelscope/models/cv/action_detection/modules/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/action_detection/modules/action_detection_pytorch.py": "0ca28204baba6bde51971a796f451c54b7a871c958196cb40c2b403f6b06d191",
        "modelscope/models/cv/action_detection/modules/resnet.py": "3fe315abdfb15b9fe1683fefade095b3d848c0467a459e012b6957d7e8cc08c7",
        "modelscope/models/cv/action_recognition/__init__.py": "1eb5c454e562385e88e5b7efc2d18743f19e2e2d1e1f05896021360d4c350257",
        "modelscope/models/cv/action_recognition/models.py": "0d0550e5e525b83dc1c6b0620a561ac97e36789e519c902d84d19ead6fa46913",
        "modelscope/models/cv/action_recognition/s3dg.py": "28c17195beadad007487166d5b4a132cc9e91a9d5cc519a857e52eb78d2a751e",
        "modelscope/models/cv/action_recognition/tada_convnext.py": "ba0907575a0a33e1c7983444033a7a26b1caf54466e0decab74558b2d988eb4a",
        "modelscope/models/cv/action_recognition/temporal_patch_shift_transformer.py": "9177e112a591f214ab38160824cd9c87fd3a23663fe3ccaf85331b944c880a02",
        "modelscope/models/cv/animal_recognition/__init__.py": "784e0061819021a17695eb6db9da89120be77668a1c96aecf4f2fd77ef91c68d",
        "modelscope/models/cv/animal_recognition/resnet.py": "9777af13e64b8c05c73e5804840610cc2dc888da753eefaacfc29c4bf022c4d1",
        "modelscope/models/cv/animal_recognition/splat.py": "493676c3011ec430e617f1f6fe83b5b0faaec6818de837d5dd565357d6e9dd74",
        "modelscope/models/cv/anydoor/__init__.py": "53b692960ff1525e9886c2a2efcccd482e19ad9496dc231b044ccfbee80e0ca2",
        "modelscope/models/cv/anydoor/anydoor_model.py": "9f47b6ae290f875377b0fac86cf74ec6cc2a1031f951490a2a95007c05be9581",
        "modelscope/models/cv/anydoor/cldm/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/anydoor/cldm/ddim_hacked.py": "0735f8c3984426919959321a07fe63740c164f5de9b63dc92dd2009860c93985",
        "modelscope/models/cv/anydoor/datasets/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/anydoor/datasets/data_utils.py": "326720ea72bba9f2c91cb3b8af9a37bd29d2f324b762792fef5304ed4efaae1f",
        "modelscope/models/cv/anydoor/dinov2/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/anydoor/dinov2/hubconf.py": "2fef4c28074d9b6b9a706a4f9370ffcfdcf53b3c1bad829d3e1e3e410e0ada12",
        "modelscope/models/cv/anydoor/dinov2/dinov2/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/anydoor/dinov2/dinov2/layers/__init__.py": "95dd8ac007f8eec8c0805fc52d87392dd063c8fb68a6deceb4e484dae73b99b8",
        "modelscope/models/cv/anydoor/dinov2/dinov2/layers/attention.py": "003ddb9969022c5a39f711b0b3531d8f56ba7750195867fbba3afba30d410e77",
        "modelscope/models/cv/anydoor/dinov2/dinov2/layers/block.py": "6537268c57412ab5c328b0f01dbe8c963c873da4684f853c5558888d74c683b7",
        "modelscope/models/cv/anydoor/dinov2/dinov2/layers/dino_head.py": "0e701e6adc5dd7df3fa7e877e4a795ebebb760b1a549a30197d96b6c8e36ae7d",
        "modelscope/models/cv/anydoor/dinov2/dinov2/layers/drop_path.py": "a5ff9e9366b729a6f32fe6943b8750b588a387c16ec20722cf0031db7ce0f4f1",
        "modelscope/models/cv/anydoor/dinov2/dinov2/layers/layer_scale.py": "a6f63ebd81371eca09787dfc71ba3f709c0ee4e6e6ee0844c47490572767f2e5",
        "modelscope/models/cv/anydoor/dinov2/dinov2/layers/mlp.py": "4e07fa72980c7d66b6464dc9682109c8dc6f694b491992c92a8b0261215b70bc",
        "modelscope/models/cv/anydoor/dinov2/dinov2/layers/patch_embed.py": "c61fe9ad52fb5608650ca47fb445237967ded70063fa4bd06fe1b29ab09a0b0b",
        "modelscope/models/cv/anydoor/dinov2/dinov2/layers/swiglu_ffn.py": "05357626718322eb037063d8a544428c99b61a889eeef7ec0f9decb768668e59",
        "modelscope/models/cv/anydoor/dinov2/dinov2/models/__init__.py": "f5ac15682762ac983494cf0789fc8b7a20df694f13dfc7a775e74b9c72752ffe",
        "modelscope/models/cv/anydoor/dinov2/dinov2/models/vision_transformer.py": "7f585f5260ef49d7c6c8d1ac3f5bacc96a5782f5e4cd554ad095b1f737051ef7",
        "modelscope/models/cv/anydoor/ldm/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/anydoor/ldm/util.py": "bd5d5415820dccea5367a1a8da4e74c94e8f69bfff391ef424915ec44834acad",
        "modelscope/models/cv/anydoor/ldm/models/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/anydoor/ldm/models/autoencoder.py": "28506df759430cce0b853be19af3930f2fc169e691e88f4ffd546e6346ff8fc7",
        "modelscope/models/cv/anydoor/ldm/models/diffusion/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/anydoor/ldm/models/diffusion/ddim.py": "673526f83c7a0758dc5370839a552ecea27e825992b3a0450730759fa96d9f98",
        "modelscope/models/cv/anydoor/ldm/models/diffusion/ddpm.py": "2b32c0888af51400d5f2eba3aea22ce4f4c56f7cfe270b77cff4dce536975dd4",
        "modelscope/models/cv/anydoor/ldm/models/diffusion/plms.py": "c9d97b5ffc86ac14c27d6f6997ead5c6e8558eab05168502937a9547abd590ed",
        "modelscope/models/cv/anydoor/ldm/models/diffusion/sampling_util.py": "1f316493aec4109ba2400486b2d48e8eaadb178795bc567308f87f33f1637fa1",
        "modelscope/models/cv/anydoor/ldm/modules/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/anydoor/ldm/modules/attention.py": "9115e1150906579772d9b3f0d167c26061cafde62ace92f199e67b23f4a938c9",
        "modelscope/models/cv/anydoor/ldm/modules/ema.py": "de0eefe14754cdad6b26d56aa8a2cb8a948414cf11c40eef0a4c7fa38014959f",
        "modelscope/models/cv/anydoor/ldm/modules/diffusionmodules/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/anydoor/ldm/modules/diffusionmodules/model.py": "3b0620616f980063d475261915019ed36f78eb89c5c3e702d63281ec7879cc22",
        "modelscope/models/cv/anydoor/ldm/modules/diffusionmodules/openaimodel.py": "7e1a5bd860eae858add183763512467bfc012df03d6647468e6c2ffeda12bcaa",
        "modelscope/models/cv/anydoor/ldm/modules/diffusionmodules/upscaling.py": "3344fb6ec1d6638dd02dd538c683b69eeeeef93f8bd122b03f457222bcfbb345",
        "modelscope/models/cv/anydoor/ldm/modules/diffusionmodules/util.py": "d1f9b52761e98457e49be8e08671e06afcbb49cd2b0c15c52204bae8379d176f",
        "modelscope/models/cv/anydoor/ldm/modules/distributions/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/anydoor/ldm/modules/distributions/distributions.py": "36196cc3055159ee0520474002d8e53b7180aeca846b9f2367b2b9868cedafaf",
        "modelscope/models/cv/anydoor/ldm/modules/encoders/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/anydoor/ldm/modules/encoders/modules.py": "b0a105228834d90274ea862af9e24d54cdad7fe6934f217bc13202de872c4788",
        "modelscope/models/cv/bad_image_detecting/__init__.py": "5106abf57da4eb203169efbb238f255e003ac8c98d601d0bbaf4d68dee9a5098",
        "modelscope/models/cv/bad_image_detecting/bad_image_detecting.py": "49eccd0d1e2d256e3bafaa14f293252eec47b5de37747fb126d7b3313fc57b74",
        "modelscope/models/cv/body_2d_keypoints/__init__.py": "92be4ab635ef0c60e2d8a811cd62ceb81b1bdf5ff4eb9719436bffc40c1fca5f",
        "modelscope/models/cv/body_2d_keypoints/hrnet_basic_modules.py": "84a8963d27f2944445e231b8b96c4dd7de6210802525cb6b441ae84e1f53b30d",
        "modelscope/models/cv/body_2d_keypoints/hrnet_v2.py": "4c92a8b271edafedd48f58b288c93c4810037c39f96a619b6ca5aa62ecfa3413",
        "modelscope/models/cv/body_2d_keypoints/w48.py": "3e2d5f25b1c5904e08ac90d0021d8132b4694c603c6034105be19fb894e42f49",
        "modelscope/models/cv/body_3d_keypoints/__init__.py": "d14341da47a1325278f934fcdf0703b46b01f84483bdfd48e3436f2deff1c170",
        "modelscope/models/cv/body_3d_keypoints/canonical_pose/__init__.py": "e52782f5dd462b42bd8ad694eee5687b96c119c9bd6a21e758216f32e06c0fd8",
        "modelscope/models/cv/body_3d_keypoints/canonical_pose/body_3d_pose.py": "36e147f59da60d6f97b5648ce1be088dee352eb02c116e981b3466b91043a2d8",
        "modelscope/models/cv/body_3d_keypoints/canonical_pose/canonical_pose_modules.py": "7b05c588866188ce5c517fc85bfbaa083aa9526721b7f1dba375b58b50446d8f",
        "modelscope/models/cv/body_3d_keypoints/hdformer/__init__.py": "040eec92467546b7ee3f3b12743500e35baee5c8d583e3cfb891674e95143c87",
        "modelscope/models/cv/body_3d_keypoints/hdformer/backbone.py": "f552b6be29205d33a1987f04aea7d97fa4112fa725ff5c7987cbd61793abfe05",
        "modelscope/models/cv/body_3d_keypoints/hdformer/block.py": "8ffbbe9ccfccd767efc11c7db16083335e508aa4269fb73ab59c8620374df5c1",
        "modelscope/models/cv/body_3d_keypoints/hdformer/directed_graph.py": "9f7dba562c1ea6bf50d703840aaeec7b1e18976c90efa20959269ff321e292d9",
        "modelscope/models/cv/body_3d_keypoints/hdformer/hdformer.py": "ee155e0859f26c3a460d964598b21687c1cedb725f771c0d06c410d83543d608",
        "modelscope/models/cv/body_3d_keypoints/hdformer/hdformer_detector.py": "29e2dce7f8a6de120833c26bb31fa837554eee28391f3a59e2d3c01a00d58bfa",
        "modelscope/models/cv/body_3d_keypoints/hdformer/skeleton.py": "4ba26108cc542f70b1d77e3156e60ee7d428af1edabf9245daf9fed513e3943d",
        "modelscope/models/cv/cartoon/__init__.py": "18b6a6fdfa2b82a8327209ae6f575f79c27be81d87cf523e2ed0c4c6a855f851",
        "modelscope/models/cv/cartoon/loss.py": "5f7e9455b38e346c62112869a329f33127bb6ae3094f50c675234b856e15ca3e",
        "modelscope/models/cv/cartoon/model_tf.py": "3717c23fb2564b92b890d9d12c14920b717de018ba49920a615c7270fb301eaa",
        "modelscope/models/cv/cartoon/network.py": "4a2d79349eccc1c6441547118a5af2855ceed86d7381921d227ca7f0b939bdbb",
        "modelscope/models/cv/cartoon/utils.py": "5500e201b60c6428cd18d5a6a4c1f49214712cf49ca526e10fda5da5aee312b7",
        "modelscope/models/cv/cartoon/facelib/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/cartoon/facelib/config.py": "4943b707ebe9df83d237870a26460f419a68fe28781ef4ed990e252d976136e4",
        "modelscope/models/cv/cartoon/facelib/face_detector.py": "75a23d296663384ffb0b15c66340d8f8482d6cf643fa76048cc2a2fbc9a4f3c6",
        "modelscope/models/cv/cartoon/facelib/face_landmark.py": "b16f88dbf0b59dc6ee04972ff4d8ab2d852123cabb7fd6f2fe98d08f51313a38",
        "modelscope/models/cv/cartoon/facelib/facer.py": "e19447f4133e3cf2dfbd774672c471a6454dd0afce2b78239cc5fd481514952f",
        "modelscope/models/cv/cartoon/facelib/LK/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/cartoon/facelib/LK/lk.py": "c83eaf58e966d3240804e46a777a1f0830f27e20701377c14c42135d4421b51e",
        "modelscope/models/cv/cartoon/mtcnn_pytorch/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/cartoon/mtcnn_pytorch/src/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/cartoon/mtcnn_pytorch/src/align_trans.py": "53c807379ae86c724ef9e54190b233d5cf1e6038b4c8d5c20b0014319146330f",
        "modelscope/models/cv/cartoon/mtcnn_pytorch/src/matlab_cp2tform.py": "5d5c08201a76e267199029527c01fdf0a9fb1e351691423e413b5e7a7fb3329e",
        "modelscope/models/cv/cmdssl_video_embedding/__init__.py": "b534df2e834cd832af2b4af6caf25ecd22f2d4bc22c976059b018b7510fa8715",
        "modelscope/models/cv/cmdssl_video_embedding/c3d.py": "c274ce868b7a1e2cad1f60e789e3b6836dc4ef64211ba6b3fe3738fda40599bc",
        "modelscope/models/cv/cmdssl_video_embedding/resnet2p1d.py": "1c2ddfa2eb51ca3e871bea398c7aa10667898f28792eda1bb7051910c634794a",
        "modelscope/models/cv/cmdssl_video_embedding/resnet3d.py": "b3a147777b9bd643b73610286f2730c147cd5f11f2e468d5850b8d848e79355d",
        "modelscope/models/cv/controllable_image_generation/__init__.py": "be83cc4c52a1a627bf1b25975d78db32554745b3bceb51cedc63266a2985ecb2",
        "modelscope/models/cv/controllable_image_generation/controlnet.py": "ff291d4f995e658d91dab2519476e5042b8a959e763db8558e8dc74f6e51be54",
        "modelscope/models/cv/controllable_image_generation/annotator/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/controllable_image_generation/annotator/annotator.py": "4ebda3c5c27ee712cf7fbcafc96c190429b6289fe22a08fbd56ec10ee49349fe",
        "modelscope/models/cv/controllable_image_generation/annotator/midas/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/controllable_image_generation/annotator/midas/api.py": "8ac5994b07e8987212ea29737a5e62dd26cf17c694bd1167cb71605e4566987b",
        "modelscope/models/cv/controllable_image_generation/annotator/midas/utils.py": "d474b40c9d9d0837bebfecaa027a0aab286daa5c5c181c5de622786e4bd13edf",
        "modelscope/models/cv/controllable_image_generation/annotator/midas/midas/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/controllable_image_generation/annotator/midas/midas/base_model.py": "f800f0c859aaea17320cd1ffade18fafdfc294c68269164414378071c37f4e0d",
        "modelscope/models/cv/controllable_image_generation/annotator/midas/midas/blocks.py": "78920bd00b754d9c2e309cb86693923270bc51aa2dcc9598c708adf53eb48fcc",
        "modelscope/models/cv/controllable_image_generation/annotator/midas/midas/dpt_depth.py": "46088778c3fd9da4f8e6df3cab5c872f96a37fee68d9ae4308813c8385701226",
        "modelscope/models/cv/controllable_image_generation/annotator/midas/midas/midas_net.py": "bc1befc42c5910ccdfabd9e3083451cf0f47d5e63d23ff3550e6d31d3e6f2bb2",
        "modelscope/models/cv/controllable_image_generation/annotator/midas/midas/midas_net_custom.py": "c90095d9f435a0568ac717fed0855b682c8bc3af46328153725bf2ec4da234f4",
        "modelscope/models/cv/controllable_image_generation/annotator/midas/midas/transforms.py": "c99820a0fefbf1dcc7af639415caf68eaff453a6c132a15ef31c4043fbe61095",
        "modelscope/models/cv/controllable_image_generation/annotator/midas/midas/vit.py": "6f10b8d74593ac33d814ddb6f5ec24a458eb14a851e63c6b5ac01f0c34d3c269",
        "modelscope/models/cv/controllable_image_generation/annotator/mlsd/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/controllable_image_generation/annotator/mlsd/mbv2_mlsd_large.py": "26c5a83c5c488cb106709a04234e5c99c12fdc90c6bde179b3251ec4da198ed2",
        "modelscope/models/cv/controllable_image_generation/annotator/mlsd/utils.py": "c8a36d0b90323bff66677994a68a5c2899cb060f6a21f015d356b4ac26519587",
        "modelscope/models/cv/controllable_image_generation/annotator/openpose/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/controllable_image_generation/annotator/openpose/body.py": "904a383630f028ed8ea2b54794c8d91613f4c68949019352ca8f78e7d4cee1cb",
        "modelscope/models/cv/controllable_image_generation/annotator/openpose/hand.py": "edb38c1b88fde72f6d76e21d0092b6253ba27ea6de1dcd1a4a24a27bd7582b66",
        "modelscope/models/cv/controllable_image_generation/annotator/openpose/model.py": "5a398ad0eb27440cda3931fef09c327f91113aef966b0d12a7d2e075afaddd06",
        "modelscope/models/cv/controllable_image_generation/annotator/openpose/util.py": "52024757d266a480bb0a413c6d1200b56fe9f853e574f040ac8bc91667233be5",
        "modelscope/models/cv/crowd_counting/__init__.py": "bd52ae94db5ccb685602386536fda6b42ee81c04b40d368ce4ff4ea0ed628663",
        "modelscope/models/cv/crowd_counting/cc_model.py": "b94709fd81949bdf39ac8d72422c8b6e083f9ddbd07ee34e4d468d2ebd932e78",
        "modelscope/models/cv/crowd_counting/hrnet_aspp_relu.py": "db66ababd7823c3fc922077692673335f2f867846ac3c6942f479ed26b8406a5",
        "modelscope/models/cv/dense_optical_flow_estimation/__init__.py": "0399efcdd6b80b3d92d1cdc8e0d3d16af6d10c2163c3db275dbbd6714d4951c0",
        "modelscope/models/cv/dense_optical_flow_estimation/raft_model.py": "281089305c3f7c29e3ff2034ee146c8cd263dd42a0dbe7dd067e3f598f6332b4",
        "modelscope/models/cv/dense_optical_flow_estimation/core/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/dense_optical_flow_estimation/core/corr.py": "96f3fa1f94098d910fcd054704d9ef5d110ade70b77eb95ea3c587d2978ba9fc",
        "modelscope/models/cv/dense_optical_flow_estimation/core/datasets.py": "1ea30c8bdfa8610bde40d095511722854f81ecdb24cedb955c0b55419ac579d0",
        "modelscope/models/cv/dense_optical_flow_estimation/core/extractor.py": "28805564b6e7059f2f7a7075d2606dbbc27f31f27c00e4e268b90eefa61e0950",
        "modelscope/models/cv/dense_optical_flow_estimation/core/raft.py": "79c5fe0490628430773cebcf3d5bfa9b25b62169425ef6476303845500945c4f",
        "modelscope/models/cv/dense_optical_flow_estimation/core/update.py": "e0dd76297b3b237ddb08e31e9f0390826ccef6d162b2ef4bf21be815b5f033cf",
        "modelscope/models/cv/dense_optical_flow_estimation/core/utils/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/dense_optical_flow_estimation/core/utils/augmentor.py": "3280e72df7ab0f0cdb76a7264db9780bfeda50f14586508cb6407653a2c1acc0",
        "modelscope/models/cv/dense_optical_flow_estimation/core/utils/flow_viz.py": "f6b7e4711b0c9e09d88b0650ce4f5620c8cc584ee58f7929744013d902f02915",
        "modelscope/models/cv/dense_optical_flow_estimation/core/utils/frame_utils.py": "b11aa7fcaf3d0db22cf112ead54f41beeae6274f0acf613bee60903b6f7d551e",
        "modelscope/models/cv/dense_optical_flow_estimation/core/utils/utils.py": "94888703ba4a1544e20b93e163a227a9869a2a115d9584887e69cd2015b04321",
        "modelscope/models/cv/face_attribute_recognition/__init__.py": "79afed3618dfe658e880d8e42029f83464c3a68861f54450b431c53785eb6ad6",
        "modelscope/models/cv/face_attribute_recognition/fair_face/__init__.py": "4ebd9094c48d5bf922a4e7a0f689f832bed44721e7ce3fdd19ed08fedaa3ad78",
        "modelscope/models/cv/face_attribute_recognition/fair_face/face_attribute_recognition.py": "20c2e4bdaab2a640aa8bc0ced52d8b3a428e8786332eb77ff8bdd4381f74300b",
        "modelscope/models/cv/face_detection/__init__.py": "37571910e21f2e4c7de3f5216ecc49e1a8ee3e1e93ae62aeef314f2c1a14d6f3",
        "modelscope/models/cv/face_detection/mogface/__init__.py": "4b9861f4d6199cdf075439005ff4ffe2548a5da0dad235b96b26d3693e10b51c",
        "modelscope/models/cv/face_detection/mogface/models/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/face_detection/mogface/models/detectors.py": "fab1d36326a30f3611ec5e902c21b03dcf02175969df5271cc71d7b94c8f5816",
        "modelscope/models/cv/face_detection/mogface/models/mogface.py": "e373e40811595af309382ecc7553fbf898f3219d11a404d66d9f9380844fff08",
        "modelscope/models/cv/face_detection/mogface/models/mogprednet.py": "948da23d1c02b5db9795f85b4ea032ca445058f75ebf85a2851522781e6df1ba",
        "modelscope/models/cv/face_detection/mogface/models/resnet.py": "a22cbe25166f7462f98312771f8c4802159f70b1ef48202a8f39c2099e3dfb54",
        "modelscope/models/cv/face_detection/mogface/models/utils.py": "f6c6db9249ff568541b8e34760245bc3fd2605af9d90a43da34d0256e34388ed",
        "modelscope/models/cv/face_detection/mtcnn/__init__.py": "d4a4b47abd6f695cd2d0a9df44058a0ea91766351a4ecba95ad0fd56a21ab6ba",
        "modelscope/models/cv/face_detection/mtcnn/models/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/face_detection/mtcnn/models/box_utils.py": "1508ebb3ae2e7e030d1241751e97192e6c6fe24923f74adb0a9842a6a7dd8073",
        "modelscope/models/cv/face_detection/mtcnn/models/detector.py": "d289d3c1c0a0bb5beebf947b00925a3d10aa67e85000ae9e97bd2ddc378f94e6",
        "modelscope/models/cv/face_detection/mtcnn/models/first_stage.py": "d49c22164b3fbfa8fc2080108e9ba2b848c78e6c94ed7546382b002f6780f1f8",
        "modelscope/models/cv/face_detection/mtcnn/models/get_nets.py": "8d4ae7a8aeaec90bfb29ba9784ecb1ba21a105b39a16e4f93ea4983a17cfca7c",
        "modelscope/models/cv/face_detection/peppa_pig_face/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/face_detection/peppa_pig_face/face_detector.py": "709e8899a5024ebd89908174097347b3ea311d188c1fcdf8e624931ef4bd6f96",
        "modelscope/models/cv/face_detection/peppa_pig_face/face_landmark.py": "6ebc055980c3ef1668f987c6bb4a2520851c594bd242226cf5dce7ebecaa8a28",
        "modelscope/models/cv/face_detection/peppa_pig_face/facer.py": "35f93d3f4d2bc124c8083672b02ba1dab62a5dbacb462b2709b6cb6ad839a52a",
        "modelscope/models/cv/face_detection/peppa_pig_face/LK/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/face_detection/peppa_pig_face/LK/lk.py": "18cb73acf45b057dbfe5db129782c6f77a96790aff775f8162bac32d13790164",
        "modelscope/models/cv/face_detection/retinaface/__init__.py": "171222a30bf406c84820bc836efa470eb2a675eeee2b747a982da9516a56a291",
        "modelscope/models/cv/face_detection/retinaface/detection.py": "97c8f64f3041febbf772e8095ac1abb608b8c7edac014125f2e537826147c4e0",
        "modelscope/models/cv/face_detection/retinaface/utils.py": "0dca71645e926bda3e02a8d5e770496bbddcdf9ec970f1b5bc32086172e3cf48",
        "modelscope/models/cv/face_detection/retinaface/models/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/face_detection/retinaface/models/net.py": "ee63258da494f808dd9800d567f263f240fbb5768e4b1b2ce48a3995f9ae6077",
        "modelscope/models/cv/face_detection/retinaface/models/retinaface.py": "5b9d36145e61a963eb88b8f9c8a533e82a4b4e3c234c7cd76dad4b99db275d9b",
        "modelscope/models/cv/face_detection/scrfd/__init__.py": "cfd62f68aa1c3b29ffcd4048aec21f08111d8860c9b986b89c6c91e46f91232b",
        "modelscope/models/cv/face_detection/scrfd/damofd_detect.py": "ca07bba2dc0c28a323d2ae4e1c944e18d1054dcfad6ff99afd4b60492dd88f37",
        "modelscope/models/cv/face_detection/scrfd/preprocessor.py": "5ba4c6be79f0827ffd064b45b7157179ec5704f5623e4264fe6b12333a82bb1e",
        "modelscope/models/cv/face_detection/scrfd/scrfd_detect.py": "83e10674975993e93411269e236417be5b791aa0f22c63d9880908c04d6d114b",
        "modelscope/models/cv/face_detection/scrfd/tinymog_detect.py": "e18c0663b8fd2bfe776ba9bb6fe8bdc33316054b339182536aaae001016d28e3",
        "modelscope/models/cv/face_detection/scrfd/mmdet_patch/__init__.py": "1b67136ec38c04298fd0ce3ea0ccabcf5a8edc4bcc303cd182f58b0b74923b30",
        "modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/bbox/__init__.py": "4c4ae4b33a21e50fd7b0e7db4820a6b96dabdc87c71750b13f82c926db729719",
        "modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/bbox/transforms.py": "2047f65a3bce0df479ba5783c9d8541f87b41a32f35dffdcc6331fe174a0deaf",
        "modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/post_processing/__init__.py": "6f56e6819ca0f8ad37d29639f627bb1c1135121495e8c672cf1c9099393bc1f2",
        "modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/post_processing/bbox_nms.py": "6514a41770ca6c4bce9865761ae272cdecfe5d427ea57347d5cdf1ce98c1d8f0",
        "modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/__init__.py": "22c15f0916794e8c4cb650abea6c785ddb39ba1814f84be5c8e7c77c531e9ceb",
        "modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/retinaface.py": "85c6a27fdacb27354d27e8f4d76163df108f210bde487be699029da2e7c36b47",
        "modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/__init__.py": "ed8a73f588a220959d0e9db6537c6f828b91b7ce1e1567a3d09b5bf0874e2c75",
        "modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/auto_augment.py": "6387ebcf3d1a448b3734bf7eabb80ec969f5b04b1a01b4604c5cfce3ad275848",
        "modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/formating.py": "41856097f50eef73b71a3a66da3efa869a0ae92f33783c7c46de1543247efc57",
        "modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/loading.py": "90053e1400ae2d4174f4878a816a403047104ba36a27c2eb91041f426a32f8a0",
        "modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/transforms.py": "f0b69cd4ca54030325b06b31f364490180d7b330a8bac59224eafe963e880d37",
        "modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/__init__.py": "ae2e61165032d9e0b08a6011cd5bf93da6b9b123ca6d72e69a6e60f9ec4c0249",
        "modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/__init__.py": "01edbdcbd5dfd7ac492ec92661c0c10841cde7d6831009c454d68516e87bb041",
        "modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/master_net.py": "5b7ab91fc091a892d6b8a821682dd38530a1cae78549b4ee7aaa4779c5cf8008",
        "modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/mobilenet.py": "5c78bb08d25d287478a3ba93f61c08fc8dde3a419b5ea5c4718f094c5ad1e3c9",
        "modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/resnet.py": "bd071c55de662d7620ac75d2e31c9fc37211cb920277005d4a3274e134f8364a",
        "modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/dense_heads/__init__.py": "f6139aaa94ab27bcc50f56d22ccedf39add94a1f1f97b2a766ced0c4ccf9487a",
        "modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/dense_heads/scrfd_head.py": "539e46d3496b4244c61d9a119aebebbb2a1c13248c761abf17d8ef203efc4107",
        "modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/__init__.py": "5d95e7d68161bb09ef3fc7a9bd9116bab5725d81fabc869d5e095fb8110e81f6",
        "modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/base.py": "f9f2d1043208675a8b7afcbb4d3ecfb48fdef375b4a4f4520e523ca7109954ec",
        "modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/scrfd.py": "732d4da4ee87e3138c3144f3695fa037649db52449d200dd5587b6ba4c0c52d8",
        "modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/single_stage.py": "4286524d5f9e7e654ea9e77402689d453c5b6ed46c8d07d8a37754b9fa88beef",
        "modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/tinymog.py": "723a8aea1a6e7a9c8af9423d651c8d888fb9a80a76f980fae70b5c87f9bfab50",
        "modelscope/models/cv/face_detection/ulfd_slim/__init__.py": "b8046e63262ed473a8baa5f4b6205e938b9e5c44d3d292adab5f3e95683c1369",
        "modelscope/models/cv/face_detection/ulfd_slim/detection.py": "fb847d5d2350ddf0ef3441f814b6ddac10f85e355a54cf299f8b10221dbfd369",
        "modelscope/models/cv/face_detection/ulfd_slim/vision/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/face_detection/ulfd_slim/vision/box_utils.py": "3b555f514d478cc56734457133ff25518b13214cad299c509ac9461b50a779b0",
        "modelscope/models/cv/face_detection/ulfd_slim/vision/mb_tiny.py": "12e430226f9ac2bdc60ac40179d31d2cdd2fcd0645380db2810a2956dbfafb7c",
        "modelscope/models/cv/face_detection/ulfd_slim/vision/transforms.py": "908d718292574d60401fc84caf3818af388078006ab8ee6a694e97090a3e341d",
        "modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/data_preprocessing.py": "dfbebf04b7b4545113272d32a37307bfc4fd34c33a7f959c90319f73794f3eed",
        "modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/fd_config.py": "df4f3f9da990689b57086581d1e944c275b524294e163d1966056f03e82ecab0",
        "modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/mb_tiny_fd.py": "581ea9a503db95fa347581976d69054d284020290da821034d6afe6c2a12e680",
        "modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/predictor.py": "2ac4cbb8daa6083185fbac44518fab9ea95bd076e2874d67fcf35a31fbae4a7a",
        "modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/ssd.py": "518f2c496fd12426338e3c517b772abe2fe32c2eb0975d93d39135d54b5b96ff",
        "modelscope/models/cv/face_emotion/__init__.py": "eefc18da43fa7f8a4bdd2a6d89adf03b09d1492165b60b11929f350ab181fee1",
        "modelscope/models/cv/face_emotion/emotion_infer.py": "f1acd7525361781d709d09402a7c16041e9e44d204e0b73eaf4e3a1e1a896311",
        "modelscope/models/cv/face_emotion/emotion_model.py": "84a826029afa6ad08ae63f7b1492a9ae08f297f790aa9e08f0931cb65a1edd5b",
        "modelscope/models/cv/face_emotion/efficient/__init__.py": "8ed3e8b41c3c5f123d803cbcbe98cc6036a3635c58cd483f2a531218afa521ad",
        "modelscope/models/cv/face_emotion/efficient/model.py": "c8abcbf8beac68bcada8e7158079452ae297525b8b31a794e7a333455c94e1a5",
        "modelscope/models/cv/face_emotion/efficient/utils.py": "a0b57aa5c654d7ae332c30da573ae853ccf4e66dcb0c6d9472ed88fb5ea5e1a9",
        "modelscope/models/cv/face_emotion/face_alignment/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/face_emotion/face_alignment/face.py": "fdf92eedc7bca83756b4ee052dde7f286f7195bb77ee3c7a7afcd828b841e294",
        "modelscope/models/cv/face_emotion/face_alignment/face_align.py": "c7944c38fb250d02030270ed0b39c7c4508dc8c889f83f4edca1e01654d59376",
        "modelscope/models/cv/face_generation/__init__.py": "97956e0caed5cf3d2ee4ba37d0a474130f36ae874e0196cb9fa59617bf356370",
        "modelscope/models/cv/face_generation/stylegan2.py": "936504d27572cfb9c33bc1ff9b08b3d89144d95030301d64bdda7075c34ae732",
        "modelscope/models/cv/face_generation/op/__init__.py": "d3bdebb6b1ea35ab8e7dd14af32919f11ae630ab9154d4c84f839397b98b2bf6",
        "modelscope/models/cv/face_generation/op/conv2d_gradfix.py": "91a17fd0842e4c6867d13d7438da9a9019fe8f69497353db4f4a2b8aed55a5dc",
        "modelscope/models/cv/face_generation/op/fused_act.py": "d3fd8a45d0e37a196869339956f1c66b37c4cfeffeeb93a5bf52d287ae4f8ede",
        "modelscope/models/cv/face_generation/op/upfirdn2d.py": "111cb7c7261d8841d27eb3751ead986b162ae94f3edd9fa8fbbde5c1594073b1",
        "modelscope/models/cv/face_human_hand_detection/__init__.py": "44b24204fdef0e9cd54aa2d92015bbef0507a88ccc2f0dd811fcc08befdb0d80",
        "modelscope/models/cv/face_human_hand_detection/det_infer.py": "1c9a2bb2eec74a7cd4c6c5c2d8666fd5b8d6180704af1b33904916b320177735",
        "modelscope/models/cv/face_human_hand_detection/ghost_pan.py": "d2618ce96c259863875f84e4218e0dbaf3426802077267cde20946e7295e4d00",
        "modelscope/models/cv/face_human_hand_detection/nanodet_plus_head.py": "2e8cc46d30e5865bdf849d9d35e776c333756748554cf44700b176d943d6d1ba",
        "modelscope/models/cv/face_human_hand_detection/one_stage_detector.py": "685847362fa6b05c4c40f91a207a9ecf8c83084e89fae422797ec1797eab8bc3",
        "modelscope/models/cv/face_human_hand_detection/shufflenetv2.py": "ed3917208160d9c9183472db58c40888f93c56aa5941e8767b94f19299221654",
        "modelscope/models/cv/face_human_hand_detection/utils.py": "a88f1261734cf4a7e81ceeb1f41d6701525ff590e6cc6ddfa9c9b5374e4d679a",
        "modelscope/models/cv/face_recognition/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/face_recognition/align_face.py": "3f7fc3a5dd165b6f3c76ed0c01c422c8676c61cb089d7987bdbba071ab2b81a0",
        "modelscope/models/cv/face_recognition/torchkit/__init__.py": "13986761ad4282512a2b39f9da35772770f4f4b0148da56334665af6037a0cac",
        "modelscope/models/cv/face_recognition/torchkit/rts_backbone.py": "547ff04bba43e349d9a5dbb421af747564cde238f3409812f18455948571aff0",
        "modelscope/models/cv/face_recognition/torchkit/backbone/__init__.py": "6ca8bde08507c7ee8e79d0b0cb765e85b9b690470c5b6c3186d27967e978fc42",
        "modelscope/models/cv/face_recognition/torchkit/backbone/arcface_backbone.py": "f42c90545c80b848764fdaed7458cc6b1596610a8552b32de3d0096d8b342617",
        "modelscope/models/cv/face_recognition/torchkit/backbone/common.py": "fc879de5c2149ec563f8b35c385a418116e12180b998bdeae8f7db51e8450e68",
        "modelscope/models/cv/face_recognition/torchkit/backbone/facemask_backbone.py": "865dfaba1312538698ecf8e89eb4ec58d1f21e37b424e8084d21960f09ea4023",
        "modelscope/models/cv/face_recognition/torchkit/backbone/model_irse.py": "18ac956b7b2a1d44b935776eb72a01b5440ec0b47b14456dbeaedaec7dba7f04",
        "modelscope/models/cv/face_recognition/torchkit/backbone/model_resnet.py": "7654681b288cc21a0e515a38525c8c0828c53c0e21e31c08a6c3ad640a0fdfe7",
        "modelscope/models/cv/face_reconstruction/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/face_reconstruction/utils.py": "f936ca6bdd20477d52b2470ea7c199777f41620d50f43f76af86b4ec8a2af860",
        "modelscope/models/cv/face_reconstruction/models/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/face_reconstruction/models/bfm.py": "f9df982f1cd90208aeb8d4ba236a1d1c37bda262bdbc5b1c2189390cc7257bd1",
        "modelscope/models/cv/face_reconstruction/models/de_retouching_module.py": "e05ffe5527b03a6418d6bc887ad4490f091b8c610010c32482afc9d363ca8606",
        "modelscope/models/cv/face_reconstruction/models/facerecon_model.py": "1cb114fef9bb7e86a99aeee904deb66f50aa18684ab1875f8fa2c720312ccb1d",
        "modelscope/models/cv/face_reconstruction/models/losses.py": "34891902dc7b66a31f45644188a8dc1508efa5f61d5db307685a48401c6edd75",
        "modelscope/models/cv/face_reconstruction/models/networks.py": "9037713fb128e8f2ddf53a8b8f734995fa12787b0dda97f21c23a4ddab719ad2",
        "modelscope/models/cv/face_reconstruction/models/nv_diffrast.py": "b45e4252f00ae51642cf432b99f64bb89b5608b104cdcde087d74aaf258db3b6",
        "modelscope/models/cv/face_reconstruction/models/opt.py": "2833560823cf78ff0fafa9b7af89a097d287f9c23a47c352b2ac29a9f5b765f2",
        "modelscope/models/cv/face_reconstruction/models/renderer.py": "5fb39e4b768da6659e58daa3c98467683efc79d3aa8798f09013a10195b02923",
        "modelscope/models/cv/face_reconstruction/models/unet.py": "10049e311a3e345a1d888141e0fd9d4bb4416adca51bbc23971aeb52dad3bce3",
        "modelscope/models/cv/face_reconstruction/models/facelandmark/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/face_reconstruction/models/facelandmark/large_base_lmks_infer.py": "ac5ad780753e2002d97e23b28d3c56e5ef5103c2d37e0ee5a806be6c80af3265",
        "modelscope/models/cv/face_reconstruction/models/facelandmark/nets/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/face_reconstruction/models/facelandmark/nets/large_base_lmks_net.py": "64c78157ff52d664170a639c8ea8a8089a01ec7c597a11012ed0233cea869d86",
        "modelscope/models/cv/face_reconstruction/models/facelandmark/nets/large_eyeball_net.py": "18bf6ed9a4382435e08a4cf4a0d9d36efd49213afacfef38b5636f9030f81a29",
        "modelscope/models/cv/face_reconstruction/models/pix2pix/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/face_reconstruction/models/pix2pix/networks.py": "26210b89b7bccb74ebc3b18dc9db865f11704b5f1c0488ad2958ecb40c2edb53",
        "modelscope/models/cv/face_reconstruction/models/pix2pix/pix2pix_model.py": "c61e7fb09b592f7b393a31928ac7eb0a6e1074cd62cbca1b229116c21942c947",
        "modelscope/models/cv/face_reconstruction/models/pix2pix/pix2pix_options.py": "038021eaf5cdd44b02e9ba778338cda3be60c3f5fac646a588e6d004b5196b33",
        "modelscope/models/cv/facial_expression_recognition/__init__.py": "f2f334013c201f6361eaa3d36e774ec3722eb759ba8be8c6b44ac201c263d468",
        "modelscope/models/cv/facial_expression_recognition/fer/__init__.py": "4fb0c2d80b1194c9b198f44520fd1ac72ce2ef4cffc7b3c4e2afa357bf000a81",
        "modelscope/models/cv/facial_expression_recognition/fer/facial_expression_recognition.py": "f1d5d645832a710ce472dd1f35edea9509b652a0f72dcf62937f62a99dcbdcbf",
        "modelscope/models/cv/facial_expression_recognition/fer/transforms.py": "54b8cfa4b92ac20df4c351910334cb27aacaff17005787b0d962fe18bd760169",
        "modelscope/models/cv/facial_expression_recognition/fer/vgg.py": "f14530817b38d77a36a00ac20e29854808cf32722b34a8ceaa5cc9c8ca8ad5ef",
        "modelscope/models/cv/facial_landmark_confidence/__init__.py": "a14bf17338b28301752abd550a36cdb81ee8630f54b84d7d43b874fd69d17d7a",
        "modelscope/models/cv/facial_landmark_confidence/flc/__init__.py": "b2ad712e24742558ede457ab8156ab03e5cf7cc45c7dfa30406e640b011658dd",
        "modelscope/models/cv/facial_landmark_confidence/flc/facial_landmark_confidence.py": "ca4ea81f50e073a5a4b65eb251c2805fa66d4af1c5617569df7279b4d4c4a094",
        "modelscope/models/cv/facial_landmark_confidence/flc/manual_landmark_net.py": "d293f2651e8f9b37803bf37130c9ca77636c2171ec64aa3bec3ad351cf0df00e",
        "modelscope/models/cv/hand_static/__init__.py": "f81a802217915dea7e8005c8fa5dd29af0c76704748c61a462605c229edb12ca",
        "modelscope/models/cv/hand_static/hand_model.py": "87978f4e0ca1e71274016e83941d79324c03d79add9b1c0bd3f1d9d42e367857",
        "modelscope/models/cv/hand_static/networks.py": "fe5180fecd70f1aee63f4067a8b64cd72e546914d684a8955bcc9eb381e164df",
        "modelscope/models/cv/head_reconstruction/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/head_reconstruction/models/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/head_reconstruction/models/bfm.py": "6c76de56d2eefc0c2974ed5aa5e67f940b340648201fcb0be5ce077f05546ab9",
        "modelscope/models/cv/head_reconstruction/models/head_segmentation.py": "d4c502c6fa68e7ad215ca9e0608da094ba36d172c9603d81f3fa538831f43e5d",
        "modelscope/models/cv/head_reconstruction/models/headrecon_model.py": "9cc5503777abdada42ed2fe1ac6f42428482663e2885c58b88bbe4c572dd8993",
        "modelscope/models/cv/head_reconstruction/models/losses.py": "b5ff17e50858a61d55cf7686df71558b031a650507a22671bb96dbd894c4c3c1",
        "modelscope/models/cv/head_reconstruction/models/networks.py": "9037713fb128e8f2ddf53a8b8f734995fa12787b0dda97f21c23a4ddab719ad2",
        "modelscope/models/cv/head_reconstruction/models/nv_diffrast.py": "ef111587b22abe47e310979abfda466b052ba2172eb448ca38c24a81828d7e0a",
        "modelscope/models/cv/head_reconstruction/models/opt.py": "a42404f04719b8b71e564d3d2140ee047b5c2bd2dc8aec4d0d71d50d87cc361a",
        "modelscope/models/cv/head_reconstruction/models/tex_processor.py": "ff2c574c0f1e0658c652435fd4dbc69d54a9a1f7701e4732ed0d47698c00db80",
        "modelscope/models/cv/human3d_animation/__init__.py": "bece3a28dd800349647cdb333743a6742d364a824d39dff1ab0a3d85fbf6de3a",
        "modelscope/models/cv/human3d_animation/bvh_writer.py": "a3bd6b3a1624c0f0e9fc39431c89aebc4d549042e7dc000b92076d3d1615a2e5",
        "modelscope/models/cv/human3d_animation/generate_skeleton.py": "e7dfb1017b5fed2c0eb41ddb46c0e97f959c61aefcfe77577cd423276f08f07c",
        "modelscope/models/cv/human3d_animation/transforms.py": "4a4e46abf5227c90e2c1bb4e1618448ba02a189b8bbca9fe428938d7911cb492",
        "modelscope/models/cv/human3d_animation/utils.py": "e1b8ee76733af3f703a7e62a4b649737deca0266a8972a72dab05ecaf4f0598f",
        "modelscope/models/cv/human_image_generation/__init__.py": "f50f09869425e93ac050b67378f7368ab37854b3fcae852bb783de9af13a4e94",
        "modelscope/models/cv/human_image_generation/human_image_generation_infer.py": "af8f2b351b04af52d6d096e9958d36e297009af15fc66c66e46c7620b39877e8",
        "modelscope/models/cv/human_image_generation/generators/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/human_image_generation/generators/base_function.py": "dd7fd45b8977cf407b10ee086968a098143acfc5dec868270e78f8c15e1f39ed",
        "modelscope/models/cv/human_image_generation/generators/base_module.py": "092d0def4a776a2f229a36d39dd358b3ef196a709b65102d91d94feec0a1920b",
        "modelscope/models/cv/human_image_generation/generators/conv2d_gradfix.py": "8a92a704e4a20f3d77a578075c9b4fd4ddb66446ec257dd5566a9b5d3beeff51",
        "modelscope/models/cv/human_image_generation/generators/extraction_distribution_model_flow25.py": "6b6f89388aa67cdca5706868a967bb032d2b9fb1a42aa3c47bdc7acecc5fe4d6",
        "modelscope/models/cv/human_image_generation/generators/flow_module.py": "1296d8d8557845bfa6bd9dced8465df867da3a717fb2c13a06e0efe760316504",
        "modelscope/models/cv/human_image_generation/generators/tps.py": "980ad412f4e81fd8a1f872aabed086d06fc7fc8c93c5c22339c0ab9ccf2f2143",
        "modelscope/models/cv/human_image_generation/generators/wavelet_module.py": "d1411dd216c5d7e83f447baaee34d50bc4627abf3a4c49f35b1900b1285f95d0",
        "modelscope/models/cv/human_normal_estimation/__init__.py": "986868e3c6aadff571fb86017af972ca3e4bb45dcf0003a86e62c60618f99ed5",
        "modelscope/models/cv/human_normal_estimation/human_nnet.py": "d0ef2e2477ff37760b44dace51098a0727049e90cb9bb3f48b0c055302fa8afc",
        "modelscope/models/cv/human_normal_estimation/networks/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/human_normal_estimation/networks/config.py": "9a870d92911a21e88c97e7a67656083eccf35532322c66346f9412a973eb4a0d",
        "modelscope/models/cv/human_normal_estimation/networks/nnet.py": "9bb9f432f1b41fcd62917166fb3f42ed04e847b73f9c68a98f49a85c94b6f568",
        "modelscope/models/cv/human_normal_estimation/networks/submodules.py": "e4c82b0a6cecef9ef4685d0954e877973af5c2130dd023b4878a2df5e6e134d1",
        "modelscope/models/cv/human_reconstruction/Reconstruction.py": "26b1a7f7d299d636e19a8b6906bbf23efe16fb3e9aadc62deb34ef7946ca58f1",
        "modelscope/models/cv/human_reconstruction/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/human_reconstruction/utils.py": "12bd4e53b52862aad98f46c8eae3a9dfa042744f5ed344a6cac43f6643fe7799",
        "modelscope/models/cv/human_reconstruction/models/Embedding.py": "ac29cfcb57a8094697c404786f13728822ab408f821b4ccea2d076cf8b153e9a",
        "modelscope/models/cv/human_reconstruction/models/PixToMesh.py": "49462b50d492feb1c7135a700a54418b4f82e6cb85d65fd5340e1c2834fb637f",
        "modelscope/models/cv/human_reconstruction/models/Res_backbone.py": "bc26aed7879a95df5a86134f759f2bef00ded3002d9830e779f3392e48649dd8",
        "modelscope/models/cv/human_reconstruction/models/Surface_head.py": "cf24abab5650785b0ce3aa73bff4c3136525c495fde89da9626496bf8048b7f9",
        "modelscope/models/cv/human_reconstruction/models/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/human_reconstruction/models/detectors.py": "ee00be8934237888bad0377792897fc53bba98dc97fd20bd8b09376332237229",
        "modelscope/models/cv/human_reconstruction/models/geometry.py": "40315a9e464256c3c6bd581370fb167af1e1b29632004b500b7a7c7ddfb8aec1",
        "modelscope/models/cv/human_reconstruction/models/human_segmenter.py": "6b0e92e61aa6992d7fb33f93c2dfbb2d6eb0b8301465730cd2113f23976a1b12",
        "modelscope/models/cv/human_reconstruction/models/networks.py": "0161b25c58fbad049171994bd7cded512baaa3cae0870f53565f035439656585",
        "modelscope/models/cv/image_binary_quant_classification/__init__.py": "374dd2dcd7e14939181cfd7fd7199bdeb0799b024065b7edd1b4c04c4c959e9d",
        "modelscope/models/cv/image_binary_quant_classification/binary_quant_model.py": "0f71fd97b616a5a34e690051485ebef5bb7a4c108571aa4c34c0d04cbf1f2cd6",
        "modelscope/models/cv/image_binary_quant_classification/bnext.py": "3e565b60919ede342f4a9c5c3671139903e18144a10a6909fe5bbed46de82d85",
        "modelscope/models/cv/image_body_reshaping/__init__.py": "d956236c37068736c43f7f5bbedcabcdabd0e97f94561a2608b44fdb15e1c7b1",
        "modelscope/models/cv/image_body_reshaping/image_body_reshaping.py": "0b3e0c6edf07d2a457e82dbbb88b302fa6f2b9a525c4f6054a71d6cab445d97b",
        "modelscope/models/cv/image_body_reshaping/model.py": "0b9edacb02a3d088016725e6758a86cdd2b6ad40e9a32dd3725453e40f3ad921",
        "modelscope/models/cv/image_body_reshaping/person_info.py": "2e65fbea7d9f1188e3382a42f538ca7082a85a4b8ddd7563ab2a4cd778af11e4",
        "modelscope/models/cv/image_body_reshaping/slim_utils.py": "f4df00b0051f78ae468956c77fe1affe1566c899968966181ae5270e2633259d",
        "modelscope/models/cv/image_body_reshaping/pose_estimator/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/image_body_reshaping/pose_estimator/body.py": "5dd9b3811d2c9ed4d87b8b1f7523d2206d5e7832a2f7f7aa0719640561ddebc8",
        "modelscope/models/cv/image_body_reshaping/pose_estimator/model.py": "6977d3499fbb1cb351cc5f248281fb122cc3d85c22dba59d9a922e46b7a43b56",
        "modelscope/models/cv/image_body_reshaping/pose_estimator/util.py": "4e37dc0d34be33250b4b50e25419983c756a56ea90e0293296f6becdebdecc41",
        "modelscope/models/cv/image_classification/__init__.py": "fc2843773903e122da09f908fd2a22b838b6feb1cc5ed5c9a548709a0e800f1e",
        "modelscope/models/cv/image_classification/mmcls_model.py": "decd3a3b0493bed221c0a6fd54b54e80cab2227660eb6710d3188b92f16be5d8",
        "modelscope/models/cv/image_classification/resnet50_cc.py": "9277a478c23934f43ebc32e07c6c09bee08a35bd017a228b39a5d02f388009ae",
        "modelscope/models/cv/image_classification/utils.py": "adb3660268a4c225fcfe2d1f3563555611fd642c282172b8f4dc4b46979e1861",
        "modelscope/models/cv/image_classification/backbones/__init__.py": "5b4094b9492927ca687629b830eb9e9ec78ea9f4a5e108e6dc8c577ec12d6646",
        "modelscope/models/cv/image_classification/backbones/beit_v2.py": "0948c91a50bc6a189c46f0e5168588f568c0b9c1b93e1e9c8cbc5ab8d733b4dd",
        "modelscope/models/cv/image_classification/backbones/nextvit.py": "45942c487f88969a417577f97a873ccb840c4e75731c19c30193593ebe044540",
        "modelscope/models/cv/image_color_enhance/__init__.py": "d5794004e8c7ff343b67853c18f110e7e691129bb4807a6a9b9b437fc1a0a319",
        "modelscope/models/cv/image_color_enhance/csrnet.py": "163964e874e66a7a6f12564754a6cf47b46e7f87573c610626ab641819dbcb63",
        "modelscope/models/cv/image_color_enhance/image_color_enhance.py": "4fb9b31234f31a73c309e734e4a629d9233e5e23df81877b667fd07375e4f348",
        "modelscope/models/cv/image_color_enhance/adaint/__init__.py": "a02d93cede59e03e7f497d433ffc4178e13dbf183940ada85e793c15c8b9e46d",
        "modelscope/models/cv/image_color_enhance/adaint/adaint.py": "84309e0c2aa2679767f704e1ee367ecc0bad428edeed337b54d82b9c334069b2",
        "modelscope/models/cv/image_color_enhance/deeplpf/__init__.py": "9408ab4cf13cdaef0fd637c6f33f1a50a37c6853f114defe8b96dfa9e2004d4d",
        "modelscope/models/cv/image_color_enhance/deeplpf/deeplpf_image_color_enhance.py": "7b0533d938464c682a35c0e40207e37850c83d1c4e9a7650db8fc6c67908f15e",
        "modelscope/models/cv/image_color_enhance/deeplpf/deeplpfnet.py": "275a15021eeaa8cb50dcb0979eb6ecf7702350b9ecd3b4c1eb53aed20178093e",
        "modelscope/models/cv/image_colorization/__init__.py": "9dd0a5978c79f942ea6eae6a81a879543f884e441a97b5244e038fa2fe11ac2a",
        "modelscope/models/cv/image_colorization/ddcolor/__init__.py": "da3fe6e90fa0f5a85c9566650f4132cb546e0b4955963588f0396015355651a3",
        "modelscope/models/cv/image_colorization/ddcolor/ddcolor.py": "2334207de924e17cb25328f64fb37774e91f2e2f083351903f824d701aa69a3c",
        "modelscope/models/cv/image_colorization/ddcolor/ddcolor_for_image_colorization.py": "c74fb5eab95de719f863f96649ed7e17c308cfb8abbc81a38e016818a14f8272",
        "modelscope/models/cv/image_colorization/ddcolor/loss.py": "2381d9897217d3f2556fabcd4b12c98816303af55e7ce25f881a9d852a1a9800",
        "modelscope/models/cv/image_colorization/ddcolor/utils/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/image_colorization/ddcolor/utils/convnext.py": "a81bd73caf90f163febb1a6b1d6357a5021cf2c0edcf245fb0912d664f4c9e27",
        "modelscope/models/cv/image_colorization/ddcolor/utils/position_encoding.py": "e76cfe16a375b18f2e631d3f4de8d2130db47aacbd070cae6fc3802bb4375b0c",
        "modelscope/models/cv/image_colorization/ddcolor/utils/transformer_utils.py": "cb2f180adaa2b4768e328aaf90601b221dceb32fe74297de709022f669829f3f",
        "modelscope/models/cv/image_colorization/ddcolor/utils/unet.py": "551d4b5731be3735c7ea4d6584a623b527511bcafe1ac1456f2acfee5735c663",
        "modelscope/models/cv/image_colorization/ddcolor/utils/vgg.py": "2d824fcc57aadb140e3b06c1c2fc206900c5850ca313ce38781b996e13a879c3",
        "modelscope/models/cv/image_colorization/unet/__init__.py": "0528250962bfc889d1445bc1909c9f03e598fa25b50c44d3c954fed9a9a12263",
        "modelscope/models/cv/image_colorization/unet/unet.py": "8cc9de7dea9ec78bb04d5db5738dada26e5986a646d6bfa68d13ea684b8bff81",
        "modelscope/models/cv/image_colorization/unet/utils.py": "f6a5132c2e1bbd827899e7dee3c75986f6e721f3435479c0970f57df6ddd4858",
        "modelscope/models/cv/image_control_3d_portrait/__init__.py": "aa3f9c65ff4d75be6438de8926bf5a639279b0eb6ada9b5c6ec539fd05aff5e5",
        "modelscope/models/cv/image_control_3d_portrait/image_control_3d_portrait.py": "afdb90371fe8ad66eeb0b5c428a50382b1dbf80094d7e2e77a18a4544b3e7e0f",
        "modelscope/models/cv/image_control_3d_portrait/network/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/image_control_3d_portrait/network/camera_utils.py": "3bed9bb15310f7737d480255819920d09f83ef81d9d07dbb86586dfa77e3a019",
        "modelscope/models/cv/image_control_3d_portrait/network/networks_stylegan2.py": "1d2934681ca99cbca603e0d2e56139f14680be60e4dfe33e3c41eb3991a6c9b7",
        "modelscope/models/cv/image_control_3d_portrait/network/shape_utils.py": "d83fe5555c43ef5d10c2c66965a4ae8a14dbcaad1f18859f351015150d8f5e4a",
        "modelscope/models/cv/image_control_3d_portrait/network/superresolution.py": "f52d63bdc04cbeb800b12e5c97edf9e26e5265856c0cd4382b123c0115f5f754",
        "modelscope/models/cv/image_control_3d_portrait/network/triplane.py": "7790b8d697895d8c02432c12d8f0e4e9fa9dfbb063e26dcc1a75cddcd6514a54",
        "modelscope/models/cv/image_control_3d_portrait/network/triplane_encoder.py": "36a2406f6c9d3e9d8529b0d9f72f2c7cdbcee54a1bad22408bafff7f8d965ab3",
        "modelscope/models/cv/image_control_3d_portrait/network/volumetric_rendering/__init__.py": "b19968bffbc8d76d5b09be6e56af604f59b4e6cbc4e1158dc8a24daae3eeae37",
        "modelscope/models/cv/image_control_3d_portrait/network/volumetric_rendering/math_utils.py": "d639b7fe69c8fbd5340e960c9c245f68b0319086655bef7df5221e4b4d1895ca",
        "modelscope/models/cv/image_control_3d_portrait/network/volumetric_rendering/ray_marcher.py": "9b79d3c8ba8b75796bea95d0216cac4dfac6cc1a222836ec58dd862f743ee2ed",
        "modelscope/models/cv/image_control_3d_portrait/network/volumetric_rendering/ray_sampler.py": "68c31700523da6bb318dc720f9056e8e249668d9e934e34ddfa779f1ef2c4f24",
        "modelscope/models/cv/image_control_3d_portrait/network/volumetric_rendering/renderer.py": "b39b6760976d7355fcb95da5f2a3d3f41a0e8712e89d2e72937c89a4ed6c02b6",
        "modelscope/models/cv/image_debanding/__init__.py": "7614ce138786885d5bd2392b3e7042f4fb20d25007d444886595506ff67d3507",
        "modelscope/models/cv/image_debanding/rrdb/__init__.py": "3fda48bd06a21bc3ac90e4c4b351a9e85ed6b1b8177602080a550e90a844fa38",
        "modelscope/models/cv/image_debanding/rrdb/rrdb_image_debanding.py": "b1474ea92dba203390b32d23b26b80b874187f7c112b722033b85ec05200b108",
        "modelscope/models/cv/image_deblur/__init__.py": "71497c52bda5ced1d25a4fa9f7f6bfc9c51f4732bd41388b97b7278621e60430",
        "modelscope/models/cv/image_deblur/nafnet_for_image_deblur.py": "c0e6f357e4ab5e16e5f5a6820401021cc506d9cc01ef746ee708e28e5854f08f",
        "modelscope/models/cv/image_defrcn_fewshot/__init__.py": "39d00bf800b49f61e50edca4b5cbc59dce64f99e4589dfd3ddb5736263e9d97e",
        "modelscope/models/cv/image_defrcn_fewshot/defrcn_for_fewshot.py": "882ed97961b8f00c1b65565df6c8c48cd25c7a262bcdc523c9b3acf6620e3fe5",
        "modelscope/models/cv/image_defrcn_fewshot/evaluation/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/image_defrcn_fewshot/evaluation/coco_evaluation.py": "53e8d440cfd1db3b479072ae4493c1e21947431824cf4fbc4e42c223ca0cbc96",
        "modelscope/models/cv/image_defrcn_fewshot/evaluation/evaluator.py": "64f951c7d31534c467f896f273ab6aaa96bd8697e54090cc9b0e63f4e3d6ad67",
        "modelscope/models/cv/image_defrcn_fewshot/evaluation/pascal_voc_evaluation.py": "b453fcf447243fc6e84ce2703b83c3e0eff6482bc900284c02dec089b5c9ee87",
        "modelscope/models/cv/image_defrcn_fewshot/models/__init__.py": "0530a08de8c0258c1d6545d1b17540fbc1a9a841993fae7c8aab973f3848fa2b",
        "modelscope/models/cv/image_defrcn_fewshot/models/calibration_layer.py": "6f7c7710a9e4d84fb14b3aa19008d437fa4f87a7c042a9249612794871d66c64",
        "modelscope/models/cv/image_defrcn_fewshot/models/defrcn.py": "724e550d982fcac0ba548c8a64d66142db16e742f519049ff751c5f526caaa89",
        "modelscope/models/cv/image_defrcn_fewshot/models/fast_rcnn.py": "3d3e9b7d0f72b31e6fd2f4daa45395d631906a9b6c336f001e025673406f09ab",
        "modelscope/models/cv/image_defrcn_fewshot/models/gdl.py": "8c87c0ee044385a0d1dce43189d77f7d5d2cff138539bd6f77d365e875380fe8",
        "modelscope/models/cv/image_defrcn_fewshot/models/resnet.py": "67d989e54498899c21c4ee51ac2d5c98bd9892067d39aca687ab920e3d56ee7d",
        "modelscope/models/cv/image_defrcn_fewshot/models/roi_heads.py": "fd7ba9cc4b9c3c5313ed68c27ddb25a05202f5c68e2a66e2c3e91215ec47bd2a",
        "modelscope/models/cv/image_defrcn_fewshot/utils/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/image_defrcn_fewshot/utils/coco_register.py": "012d01e99f5dd50f9a233fa205bad05873cf3cf2504595de12450c36a7b233a1",
        "modelscope/models/cv/image_defrcn_fewshot/utils/configuration_mapper.py": "4f317a38dda24765d5841448d2887c857237b051e07df7a830be1c8b1dc27594",
        "modelscope/models/cv/image_defrcn_fewshot/utils/model_surgery_op.py": "9f407d92b8eb9790f75e7bca9d4ac2868c78cb50347db6d9725a5867c3f26153",
        "modelscope/models/cv/image_defrcn_fewshot/utils/register_data.py": "1387b3c59bcad570272a5c2800643ab747e562f6b45bb15e5f969e2433ca6358",
        "modelscope/models/cv/image_defrcn_fewshot/utils/requirements_check.py": "be84747aeacf20ee6c492c1b2bd8ec8f2ad1bd846460c27f88970bb26ca60926",
        "modelscope/models/cv/image_defrcn_fewshot/utils/voc_register.py": "ea6a242358064444361e59cccf37f4472dc9037a5ce88adbfc12ffca8146dc69",
        "modelscope/models/cv/image_denoise/__init__.py": "e5e13bc52426211017426a35a175304acc48416aa171ff2dd0481fa4de377265",
        "modelscope/models/cv/image_denoise/nafnet_for_image_denoise.py": "78fbb5f8db6c280cf9aeb3c899e83635f943b7d32594628e9631845295975524",
        "modelscope/models/cv/image_denoise/nafnet/NAFNet_arch.py": "0c31d04818defad5842d9afca0f513c5c9165c7167a2a9a46558ec2f34490ce7",
        "modelscope/models/cv/image_denoise/nafnet/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/image_denoise/nafnet/arch_util.py": "a6f0e09ac4fc246d5f923f2e1c142697778748aaa0b455946b1c5daabccab987",
        "modelscope/models/cv/image_depth_estimation/__init__.py": "23f00d77175c207a64233217735c8a3a55b0cdbe286341704cfab5918b60cd0c",
        "modelscope/models/cv/image_depth_estimation/newcrfs_model.py": "c46f44e11d42c9415e825825af24f8b588200f5002a5c6fde705ba0f5d204e58",
        "modelscope/models/cv/image_depth_estimation/networks/__init__.py": "23f00d77175c207a64233217735c8a3a55b0cdbe286341704cfab5918b60cd0c",
        "modelscope/models/cv/image_depth_estimation/networks/newcrf_depth.py": "3f9e9b85096591f0e26a53231e2d5e8cb8c3bdbab191b41b453265ea3ae52ba4",
        "modelscope/models/cv/image_depth_estimation/networks/newcrf_layers.py": "aee831c7d4c461a53d03df4518fda47d27b17ae12508cec00aeac7bd43766749",
        "modelscope/models/cv/image_depth_estimation/networks/newcrf_utils.py": "d77587fefcd38498abec222667db3a0d200155fe6873e460ed8e7cc65077e045",
        "modelscope/models/cv/image_depth_estimation/networks/swin_transformer.py": "a9ec555402f2b934ae2b8c48e4c3b91bdd9dd272ba1de616dee802cb1280edbe",
        "modelscope/models/cv/image_depth_estimation/networks/uper_crf_head.py": "7f537d91f346fbf44a20f0300ef849320456ac516c9601b6776c87317bacc16c",
        "modelscope/models/cv/image_depth_estimation_bts/__init__.py": "6a109b27a94d2eca3dd8858aa0d81d15df4c563d6b626e0f126a2c1045df55c0",
        "modelscope/models/cv/image_depth_estimation_bts/depth_estimation_bts_model.py": "b3c4fb6908080d1b44f41837af619e2faae073521706ba3fdd09bd33b1188b13",
        "modelscope/models/cv/image_depth_estimation_bts/networks/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/image_depth_estimation_bts/networks/bts_model.py": "d52aec8b4f6eb3a137f88ace5dddeb68bed38457e7f7140a22a5d1bd08230c86",
        "modelscope/models/cv/image_depth_estimation_bts/networks/decoder.py": "784a0fe3a5dc4ddcfa1e847bcffb6f153d1ac9fcf1607e2a6ce980588c3c5486",
        "modelscope/models/cv/image_depth_estimation_bts/networks/encoder.py": "8f9dc10017a9e54fedb008dd35bf026e18c9c0aa875e4b3140bb3df3c2451fdb",
        "modelscope/models/cv/image_depth_estimation_bts/networks/utils.py": "acc6e2823714543cba13f4a4f9b271c8d8742a988f266c0369530633af19b082",
        "modelscope/models/cv/image_depth_estimation_marigold/__init__.py": "e4fdfaf8e0de7ba9c15fa482ba0de6faa58f8e8a9e100e44a90edd627645bab0",
        "modelscope/models/cv/image_depth_estimation_marigold/marigold.py": "fb050b59c75bf3113608158daf5c4fbe556b3968924f9d69b1d61e3e61ca8668",
        "modelscope/models/cv/image_depth_estimation_marigold/marigold_utils.py": "1c7bfffc4365a2a79974219678610aa822b8cee32222732d242cc7942aaf8cc0",
        "modelscope/models/cv/image_driving_perception/__init__.py": "26a9b62cf24b5fe5217fce5f86ab08ebaeb7d0efcbc4327cf1884241483b6308",
        "modelscope/models/cv/image_driving_perception/image_driving_percetion_model.py": "dbab978770c2317ceaa191eab86554719d568bc92f4f85012c6f3335ba3fc401",
        "modelscope/models/cv/image_driving_perception/preprocessor.py": "cbefc896f635d784820882304a120a3d7aa8a548d3c116bc5d47a95baef28245",
        "modelscope/models/cv/image_driving_perception/utils.py": "66e6cbd05b46a00f91b26e316e8d37fa53177a8922af3f48a676e34a16a3f90d",
        "modelscope/models/cv/image_editing/__init__.py": "314f3519c96c5b898ccc115c0d7630c0e060673455d641c1ea27bfa7a6fbf9f5",
        "modelscope/models/cv/image_editing/masactrl.py": "5d7d0fad9a5e8a48e89e23c5adbe2a84cd4f75485b20aca572d662dcb316d90f",
        "modelscope/models/cv/image_editing/masactrl_utils.py": "9077056e554d212d98d3f86b3866f48ee47631d52e11623c12a19248f1a8d5b4",
        "modelscope/models/cv/image_face_fusion/__init__.py": "1ae82f1e529fe357823d278be3a1c03b48150dead7ede400945a0d3404feab6d",
        "modelscope/models/cv/image_face_fusion/image_face_fusion.py": "5295ba866a84a70850dbee806359067d6a708c206103eb2252ed12b6bc79066f",
        "modelscope/models/cv/image_face_fusion/facegan/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/image_face_fusion/facegan/face_gan.py": "9d60bff6e7e9e36363913bf64c69fffdbfe1755076d2576a0e6584cff0c55ba3",
        "modelscope/models/cv/image_face_fusion/facegan/gpen_model.py": "b175de59e4f1029dfa604dc3c3636dbd061c40a0a49e59f8b26ecb6a7f433616",
        "modelscope/models/cv/image_face_fusion/facegan/op/__init__.py": "d3bdebb6b1ea35ab8e7dd14af32919f11ae630ab9154d4c84f839397b98b2bf6",
        "modelscope/models/cv/image_face_fusion/facegan/op/conv2d_gradfix.py": "91a17fd0842e4c6867d13d7438da9a9019fe8f69497353db4f4a2b8aed55a5dc",
        "modelscope/models/cv/image_face_fusion/facegan/op/fused_act.py": "176828fa9ad2df1acf9cf7cdf2f1cdb79d4169b605528b1802dd2a3f98862aac",
        "modelscope/models/cv/image_face_fusion/facegan/op/upfirdn2d.py": "0653bf1bc6ea7e735ed0cb6c33b90b14afa8bef9906219e135201806f305ec03",
        "modelscope/models/cv/image_face_fusion/facelib/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/image_face_fusion/facelib/align_trans.py": "eb6372dad76d35e3549ae9d4dbd1b52cff5367091230da0bfebf8c79e0c87b4d",
        "modelscope/models/cv/image_face_fusion/facelib/matlab_cp2tform.py": "3ffda1968cbdd684ec8e96c9a78c2b460b5207990686d636696a34485fc7a914",
        "modelscope/models/cv/image_face_fusion/network/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/image_face_fusion/network/aad_layer.py": "8f761bbc9dc6b3d870c1762a50623d7095d517fd853691b7b660705b45ed3aa1",
        "modelscope/models/cv/image_face_fusion/network/aei_flow_net.py": "24c22cf1da329e1825ad6bb10d7d7d8a34dbd76778658dbc082beee78975f4b9",
        "modelscope/models/cv/image_face_fusion/network/bfm.py": "0dd8b00465d28825beca12b85397f85c0af5d36c03a21533b3622c18a9880fa3",
        "modelscope/models/cv/image_face_fusion/network/dense_motion.py": "2f3549cb23f8b878777b1a673c00ea30368d35d88f2638e020126140eba36a98",
        "modelscope/models/cv/image_face_fusion/network/facerecon_model.py": "43330ade0840f4ec933ed6e5a81cb8e14481ae0605b7ba3ba60f1a22796fdc63",
        "modelscope/models/cv/image_face_fusion/network/model_irse.py": "4f0ac0d014ee9ddec5d6b1eb8f2e856c5b12815350a2ee6a50dfd2e0a96aa4b2",
        "modelscope/models/cv/image_face_fusion/network/ops.py": "ab0841d4a210ece3e208890a30e703e28ec08098f0e69ea4ccd29afedd684126",
        "modelscope/models/cv/image_human_parsing/__init__.py": "a9e814661d53e1fc3d74c46d19c0a33e7715ae37577c75479e3c4971d0557b1b",
        "modelscope/models/cv/image_human_parsing/m2fp_net.py": "b9fc02ef5844cc86cfbe7de413adeeb86a35b506982ad36a4df195af3d9b5725",
        "modelscope/models/cv/image_human_parsing/parsing_utils.py": "6e3e8d6ee68dedac0db2ba59aa335915a25d7901fd3abbbe1d9b7cc70c86aabe",
        "modelscope/models/cv/image_human_parsing/backbone/__init__.py": "bf60410ccb4a6e2d31a50e787b57a4feb0dacc9541ff9a921f67e9c7b4a18461",
        "modelscope/models/cv/image_human_parsing/backbone/deeplab_resnet.py": "652c0c7820b6387394a29ab8d54ef47f03c2c2d24f3a0cd4fbd501529b08ea9d",
        "modelscope/models/cv/image_human_parsing/m2fp/__init__.py": "740c654ecc0a13ab9d2de21620149af8a9f02ea588e0c69a034d0ce0988996a6",
        "modelscope/models/cv/image_human_parsing/m2fp/m2fp_decoder.py": "f9c4063fd6550bfe84861c5c54fec70616043332aedeb5e77d300bf029e05402",
        "modelscope/models/cv/image_human_parsing/m2fp/m2fp_encoder.py": "d616b272d01766324eedab35a01f53f6a09557e8a77cd70f0a9e34a5cec9d08e",
        "modelscope/models/cv/image_inpainting/__init__.py": "d17aaff4440b6729f63898843a43d535b688df60a4b06dffc1c96baad25d0b0d",
        "modelscope/models/cv/image_inpainting/base.py": "e1c250c79ba52501c1c491f74bc4abb3e9528186e6747a38722d3936168a6619",
        "modelscope/models/cv/image_inpainting/default.py": "44e2d70f9c9cfccd746f880616a3ea7994e400c7ef9997144b423040a396d02d",
        "modelscope/models/cv/image_inpainting/model.py": "ceb6f80efc0f0fd02b1b44d98eb9b7c8c18da6a333b7b081ed7247525deb07c5",
        "modelscope/models/cv/image_inpainting/refinement.py": "46cc9732d9eba034a332fb614536a54846852581c68fa54681e73211973482b6",
        "modelscope/models/cv/image_inpainting/modules/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/image_inpainting/modules/adversarial.py": "b7e377e96f149a7b7f36d53c0f02176b865d6ce7f5cb7caec081b61d74e5a440",
        "modelscope/models/cv/image_inpainting/modules/feature_matching.py": "9827d6cf4ddef1f46022a47c059e7d8248ac39a31a8d262dd6eae7118b51d0f8",
        "modelscope/models/cv/image_inpainting/modules/ffc.py": "81bd508ebdee0e1d220f366a312ced0852d26910ea02b2eb96f0eb76699780e4",
        "modelscope/models/cv/image_inpainting/modules/inception.py": "54f899c108909a2b26976498c6489d8a635e17bb8538c558d3c2c3e8b87c185c",
        "modelscope/models/cv/image_inpainting/modules/perceptual.py": "4fe5a2950594b13970c6e402e6c8f1ace6c1d0fe5047563fb698db92fe64e1f8",
        "modelscope/models/cv/image_inpainting/modules/pix2pixhd.py": "376575c4f129fb1482499b2d657a8963d0353b3297b286a6ffb7c54ce1ba09c8",
        "modelscope/models/cv/image_inpainting/modules/ade20k/__init__.py": "3826a7aae6836a4a823e12e42cead9c62f2fed0078997bafd7ccd4e8d190f907",
        "modelscope/models/cv/image_inpainting/modules/ade20k/base.py": "380eae24bba76ead1ac432a6b7ff3964697946e89451094c2311390bfb68897a",
        "modelscope/models/cv/image_inpainting/modules/ade20k/resnet.py": "71aa8919c5f5bf4ab2810f8d88c45a2f5a307714d32c306f51a4cea8f3ace70d",
        "modelscope/models/cv/image_instance_segmentation/__init__.py": "ad2feb1b1af06fa7bf40849cb7137be8a9ad9c4e8aab895280da294f2fddeb00",
        "modelscope/models/cv/image_instance_segmentation/cascade_mask_rcnn_swin.py": "603767259ad5094e02d2f2d94bf643d6c81ec61cd96b2bbce634fa35774b7e97",
        "modelscope/models/cv/image_instance_segmentation/fastinst_model.py": "e52298e684e5415344f362c7d7ae6ec960bd5fb9a5e682d09f5e5daa333e29e6",
        "modelscope/models/cv/image_instance_segmentation/maskdino_model.py": "eeaeb28e480997fe61ceafbed4c2e98cc7fee2148e56ff1de33158e068e9914e",
        "modelscope/models/cv/image_instance_segmentation/maskdino_swin.py": "d46f0e0192e239ec67c80b4358c18d18871b1e15f53932bcae18f99ea1d61f28",
        "modelscope/models/cv/image_instance_segmentation/model.py": "0b2dc27fc1afddc32d232bf2641d5771f693d9268d5bc92b87417512458da87c",
        "modelscope/models/cv/image_instance_segmentation/postprocess_utils.py": "4759d48888e885ad633f529c5bb321b0d1b453d0fd59ba1e7d3f422a6b179654",
        "modelscope/models/cv/image_instance_segmentation/backbones/__init__.py": "a68c7378e5ccc5c4c77d314f7f50bbb755506091b43410f5951f38d4b5a9c7fa",
        "modelscope/models/cv/image_instance_segmentation/backbones/resnet.py": "f57ac68eb642406be13eefe1231e653491cfa8633dd446d1c8b6a9890c7e0596",
        "modelscope/models/cv/image_instance_segmentation/backbones/swin_transformer.py": "31a9a9b7d4838de3e199508c5b794201086ed6ff64a112377689c7dfef2ca3a6",
        "modelscope/models/cv/image_instance_segmentation/datasets/__init__.py": "13690451c21b6a05392b6c18533af6bd370370e18e380460abd230515e0c0237",
        "modelscope/models/cv/image_instance_segmentation/datasets/transforms.py": "9b610e3e10091ccbe85c6ac1ff3669eb13b7140f7c4308d59a5091b20395402c",
        "modelscope/models/cv/image_instance_segmentation/fastinst/__init__.py": "23f00d77175c207a64233217735c8a3a55b0cdbe286341704cfab5918b60cd0c",
        "modelscope/models/cv/image_instance_segmentation/fastinst/fastinst_decoder.py": "cd2ed95185c6a2b77ca0685cadb00752d51f519f755c34d40d39657014565319",
        "modelscope/models/cv/image_instance_segmentation/fastinst/fastinst_encoder.py": "29c4088c6e530e558319463887e378aff9041a10826778b4cf997de3bc257bb1",
        "modelscope/models/cv/image_instance_segmentation/maskdino/__init__.py": "5ed6b83f51ff87b9f1fe8c4dfd976aa957e34d3d65e49d2bbf13e6d17fb57738",
        "modelscope/models/cv/image_instance_segmentation/maskdino/dino_decoder.py": "d6ac7b00e4c4bf207b2d31a38766a676d02682b4bf350b2aea66cd9b810282ea",
        "modelscope/models/cv/image_instance_segmentation/maskdino/maskdino_decoder.py": "272a4f8135e349941c3c0b80db6eb552805f505c6400769e8903f0a624de6356",
        "modelscope/models/cv/image_instance_segmentation/maskdino/maskdino_encoder.py": "967b2964a10fee6de47db7f8464d5e2c421a48fae18b5b3ac2ed96bcc1a4c088",
        "modelscope/models/cv/image_instance_segmentation/maskdino/ms_deform_attn.py": "73f16fbf41211d18cea3c31e9e0f944a4b14016eaea4b922cbbb028d0fb78c07",
        "modelscope/models/cv/image_instance_segmentation/maskdino/position_encoding.py": "f0ec9de599154c25ac4326cd0c8ea1a91e66d75260ff487b0ec4e08145458eac",
        "modelscope/models/cv/image_instance_segmentation/maskdino/utils.py": "ee9ca773f8d5b3780467db1483eadcace38740b6e5d88aff1421d6d149306eaa",
        "modelscope/models/cv/image_local_feature_matching/__init__.py": "c3cd6561d0185251cec8a6ab40df82f6734b2ab585c0b327b5a33e83a0ceba58",
        "modelscope/models/cv/image_local_feature_matching/loftr_model.py": "bfcd81d97f973af97a1b5c11a4e206103bc4ca9e1710330b4ec3b187e9acc7b4",
        "modelscope/models/cv/image_local_feature_matching/src/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/image_local_feature_matching/src/loftr/__init__.py": "99ce5f8f0d3f1d92f6882a3d572cec0d7a06ef34b900163353959955a033433e",
        "modelscope/models/cv/image_local_feature_matching/src/loftr/loftr.py": "1ba86df55a70eb6f2cbacefd7201c13ff616283d48e6daf50969a1c3a26c8b7e",
        "modelscope/models/cv/image_local_feature_matching/src/loftr/backbone/__init__.py": "88b918c0fcf22f3833f95c1fb386dcfadf8be951f213069e3d3781eb9537db1d",
        "modelscope/models/cv/image_local_feature_matching/src/loftr/backbone/resnet_fpn.py": "30f33fa1907ca6d7e5bec72ecab27ad6df5c5b52ed8127162bf2b42945a79a8e",
        "modelscope/models/cv/image_local_feature_matching/src/loftr/loftr_module/__init__.py": "9341e09546550b57e2f7a901a9a0122102e7ecf599fb9ad508704ce2974d7c5b",
        "modelscope/models/cv/image_local_feature_matching/src/loftr/loftr_module/fine_preprocess.py": "11a76ba6200f0ba4d31ec32fe88753b563abcf35950502c7d89cd38532bae42e",
        "modelscope/models/cv/image_local_feature_matching/src/loftr/loftr_module/linear_attention.py": "7bc1ae6a873dad96883e66b37df1d8dc3f82fe7ec2ce3fb73c3d3eebc759e137",
        "modelscope/models/cv/image_local_feature_matching/src/loftr/loftr_module/transformer.py": "8c4d619c31b771166ec8c6754788a2dce38ec98132d7a30a56a15a7159341425",
        "modelscope/models/cv/image_local_feature_matching/src/loftr/utils/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/image_local_feature_matching/src/loftr/utils/coarse_matching.py": "005d71d6a9c317e09d4d9282b64cfd0c13df33e5ae9e9e6dedce872c5215bdfa",
        "modelscope/models/cv/image_local_feature_matching/src/loftr/utils/cvpr_ds_config.py": "bd4ac02662c431d771b6d479ab886bf084f033bba6a0126ea8f4a791e7931006",
        "modelscope/models/cv/image_local_feature_matching/src/loftr/utils/fine_matching.py": "f6406c6e74bf23099bf2acd30219e697b7ce676f8be7042c5b12c5540c5a48f3",
        "modelscope/models/cv/image_local_feature_matching/src/loftr/utils/geometry.py": "c341a89a071c2229f1bb3a38120e99ebb8ba4b20b30a76d2ed24a8f5c9329453",
        "modelscope/models/cv/image_local_feature_matching/src/loftr/utils/position_encoding.py": "398a13d553cec732f44e1bc48d79f40fe79a1d41f0029cd5915ecd16f6522e1f",
        "modelscope/models/cv/image_local_feature_matching/src/loftr/utils/supervision.py": "9794e168419c4a22d460255b9e3b213bc6ecd69ad516cfa0b78b7ae65bed7486",
        "modelscope/models/cv/image_local_feature_matching/src/utils/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/image_local_feature_matching/src/utils/plotting.py": "cf164e22b58004b5b032e0b8b575fb3751ccf62f5cb8689ab23e93baf7b29e2a",
        "modelscope/models/cv/image_matching/__init__.py": "8f2c4f726937799db022988e02f62e9ac57cd4ce755e94e6f4c47bfcfd57b75d",
        "modelscope/models/cv/image_matching/quadtree_attention_model.py": "e1ef691a3a1ec87369c9f5f95eb9d683c45186a73f11cd7a80d91a6b2bf0856d",
        "modelscope/models/cv/image_matching/config/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/image_matching/config/default.py": "d1100a8d85f1043116722f0c7ad78449f74acccf448468cac92f32d4556da71f",
        "modelscope/models/cv/image_matching/loftr_quadtree/__init__.py": "955b9dddef6b95709de47a167025fc9d40ff5278a50d31d9847ebef697041a39",
        "modelscope/models/cv/image_matching/loftr_quadtree/loftr.py": "7be11562c9593f06b61b6be0f7844c389c709e0b117000c6f8922ee80224ca15",
        "modelscope/models/cv/image_matching/loftr_quadtree/backbone/__init__.py": "accbcb0b2d64a2360dbc43b745f8e97671ffabaca41d0b5c09aa9046b64ce726",
        "modelscope/models/cv/image_matching/loftr_quadtree/backbone/resnet_fpn.py": "6bcd0bed3ceea94b75aa2ff83ab3910930ae86722bc89887bdff08771cc13cef",
        "modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/__init__.py": "39e658dd26b32ba3813e4d334c7db7ad88ed9673a29d45b5cab093942c4599a4",
        "modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/fine_preprocess.py": "cefe3b4b3df62ab5a8ac0b483524e3f38da0c5c8b53668a8fd284010c7b20734",
        "modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/linear_attention.py": "93d7ef98a63c651cac37f01c217b17898743168d0340fda18f81976c572366d7",
        "modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/quadtree_attention.py": "b1cb0fdc1a40873feb1f4383d3800c546fecd46aa3048c7d131747b87b9dc3cb",
        "modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/transformer.py": "a14f78a426bb364d540ce9a1fec64e57120eb3c8cc2b9492d22d7d24f79b8d44",
        "modelscope/models/cv/image_matching/loftr_quadtree/utils/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/image_matching/loftr_quadtree/utils/coarse_matching.py": "da714d945eaaa7c110fd127212e14f7feefa3428855c869246c67b5ada0be134",
        "modelscope/models/cv/image_matching/loftr_quadtree/utils/fine_matching.py": "69de7e1038479e5dfbad1e88e9070d293facb16409281a93c024f1f59a1bd7df",
        "modelscope/models/cv/image_matching/loftr_quadtree/utils/position_encoding.py": "18ab8f7b1eaf5b64a1ae85f38534166abc8e2afe81b1cb1334fd756e9431da1c",
        "modelscope/models/cv/image_matching/utils/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/image_matching/utils/misc.py": "fa8d0af7f5909cfb71fc56f13da9cdcdd1865e4b66d71ce524a495186ecce1a4",
        "modelscope/models/cv/image_matching_fast/__init__.py": "716804def5a31d5a98fa0b793084426fac6ed4767c67d205aecf093d4fc00a1c",
        "modelscope/models/cv/image_matching_fast/lightglue_model.py": "1dbac816999a48ef3883e12d7e156d098266498f36d4432d80eb3582b3b50463",
        "modelscope/models/cv/image_matching_fast/config/__init__.py": "cf22ba9144d1a2abb5093c4dd40844e0245a7e27c481751bb2e75ebf43c38ae0",
        "modelscope/models/cv/image_matching_fast/config/default.py": "10276541284074fd1be9d38a50eb3862c1c58d8c9df0c0cc5d1ec7183d1fb816",
        "modelscope/models/cv/image_matching_fast/lightglue/__init__.py": "a88da90e5e0c736857aa3f85fc40b2618c5ba3f755d4207cf0951f974a02e92c",
        "modelscope/models/cv/image_matching_fast/lightglue/aliked.py": "3c3b27f17507fc520f10aed89dac9c7fcb649bb8ebeb099c32180452871b4ab3",
        "modelscope/models/cv/image_matching_fast/lightglue/disk.py": "4205995b7e8f157fca82a561ba3be4234320e618e57b1791fdbe347558dd4818",
        "modelscope/models/cv/image_matching_fast/lightglue/lightglue.py": "825631c65b57b939dc3359d67480ea7dffca81b2fe91b4613f6a7e71f48bcae3",
        "modelscope/models/cv/image_matching_fast/lightglue/sift.py": "4314c0f759c590f1112bd834606f438c0be2ab57021b4b204fcac189f69fb08f",
        "modelscope/models/cv/image_matching_fast/lightglue/superpoint.py": "e580a882b0761f66f8c9dccb35a029536649dcb420f4cd96f04d054da8fec0f1",
        "modelscope/models/cv/image_matching_fast/lightglue/utils.py": "76abd03d282c872d003914e310408b467c29ab87e472e0b5beade34fec17eeb6",
        "modelscope/models/cv/image_matching_fast/lightglue/viz2d.py": "870a9b71eddea5075dc19ad6f3471f22e41fec01dfae7a397ae2e49147f80c81",
        "modelscope/models/cv/image_mvs_depth_estimation/__init__.py": "2f96541bce33def8ef8cb362b91e69b321ee0e98af67dc895207cb0f2e75f04d",
        "modelscope/models/cv/image_mvs_depth_estimation/cas_mvsnet.py": "9e6bdd4d934bbe5e9aebef947e620689f8ba8bc55bb868996088d98252ef487f",
        "modelscope/models/cv/image_mvs_depth_estimation/casmvs_model.py": "8a9ebcdddf73771a3d4be209b143ecb814a204b04e788923c88a6ce0baf83bf2",
        "modelscope/models/cv/image_mvs_depth_estimation/colmap2mvsnet.py": "1d9571ab5339d491fa228979bce664c1b24d8403c776085bc0d5fa71e7294e87",
        "modelscope/models/cv/image_mvs_depth_estimation/depth_filter.py": "d9f163c29987679246e5a23e6b5b4c73cdc2b3a42ca73642a76dafe1b3cb5b5a",
        "modelscope/models/cv/image_mvs_depth_estimation/general_eval_dataset.py": "2c0e2a9e6cb0e0a53a93d268c2e0e300496edf0ba47ca2240427c9c41215e9b5",
        "modelscope/models/cv/image_mvs_depth_estimation/module.py": "98a780a2ff7721726005b093dc7886f4601450912a500f0f4d04aaf4c78a001b",
        "modelscope/models/cv/image_mvs_depth_estimation/utils.py": "87d437dd46c6b7dade8cc6086aff62e6aa42f5e5b8c6912769584ad746b63e1b",
        "modelscope/models/cv/image_mvs_depth_estimation_geomvsnet/__init__.py": "82e731008266bca99602b49f31a603b7c2f1da042874a70330e97e4321cc8e35",
        "modelscope/models/cv/image_mvs_depth_estimation_geomvsnet/colmap2mvsnet.py": "1d9571ab5339d491fa228979bce664c1b24d8403c776085bc0d5fa71e7294e87",
        "modelscope/models/cv/image_mvs_depth_estimation_geomvsnet/depth_filter.py": "645c768b96d53a6b7dbe868ffeb9ba484ea9377cdf9d38b6f707cac4143c5c69",
        "modelscope/models/cv/image_mvs_depth_estimation_geomvsnet/general_eval_dataset.py": "b932e68f9374969cbf26f9ce6af17a69cedec859f739947796a5d04d371233b6",
        "modelscope/models/cv/image_mvs_depth_estimation_geomvsnet/geomvsnet_model.py": "7c62d2e3238a29a7733380902da3cf379637f7ac2452cda36a2c2e9fe41fa37f",
        "modelscope/models/cv/image_mvs_depth_estimation_geomvsnet/module.py": "98a780a2ff7721726005b093dc7886f4601450912a500f0f4d04aaf4c78a001b",
        "modelscope/models/cv/image_mvs_depth_estimation_geomvsnet/utils.py": "87d437dd46c6b7dade8cc6086aff62e6aa42f5e5b8c6912769584ad746b63e1b",
        "modelscope/models/cv/image_mvs_depth_estimation_geomvsnet/models/__init__.py": "1100ac4904dbdef7fa3f72347be1fedfde5a35f14b13226459ec3f8665a0064f",
        "modelscope/models/cv/image_mvs_depth_estimation_geomvsnet/models/filter.py": "9ad3b832fc14fe0bdfc65f0fc8445217a8b9d842eecf8f7eb978939ec44aaa3b",
        "modelscope/models/cv/image_mvs_depth_estimation_geomvsnet/models/geometry.py": "eaebecee8b9e4e6a16022bf04943c6e781da3dd67d642321ddd69f3f3931a17d",
        "modelscope/models/cv/image_mvs_depth_estimation_geomvsnet/models/geomvsnet.py": "c23bb48aff01cd65d7cea033887bea656aa00c50d44b67a8e979615ea1b27d5a",
        "modelscope/models/cv/image_mvs_depth_estimation_geomvsnet/models/loss.py": "8e7420df4d446c04c70ae23b05ce0a807ac0bab3fae597cf98729bf5782ec0fe",
        "modelscope/models/cv/image_mvs_depth_estimation_geomvsnet/models/submodules.py": "deccda7960c5a86436057f5554d42ccd0eb533bdd8ec4347249c48fe8c3642ba",
        "modelscope/models/cv/image_mvs_depth_estimation_geomvsnet/models/utils/__init__.py": "6a52031819f1587e09bcff945beecdf7db1e0418b4af5195d61f1fd4444505e7",
        "modelscope/models/cv/image_mvs_depth_estimation_geomvsnet/models/utils/opts.py": "56b18b0aa893458c011fb99e20c5b5332d0c2cea1c6bd4e96dde62f91f6238ff",
        "modelscope/models/cv/image_mvs_depth_estimation_geomvsnet/models/utils/utils.py": "e72d12003ea85dda719ced3160f50cf25c9e2d8e1124e2e2d6fcc12698917867",
        "modelscope/models/cv/image_normal_estimation/__init__.py": "8a9f94c58788ea427ebfef2750b4674ee59136ee080ddfab879dff1a05a37ce6",
        "modelscope/models/cv/image_normal_estimation/omnidata_model.py": "5b5859d254d9154bb37f2dd87ef4f43da2aec073e61d3f4176ffe405f71396f4",
        "modelscope/models/cv/image_normal_estimation/modules/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/image_normal_estimation/modules/midas/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/image_normal_estimation/modules/midas/base_model.py": "58b0dc8eb2ba6d9e76ad135de299cc2cd137d80b3ce3136e4449766290f74311",
        "modelscope/models/cv/image_normal_estimation/modules/midas/blocks.py": "62acae9599809865c69f8eb420e6a9ef7828d335fc9ca7018cc74e746e1376bc",
        "modelscope/models/cv/image_normal_estimation/modules/midas/dpt_depth.py": "e6fb78ad65029c1aaccc689c97b26487159cff587350349977162dd121b77d2e",
        "modelscope/models/cv/image_normal_estimation/modules/midas/vit.py": "21e8014488e6708d7d516c440b0b466ed21e1f27e354eb234f0b494150ab5c06",
        "modelscope/models/cv/image_paintbyexample/__init__.py": "e56d4e39d33dc67c90680113550210b02602e11edf341c270fdc3cb4545dd9e0",
        "modelscope/models/cv/image_paintbyexample/model.py": "be58b1ec00642bb65a21afac425ddaa59a4933ea801bd5a07ecd272ef574c4e9",
        "modelscope/models/cv/image_panoptic_segmentation/__init__.py": "5908d80ce950934856b53c1b9e38f5a29518bdfdcb1ac513f9407bfc31a40fc6",
        "modelscope/models/cv/image_panoptic_segmentation/panseg_model.py": "236854aac640b4488aefb31603983036d59c9b400ee666ea14755fdbaee35743",
        "modelscope/models/cv/image_portrait_enhancement/__init__.py": "d8d9a86f9dac4100041bf62eb6fe42ef76469538f18b2f70c6269edaa1badaf2",
        "modelscope/models/cv/image_portrait_enhancement/align_faces.py": "bee7e5287b56826909721682e908a56b3b64bccb8c5585ed49c7ad6e62324823",
        "modelscope/models/cv/image_portrait_enhancement/gpen.py": "7de96cee9188d75a11b2c07fc836741c32bc33352c60d8529b3d3c81c3ad77dc",
        "modelscope/models/cv/image_portrait_enhancement/image_portrait_enhancement.py": "47108333aec24d786d1a49ba30b87a285ee6a8c50511625fb6ff6422dd570899",
        "modelscope/models/cv/image_portrait_enhancement/eqface/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/image_portrait_enhancement/eqface/fqa.py": "8fda030e4c13bbda288723faab571790c26b8b8f2315196d9b049babc3ecf28c",
        "modelscope/models/cv/image_portrait_enhancement/eqface/model_resnet.py": "dfa57b539726533b9d0d34212660f514b0781d579a1313e13ec6519dc9de39a8",
        "modelscope/models/cv/image_portrait_enhancement/losses/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/image_portrait_enhancement/losses/helpers.py": "41f23cb1127b5997aeb2a87915e211e182bd2783f9a6bf640c3ce10953a57116",
        "modelscope/models/cv/image_portrait_enhancement/losses/losses.py": "bbd9ace0f510e6ba1cd0228ae1cab05a610301895e1156da588b261a2bf623d3",
        "modelscope/models/cv/image_portrait_enhancement/losses/model_irse.py": "083eb2c647d26a3a0a9d9cc9eaab829ed20a2146d3592ebf9d5db83ca11a50fc",
        "modelscope/models/cv/image_portrait_enhancement/retinaface/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/image_portrait_enhancement/retinaface/detection.py": "f61ab3abe42b42ab917fa622a9ba83e4d06f10c649954cec630f6f3a712c6ea2",
        "modelscope/models/cv/image_portrait_enhancement/retinaface/utils.py": "0dca71645e926bda3e02a8d5e770496bbddcdf9ec970f1b5bc32086172e3cf48",
        "modelscope/models/cv/image_portrait_enhancement/retinaface/models/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/image_portrait_enhancement/retinaface/models/net.py": "2fbf0a3a585b9624279bcb7bebdaea1088bb7a6ee6ea6d826782642bcb77c703",
        "modelscope/models/cv/image_portrait_enhancement/retinaface/models/retinaface.py": "8036e0667611a95b78b33aa14cb63edbd05975da63e4433e82f2c13361d197ea",
        "modelscope/models/cv/image_probing_model/__init__.py": "1cb28a9492f189b107987b60810870b5496080ab525bedc26091e892cc22fc2b",
        "modelscope/models/cv/image_probing_model/backbone.py": "91b145b6e3bb3afe17fe05feabb68f8cfadc1889ec57f3d4c957ea646a53bff3",
        "modelscope/models/cv/image_probing_model/model.py": "6608548877ec91841a408862793d1978e7bc5553a4d840d9d7e6b6db4dc6ce1c",
        "modelscope/models/cv/image_probing_model/utils.py": "30f88fb56f74808a33082ca344b10ac0b827a3e8e8f4b58597142dc1c4aa3e80",
        "modelscope/models/cv/image_quality_assessment_degradation/__init__.py": "dd6557cf72868a4c4018abad3c1cae02e4724603b4db4a3ca865b0b122a0e64c",
        "modelscope/models/cv/image_quality_assessment_degradation/degradation_model.py": "f5920a757a016e1e83fb2a66f130908575f7b4b9e80da397f88ed711f5f8bcbf",
        "modelscope/models/cv/image_quality_assessment_degradation/image_quality_assessment_degradation.py": "2c1cbf087f9eaec88a43a45af63459e1eb52a2f5a885a36e99e73ef95532687e",
        "modelscope/models/cv/image_quality_assessment_man/__init__.py": "8014d93f1666f2f94e192da52cea2de8996e0979a3607ae998c84c9464e333d6",
        "modelscope/models/cv/image_quality_assessment_man/image_quality_assessment_man.py": "8f121ecb835cf486d38d963ceb6e7daec70b87dc597936d02d64434633ebfab6",
        "modelscope/models/cv/image_quality_assessment_man/maniqa.py": "8a0c04f3feffafad05cf3c7b1817e149a93796bc0ceb6f13da29f526bc04c46f",
        "modelscope/models/cv/image_quality_assessment_man/swin.py": "1ae686611e06d42f2738b907119ee0a67fb50c01ba3dbefc507e55946523f127",
        "modelscope/models/cv/image_quality_assessment_mos/__init__.py": "44dce186516ddca1166aad1ec24958fc9f031ea47ad8d7ba2576b62faeecc1d7",
        "modelscope/models/cv/image_quality_assessment_mos/censeo_ivqa_model.py": "49ff14a0396cf045402914d8501de36554d371a57d7a719d7f2ce4ee35ed9eef",
        "modelscope/models/cv/image_quality_assessment_mos/image_quality_assessment_mos.py": "0e74811966c4755935b7c77524f03c34f2dae69cacb63c88f95285b8e1642f4a",
        "modelscope/models/cv/image_quality_assessment_mos/backbones/__init__.py": "5686a8df64f8711eab61064163ebf95614238579163d2a347064de887430ca4c",
        "modelscope/models/cv/image_quality_assessment_mos/backbones/resnet.py": "df0a50c03d2fec8088c380dd828e861fa297cc40f7cd4aa5b5d4877b5b2dc386",
        "modelscope/models/cv/image_quality_assessment_mos/heads/__init__.py": "8b4b0bde47832fd8f7b321ee61229710a7980627c32b32c530d92b288f1b0e18",
        "modelscope/models/cv/image_quality_assessment_mos/heads/simple_head.py": "ee1634868ded298dfb547bf1b5d57304d5585a519b1127023ee548941a090f82",
        "modelscope/models/cv/image_reid_person/__init__.py": "84560842507673ddd3d16bef6a9e472c88e8a126329e71e401045529f9d0f6eb",
        "modelscope/models/cv/image_reid_person/pass_model.py": "f227d601a15d9b71548ec50ab69a21de274e7bfd43747ca281addbb202f6a9d2",
        "modelscope/models/cv/image_reid_person/transreid_model.py": "15a00b54327731e9cbe86c52a7670a4f6982b31171bd7decb9045573fdd48ab9",
        "modelscope/models/cv/image_restoration/__init__.py": "7029f4e6ff1cce6f3a433e0afdc22598fa6eb55f5456f79eec2fb960ebf48a1b",
        "modelscope/models/cv/image_restoration/image_restoration_model.py": "74d1f24aa54159cec156759067fffece2ec52447789f82e2f00c192ffa4a2957",
        "modelscope/models/cv/image_restoration/demoire_models/__init__.py": "60d4b9377ce16f80b71d45261d280e8d64134c43bf0c30392c4d22825f57f73f",
        "modelscope/models/cv/image_restoration/demoire_models/nets.py": "4b59132fdcfc33d56a394f981d55562d0e01b1928706259aa8e5a972bb377c51",
        "modelscope/models/cv/image_semantic_segmentation/__init__.py": "b96508158b08b72af2e10a505d3531410d96a247c91d3050c3d6f694f4f73af3",
        "modelscope/models/cv/image_semantic_segmentation/ddpm_segmentation_model.py": "775d038495e55ba0b7da3e0d1a38f2b966f73ef40739af337b59c538435af7a7",
        "modelscope/models/cv/image_semantic_segmentation/semantic_seg_model.py": "117d72c3ea075e4636bb722de4c941a914bf6229e86ac2af1108e2550dc82de7",
        "modelscope/models/cv/image_semantic_segmentation/ddpm_seg/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/image_semantic_segmentation/ddpm_seg/data_util.py": "a092eacfad47dbb6dfc39e518f938458976e008032c4c22f910436faeaaf8350",
        "modelscope/models/cv/image_semantic_segmentation/ddpm_seg/feature_extractors.py": "9fc8dd93d6523c8d570a98d2758afb6ba4042f5201b5c88fb2037a79b38982f6",
        "modelscope/models/cv/image_semantic_segmentation/ddpm_seg/pixel_classifier.py": "b43db8c406cd7daf6a0f62deb7adf078b0d9e3da925d9dd96f89c6803cc001a3",
        "modelscope/models/cv/image_semantic_segmentation/ddpm_seg/utils.py": "d9306ff1cd861e4a2c8110b44c4f2ceab775a9adc3bbc741cdd2f8a3efafa716",
        "modelscope/models/cv/image_semantic_segmentation/pan_merge/__init__.py": "a921929186db5c11a669e46ebd421058d2f1c508996e9a0e6cedc6ab23d9e98c",
        "modelscope/models/cv/image_semantic_segmentation/pan_merge/base_panoptic_fusion_head.py": "7b0d78166e58cf33f842a31733db1e86d073db312ae476a8c3a91a001f2ed487",
        "modelscope/models/cv/image_semantic_segmentation/pan_merge/maskformer_semantic_head.py": "724768d1d617f98fa11573b85e627f372e507dd91a74a9fc490dc3a1137b634f",
        "modelscope/models/cv/image_semantic_segmentation/vit_adapter/__init__.py": "39fabed7dfe7c31869e1ed66ce4bfdb5aae00076cc299f4eff906279fd4f8d03",
        "modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/__init__.py": "e0fb72e9094a96dd15aa2077bedba78d50d959c48db7b0d9f7a809b9e23ad3c8",
        "modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/__init__.py": "17f207173b2e62af4965ba2bc4a19480d27dc8795913d7bb09c7f6c644ca93ce",
        "modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/adapter_modules.py": "6b19a327886281a3e465510850591f6c7e1ad89f8395e3997addd1ff1b8bc13b",
        "modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/beit_adapter.py": "f7596f21dbdf75bc705737f547dac48307d38ea611330b42e02c5cc206a21150",
        "modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/base/__init__.py": "e14710c8d6faf1d4f38f7bdd4a8ca1250d70e3505183db139ccc6bae73675447",
        "modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/base/beit.py": "ee75528d53d26d18b555f95c19d807f868279cd535715ddcc34c10b68f3677f0",
        "modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/__init__.py": "a4989203168f684577001d9d7d10190ac36a84abf40a0a2559d2e3549a2e4ee2",
        "modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/base_decode_head.py": "15aee0575d99d0dd770ae2e0260080b91b069e4ccf7dd3c8a37bc277313f21c6",
        "modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/mask2former_head_from_mmseg.py": "0796b5efc29aa0dfeffd5860231ac44c18dbc169a1813940642db59f3c703de9",
        "modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/__init__.py": "616f773ef6fff6ff48cda437b2434830afb9a66d3b57f62590e61ca459290ba7",
        "modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/base_segmentor.py": "ab98e5bb4928118eac660d427244945afe7d8bec1950b7e4268c2e5c06dd396c",
        "modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/encoder_decoder_mask2former.py": "34be6bb2eb04ccaf021fc96c379b3ee41e52ea15d532ef815be55e4b21bb3d53",
        "modelscope/models/cv/image_semantic_segmentation/vit_adapter/utils/__init__.py": "a9b4d521e2e0ae33ea8bc25bc3f6edb4c5f7961e414d310ee11123bc91d18087",
        "modelscope/models/cv/image_semantic_segmentation/vit_adapter/utils/builder.py": "11b805f3b230a3377e7b916ac793f0d31bde056af1c2ebfd1ab9123e53b5067f",
        "modelscope/models/cv/image_semantic_segmentation/vit_adapter/utils/data_process_func.py": "086c3a6f75344c25434e94e89601921f33a2deb1a1b7dadf5491f53ea71c7db6",
        "modelscope/models/cv/image_semantic_segmentation/vit_adapter/utils/seg_func.py": "aec5f6a56f818918fb7e60af9bb40393122cec34122eec04b7c7c7cbece8e921",
        "modelscope/models/cv/image_skychange/__init__.py": "5cbf543f360df7284f8cb50d9939a1499d4b2c1f8444aa094949348f8dd6d0d6",
        "modelscope/models/cv/image_skychange/preprocessor.py": "05cede81e805e5e939cb1c9756f5fdf75ed0ba5e3726ae67ff7c23b840ebb96b",
        "modelscope/models/cv/image_skychange/skychange.py": "6a5db84b84c754ce74bdfd359ec219bcdd071808a3b075ab89474bf8a9003139",
        "modelscope/models/cv/image_skychange/skychange_model.py": "8a77984a808734ef90c92460ee25f94637ded97878c6eaa87520947de1253728",
        "modelscope/models/cv/image_skychange/ptsemseg/BlockModules.py": "330fcf0b3d9b73a61f560800a4609b9e31769285458e242f7054807e9f2c1284",
        "modelscope/models/cv/image_skychange/ptsemseg/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/image_skychange/ptsemseg/hrnet_backnone.py": "e2dd55aca0ebf219846b9e0653f6850f3916211d95e4a5dda2955040d94bc1f2",
        "modelscope/models/cv/image_skychange/ptsemseg/hrnet_super_and_ocr.py": "d1d89616bb07a1c928de26dfbd743cfc405b59c1fdcde0625edbf0a8c7e3f42c",
        "modelscope/models/cv/image_skychange/ptsemseg/unet.py": "d39e9c81ba312c8585bf1bf090738d0285c26ea062b6ca3befe9193e54322ada",
        "modelscope/models/cv/image_super_resolution_pasd/__init__.py": "30c006486ea7a1ed6da848a4ae902450c89aec24b89f830b79f0518c88efd072",
        "modelscope/models/cv/image_super_resolution_pasd/attention.py": "2c89ea15a362792d893d1f44e0dbaac9bdb9b720ffe948761045fc184d24e2a8",
        "modelscope/models/cv/image_super_resolution_pasd/controlnet.py": "5637bf935274d955a6d85505747abfaf51a9979362e7b672ef6de54717c068e3",
        "modelscope/models/cv/image_super_resolution_pasd/misc.py": "6cb15da0f472427d9bd681d3e21428772a606a48632d657cce1870c8557194e2",
        "modelscope/models/cv/image_super_resolution_pasd/transformer_2d.py": "5f09d1715f0d5cd3b965eac8acd110a0ff9c39b7b529b55d66da232d6a8b9b41",
        "modelscope/models/cv/image_super_resolution_pasd/unet_2d_blocks.py": "2d8ba058097661d84f41be4b6198c04d2eaae217bbb369bc71795f44b0c1228a",
        "modelscope/models/cv/image_super_resolution_pasd/unet_2d_condition.py": "ba3a60e939886c47b2cec3c2eb133820716c14bbcccd39ef2877c7a8b71e6ad5",
        "modelscope/models/cv/image_super_resolution_pasd_v2/__init__.py": "30c006486ea7a1ed6da848a4ae902450c89aec24b89f830b79f0518c88efd072",
        "modelscope/models/cv/image_super_resolution_pasd_v2/controlnet.py": "fa28463910383a08e2f323766e6c200fb38547c5a30730e3595ef40da8b3b1e7",
        "modelscope/models/cv/image_super_resolution_pasd_v2/unet_2d_blocks.py": "72c45eaa602297779cc0ed502c1f6c6a7c662f6dd09822452cf236eaf7256679",
        "modelscope/models/cv/image_super_resolution_pasd_v2/unet_2d_condition.py": "d993a0e68d5e3a51476f6dbb7b1f7d772ba66409a86150cc70701143459618e8",
        "modelscope/models/cv/image_to_3d/__init__.py": "cd1724ee7f291418cdce72dd1c69d65da1c6fd50794de586078b9cce1b90e1af",
        "modelscope/models/cv/image_to_image_generation/__init__.py": "5656999e63e83754585040086d1d226d5f5003aceed867d027ca508ea6013ed6",
        "modelscope/models/cv/image_to_image_generation/model.py": "e86f2c9f44d1dd44d6b6e3472780a5210a4ee44687c9fcc0bf2954c0a75041af",
        "modelscope/models/cv/image_to_image_generation/data/__init__.py": "67069e2fe982abb9ec7f456c10c38023f94aeb45a137cf4cdbdc0efa40d108f3",
        "modelscope/models/cv/image_to_image_generation/data/transforms.py": "542d3f422c3b62cbb473721cb7443af4fc0daad03b1274913fb3aca8dea7784a",
        "modelscope/models/cv/image_to_image_generation/models/__init__.py": "cd971e52147504ee478ff3ca791443bc222a9d87734d46f1bf08155c57a52f08",
        "modelscope/models/cv/image_to_image_generation/models/autoencoder.py": "19c3a2135ea846a3adf8660f10a7bd300600429cbec8ee0351666dfdb2263a6c",
        "modelscope/models/cv/image_to_image_generation/models/clip.py": "fd788fd8faceb93dcc2ce50e6ae43eb5e1077d3acaeb21402db3f632f2dbd7a5",
        "modelscope/models/cv/image_to_image_generation/ops/__init__.py": "bde7c456577387ae63f15634623a1643031f270b1d7ea427a5c8b0daee3d0351",
        "modelscope/models/cv/image_to_image_generation/ops/diffusion.py": "1bf3aba0f8d5fe46786b0e61e52788e2bfbf2d73221858dd8bfdd4a5b9b90d55",
        "modelscope/models/cv/image_to_image_generation/ops/losses.py": "2b4691c0d878541db47691e847bc12b1546d552c91c1000a7751862bb4986251",
        "modelscope/models/cv/image_to_image_translation/__init__.py": "4d1b58fc86b52d46185c416c345c078ee35dbcff1a1bcb76101ecb3a0395e3d3",
        "modelscope/models/cv/image_to_image_translation/model_translation.py": "05465d46043b614b7ef92b3a0c83c7b7d844b85a486572ab8a9c40538f743f25",
        "modelscope/models/cv/image_to_image_translation/data/__init__.py": "accc781e492c519601887341c193e9b14d6280350900cb901360a79396606824",
        "modelscope/models/cv/image_to_image_translation/data/transforms.py": "542d3f422c3b62cbb473721cb7443af4fc0daad03b1274913fb3aca8dea7784a",
        "modelscope/models/cv/image_to_image_translation/models/__init__.py": "526131d7ef40d77c52c6fa7d6643516db2c58f69a33cec57f8da0b4a00b20090",
        "modelscope/models/cv/image_to_image_translation/models/autoencoder.py": "19c3a2135ea846a3adf8660f10a7bd300600429cbec8ee0351666dfdb2263a6c",
        "modelscope/models/cv/image_to_image_translation/models/clip.py": "fd788fd8faceb93dcc2ce50e6ae43eb5e1077d3acaeb21402db3f632f2dbd7a5",
        "modelscope/models/cv/image_to_image_translation/ops/__init__.py": "bef59a28134bbf506451e60eec9b5f6e12e82b11ef741167820cafd9fb064550",
        "modelscope/models/cv/image_to_image_translation/ops/apps.py": "99ba0316ba8e2f688506b9d4b8b38f72dfcf377a0a5c901c27081404d0857aee",
        "modelscope/models/cv/image_to_image_translation/ops/degradation.py": "ba04d5adb820c88f18818f6b4d5e52541fd28815c666812941caffb536d32d9d",
        "modelscope/models/cv/image_to_image_translation/ops/diffusion.py": "d3804189d9962b722978f885d1a2f6342c51504da54ebcd4711e35ac4a0413b0",
        "modelscope/models/cv/image_to_image_translation/ops/losses.py": "2b4691c0d878541db47691e847bc12b1546d552c91c1000a7751862bb4986251",
        "modelscope/models/cv/image_to_image_translation/ops/metrics.py": "9ce07b6d1efd4d98409ab6033bb6c54e494584007a603f40a9d33f40db0643a5",
        "modelscope/models/cv/image_to_image_translation/ops/random_color.py": "9e0dcc9e0d0205e5bd3a465c2a1643c92b7b8c9809b823534297e386e1c77c28",
        "modelscope/models/cv/image_to_image_translation/ops/random_mask.py": "ad2996e9559e89fb61bb99c13b3fbf1300f6488dcb1219c9d695cda69809c891",
        "modelscope/models/cv/image_to_image_translation/ops/svd.py": "bc30820dd416b5762d17756a97713b653fc7484cb6f3d5166b4f1f9cc97d1d96",
        "modelscope/models/cv/image_to_image_translation/ops/utils.py": "15710e956d41e0d302749ab2159c2e13c90424d1b54209d0c81d1971061ac86f",
        "modelscope/models/cv/image_try_on/__init__.py": "fa38bc4054c0256550ba958b1e3b762cb7956d3b0ec6a9d8d625a45c23b50d3c",
        "modelscope/models/cv/image_try_on/generator.py": "f9d92962d414a18a3d6c95e0aeea9edd9986f71a67ba532f0467fb69890eb844",
        "modelscope/models/cv/image_try_on/landmark.py": "3213da47f1692554439afcb617ae7445b83394a09d496b3fc0ce54b118df93fa",
        "modelscope/models/cv/image_try_on/try_on_infer.py": "948e4f45fac277ee30cafa2e1be729bb4ae0f10dbccc75f3405be0ce1ac3961c",
        "modelscope/models/cv/image_try_on/warping.py": "341f18afdcd4c4184b338e3b095de0e2a1bcc37b0cfc791701874a41dafd396b",
        "modelscope/models/cv/image_view_transform/__init__.py": "679121fa3e8b93b7fce689ef990a6fc9c27a64e93025f1ab5f898f50169cbdde",
        "modelscope/models/cv/image_view_transform/image_view_transform_infer.py": "e5fa33c65b5ffa48ebb6fe98dee682f4029dada034221afd7525cc191fbb0ab7",
        "modelscope/models/cv/image_view_transform/util.py": "e68742af9d8ac0f874471a6f552635cc7cadac7198fb91f0a1d05babb2086d56",
        "modelscope/models/cv/image_view_transform/ldm/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/image_view_transform/ldm/attention.py": "938db65027b05fe4e3253f8942fe8b52f3784c93096d434b4d759c41702355d9",
        "modelscope/models/cv/image_view_transform/ldm/autoencoder.py": "087afc59a655eada826fafff398681cff5becce8602d9e7578f3113823dbe614",
        "modelscope/models/cv/image_view_transform/ldm/ddim.py": "0d32c000fa8f7b98f16e637d0912ffa4d340f3e53fe5d931315f75838804c0be",
        "modelscope/models/cv/image_view_transform/ldm/ddpm.py": "b4aff2cfe333d9f627070979c933199811a67adc706acf558a3a4b68472358a3",
        "modelscope/models/cv/image_view_transform/ldm/distributions.py": "d5f4711b99cad163de07b5c5bef6dfd6741bfdca86baf83f01393e875e556220",
        "modelscope/models/cv/image_view_transform/ldm/ema.py": "7028572afa66dfd0680eeeff94cb7d6375b3cdbc6c395cbb0f38d8b859b2c89e",
        "modelscope/models/cv/image_view_transform/ldm/helpers.py": "00548cfbac62ea00bf92af087f98abe9aeb90f6122e0318f31efa627123d8470",
        "modelscope/models/cv/image_view_transform/ldm/id_loss.py": "b566cad0d25ff955a9d62fd3649ab2fcfa292b044ce1767a70c31d8c8f321260",
        "modelscope/models/cv/image_view_transform/ldm/model.py": "4a3a17a40a696b6dc1d4aa36dfc53bfdcd24ab1097bf5e6aaa24e76fdeb27911",
        "modelscope/models/cv/image_view_transform/ldm/model_irse.py": "ee044e14f9c1fc761924f1ea81e5d3abc1ce9969467c2dd7afec44d3453dea83",
        "modelscope/models/cv/image_view_transform/ldm/modules.py": "b487ea30c67f160100ce2261951b15b82740f92dde923003042d7170d9d4be9a",
        "modelscope/models/cv/image_view_transform/ldm/openaimodel.py": "78594bdfae39ee9e23b454e3c2fe1c4c18e866f78faa17917bd35ebce16b106f",
        "modelscope/models/cv/image_view_transform/ldm/plms.py": "14a2f8246708ea3eb5c0d72348eb501cc71577e7974e4874a4db81927b4d1286",
        "modelscope/models/cv/image_view_transform/ldm/sampling_util.py": "ad922ebc60e5de933fad014464886fe8c2266c55ce153f557f1b121291ac5e2f",
        "modelscope/models/cv/image_view_transform/ldm/util_diffusion.py": "34530a2c52399bafa6bf55ac54e7a151383cf379547e579a6ace16d69bbe71b0",
        "modelscope/models/cv/image_view_transform/ldm/x_transformer.py": "609cd9b6dc9b36907368270a364faf2fa3e09ba265e39dbe38b753f763a12136",
        "modelscope/models/cv/indoor_layout_estimation/__init__.py": "0c59b9c752dc2209c1dd8436fd984d013f8c62524eb40ce428f87efcf826ffd1",
        "modelscope/models/cv/indoor_layout_estimation/panovit.py": "f31ed973b3d12ec80df8bc0a14cad1a01fef6d7866019bcc09621b4b48ba901d",
        "modelscope/models/cv/indoor_layout_estimation/networks/__init__.py": "23f00d77175c207a64233217735c8a3a55b0cdbe286341704cfab5918b60cd0c",
        "modelscope/models/cv/indoor_layout_estimation/networks/panovit.py": "e3e572b35cec1f923b038c30c81daede0922af713b75bc3585672f7c2bde297d",
        "modelscope/models/cv/indoor_layout_estimation/networks/utils.py": "113a025e3a018be6e252e557e268124ccbe11de2312988446a7be33b6162dc90",
        "modelscope/models/cv/indoor_layout_estimation/networks/backbone/__init__.py": "141b239fd0788b8466e8b6fb97271ea1e203f345eed425e70e4d46d7d9be56b2",
        "modelscope/models/cv/indoor_layout_estimation/networks/backbone/resnet_DA.py": "6f2806b7e312ce3ef54342607c08d00d9faf9891bc56cc15c714284fc298afe2",
        "modelscope/models/cv/indoor_layout_estimation/networks/backbone/vit_horizon_pry_image.py": "5b7cc0ad97e3f2e0e55141d5fdb9daa3e3cd5977a67bb575ba9afb2f61a0ab94",
        "modelscope/models/cv/indoor_layout_estimation/networks/misc/__init__.py": "23f00d77175c207a64233217735c8a3a55b0cdbe286341704cfab5918b60cd0c",
        "modelscope/models/cv/indoor_layout_estimation/networks/misc/fourier.py": "4e487368bdd423f4df37f5372fc34669c64d4c1163f71d4505d393124542498d",
        "modelscope/models/cv/indoor_layout_estimation/networks/misc/panostretch.py": "e7fcd8c3e0b6801c052e6e99d8ee8b3401ef744bea5c238dac9feacecc688f89",
        "modelscope/models/cv/indoor_layout_estimation/networks/misc/post_proc.py": "315726b5caef04655fda801ef93b2bd41828bcde86127896e111774626de4d24",
        "modelscope/models/cv/indoor_layout_estimation/networks/modality/__init__.py": "36ebc1e9d5d2778f4ea1717c56d6fc6864a933c5e68d1ba874a54f14731a26aa",
        "modelscope/models/cv/indoor_layout_estimation/networks/modality/layout.py": "e378c76af308ec30ff515b14fa4037ac5e408e72b1ad38a19e4f73e7198adbc3",
        "modelscope/models/cv/language_guided_video_summarization/__init__.py": "e0bb2cc38b8a8d4fc0cfc22217b83a7e50552d4d5de3b47ee3e93b300dd5abaa",
        "modelscope/models/cv/language_guided_video_summarization/summarizer.py": "de2d7b4baa3cb4df36d7a6462162cc159bbd16c616a1b443ca60695a78ca6ceb",
        "modelscope/models/cv/language_guided_video_summarization/transformer/__init__.py": "edc74c67ba5ad20eed57bd47ff43a50ab78829b0e746b3dd8e4ec54a1e4d81fd",
        "modelscope/models/cv/language_guided_video_summarization/transformer/layers.py": "3c717658b4db199b2eb0f2974a068e9255899d1548b167e9bd1912d90f7f12c3",
        "modelscope/models/cv/language_guided_video_summarization/transformer/models.py": "7f77e852aade6825b61f10c3a3d6f696fb9fe5d3004b393a63608fcee2479442",
        "modelscope/models/cv/language_guided_video_summarization/transformer/modules.py": "40c508c5435add158ba6c292bd82b9d4eec8a4dde5d322f026ad4f3831f08549",
        "modelscope/models/cv/language_guided_video_summarization/transformer/sub_layers.py": "c2c61bbd47f2b224385a3750010e0b861c283a560c2c8f32d3ed61b7d62caa5a",
        "modelscope/models/cv/motion_generation/__init__.py": "d8a8206ac7e0ed07a7e350d05dff9da09ce8cc981ceb5d9d4872791c3ff61f49",
        "modelscope/models/cv/motion_generation/model.py": "269bc97f0302b45e32ac7e97a05e5e12be1bfebee9c50d3cc5ca4aa62ad8d5c4",
        "modelscope/models/cv/motion_generation/modules/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/motion_generation/modules/cfg_sampler.py": "96a6b959377b0800063574d1f156ed6d965837ddf467d0e5b0c4f90ad691245c",
        "modelscope/models/cv/motion_generation/modules/gaussian_diffusion.py": "9ba20caf07f06904211ef6a1f70fa2ab88996af2bef77746dc3fff3e315e5e56",
        "modelscope/models/cv/motion_generation/modules/mdm.py": "838fbda0f69042eb25126ba04b7189ea4c7ead3a03fd0c04a0ac93d2a7d7272c",
        "modelscope/models/cv/motion_generation/modules/respace.py": "31cbeb6caad2b8001696b9c556224cc4d0f5e23833f78b7ca95463c0b56fe903",
        "modelscope/models/cv/motion_generation/modules/rotation2xyz.py": "49970a9b8d97d755b61903e82c9efc89240ac2ebb951d3013d5fe64d821c5e0f",
        "modelscope/models/cv/motion_generation/modules/smpl.py": "8836c36c17d2fbc9a5349512b396b87a0406a279540c50dfbe80bdf6791cd32f",
        "modelscope/models/cv/movie_scene_segmentation/__init__.py": "71ce2e4b695f397eb6f91fafb0c210dd8e0b12a1d3dee813ac56e99570ab3844",
        "modelscope/models/cv/movie_scene_segmentation/get_model.py": "88d64e058bf2f2486b30d91110ecd65d5a20029289ff0d32fbcbdacf6a53e998",
        "modelscope/models/cv/movie_scene_segmentation/model.py": "e31d6320d4fd485c1c63163980b22b8c96cec848e44ad0fa0ec1f3cb58a96c9b",
        "modelscope/models/cv/movie_scene_segmentation/utils/__init__.py": "adac9fe89f37f3b4dca9aad132726e538e7ca9cc36de5c278e09fae5a52fe2c5",
        "modelscope/models/cv/movie_scene_segmentation/utils/head.py": "f73523cdf90720da0628a6edef9cca5f93ba146e8e39c687ff8aba79048e5ac9",
        "modelscope/models/cv/movie_scene_segmentation/utils/save_op.py": "fc8f58a3f6d8c86b804e2fb671dcf3f078e3ec5d4a748e519ee5b8325015143d",
        "modelscope/models/cv/movie_scene_segmentation/utils/shot_encoder.py": "b26db6b15e387f23bf2d2dff1f67bb45a08d86c490299ec90ea3c557164dc929",
        "modelscope/models/cv/movie_scene_segmentation/utils/trn.py": "d5595be5ab633681de592aeba6e20b1b6011ceae38f2f3b231814194d9f141c4",
        "modelscope/models/cv/nerf_recon_4k/__init__.py": "8adc976115b5ca668c3ea218c329f87dc62e16402246545a985d00f3203929df",
        "modelscope/models/cv/nerf_recon_4k/nerf_preprocess.py": "9947d6a39fcff4e3bedce17a158cbad68a2225d0a4a9fcdde9c25eb3da0e0681",
        "modelscope/models/cv/nerf_recon_4k/nerf_recon_4k.py": "14cfc632fb6c2c64ec24831ff57859ee1fbfbf43bf6b6e8de2daaac75bf3896a",
        "modelscope/models/cv/nerf_recon_4k/dataloader/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/nerf_recon_4k/dataloader/load_blender.py": "3cf7a3a8795e22d6ab6980e3bb6e6a421096368b96adb8c7552c0d6de0ec5c0f",
        "modelscope/models/cv/nerf_recon_4k/dataloader/load_data.py": "10b1781ba4e66501467c744589ab94e1987d0bfaa3f7fbb2a782f1e99aafc208",
        "modelscope/models/cv/nerf_recon_4k/dataloader/load_llff.py": "faa0610e95a87de034a153944bdb2a1bc7b0d39f4b8a7d096100aaeb8e643947",
        "modelscope/models/cv/nerf_recon_4k/dataloader/load_tankstemple.py": "7af5bb6e740d5074ca70d0eaaa02dce94845c89067c8d1043e953c29c6cffefa",
        "modelscope/models/cv/nerf_recon_4k/dataloader/read_write_model.py": "6076774a7b7fd8f756c01c14eaa508f02c5b7c015ad84eb77673ab77b8734fda",
        "modelscope/models/cv/nerf_recon_4k/network/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/nerf_recon_4k/network/dvgo.py": "38eb36a178f228fb0dd9de61fdf4ed8b136d98f6607ef41576b1c5c4a8b455af",
        "modelscope/models/cv/nerf_recon_4k/network/utils.py": "fb26a52e39d4100c87a3b3116f30de659ffb3b519a2bd45edec47c1b832ca9ab",
        "modelscope/models/cv/nerf_recon_acc/__init__.py": "97c1257e8f8d95443a22b6b140f49c45ed03f591eaafded3546989c876c7ecb1",
        "modelscope/models/cv/nerf_recon_acc/nerf_preprocess.py": "9947d6a39fcff4e3bedce17a158cbad68a2225d0a4a9fcdde9c25eb3da0e0681",
        "modelscope/models/cv/nerf_recon_acc/nerf_recon_acc.py": "1acba15170328ce4456957f00818d7fae79b5f3ad26434f9eaafead903d966b6",
        "modelscope/models/cv/nerf_recon_acc/dataloader/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/nerf_recon_acc/dataloader/nerf_dataset.py": "e3d0dd74a89a98406e836760936ccafffc7a4aa272a40fa167c90e9c6127b191",
        "modelscope/models/cv/nerf_recon_acc/dataloader/read_write_model.py": "6076774a7b7fd8f756c01c14eaa508f02c5b7c015ad84eb77673ab77b8734fda",
        "modelscope/models/cv/nerf_recon_acc/network/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/nerf_recon_acc/network/nerf.py": "e8bec2d49870fae9a0918df4c8f5a2e9a930d5402dc11be2acdca6a105daf4aa",
        "modelscope/models/cv/nerf_recon_acc/network/segmenter.py": "d7e59e8ad60dd73b6776abd0ff5294469c1794dc2cf66f6778fb6f7362a296a6",
        "modelscope/models/cv/nerf_recon_acc/network/utils.py": "fb26a52e39d4100c87a3b3116f30de659ffb3b519a2bd45edec47c1b832ca9ab",
        "modelscope/models/cv/nerf_recon_vq_compression/__init__.py": "6dab2c691a2b99c9c114e423c2bb4c3077e5c81159d86ca4b60ad1ee2282cc18",
        "modelscope/models/cv/nerf_recon_vq_compression/nerf_recon_vq_compression.py": "554c9276522c8307fb1b06f37ca473155533d76529c0769041fc289f6e0bc9a8",
        "modelscope/models/cv/nerf_recon_vq_compression/renderer.py": "943da0f37f86c5f41d4e54e913a3778e2daccd574ef8f878ba606d6dd2b8d62e",
        "modelscope/models/cv/nerf_recon_vq_compression/utils.py": "f972734c1ed43b4b5db12cbdf28d081f74f0eff6e7eee876ac886cc1262e04b8",
        "modelscope/models/cv/nerf_recon_vq_compression/dataloader/__init__.py": "7f453cb6725162200c819d6c8ffef2c64fe8cddd966453a8f0adfcd85c619950",
        "modelscope/models/cv/nerf_recon_vq_compression/dataloader/blender.py": "ef9fb91dc46ea9e02e21114939c48ae7c79da55cc0586fa0218eacaebab87113",
        "modelscope/models/cv/nerf_recon_vq_compression/dataloader/llff.py": "790e969de2f35a77b883f252cd33346a7049a5fa294a98d0a3fa8dd20f1038e6",
        "modelscope/models/cv/nerf_recon_vq_compression/dataloader/nsvf.py": "363c62dab700f929e2a99de036ee61e4784733b815c35f16acf9fc225de46335",
        "modelscope/models/cv/nerf_recon_vq_compression/dataloader/ray_utils.py": "836b9ce4f702ed235f2764e7dbad50d85f68282750963f4b602192e123f777e8",
        "modelscope/models/cv/nerf_recon_vq_compression/dataloader/tankstemple.py": "eab44e8b2f2f5e971a74d22346ef4313f70a9793f9d8d1d0cbda179b3074f12c",
        "modelscope/models/cv/nerf_recon_vq_compression/network/__init__.py": "dbac242d05e245771ba5143d7a9e4fe785d09b25bf07ad9ab3c42d28e10f607a",
        "modelscope/models/cv/nerf_recon_vq_compression/network/tensoRF.py": "2a90aafbed766cc2f552e99368c99b10d5881520628105a3587ada5e4732d1b8",
        "modelscope/models/cv/nerf_recon_vq_compression/network/tensoRF_VQ.py": "6082c7674c9635c6bf0b437bca9ddb4dffb2fa50918b29505b312aacf8d9843f",
        "modelscope/models/cv/nerf_recon_vq_compression/network/tensorBase.py": "884268e7f0b2bf833f702e46f8c53a7494361a3c7466a5bd5e9196ff76ab5a4a",
        "modelscope/models/cv/nerf_recon_vq_compression/network/weighted_vq.py": "05dd6e581c32b450c0343752c866ba000ca74c6b9a4938daf21ef9b0403f7b96",
        "modelscope/models/cv/object_detection/__init__.py": "970f6fe8312cc306ab383a5b67ac5c55019d98b09e35e1799ac6fd03968c4439",
        "modelscope/models/cv/object_detection/mmdet_model.py": "98393b4e5eb72dba4bf8da407797f50f30dd943a83001f6f90c7e66fb8954006",
        "modelscope/models/cv/object_detection/mmdet_ms/__init__.py": "b67599b54e29e9fb8959762ab3282c3e52cadd95a7b660636964954a78bf898b",
        "modelscope/models/cv/object_detection/mmdet_ms/backbones/__init__.py": "6f30ade3960118253903c795c5c7b9953fa972fd735214e0d28a641b32ff6029",
        "modelscope/models/cv/object_detection/mmdet_ms/backbones/vit.py": "917bf3d2bbbad3df0ff6235b8e660aeb7e2154eb8ba07e92077fcecc02f2a78b",
        "modelscope/models/cv/object_detection/mmdet_ms/dense_heads/__init__.py": "c13dbeb1e59b72c98c08f31ff2d18a7f2169d848db8d71917db5ce72726860c2",
        "modelscope/models/cv/object_detection/mmdet_ms/dense_heads/anchor_head.py": "025de64ef12630ac5a100a6e5828f22500e3d73ce2068af0ffbfe7a6ec39e32f",
        "modelscope/models/cv/object_detection/mmdet_ms/dense_heads/rpn_head.py": "613e5769cf5d8eb7d046594340242370fe75c4bbe342387808cb933d0e205f50",
        "modelscope/models/cv/object_detection/mmdet_ms/necks/__init__.py": "d387424ab5dc5271dc388471b039b1855199ebf490a633c190a5e49563251c68",
        "modelscope/models/cv/object_detection/mmdet_ms/necks/fpn.py": "c7b4319c10d5510a00d2186478244ea60f7126822e0be8e655ef1453c6aa6642",
        "modelscope/models/cv/object_detection/mmdet_ms/roi_heads/__init__.py": "46069859296d9e25b72754ad0d97763e1e91172c18539aa8419e4d151f8c8df1",
        "modelscope/models/cv/object_detection/mmdet_ms/roi_heads/bbox_heads/__init__.py": "0ac48063f1ede08ed8622d6094ebff9270da8319788645bf1ac96098bcc3c9e2",
        "modelscope/models/cv/object_detection/mmdet_ms/roi_heads/bbox_heads/convfc_bbox_head.py": "807fd260131a02fc323b76bf82b6a46679e120c2a84a4e830fad4a05f151a9c0",
        "modelscope/models/cv/object_detection/mmdet_ms/roi_heads/mask_heads/__init__.py": "329cb3a061c5ae6c4ad624789075a16b729af5140a1143a09aa35aa2eba5509a",
        "modelscope/models/cv/object_detection/mmdet_ms/roi_heads/mask_heads/fcn_mask_head.py": "bc3a91d2395e70a660e9e63f48d560861f909477188447563e928f6fd58a84e6",
        "modelscope/models/cv/object_detection/mmdet_ms/utils/__init__.py": "1535172a45e320bea0433797cae58f4021e0c7649841ee99873e7a126de54cf0",
        "modelscope/models/cv/object_detection/mmdet_ms/utils/checkpoint.py": "5a9b4ee795e6ed751d0be8530f618ced028384cbc23e1096155be9490cce3d66",
        "modelscope/models/cv/object_detection/mmdet_ms/utils/convModule_norm.py": "0ce339716aea1e8606fb8bf3466bc4698a056b08490436ccef1f4b146b27d6fc",
        "modelscope/models/cv/object_detection_3d/__init__.py": "c91c7c331edfff3ad6b524a64390417a2559480ef828409676bb3f4b9b10f848",
        "modelscope/models/cv/object_detection_3d/depe/__init__.py": "def8245d50695be54f5b839303f031f9cceafd6150a031500ae47fef39e2b2e1",
        "modelscope/models/cv/object_detection_3d/depe/depe_detect.py": "2fa7bb4c1b545e5b517cdf0ca7f69251b3dd46862440412a9fef845e657d300b",
        "modelscope/models/cv/object_detection_3d/depe/result_vis.py": "f4c940761e6f132664e97a9a9f5d89551fd2064c37474e46ad85c62ecdcc08cd",
        "modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/__init__.py": "797189f95470e052979ee66e24407c4613b88d796a155b753622ce31b8d8739f",
        "modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/util.py": "322a5a45f8c6a67e3b5649e93e6999badb23c01e424dd5bc42db93d843107ed5",
        "modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/assigners/__init__.py": "c0e3c18003185b4384591b6c68fb601ed1b7edf54cda606418be046e173510ef",
        "modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/assigners/hungarian_assigner_3d.py": "10b73960761785569a13de2f0eb9b6e29dd85e1af6d4fd4fc2e91a18595fc3cf",
        "modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/coders/__init__.py": "1dbb843b9766a3df2107aa6a61f5e55552fceab606bbbabcde2cf37127897266",
        "modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/coders/nms_free_coder.py": "18870bcc60ff4060affb193907fb586736fb4658a9ecef20dd0d6f5aba464d35",
        "modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/match_costs/__init__.py": "752f89f63abaa4c7bb020cf2b250a528dfbf187295dc421b901be24e14dd517f",
        "modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/match_costs/match_cost.py": "89c9a2f524b9a361a496ea20b3fc4eb00dc79a2ac21cd0ea6b03e364a8f902ed",
        "modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/__init__.py": "af1719a563589a55b486bd86da8b162dcde06420db591471378e29700792765b",
        "modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/nuscenes_dataset.py": "a66839c6af7d6e2163e7aa633deba1afe3a098a53ad419d5387b313a384bd891",
        "modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/__init__.py": "2d0c363201b13075b12e4aa6e398663bf77c70c5c54cdc3b2e586f38c7fca766",
        "modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/loading.py": "bd425df7a340a62b09aad07e195b192610fe344e82e05781b04e401a45368766",
        "modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/transform_3d.py": "db748fb36e84d791079d16cc8d65d75437685310571c59ace3737d83a8845fb5",
        "modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/backbones/__init__.py": "9d4258324ddafad0a0c8773fc09271d34af1de9fc08040ed7d7a49d4eda9b2d5",
        "modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/backbones/vovnet.py": "778d21a721f1bbeb1fe864301399ca9e1264ff147865ceeaddb0425ff7cfe166",
        "modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/__init__.py": "bb7412e4e347b0200d2a86d7b70a50bbd3ea16e9c5d2a99ec28f0ad76b0761a6",
        "modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/depth_net.py": "a41e7506c99844bf311f37c64dcde261c23439c23a25f65e431332d65d5b2d83",
        "modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/petrv2_dednhead.py": "81579d245288e9668f19af5e60474134904b0a3164518eed057a1bf4b1fab662",
        "modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/detectors/__init__.py": "10bb54ef3c92f4255d1030f5f174a8c2e7d532523627fcd8486cbaa6e078cf1e",
        "modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/detectors/petr3d.py": "69865acd3b3fb4e4647a989712da73f774921ac8ce768ae3f56b5829d4e4b56d",
        "modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/necks/__init__.py": "b26ad72e2d8fd9b36586fe0318654f50d8935288619440365775e8e3ef97c1c8",
        "modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/necks/cp_fpn.py": "3d51c7d583e59c412e152628ff382750b0c7a20689e5d6081cc6789f6b1c2391",
        "modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/__init__.py": "9e12c83dbb7f9fbe0ccda3d01c516e75af3d52af27119d61d3f5ba0d38fc93b7",
        "modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/petr_transformer.py": "c489d033543ff72979a47726bd725bb5c78982588c7e56b31611ca22fc686616",
        "modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/positional_encoding.py": "aad780e995f0a528b8edfc1718a9cbc397a25618d1d00ae7ba618a5f1e17f408",
        "modelscope/models/cv/ocr_detection/__init__.py": "b8bac8b057644f3b19bd6259d43c34994f665d7ef6d8f90943979cfab5967e47",
        "modelscope/models/cv/ocr_detection/model.py": "6ff27438c7b872008443c39bcfbc45aadd101e54c27d78b9ccf52303ede5feea",
        "modelscope/models/cv/ocr_detection/preprocessor.py": "630eb7ae40b6825af971a71c38ea592de3e34e2bc11d28447dac77bccbe04238",
        "modelscope/models/cv/ocr_detection/utils.py": "64c3a47ada0fc4fa7fe35db81f7fe66de14552630fbd58d6c783c4eaad974557",
        "modelscope/models/cv/ocr_detection/modules/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/ocr_detection/modules/dbnet.py": "f486e95af5c9d1d9901b55c58e17ef6e07fcd2c44e424f343d99d7b04a824511",
        "modelscope/models/cv/ocr_detection/modules/layers.py": "b0fd30940d914a0b11ad9f12a779b44bfd601992cb2166226269650ccca3f731",
        "modelscope/models/cv/ocr_detection/modules/mix_ops.py": "563ac3a73fc16d1ff31df44e2f2b4b747b02daf0775e5019ef3243e21b714dd4",
        "modelscope/models/cv/ocr_detection/modules/proxyless.py": "cb793eef0739238dc4bbfa2f19c2aeaad680b6d1954f0b3ef2ddbd3961d29e4d",
        "modelscope/models/cv/ocr_detection/modules/seg_detector_loss.py": "a5b6d0ecb0960d0c4d1b04463e61f5fe4b8256cd8ff9fe29463f09fadc7a5aea",
        "modelscope/models/cv/ocr_recognition/__init__.py": "c6df75f40850a6f223467f9c3310c040e2ab3fae9745a05630ff665fb414344d",
        "modelscope/models/cv/ocr_recognition/model.py": "3ea1ad9b2d080533564390cf41bd4acec7fe41a8b4cc51f1fd661f82687b7890",
        "modelscope/models/cv/ocr_recognition/preprocessor.py": "9b4cf5a9e5d53bd674dd7d17c64cdb17c770ea4d88afa77c0b23da120dae2e5d",
        "modelscope/models/cv/ocr_recognition/modules/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/ocr_recognition/modules/CRNN/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/ocr_recognition/modules/CRNN/main_model.py": "88b59d7f1f0779bb9400e3b1304807223d55da52a7182d379eddd910d271f608",
        "modelscope/models/cv/ocr_recognition/modules/ConvNextViT/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/ocr_recognition/modules/ConvNextViT/convnext.py": "72efe83f3139ec93a22ef41b7502efa3e5ce1cdfbd76b7686bac1d0ef702f642",
        "modelscope/models/cv/ocr_recognition/modules/ConvNextViT/main_model.py": "a790e06bb3484b71f2268b2fe46ecbbfc1920bcfab012ecf06b0fcf997b1464f",
        "modelscope/models/cv/ocr_recognition/modules/ConvNextViT/timm_tinyc.py": "b244726bd34ff1b2495de30600cf6f3f449705d638b9a766672377a4926da927",
        "modelscope/models/cv/ocr_recognition/modules/ConvNextViT/vitstr.py": "a8701be0644598afd74d1fd36710c5a614ce31cbd90aa816e4320016a1281ce6",
        "modelscope/models/cv/ocr_recognition/modules/LightweightEdge/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/ocr_recognition/modules/LightweightEdge/main_model.py": "b063be3a69ca1f28101143a32dded7b9c0d381c1764cba4775f4ae2a829d9a43",
        "modelscope/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/__init__.py": "a0902a25b8607a1e16a6c6207bb302d2026beae175d72fbffb858a487945d5e7",
        "modelscope/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/layers.py": "e5ba17fdb830db45f6ebde4a1a126835169dbb4bb6ee5da433b352a81f1f43f4",
        "modelscope/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/mix_ops.py": "435535417fdd6f0bd1c1a1d1f47bc7106416da032cdde9bf143b5408879d1add",
        "modelscope/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/proxyless.py": "6d4e84859f855fbd889e03099eefcf04e5b04e98e8c0eb8ee7eee34351ce094b",
        "modelscope/models/cv/open_vocabulary_detection_vild/__init__.py": "cd70aafa5389efd64b3f0d1165c8e4b1a793c3773f52204f0a3dce0b452a98a0",
        "modelscope/models/cv/open_vocabulary_detection_vild/vild.py": "41406c3809cd97e057759141bde80e7e188bec307702797f0237c3c0aa3947ba",
        "modelscope/models/cv/panorama_depth_estimation/__init__.py": "766ae61093d12964fd20975a94d1194bca89cc0d58415e2d49c167c369381d77",
        "modelscope/models/cv/panorama_depth_estimation/unifuse_model.py": "21fdd66207a7eca1c73332a83b460d4d71d2a6fac686c7f5cb7b450f30f7eaa8",
        "modelscope/models/cv/panorama_depth_estimation/networks/__init__.py": "b9875d935d60fc8475362aae5be67af0d1e18420f7314b7375dbf34bc6325bc0",
        "modelscope/models/cv/panorama_depth_estimation/networks/equi.py": "50d5c24ee533786983457ddc56b685b485a032d53cfb1b3992081b77d4d04911",
        "modelscope/models/cv/panorama_depth_estimation/networks/layers.py": "cb0cfe23bd633371e9d2443e04ac2f76336be965a4891658b8375ac4cb887544",
        "modelscope/models/cv/panorama_depth_estimation/networks/mobilenet.py": "81d73faaf0a1d3b7aa52c61862e2e450dc21039d41e93b67a870bf8328e7edad",
        "modelscope/models/cv/panorama_depth_estimation/networks/resnet.py": "167cd469e1cd8a9f396896d58576c372128863920c8e04372af9886a52cdb8ce",
        "modelscope/models/cv/panorama_depth_estimation/networks/unifuse.py": "5c55cc81900da6d24fad57c6b6473b1c63fcb5457eb5d8a8287ec35ed9d818b7",
        "modelscope/models/cv/panorama_depth_estimation/networks/util.py": "6890aaa92416580cefeeb5dcf06f86ca882e5a4a199dc3ab5fffdc8c1fdd4cc6",
        "modelscope/models/cv/pedestrian_attribute_recognition/__init__.py": "6490f7b7c8aa091947c33ebd05c0182cb2530c1beb8fee00c6a79c9f0defa62c",
        "modelscope/models/cv/pedestrian_attribute_recognition/model.py": "a855a65d06fed7c57c3f7f4c5885e2543d3f831ac9f1f1dcbff06c1d12c7e846",
        "modelscope/models/cv/pointcloud_sceneflow_estimation/__init__.py": "81698d5983a76c974c2c042bd77ad8d71032780f0c7a8f69ee1e4eddbd8e2883",
        "modelscope/models/cv/pointcloud_sceneflow_estimation/common.py": "1576fc2962c096d36f424fca559481b39d39aca041c20251493c11755dd608d0",
        "modelscope/models/cv/pointcloud_sceneflow_estimation/pointnet2_utils.py": "f7b58034f9daea6e939f25c6a293e70f1c7184290d925dde531a7af56f84ca69",
        "modelscope/models/cv/pointcloud_sceneflow_estimation/rcp_model.py": "0a28be2728f71b148a0a3e6c7034ac4d921ee283085cad8709cef5f14b639240",
        "modelscope/models/cv/pointcloud_sceneflow_estimation/sf_rcp.py": "63f5d1b853ce154c8e25cec05d9f8c1418eb2a63abcc583781fbcebf07cafe20",
        "modelscope/models/cv/product_retrieval_embedding/__init__.py": "1a93fd680c7cd21183b8d29e648e22743b9ea700163df98f620841c02df7be18",
        "modelscope/models/cv/product_retrieval_embedding/item_detection.py": "98058ee6a1993138d7b18f3360fa35ba135391e7149f64fd82f8d8a1bca3419e",
        "modelscope/models/cv/product_retrieval_embedding/item_embedding.py": "95b8d5ec4121d87b5a057f0a5f88235c850dfc759ad2b0ba2600a265fd604b57",
        "modelscope/models/cv/product_retrieval_embedding/item_model.py": "7caf80d183ed7c0094c236c842a78c8b6ff741d1a5c185119255a8a28c61cd28",
        "modelscope/models/cv/product_segmentation/__init__.py": "15f06f9ce33532d21a1170af4f29f4b598578de7a5205b55f69be55853b1b3ce",
        "modelscope/models/cv/product_segmentation/net.py": "f1188b118bbb4adefb0c359c7f47e78f9d42465730e04a9617ec72048bd1bdc1",
        "modelscope/models/cv/product_segmentation/seg_infer.py": "669d09d7f2c1f484192b265e450683728d744687e8eb1349af7694a081774645",
        "modelscope/models/cv/referring_video_object_segmentation/__init__.py": "fc7eb282f008ee9759bb84fc4fde3a7d37f6347411f2a847f9949ac1680e4e7c",
        "modelscope/models/cv/referring_video_object_segmentation/model.py": "7e48f99b81cfc8fd42f60075d93a93495aea172488cfaca84945f31e6b0dba7f",
        "modelscope/models/cv/referring_video_object_segmentation/utils/__init__.py": "d61aa76e0d77aa4c56703403d411e9192ec9fa876f66ec5163ccb6b34ef6968f",
        "modelscope/models/cv/referring_video_object_segmentation/utils/backbone.py": "71cbb3ba733130ee3e2a45c735ad83fd248d7d18d85ddb67c1cd4be9251f2bd0",
        "modelscope/models/cv/referring_video_object_segmentation/utils/criterion.py": "d452b78be19c8a4d8be87dd227e2a34463951f61d96ae8143aff2c15cd70965a",
        "modelscope/models/cv/referring_video_object_segmentation/utils/matcher.py": "cf712b435a7f82b82a1af463c7d3218d095eefebed774b3a6509efcd1cd7e803",
        "modelscope/models/cv/referring_video_object_segmentation/utils/misc.py": "1098cfa743cda45137dae7f7fa60d5eaa3ff35865b01b195a603c4c8bc27d6d9",
        "modelscope/models/cv/referring_video_object_segmentation/utils/mttr.py": "3abcef733499d9732238e7f510f0e84dd0b1733c95da462d90976d1cae0cda2f",
        "modelscope/models/cv/referring_video_object_segmentation/utils/multimodal_transformer.py": "14d49cc3db113865c5d230d416198e8f64b40b478712547cd8696f4bd49480aa",
        "modelscope/models/cv/referring_video_object_segmentation/utils/position_encoding_2d.py": "da8fd4ae38590b881cf6b54795424141020e776e3fea23b349a5b601ee77b65c",
        "modelscope/models/cv/referring_video_object_segmentation/utils/postprocessing.py": "04092d59e2af8dee22666ee5cb27ed65687c45cba9324a5a4dc55423f5f2951e",
        "modelscope/models/cv/referring_video_object_segmentation/utils/segmentation.py": "2877113831b6833864a226f7a703383c91b3b72fa841bb0d4d56fca4ea9bd93b",
        "modelscope/models/cv/referring_video_object_segmentation/utils/swin_transformer.py": "82da171dcdafc5ea74c32ad4b2afbe25b1721af90ceff51ed11dbb8e98eb2b43",
        "modelscope/models/cv/robust_image_classification/__init__.py": "ada8a931e8cd9ef277d3dcb5f004ae86d18214b0dac27c5a1e58045f7f1a7dfc",
        "modelscope/models/cv/robust_image_classification/easyrobust_model.py": "d57128644a88d3f7c0a452c3d36e717b0c3083855aaa7315f2692b83fe0d9b23",
        "modelscope/models/cv/s2net_panorama_depth_estimation/__init__.py": "8212ddff9f0d15f015bff05331a6199491444ae19dc7dcbf550dda90c8479f32",
        "modelscope/models/cv/s2net_panorama_depth_estimation/s2net_model.py": "50a8626d9e40b60cc75263929030d433a78a8d3bcf8c7f3ed7cf880ba53578d5",
        "modelscope/models/cv/s2net_panorama_depth_estimation/networks/__init__.py": "296a152a94f1febf9d2f21e09c8caf78473b71ba6d32e40d61efad8e1526e522",
        "modelscope/models/cv/s2net_panorama_depth_estimation/networks/config.py": "bf43765b055b21a8b6d775816db10a02e392d6a723aca79e29607f37b61b0e87",
        "modelscope/models/cv/s2net_panorama_depth_estimation/networks/decoder.py": "8997fb813a5eace2edf1beae9ce028d67367ecd0c41c4dab5272eae829dc4ebd",
        "modelscope/models/cv/s2net_panorama_depth_estimation/networks/model.py": "034636252598e4a553b53be749a2136e7390b7455825420b51ab63e64d3315ca",
        "modelscope/models/cv/s2net_panorama_depth_estimation/networks/resnet.py": "ac0db99ca1c55b47f9d2431166d266bebafaa1b399c56ce3bdc0d7b27057c5be",
        "modelscope/models/cv/s2net_panorama_depth_estimation/networks/swin_transformer.py": "0e86b4be09c94df780a37ce5f752c3e8fa1fb4ab02ab3e360108b363d9646a05",
        "modelscope/models/cv/s2net_panorama_depth_estimation/networks/util_helper.py": "feb1b503098eff0e993e576379395fe623540dd581179efbb4d35c47ecdf4e8a",
        "modelscope/models/cv/salient_detection/__init__.py": "0316274c2f113ad8e61cd2c4e0e859332898c5406c2449262da84a1f3c1ddce5",
        "modelscope/models/cv/salient_detection/salient_model.py": "eff48980fb267beb2ce1b01c5542b1a747e1d6066f6015244702a7ef7c48c835",
        "modelscope/models/cv/salient_detection/models/__init__.py": "adad6b0cc535dab64c57d2d4c9d4eb679f0026e64b9c68799d30b8d35c08bd8b",
        "modelscope/models/cv/salient_detection/models/modules.py": "ab8046ea5b215195498ed34ad713e6982f08313de80b0ec6f6910b9bd386e1a0",
        "modelscope/models/cv/salient_detection/models/senet.py": "956a96f6b337675ba3bb4e06a71023d9d8e081d3748a750961d1af9e34c6a1ae",
        "modelscope/models/cv/salient_detection/models/u2net.py": "0ba71c5b1fe7ee84b929c8460683d7d0876d93b77c3b3692df6dfd391e41f070",
        "modelscope/models/cv/salient_detection/models/utils.py": "4019fd1cdafe1660cb10328cf4f2bd22bddbb7e9c8b74425606693cf331d2dc9",
        "modelscope/models/cv/salient_detection/models/backbone/Res2Net_v1b.py": "9316798a1b26cc2c8642232ce16154915178ad6046f8a94a2f6ee32a5b6cf3bb",
        "modelscope/models/cv/salient_detection/models/backbone/__init__.py": "1b0d64d700738a1c7002a3a32f16d7671a493a563701556177cc69d1a6b04789",
        "modelscope/models/cv/self_supervised_depth_completion/__init__.py": "3a22cdb028dc4b851663c1c83e1a20f88adca7054cdee0ea2973d98e1cc53521",
        "modelscope/models/cv/self_supervised_depth_completion/criteria.py": "e714a1f2c582642110972d9d757a6a1898775e0eb72843e4591fe85d8cdfedf2",
        "modelscope/models/cv/self_supervised_depth_completion/helper.py": "5dd310f3c3bd6913ed22cab7d8d75551a1ef0ae0ec23e7e378f71a17f812c571",
        "modelscope/models/cv/self_supervised_depth_completion/inverse_warp.py": "25949e6e8b81d491f747fd6766d304731f1912b26e525ec192cf4719dcf2a2a6",
        "modelscope/models/cv/self_supervised_depth_completion/metrics.py": "38b8207288ae8bf5c8a85364b087ead72510859a73b71305ba26ad278bb567d8",
        "modelscope/models/cv/self_supervised_depth_completion/model.py": "f2ccf790f9536cbd519ed415ed55eca863d3334991d146a165fa4b6c087f21e7",
        "modelscope/models/cv/self_supervised_depth_completion/self_supervised_depth_completion.py": "12b1f3bae650da55af9e248b97262a4240077e1ae0f1862fc7255da89caa024e",
        "modelscope/models/cv/self_supervised_depth_completion/vis_utils.py": "8a5e0f1e8d1e91cfe1cd70cc1abaecd036af88a446efd57124b5cd3df8fd264b",
        "modelscope/models/cv/self_supervised_depth_completion/dataloaders/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/self_supervised_depth_completion/dataloaders/kitti_loader.py": "f26f0800e8e3b80e0e724d9339858489ac077e543b1426e9a3540a01148817ae",
        "modelscope/models/cv/self_supervised_depth_completion/dataloaders/pose_estimator.py": "a4f611fd252faeade07ffdd58ece03dd2c50eb401b4d0b9de5fd7e49f7249575",
        "modelscope/models/cv/self_supervised_depth_completion/dataloaders/transforms.py": "8964eab312315452ee12df92ddf1b699e66ee05e7c8aec603dd22e5cdf9c05a5",
        "modelscope/models/cv/shop_segmentation/__init__.py": "a583bf2c218e70dd6c968ec3dbd7e635b712881e5e0cab532b5be95ea21719e5",
        "modelscope/models/cv/shop_segmentation/common.py": "4a4fb47edead95ed8b365a3779f0951c926c8e2cb62773d7ebb4805c06aa8f66",
        "modelscope/models/cv/shop_segmentation/head_fpn.py": "381eb867fdef0a56d6f916936b8a79f36752ab5314dc535c774c33787b3469d3",
        "modelscope/models/cv/shop_segmentation/models.py": "32338a2da112185064d20952aa73de5b88fa4013965a9f19b579029cad3d5f77",
        "modelscope/models/cv/shop_segmentation/neck_fpn.py": "705d172f8d0eca76b2828bcbbe7cd7d9c14adfe2259a3df0e3954a67a9b5f900",
        "modelscope/models/cv/shop_segmentation/shop_seg_base.py": "c7992a2644717d60d0b8f7ee4b6dd6fa84b739311ab4f76231ef0a38ba5eb946",
        "modelscope/models/cv/shop_segmentation/shop_seg_model.py": "35d1db5276f43f441206b2e475089ced947afd6bcedf1945c3d2f4b709fadd35",
        "modelscope/models/cv/shop_segmentation/utils.py": "1351e60340db0ae71bcc1dc9cda4016ad5b191d68800bc7ac7474c606add6121",
        "modelscope/models/cv/skin_retouching/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/skin_retouching/unet_deploy.py": "5fa3b9a4ba599908025057d64fe3b44ad71f6bb8614c8d13618a4cd5bbe7936b",
        "modelscope/models/cv/skin_retouching/utils.py": "f075ac6d4997370d80b10d946c0aebcecbc094bdbd75072236b3d8b905403d88",
        "modelscope/models/cv/skin_retouching/weights_init.py": "5feb5da62e7a97cca5e60488c96d76c48074ca7521526dca0a91498880381e5b",
        "modelscope/models/cv/skin_retouching/detection_model/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/skin_retouching/detection_model/detection_module.py": "23fce16544465ef41232ce652fecc95a71db3bb81af575d4aefc472a4e45a2ec",
        "modelscope/models/cv/skin_retouching/detection_model/detection_unet_in.py": "e3b02ff03941aabc967c0fa66c39a00a56e84fbbe98f15c52de6bdf5555a9168",
        "modelscope/models/cv/skin_retouching/inpainting_model/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/skin_retouching/inpainting_model/gconv.py": "fca8ece60d31dabf3d6eda186657efd72328f94aafe7b11fe130259ee873bd20",
        "modelscope/models/cv/skin_retouching/inpainting_model/inpainting_unet.py": "bc151c88dabac96ef2a17f31c6dc979688d65c4f0f0f8dde73e1c2e845f462dd",
        "modelscope/models/cv/skin_retouching/retinaface/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/skin_retouching/retinaface/box_utils.py": "9f60020bd083861787deea87f433a13b3ed977da0e2932ca141808ce3f646937",
        "modelscope/models/cv/skin_retouching/retinaface/net.py": "a7ad6d4ea45e0aa7439ca6328b3704ce6be5a37ff9a3a7495141fbc77c1a6edc",
        "modelscope/models/cv/skin_retouching/retinaface/network.py": "46b15581b5a830153e551df7e8977af8da7bd0b2c58e4211d48dea68703ddfea",
        "modelscope/models/cv/skin_retouching/retinaface/predict_single.py": "73b9a818c338cdd2f3448bb42627abfa9e0d12b196d1d866bfc876d0593677e7",
        "modelscope/models/cv/skin_retouching/retinaface/prior_box.py": "e7e98193c0dac49e274f24330770b2ec00ce72f862e974037977e80fe7f41bcb",
        "modelscope/models/cv/skin_retouching/retinaface/utils.py": "2cad763eec71355996209642da07f4f8468c6b80a0d232b723c712242d8de4d9",
        "modelscope/models/cv/stream_yolo/__init__.py": "ca7037ba441020fc0e9696902eb40775d7e864a11759c020303fc20ede72cbf1",
        "modelscope/models/cv/stream_yolo/realtime_video_detector.py": "d0fe643834a5845f30faae204cc48225dc9ed0d492c603515f761834b9b9c43d",
        "modelscope/models/cv/stream_yolo/data/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/stream_yolo/data/data_augment.py": "e9d1cff8f376809e262ad4d41a66960803fd566e1092ad1c815c93569385cce2",
        "modelscope/models/cv/stream_yolo/exp/__init__.py": "02c13e29786e45825300f28b56e004423361668683502a3816451a1b5320f536",
        "modelscope/models/cv/stream_yolo/exp/base_exp.py": "93dfcef2a09d83ef442ab04d731c60906b6abb6239dab985445a0ecc3dbc92f5",
        "modelscope/models/cv/stream_yolo/exp/build.py": "1942eecb2860fe39c1076edf8e591d780da854df3d5ca07f96c2a19f10d89f28",
        "modelscope/models/cv/stream_yolo/exp/yolox_base.py": "2a89b59c28476e2b76f3db8550c04b088b9e0e6df6784b29c973445d535401a0",
        "modelscope/models/cv/stream_yolo/exp/default/__init__.py": "777f3ab866a9faf9b8ab37f7306d1dfe9e5475ce673cb41ceeed4b495ceda5b5",
        "modelscope/models/cv/stream_yolo/exp/default/streamyolo.py": "8c85a9d99243c8f62794452b9ed6c0a9668b2c3d0c288737bd1392e48675da12",
        "modelscope/models/cv/stream_yolo/models/__init__.py": "e55d5e7de4c433a603481935cb3d1bae46d88b8983f230b726381040778fb28a",
        "modelscope/models/cv/stream_yolo/models/darknet.py": "a5750150d522379982986015e8f82bf8d4b5f159b800f6c4d2974f6539bc8aea",
        "modelscope/models/cv/stream_yolo/models/dfp_pafpn.py": "4696698b1747df6e46d3deb04ead6da633b4c3d76bd9bc5308d332f96b0815f6",
        "modelscope/models/cv/stream_yolo/models/network_blocks.py": "83d55793e2e1773af718b802f04f7982c9dc8ab44ecdff1ff46e0d1d52ee6ef4",
        "modelscope/models/cv/stream_yolo/models/streamyolo.py": "694e27d36d8855a18c4998674dcb88801db6039fce0e652ff16ad03782a8d713",
        "modelscope/models/cv/stream_yolo/models/tal_head.py": "d12cd36282569b8b6f8b424a93c5b2b847eff2c7106b8eb0230d1b9abb92b720",
        "modelscope/models/cv/stream_yolo/utils/__init__.py": "4a3c52c7b6f664e0bb7073d80759c94cb7871a80064a57ac040b0e5bb9bdb01b",
        "modelscope/models/cv/stream_yolo/utils/boxes.py": "6b97cfe014316e6b17e692ad979e3dbf8086def375beecf480a27d005c58d056",
        "modelscope/models/cv/stream_yolo/utils/format.py": "952de87bf594c2138f4ea6d1bed31cafea45572f4da07dc08e2a5906f1fd0d95",
        "modelscope/models/cv/super_resolution/__init__.py": "a1443c2dec87e62f742dda2170fdee8de379d441644a630b083400261bde9c7a",
        "modelscope/models/cv/super_resolution/arch_util.py": "5571950d6199356d726472f04318727986fc6004661f4c7e0deec13c0f8c8af6",
        "modelscope/models/cv/super_resolution/ecb.py": "67e3f2a67c7ff07a2ad9b8061d057fa4ee9085aafa9f76a9859f0e1668740705",
        "modelscope/models/cv/super_resolution/ecbsr_model.py": "f57ca3578b8bb1ad4d98535b099604b1fd4efd9f59375a5aba492bb2f4f29634",
        "modelscope/models/cv/super_resolution/rrdbnet_arch.py": "51fc3f8bd8b8e614351f4f8c0867265105582cdd2f55813343ac9a916fc3c4aa",
        "modelscope/models/cv/surface_recon_common/__init__.py": "6d840af5662f22b76ba82876b545478ee89fffa7fd13a4039583d7456f7130f8",
        "modelscope/models/cv/surface_recon_common/dataset.py": "54cae0c1d7524b10dbfcba21661f0967b603a778b82824d59a88e5838072ac9c",
        "modelscope/models/cv/surface_recon_common/fields.py": "c7834d4600d30b8f2c669beda26c458250690d1ab51ced9750e494e0f8f7b014",
        "modelscope/models/cv/surface_recon_common/renderer.py": "909937d1ee739effe67980d7b55371d965d92fc4643411bec01d3a6d9ba86670",
        "modelscope/models/cv/surface_recon_common/surface_recon_common.py": "93ba9f708cadd1adc174a304099990561827a6eba70e9f9f3b6ef027a52f8d0f",
        "modelscope/models/cv/surface_recon_common/utils.py": "789373780da6980cd12636df096a31bcacb72cce356eebf43ddd94286e83f685",
        "modelscope/models/cv/table_recognition/__init__.py": "35103ea79207eaf04979a7190c82fc02865569269cabc8b8ca6d086383386e3b",
        "modelscope/models/cv/table_recognition/lineless_table_process.py": "4b08cb5b96b3e4402f58af8484a0e24adfa01aeb7865f4f080d18c844cb85e61",
        "modelscope/models/cv/table_recognition/model_lore.py": "c15bbc6c5fef5db5582e4ab49f87310257b792341f58478e92bd1832d2ca978f",
        "modelscope/models/cv/table_recognition/modules/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/table_recognition/modules/lore_detector.py": "e54b56069390d3c6d174775ece533e1e0f245c9c0f49154a4b7db5fe2ddc117d",
        "modelscope/models/cv/table_recognition/modules/lore_processor.py": "14d8c2be0335760a445b35e91e39a2e4622c524037caaffe982c8a93fe9539c2",
        "modelscope/models/cv/text_driven_segmentation/__init__.py": "33c8ca4bfd0a070438ed31be39e68e43e910fe4cc3439d5adb4a7aea41a35b8c",
        "modelscope/models/cv/text_driven_segmentation/clip.py": "5531a100aa41ca3b8d3cf2c0014031b6c0c160fa21b100261cb856d164663585",
        "modelscope/models/cv/text_driven_segmentation/lseg_base.py": "a62a8811e5901d00e0606d290a05d54a960b8139793a72ee458f78badf791939",
        "modelscope/models/cv/text_driven_segmentation/lseg_blocks.py": "62bd0dfbe55d35e5c7f8d378b670554950d4a5b6865d6da853d9865a77755dd8",
        "modelscope/models/cv/text_driven_segmentation/lseg_model.py": "f90594710279d243316940d4246ac986b40ff7ae8545670f3f1cfdfdfd3da621",
        "modelscope/models/cv/text_driven_segmentation/lseg_net.py": "c8cd270c664d9f33ff0cebf8356042a18c4e4f66d047efe207cf7dd0d769cad5",
        "modelscope/models/cv/text_driven_segmentation/lseg_vit.py": "6e1269ef6ad83b3050e76b3773a6f9c115f17675e5da5aad05d4364f3009e55a",
        "modelscope/models/cv/text_driven_segmentation/model.py": "b60a21c3cab1c989d90f2431c84352a2f1d155ac311c0b63390f4d2007875dc3",
        "modelscope/models/cv/text_driven_segmentation/simple_tokenizer.py": "a2a8f28cd1f0a3bcca1b93311a544e6fcc48a634a02eed59c5fc6dfc4bb70555",
        "modelscope/models/cv/text_texture_generation/Tex2Texture.py": "e4d60e9bbf3c258a95e1713565760d27c4c4791967ffc30f662a4eb2c75a6d9c",
        "modelscope/models/cv/text_texture_generation/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/text_texture_generation/utils.py": "0045885835bc3e113857eb7e7f7ba18e3950732fae8360fa08f9e5edc7bff1ab",
        "modelscope/models/cv/text_texture_generation/lib2/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/text_texture_generation/lib2/camera.py": "5513f31ebf9cbecb7576d58102958c7cb25ec45d26400bcf563a048bb36bb840",
        "modelscope/models/cv/text_texture_generation/lib2/init_view.py": "16f3bf94e8effb3a43e9b394991101be9d50d66e690a45d2780d2bf0e157dcff",
        "modelscope/models/cv/text_texture_generation/lib2/projection.py": "fc45b357eb3832f7a416742d32757c16372c68ccca8a9051e78fbe5d363ec63c",
        "modelscope/models/cv/text_texture_generation/lib2/viusel.py": "416d516ee5a1d189403dffd3c5aa3f72e7e943214c11494e8b21c749993e9f30",
        "modelscope/models/cv/text_to_360panorama_image/__init__.py": "904731f5b4a7859f4dc2db57268c09a935086b87aa213a8d973e9aa62dca11b2",
        "modelscope/models/cv/text_to_360panorama_image/pipeline_base.py": "c18519cce26e76494c002563cdc0ab3828a9a6d74f96bb3fe02fb77315b683be",
        "modelscope/models/cv/text_to_360panorama_image/pipeline_sr.py": "d78187fb2611e430d51012fd3a9bff7a9bedf6548b9aaf5e4670277175a79e14",
        "modelscope/models/cv/text_to_head/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/text_to_head/text_to_head_model.py": "650c12496683d73e1307abd9f84694f10c82f2dada645fd93a98569fb28c9051",
        "modelscope/models/cv/tinynas_classfication/__init__.py": "e85e75a8c2f4defdb5df3cb430c671937b867630fca5e6a471b28a7f6965a3a2",
        "modelscope/models/cv/tinynas_classfication/basic_blocks.py": "7d144fa19458f76538b9da3237db5c57d13d72ec8307c7649aeaa3103cec60cd",
        "modelscope/models/cv/tinynas_classfication/global_utils.py": "de4f6ba29578ddd599eb4187724b940649c28e8354172184b2b1df3805a7c958",
        "modelscope/models/cv/tinynas_classfication/master_net.py": "c6e9e984024c0b65331794e4eaa310a8a44ea6cb99e0c2358cc9bf340bda1f75",
        "modelscope/models/cv/tinynas_classfication/model_zoo.py": "0b9421a56d7fa1d1b6d8200cbbb81e2d5667048578901bbbd2886df6b561ceef",
        "modelscope/models/cv/tinynas_classfication/plain_net_utils.py": "19d5487d70dfe4850b0750c96fbf2eaa238fa60ad3326b4444dff596422acc1d",
        "modelscope/models/cv/tinynas_classfication/super_blocks.py": "163d546820bf9c01cde99b6cac86253ed40398da1f40e3cdeb8baddcb65b8a93",
        "modelscope/models/cv/tinynas_classfication/super_res_idwexkx.py": "d351f2d5daadb33780990b64717877ed058a493a5df2e4f77632351e002a4703",
        "modelscope/models/cv/tinynas_classfication/super_res_k1kxk1.py": "8784abd98c4630f9856477b509d35668f89ad11e9c9a1ea9d0c800852303aa07",
        "modelscope/models/cv/tinynas_classfication/super_res_kxkx.py": "7350899a24a0c0c1f816ac03818c390325b5e232071b94023a7bf534824ff1d7",
        "modelscope/models/cv/tinynas_detection/__init__.py": "7952b0dfb97fd0d7fd51ad7ea9a541437b19c0000e46061f8b3df69a1ca41599",
        "modelscope/models/cv/tinynas_detection/detector.py": "1a83cd8005dc14e6d7ccdbde63e85f866fc6dded3b928c7198c275e95262f280",
        "modelscope/models/cv/tinynas_detection/tinynas_damoyolo.py": "500a28ec6ce82ece76c09d1b42f7d8e8fd0ac2b8c787896e5d5ed1799a8f0bdd",
        "modelscope/models/cv/tinynas_detection/tinynas_detector.py": "2831307112b7ecdb0bdcd34d6e0390534f377cb5d86312181583a62330eda154",
        "modelscope/models/cv/tinynas_detection/utils.py": "4c6119701a565395d0468457e167fd02bd621d5320bbec57e77d256d5951f2e6",
        "modelscope/models/cv/tinynas_detection/damo/__init__.py": "23f00d77175c207a64233217735c8a3a55b0cdbe286341704cfab5918b60cd0c",
        "modelscope/models/cv/tinynas_detection/damo/apis/__init__.py": "23f00d77175c207a64233217735c8a3a55b0cdbe286341704cfab5918b60cd0c",
        "modelscope/models/cv/tinynas_detection/damo/apis/detector_evaluater.py": "a4c620620e6267f6391048f39e36e80507807302e7f5e00f1db9fbfe7f6c5459",
        "modelscope/models/cv/tinynas_detection/damo/apis/detector_inference.py": "948661900d04c27c96a92e19650b44958ddbd5729894c5220011833cf5a7efc0",
        "modelscope/models/cv/tinynas_detection/damo/augmentations/__init__.py": "6001bdc7bb7983cb6080e69dbf906102a752c8e0383eb2336087eca4c02a5653",
        "modelscope/models/cv/tinynas_detection/damo/augmentations/scale_aware_aug.py": "033a765bbed533214b1ce00ec569e3203a7f564875061f45a0eacab26ac08fc6",
        "modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/__init__.py": "6001bdc7bb7983cb6080e69dbf906102a752c8e0383eb2336087eca4c02a5653",
        "modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/box_level_augs.py": "87a349ce5d340acef62e3cdd69b5fb6e483570f8eca16a4a990d2cea6e4b511b",
        "modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/color_augs.py": "15ddfd623237703d24371829ecccda6487f4cb80073edb625890578ccc9dff9f",
        "modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/gaussian_maps.py": "2249624a2db43fdd4c49f049c5477eadd872d50983f3d50e1fdf1e71157b192f",
        "modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/geometric_augs.py": "3a9f7eb2ea2b790615443ad222de5cc28505f617476aa0092cbb25603ec7ddeb",
        "modelscope/models/cv/tinynas_detection/damo/base_models/__init__.py": "93078d8726f9a4d837a6b764c361ba4c9bb619c58a5c7faee5f8ff1e687d1dcc",
        "modelscope/models/cv/tinynas_detection/damo/base_models/backbones/__init__.py": "9e72948dd835fd5f416ea03bbfdada890c9a595e075bc03e2628255c66572875",
        "modelscope/models/cv/tinynas_detection/damo/base_models/backbones/darknet.py": "ef97ef03697c5d7923cfdca6e55bdb15202627b8a6012b5107f8d78c65d97663",
        "modelscope/models/cv/tinynas_detection/damo/base_models/backbones/tinynas_csp.py": "56c650e3efbb6443d12eeda034d6c514ca2e0c15c8e619e00007d2169dfabeef",
        "modelscope/models/cv/tinynas_detection/damo/base_models/backbones/tinynas_res.py": "49b29cd1eb3b53db64a83062ea79c217cb13695041215b177c8eb526d416ebc7",
        "modelscope/models/cv/tinynas_detection/damo/base_models/core/__init__.py": "23f00d77175c207a64233217735c8a3a55b0cdbe286341704cfab5918b60cd0c",
        "modelscope/models/cv/tinynas_detection/damo/base_models/core/base_ops.py": "23ab49eb0bbcfd637b10f46b73fe39353b02f79472d323601be8c301b4e33f0d",
        "modelscope/models/cv/tinynas_detection/damo/base_models/core/neck_ops.py": "85b80d25ef38d2a1cee46536c0df0e5f7f8010548f1153ca840a3a80a64c0933",
        "modelscope/models/cv/tinynas_detection/damo/base_models/core/ops.py": "587f40574e7941c63784477d26e3700a6da8798dfd9b62e79dfb605871340006",
        "modelscope/models/cv/tinynas_detection/damo/base_models/core/ota_assigner.py": "5b86edf28c3d732af22b2e1d14f1a07391add18b619c46e26416c997cfab19d1",
        "modelscope/models/cv/tinynas_detection/damo/base_models/core/repvgg_block.py": "ef5edd4f43bca7f4450d6d58f97c5cc9ca487691a414587f2e995ec60a15f698",
        "modelscope/models/cv/tinynas_detection/damo/base_models/core/utils.py": "68c87acf0f4d93a18bc1f01e65d6a5b1c0fa5f9eb69f76244e6da6b2fc50afc0",
        "modelscope/models/cv/tinynas_detection/damo/base_models/core/weight_init.py": "7df0b33af0aaf022a039bba1c84d0f5d698126c06eaf3c880207965fa133c8ae",
        "modelscope/models/cv/tinynas_detection/damo/base_models/heads/__init__.py": "9f916729292980319da04bb2bb7f49a7006706200c6b111f9c216db2f66d6a8c",
        "modelscope/models/cv/tinynas_detection/damo/base_models/heads/gfocal_v2_tiny.py": "84aaa00781334b6792d9b1a19b83f7472c91cfa2b56ac36884375c6dc1561bc7",
        "modelscope/models/cv/tinynas_detection/damo/base_models/heads/zero_head.py": "8b3a829e7c765c44b6fc395d135a55e28849d5edb35a33f4fb5b9f5f5461480a",
        "modelscope/models/cv/tinynas_detection/damo/base_models/losses/__init__.py": "23f00d77175c207a64233217735c8a3a55b0cdbe286341704cfab5918b60cd0c",
        "modelscope/models/cv/tinynas_detection/damo/base_models/losses/distill_loss.py": "a0ac356be373435b1b2267ca4be8623a246313006f14a74ef62d7a6e6f4e220e",
        "modelscope/models/cv/tinynas_detection/damo/base_models/losses/gfocal_loss.py": "c2b2e601450ea6c2d771f8fd4f06284055bf1ce443049ef7c9eba02523dc17bb",
        "modelscope/models/cv/tinynas_detection/damo/base_models/necks/__init__.py": "9c5f741a4960fd1d362c62cf15a19634ef22ea81bc0a4ef871e6420dc35ca076",
        "modelscope/models/cv/tinynas_detection/damo/base_models/necks/giraffe_config.py": "757e8d8b0f0a08935bfe004bb86992dad776e816615bf4652032e48303ff5068",
        "modelscope/models/cv/tinynas_detection/damo/base_models/necks/giraffe_fpn.py": "538c66b2013ad6d2a7a09bca2e19d5f0f139bf48d57c58d12af06b57aed4ad63",
        "modelscope/models/cv/tinynas_detection/damo/base_models/necks/giraffe_fpn_btn.py": "b0190dec094949bcbc73a3599dddb7dc3fe853aeaddbd63ba027d7781edb70c8",
        "modelscope/models/cv/tinynas_detection/damo/detectors/__init__.py": "23f00d77175c207a64233217735c8a3a55b0cdbe286341704cfab5918b60cd0c",
        "modelscope/models/cv/tinynas_detection/damo/detectors/detector.py": "d9728c0c1c621bfdf34e62404293839e89b821f1454d251d5aa05418d468285b",
        "modelscope/models/cv/tinynas_detection/damo/structures/__init__.py": "6001bdc7bb7983cb6080e69dbf906102a752c8e0383eb2336087eca4c02a5653",
        "modelscope/models/cv/tinynas_detection/damo/structures/bounding_box.py": "6334964a245bd5c35b201e5c21f4e3086ec6fa21d6c3ec1c282662f15b9b4cc1",
        "modelscope/models/cv/tinynas_detection/damo/structures/boxlist_ops.py": "f8f30eb9e03320e9e413688b30702c238d5a14ef5b9d3ff18d5141decf9d305a",
        "modelscope/models/cv/tinynas_detection/damo/structures/image_list.py": "2262a3c1e50d73452c96988b9f16c12b161808daa8281bad179bb95b9bef04f5",
        "modelscope/models/cv/tinynas_detection/damo/utils/__init__.py": "eda6c48df422441496c776551212f36afa07d6cb7214d4d3d64701546b06c9d6",
        "modelscope/models/cv/tinynas_detection/damo/utils/boxes.py": "ab0b7690b6aecae34c125c4bea86ae177ec67be91ecc4c1d387d62692221306f",
        "modelscope/models/cv/tinynas_detection/damo/utils/model_utils.py": "534acb4dc96e5288f853923fa4b7b0c6c555679a25040e8d0c3a374d506bb49a",
        "modelscope/models/cv/tinynas_detection/damo/utils/scheduler.py": "3d55594cefc43eb696f48ccc7b7eb4231f8f5bb8787b8dac19c1e68a389de009",
        "modelscope/models/cv/video_deinterlace/UNet_for_video_deinterlace.py": "d4ad93269ea15e51f370b1d175d5a2215cf50e691f61ac4d2ec1cd32dc654273",
        "modelscope/models/cv/video_deinterlace/__init__.py": "24fc8487040bc8038df4531ec9aeb17f88d3f59be547563ee2ee0a3e3b62a4f0",
        "modelscope/models/cv/video_deinterlace/deinterlace_arch.py": "273c2137ed5d46448f93e08d72d44044e04a5c3d08ecec4567354df31d733874",
        "modelscope/models/cv/video_deinterlace/models/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/video_deinterlace/models/archs.py": "b18338d6374def3722a9a351ca42ccb65eda54753b0f95e887da2c67208d32c8",
        "modelscope/models/cv/video_deinterlace/models/deep_fourier_upsampling.py": "156087a5177307a33d7b485d2002f73f0ed8c1b0cf6a5348ff99fb8b47d735b9",
        "modelscope/models/cv/video_deinterlace/models/enh.py": "55b74903aad3b19a338c8f4b6ed6d937483811ffdb575c422ab59235111050c9",
        "modelscope/models/cv/video_deinterlace/models/fre.py": "458cd8fa0bc21bb72afb9e34a59372a272c7f0594198bb6823786a97b8d0467c",
        "modelscope/models/cv/video_deinterlace/models/utils.py": "f12fc02bc59661e181d6c1b6fe67cb598141b0cbe0924382c1a68f96539c5167",
        "modelscope/models/cv/video_depth_estimation/__init__.py": "e866c2ecc62230c4d3f21f9f2d9b80ca9947a0464431e061056ed3e245d8c51b",
        "modelscope/models/cv/video_depth_estimation/dro_model.py": "563912c55ef0d8d5464676371a31247cee8d808cb6bdfdd53464a9eadd945b76",
        "modelscope/models/cv/video_depth_estimation/configs/__init__.py": "23f00d77175c207a64233217735c8a3a55b0cdbe286341704cfab5918b60cd0c",
        "modelscope/models/cv/video_depth_estimation/configs/default_config.py": "2f0766433f905cfafbf4a83aee692e848a874746779dc2179ba99d142caed5e9",
        "modelscope/models/cv/video_depth_estimation/geometry/__init__.py": "23f00d77175c207a64233217735c8a3a55b0cdbe286341704cfab5918b60cd0c",
        "modelscope/models/cv/video_depth_estimation/geometry/camera.py": "bd4d8ba670e41efcde61be1a7bfb90e386227e726f729cfa5b22e0a2ea68650c",
        "modelscope/models/cv/video_depth_estimation/geometry/camera_utils.py": "7a31f627fbf4c31b0c1b32517f841091a71cfed5d7cff2c0322866020c956987",
        "modelscope/models/cv/video_depth_estimation/geometry/pose.py": "dfb28a58cbd0ec971a3880d56c5903a58a52454fce4d39d227e1afa51392e998",
        "modelscope/models/cv/video_depth_estimation/geometry/pose_utils.py": "0f74e15b93250ddb9fbbb19bebfa5afc6589d9427cfd4860531fa391ac1509c8",
        "modelscope/models/cv/video_depth_estimation/models/__init__.py": "23f00d77175c207a64233217735c8a3a55b0cdbe286341704cfab5918b60cd0c",
        "modelscope/models/cv/video_depth_estimation/models/model_checkpoint.py": "2bff501960724131a6ab69bb7e33a567b3e99d561afb2c69de99d483cac11649",
        "modelscope/models/cv/video_depth_estimation/models/model_utils.py": "ca4bbd0f94c52569f83ddbca8c2ca9d8ba3d04115d64aefa4bf640dcaf2c6059",
        "modelscope/models/cv/video_depth_estimation/models/model_wrapper.py": "1ab1bae47b27caa39fc0a230cb493a938ef7560e5d169e96ec0b12e62001f847",
        "modelscope/models/cv/video_depth_estimation/models/sfm_model_mf.py": "8bfa24bc0dc14955efa5fb8beff376d513f725327b6e2e825266c17ece54fdc6",
        "modelscope/models/cv/video_depth_estimation/models/sup_model_mf.py": "615e237e2e19b73034d60a9bd6bef1f2cabfa94949b0869aa131351380c2dd87",
        "modelscope/models/cv/video_depth_estimation/networks/__init__.py": "23f00d77175c207a64233217735c8a3a55b0cdbe286341704cfab5918b60cd0c",
        "modelscope/models/cv/video_depth_estimation/networks/depth_pose/__init__.py": "23f00d77175c207a64233217735c8a3a55b0cdbe286341704cfab5918b60cd0c",
        "modelscope/models/cv/video_depth_estimation/networks/depth_pose/depth_pose_net.py": "e5c1ab711ef8947f086c1f322b34188e0245a13f35b35baaec37ee1fc7e9d789",
        "modelscope/models/cv/video_depth_estimation/networks/layers/__init__.py": "23f00d77175c207a64233217735c8a3a55b0cdbe286341704cfab5918b60cd0c",
        "modelscope/models/cv/video_depth_estimation/networks/layers/resnet/__init__.py": "23f00d77175c207a64233217735c8a3a55b0cdbe286341704cfab5918b60cd0c",
        "modelscope/models/cv/video_depth_estimation/networks/layers/resnet/depth_decoder.py": "6fde196640213e8269b431110e6503144347d4504352e7ad4347faf5ede1005d",
        "modelscope/models/cv/video_depth_estimation/networks/layers/resnet/layers.py": "c563e9f74b65d6e7ea1d215c66b20c15d9222b13fbeb94df548c5664984227f9",
        "modelscope/models/cv/video_depth_estimation/networks/layers/resnet/pose_decoder.py": "8103a823cfb536c37f4b5c162acf53f327bb01790e101480c7e8d28a136f4df6",
        "modelscope/models/cv/video_depth_estimation/networks/layers/resnet/resnet_encoder.py": "6a8ec8f26d65c59d32678d9e3c571d8a7eac2f6640ad214b102f9a835d0f5864",
        "modelscope/models/cv/video_depth_estimation/networks/optim/__init__.py": "23f00d77175c207a64233217735c8a3a55b0cdbe286341704cfab5918b60cd0c",
        "modelscope/models/cv/video_depth_estimation/networks/optim/extractor.py": "61dfe9b03249936e1157ef13012ef53d2130d16bd42e0598e48ac7dce5d309cb",
        "modelscope/models/cv/video_depth_estimation/networks/optim/update.py": "1cbaa79e568052dab5bf090b5e2c41d40e97216bbf69c3cefc252da539329b67",
        "modelscope/models/cv/video_depth_estimation/utils/__init__.py": "23f00d77175c207a64233217735c8a3a55b0cdbe286341704cfab5918b60cd0c",
        "modelscope/models/cv/video_depth_estimation/utils/augmentations.py": "229e3e00eb7c18f34254b88508f85349b9f27737762979bcd20163557efe494f",
        "modelscope/models/cv/video_depth_estimation/utils/config.py": "2cad87600a8710517ecff962283f9d2080fa1c1aeb3c0c24141447e721b603f5",
        "modelscope/models/cv/video_depth_estimation/utils/depth.py": "4233f730b8cb3c0b703d7e6b5b0ec5e3bf5214c77aa7356cf8306877bfca186c",
        "modelscope/models/cv/video_depth_estimation/utils/horovod.py": "1d19504f4371f0cc2013fa9a7868918194e9db89de823582c2745a408dbea820",
        "modelscope/models/cv/video_depth_estimation/utils/image.py": "07c01464e6bab3155dd67d6c29e7a81ada15051585636b01060ab647317437b1",
        "modelscope/models/cv/video_depth_estimation/utils/image_gt.py": "b72ea2ff161bc161c647b951658e3098912193215ea2895af06f241ec29e1752",
        "modelscope/models/cv/video_depth_estimation/utils/load.py": "0af3302d721f3cdcd1b06359e7c3a58a4f8a364504e204b11b81994889168c6b",
        "modelscope/models/cv/video_depth_estimation/utils/misc.py": "ab832eb01cf1387c72f32bfd36cd1e114511762ad19bf001f2db8bc75381cb62",
        "modelscope/models/cv/video_depth_estimation/utils/types.py": "14cbc46f51dda42d5f1d860a0b3883dadc9d979e2283bd9482077e5ab26d53ce",
        "modelscope/models/cv/video_frame_interpolation/VFINet_arch.py": "9e6ad338cc46d3e0db3d349a09bb282e0007f0c12f3b52d322d1d5b868acf991",
        "modelscope/models/cv/video_frame_interpolation/VFINet_for_video_frame_interpolation.py": "ebea71598d97c35248e510f2c58be09ad91a5ef9566f01949af74c67b8f92425",
        "modelscope/models/cv/video_frame_interpolation/__init__.py": "1c1c354d71fd72ee437c5ebd37b9f0912d557702187d78f48f2d999345941b17",
        "modelscope/models/cv/video_frame_interpolation/flow_model/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/video_frame_interpolation/flow_model/corr.py": "309e05c74deaf3ade631124522b34dea2a63fc6ee413500da442eec61ff0adbf",
        "modelscope/models/cv/video_frame_interpolation/flow_model/extractor.py": "af973cd9cbf5699716ef2a286743304e29ba64574b10cfbdbb0958863ff298dd",
        "modelscope/models/cv/video_frame_interpolation/flow_model/raft.py": "cc0aa18a7d5ae6a9794e9cf1ef9cf9797642136c9029b7fbd28004252896e8ac",
        "modelscope/models/cv/video_frame_interpolation/flow_model/update.py": "e2f141bce84fac06b73b3ec965fe24ae09f3166c2b443c4755edd8d0ab57a200",
        "modelscope/models/cv/video_frame_interpolation/interp_model/IFNet_swin.py": "8e661b77c551cd04fe8af722ee6624ae8b16894cbefc65b04bbc93cec91c5434",
        "modelscope/models/cv/video_frame_interpolation/interp_model/UNet.py": "4bb09146b68dcc5448440f4d35e30d4f56d18fe24b38f5e4f05c8ef4b6f6cc18",
        "modelscope/models/cv/video_frame_interpolation/interp_model/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/video_frame_interpolation/interp_model/flow_reversal.py": "935c757af8d0f5b973b25458e235527e39d45d1548a50fd3c406b29f7dc0d8f5",
        "modelscope/models/cv/video_frame_interpolation/interp_model/refinenet_arch.py": "d6828fc6e77576ae6f52a9f8b3d8cef3c5e5a1f637d7d13c54703fe354629d10",
        "modelscope/models/cv/video_frame_interpolation/interp_model/transformer_layers.py": "a4b7a6136e1fbaea895495be5d1e99538a32df40247835912eded7640fd2a08c",
        "modelscope/models/cv/video_frame_interpolation/rife/IFNet_HDv3.py": "1cf860f4be7563cd78c5de2dbb522aa9f7ff560b7049d2e2ecbeba7dcf2b551b",
        "modelscope/models/cv/video_frame_interpolation/rife/RIFE_HDv3.py": "e58635680e0eef154abfeae42472678bf28cf1931b9788ab644460bd0f61f898",
        "modelscope/models/cv/video_frame_interpolation/rife/__init__.py": "e843bde327fd422bd60590c652847de82d98ee5828cb38863edc12efa6fb2797",
        "modelscope/models/cv/video_frame_interpolation/rife/loss.py": "c91189dd775be24620555fe8432c0652292ea9face152bce46006fb8f8ca068c",
        "modelscope/models/cv/video_frame_interpolation/rife/warplayer.py": "c5ca587c022a469a17a0e555e371d2ac1eaafa156c63ee44cfe535da5c783f2b",
        "modelscope/models/cv/video_frame_interpolation/utils/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/video_frame_interpolation/utils/scene_change_detection.py": "2f8bcd46d07e2e99e7703eb25a597a2ab87074b28e0c96eb3cbb003094bef1d9",
        "modelscope/models/cv/video_frame_interpolation/utils/utils.py": "15b617d621e47959474573bfe546426b0e9d6cdab06ab10a3a31e56289f49a4e",
        "modelscope/models/cv/video_human_matting/__init__.py": "2c3bfa5dbde07f2cfbea9b7ebb99ff0512c9588138f6802dfc8d3477c0c5ad63",
        "modelscope/models/cv/video_human_matting/model.py": "b27333cb2532647884d14748a70bd05650adf79cd4175abe82118be3e51cfcb3",
        "modelscope/models/cv/video_human_matting/models/__init__.py": "7a9f38169749af0a335545f21feb3bb0803c38154bfd782a972a1358d589cb15",
        "modelscope/models/cv/video_human_matting/models/decoder.py": "07706d2f054d2c9d9c17a8c6d7615127a6a9a712712d9dad4fe13482e51d2d7e",
        "modelscope/models/cv/video_human_matting/models/deep_guided_filter.py": "6c9484edaaf7852c48b9b8694fd87a7e43a3c037349796fcfbb6d84aecacbd39",
        "modelscope/models/cv/video_human_matting/models/effv2.py": "ddaec53443a9190a0360318723daaaace4ae68c1d50b2c74165875d5224bc0df",
        "modelscope/models/cv/video_human_matting/models/lraspp.py": "e48178cc887733e6aff0ffc1a444864c1bfcf9721915cd3af5db3e0c1a8e94a7",
        "modelscope/models/cv/video_human_matting/models/matting.py": "aa4ca5a59df213cf30b3bbba94ad6f6f8142d648ed4564582f1870f11c836396",
        "modelscope/models/cv/video_inpainting/__init__.py": "2d9fa3bd31e46a97c219c421cbc1f57a144f2c7f97dd20d1931147158abe343c",
        "modelscope/models/cv/video_inpainting/inpainting.py": "d349663f28ddd7ab224031a83fe27f5d645e36f0ff542e28a7e4961265718276",
        "modelscope/models/cv/video_inpainting/inpainting_model.py": "d173add1f5bfcc116d2690fa2d7633d51f2e5537517bcccb30d65691520d864f",
        "modelscope/models/cv/video_instance_segmentation/__init__.py": "bbf91006ba00bc16e1d96300dc3c6f22746eda2a04fcece0c2d3721e9b6d7245",
        "modelscope/models/cv/video_instance_segmentation/utils.py": "ee30caca0fd424b64e8073ea903f510375a5bb4f0411387907bdd0d416cda0f9",
        "modelscope/models/cv/video_instance_segmentation/video_knet.py": "5ad25989b6339ebc10b2f0f7bbbe72b40cf1b479b4308387636124ff482056ef",
        "modelscope/models/cv/video_instance_segmentation/head/__init__.py": "23f00d77175c207a64233217735c8a3a55b0cdbe286341704cfab5918b60cd0c",
        "modelscope/models/cv/video_instance_segmentation/head/kernel_frame_iter_head.py": "5fab019c8f168ea88ecae717cf9184810ad4381d5e4922e1d05a3feb09e3c8c6",
        "modelscope/models/cv/video_instance_segmentation/head/kernel_head.py": "d3e520ce81a4bbe30898f97454ab1265af679e9113dec771054449da4976da10",
        "modelscope/models/cv/video_instance_segmentation/head/kernel_iter_head.py": "46a9abb65ef4c7aa3be7096455558b02fb5e2fc600c82b905d6cf30809bfd3f5",
        "modelscope/models/cv/video_instance_segmentation/head/kernel_update_head.py": "750c4c0839ec524794fb0280f73a385ad2e737014e4f4f016f5673bbebb3d646",
        "modelscope/models/cv/video_instance_segmentation/head/kernel_updator.py": "84c8596bd6e35822998a8639ac63cdd481ee9a9fcbeb40b3c38602204f52c1e8",
        "modelscope/models/cv/video_instance_segmentation/neck/__init__.py": "c925e928d2aaee04e14468659e92bdd8eb99aca19f877df8c5eb9fae55d2b484",
        "modelscope/models/cv/video_instance_segmentation/neck/msdeformattn_decoder.py": "bc919b59f2d2c1ef4e84c2ea7c906760952bae1a36ea29c12cecd71cc09842ae",
        "modelscope/models/cv/video_instance_segmentation/track/__init__.py": "23f00d77175c207a64233217735c8a3a55b0cdbe286341704cfab5918b60cd0c",
        "modelscope/models/cv/video_instance_segmentation/track/kernel_update_head.py": "98a91ef952d394f3955c6a974aad291680cfe902e2429f52157b0d49c8f6c64c",
        "modelscope/models/cv/video_instance_segmentation/track/mask_hungarian_assigner.py": "0c2c428a02db0be359610b66f74265366a468494096dfddd8b2940481cf5119d",
        "modelscope/models/cv/video_multi_object_tracking/__init__.py": "5d25df468017de29b9e5c2cb585b23d861c1d7bdb048e5330622318468fb2623",
        "modelscope/models/cv/video_multi_object_tracking/models/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/video_multi_object_tracking/models/common.py": "7edd632961f0b32dce567bf3bedbff21c083e0b82084dc2ed4531b4e165a48ce",
        "modelscope/models/cv/video_multi_object_tracking/models/decode.py": "be53985be17b78399e8385fa270eefce60ddc180bf53b008e653ad702f3d312f",
        "modelscope/models/cv/video_multi_object_tracking/models/model.py": "892e883f484135aa4aa598726d3f3bbf193b88577dfaa6dc8ceac99dd68be781",
        "modelscope/models/cv/video_multi_object_tracking/models/yolo.py": "2f3ab0b675e939187717ada6574917199478fbefca3e5feff5c7ed540c6f0fa8",
        "modelscope/models/cv/video_multi_object_tracking/tracker/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/video_multi_object_tracking/tracker/basetrack.py": "5842ac09c6c48878df500f8c5aa26c490295f79df0069e275257837cf82d0464",
        "modelscope/models/cv/video_multi_object_tracking/tracker/matching.py": "a47c3f52167c4c8174454eaf21cc5e6ffaedbd36cf7eb92c1324f3d472d19da6",
        "modelscope/models/cv/video_multi_object_tracking/tracker/multitracker.py": "c32155cb9eb2dcb2d865d21300097d0780f9ab94af7061e86e230a2ab07d666a",
        "modelscope/models/cv/video_multi_object_tracking/utils/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/video_multi_object_tracking/utils/image.py": "c5cc1aadf4bf6332df164ed17e38d4be2ce5935646859db563e0f895c328eee9",
        "modelscope/models/cv/video_multi_object_tracking/utils/kalman_filter.py": "66b2907256328091518f1e38f4e57c6400c072621b3d8c0c42def8affbbd4597",
        "modelscope/models/cv/video_multi_object_tracking/utils/utils.py": "408144f8e0c3787831f9ab7761259b044bd247e358a03830f863575d832338af",
        "modelscope/models/cv/video_multi_object_tracking/utils/visualization.py": "935f238fd4d295ed14ef522e52c8bd3ad3ea290533130d9e086557bc8b00475f",
        "modelscope/models/cv/video_object_segmentation/__init__.py": "9fd1ef5a8f2bc00639004d83c4343b4f8f5a8befdd0c3831c357980bd70d4b25",
        "modelscope/models/cv/video_object_segmentation/aggregate.py": "b8d3032ede05e96ef93d50408c2894ba73124a686b2ed96cc864d41b49b9e32c",
        "modelscope/models/cv/video_object_segmentation/cbam.py": "f50a9edba61a1a372189ac28d742756adb63eb0f445f1d08422882df1359d1e5",
        "modelscope/models/cv/video_object_segmentation/eval_network.py": "ccf354c4f8ca370c4e1cf0499ae5c1321d7850d00bfd3e122754c2150718fb9f",
        "modelscope/models/cv/video_object_segmentation/inference_core.py": "a3f5327bfd027cea23b6c28db4d73b08fbbcc4f81bddf7d250756a4058c490e1",
        "modelscope/models/cv/video_object_segmentation/inference_memory_bank.py": "1399736f123cf4580173dd5f51d05c21865d29bc2fb1be0bd0f799bee9e2c09c",
        "modelscope/models/cv/video_object_segmentation/mod_resnet.py": "2b02b4cbc7c5fc5b152ecab2d839eb02fcc8010f6ce37a8d777411afbc778858",
        "modelscope/models/cv/video_object_segmentation/model.py": "533670d22047524cc656d54b2079bb299bd0710fca4c59f95c0003b16bd7521f",
        "modelscope/models/cv/video_object_segmentation/modules.py": "fb1d8cc3bf50b2234a5192996f67b571c46215b04d32618bacc7b23da4ec5c89",
        "modelscope/models/cv/video_object_segmentation/network.py": "cb2611e432ac21f1ded8979cd7e34ecb884d22ade099daa39642e9729a8ba18b",
        "modelscope/models/cv/video_panoptic_segmentation/__init__.py": "4f55bc63f025e675f799f945a4ccc71d7e07f82bc099e509e46deefde68d88b0",
        "modelscope/models/cv/video_panoptic_segmentation/video_k_net.py": "17e5eab5602c6ba400d5cfe9a2c8f1da3751ce160bdcde988298906e91bd35b4",
        "modelscope/models/cv/video_panoptic_segmentation/visualizer.py": "b6885139c3ee7c6b9682985df9e4ca874152e747ef94cad34a81ca23df06afb6",
        "modelscope/models/cv/video_panoptic_segmentation/backbone/__init__.py": "23f00d77175c207a64233217735c8a3a55b0cdbe286341704cfab5918b60cd0c",
        "modelscope/models/cv/video_panoptic_segmentation/backbone/swin_checkpoint.py": "ee0dcb3bba04835c422a5eb2a810e242732be9cb04b8369e1c1610368ea4ce71",
        "modelscope/models/cv/video_panoptic_segmentation/backbone/swin_transformer.py": "850f6a149318bcd570eb1ff846006af9171686b720f389c80d7675c6a6d315b4",
        "modelscope/models/cv/video_panoptic_segmentation/head/__init__.py": "cffc0451e68b5aa6bd6a4edafc9c576c5521b43d3de0735d63b6e6d3043a8847",
        "modelscope/models/cv/video_panoptic_segmentation/head/kernel_head.py": "11ca2564e6d254e6d267dad7f4d4163d82d5f6936707dddaa53e7838d06f7ec0",
        "modelscope/models/cv/video_panoptic_segmentation/head/kernel_iter_head.py": "e1ebaa525c1128bdff4d6700e777cf3c9507339cb20ce7764db53da6ba8e14c7",
        "modelscope/models/cv/video_panoptic_segmentation/head/kernel_update_head.py": "49c672955c249ca5b5ca82c910197328261fd559834d5a2d6c7b2c4b51ca7741",
        "modelscope/models/cv/video_panoptic_segmentation/head/kernel_updator.py": "1c8902685ee9b082bfb500da0bd37fc3f22e468fcab06aa30523a6298d434210",
        "modelscope/models/cv/video_panoptic_segmentation/head/mask.py": "dcab907c7e31f012f34bcbc42041b735b792e14d5f6674c576e38ab8317ba798",
        "modelscope/models/cv/video_panoptic_segmentation/head/semantic_fpn_wrapper.py": "8b49c8f693cfc04eaa7809eb78c4a69173448ed678f4aa1f585224825ba4627f",
        "modelscope/models/cv/video_panoptic_segmentation/head/track_heads.py": "39e190956c1438ade195b009f7cb8c905ac9f2711c97388def8265a5c454a53c",
        "modelscope/models/cv/video_panoptic_segmentation/neck/__init__.py": "23f00d77175c207a64233217735c8a3a55b0cdbe286341704cfab5918b60cd0c",
        "modelscope/models/cv/video_panoptic_segmentation/neck/fpn.py": "8a332a401d9ec2c84f29c7c1922aa57bf541baae92e0fb1db3fac27971f05a32",
        "modelscope/models/cv/video_panoptic_segmentation/track/__init__.py": "23f00d77175c207a64233217735c8a3a55b0cdbe286341704cfab5918b60cd0c",
        "modelscope/models/cv/video_panoptic_segmentation/track/quasi_dense_embed_tracker.py": "665694e250c88fa49450613031a9501f364044b513b8e8e0dd19c5d2e048481f",
        "modelscope/models/cv/video_single_object_tracking/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/video_single_object_tracking/config/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/video_single_object_tracking/config/ostrack.py": "ac6d809dd31fdc4b91cb69431c1419f6f266a80f62a39045cf04ed301c8517d7",
        "modelscope/models/cv/video_single_object_tracking/models/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/video_single_object_tracking/models/layers/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/video_single_object_tracking/models/layers/attn.py": "d6d92852ba5f2dae71b620b49d4427f22563b112959afcd6c307aabc20d815ef",
        "modelscope/models/cv/video_single_object_tracking/models/layers/attn_blocks.py": "8a086e8ac547d51e66a2acb78ee9df70bd5611db036a0952c76d61f2fbfd1fce",
        "modelscope/models/cv/video_single_object_tracking/models/layers/head.py": "9267e0a10beff702fb37b4e504954bc70ab76ddbf19716d0db567ef6d7b9e4a6",
        "modelscope/models/cv/video_single_object_tracking/models/layers/patch_embed.py": "23985945240ec921c2b3df1c9b2f4fa343f4d4608514651461e9b0368a4c8ebe",
        "modelscope/models/cv/video_single_object_tracking/models/ostrack/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/video_single_object_tracking/models/ostrack/base_backbone.py": "df03b69529125a410b4dd5bc79c66a907034330458c01bcadbf0c8300b06b7d3",
        "modelscope/models/cv/video_single_object_tracking/models/ostrack/ostrack.py": "13aa2be79522d41a69a2b08d1ed1345608f0bca55ef4317016d6ce45057f1a2e",
        "modelscope/models/cv/video_single_object_tracking/models/ostrack/utils.py": "ef64c10a1aeb56c1750f0b87f090d39ad5c2e8ddf40750dc9bdda57763e96872",
        "modelscope/models/cv/video_single_object_tracking/models/ostrack/vit_ce.py": "0afd3ed6315e38f392638bf22abd324c3e7ac1213d0c9e8b64e1709681c5510e",
        "modelscope/models/cv/video_single_object_tracking/models/procontext/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/video_single_object_tracking/models/procontext/procontext.py": "7e3b65a7185206aedbc229b63f69a9f4f9f059c797ab149e3af621807c4b0434",
        "modelscope/models/cv/video_single_object_tracking/models/procontext/utils.py": "cd1b03e040320295c85f66c584b8279cd91e000a2c141c3cbd1c439758f01780",
        "modelscope/models/cv/video_single_object_tracking/models/procontext/vit_ce.py": "b6a9dd50cdb76b0011a22695b992dba35358f6887897909a67c202d76ce28071",
        "modelscope/models/cv/video_single_object_tracking/tracker/__init__.py": "8b6e9976d2676a08dcdec6a753bd3db3aa9a7adec4f5787eb8fe739c606b117d",
        "modelscope/models/cv/video_single_object_tracking/tracker/ostrack.py": "a33eaff8f745d6e31036d89fc71b76c26c0fbc3b79b1d94ea9f8d3b27a41f252",
        "modelscope/models/cv/video_single_object_tracking/tracker/procontext.py": "0c4f0c2eec9e2bbe81776e49f23c484f34cebfe69cd5f85c36da27a835deee5b",
        "modelscope/models/cv/video_single_object_tracking/utils/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/video_single_object_tracking/utils/utils.py": "a26704430e53cec0574b5d95f3e89863c8667c878a42addf9e7100f2dcb683c1",
        "modelscope/models/cv/video_stabilization/DUTRAFTStabilizer.py": "1c028636cd14be974a92f52c56b587a2f01bd8f96637a2648303a556134664ed",
        "modelscope/models/cv/video_stabilization/__init__.py": "9bb2507dc80b892824e8132e0f5a21951571fd420b282218c579f32ad93780c5",
        "modelscope/models/cv/video_stabilization/DUT/DUT_raft.py": "2d831635a6d6317a6e6f3f9cf34a1ebce8643ceac2307e0a472b54061afe3344",
        "modelscope/models/cv/video_stabilization/DUT/MotionPro.py": "2503d0a9d64c9e62c5a72f27d0a8716320c99fd7aef5c3eb58624e61349af026",
        "modelscope/models/cv/video_stabilization/DUT/Smoother.py": "000f4f0f5b8d2b7df88284e1de6afc5c6a51f77fe0f1242a079fc4133b7ffcbd",
        "modelscope/models/cv/video_stabilization/DUT/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/video_stabilization/DUT/config.py": "ba19a2a86ebabb534f611382108ec9c788fa1fe74493d7786b0d066413f1bec7",
        "modelscope/models/cv/video_stabilization/DUT/rf_det_module.py": "ff6d2d9a3aa22e4d5d93ec34981ccc36d15240ed481cb5d537500c90cd1f3775",
        "modelscope/models/cv/video_stabilization/DUT/rf_det_so.py": "9e9f0dcdedd5f67ce471e5a7bff8178bef9974ed6dcaa33cd3a187393cbc29eb",
        "modelscope/models/cv/video_stabilization/DUT/RAFT/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/video_stabilization/DUT/RAFT/corr.py": "79f4d9d5d1513797002bffcab43017dcf4759794e97ac1003d7e410407fb3471",
        "modelscope/models/cv/video_stabilization/DUT/RAFT/extractor.py": "59589ce1c30f6f426f0cffbe41cf04931c2a72b42b10b3ad75267dfa5e244e6f",
        "modelscope/models/cv/video_stabilization/DUT/RAFT/raft.py": "b2d0bfef64dc6eeafb4748ca056fa390eb16bea37520a46426d0b474e57e889c",
        "modelscope/models/cv/video_stabilization/DUT/RAFT/update.py": "661131dcb82fb953fe450644f8bce576be0837a71a97cdd948f3bfce4523ea1d",
        "modelscope/models/cv/video_stabilization/utils/IterativeSmooth.py": "2c58a7cc970579fde5065ee03fabac40356df221623f260aef9fb44c3f6f241a",
        "modelscope/models/cv/video_stabilization/utils/MedianFilter.py": "c21cb35dfdb7c9113b42432745c46b8305d82b9d52ee8bea243a56a3fed5d34f",
        "modelscope/models/cv/video_stabilization/utils/ProjectionUtils.py": "548772d9da3735d3a77c8e12cf87b874010da7aa64f8d024e13cd975958b31f6",
        "modelscope/models/cv/video_stabilization/utils/RAFTUtils.py": "b00547ef41713639a3bdf15737fde88adee40e9f348ae15b36cda3d0ce41dd1e",
        "modelscope/models/cv/video_stabilization/utils/WarpUtils.py": "50d6ebc0102f1dfe7a675c259684dd07078c183ef44c9e688dce2fba505dd909",
        "modelscope/models/cv/video_stabilization/utils/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/video_stabilization/utils/image_utils.py": "f8fffbe4fdb6bf0f2c767ffcd32ae957d1c5bf1b971125da791860a9dedf5b93",
        "modelscope/models/cv/video_stabilization/utils/math_utils.py": "e50a6ea1a91f4377e7800a99b9ccddf87a3c9708e5ddc98f963d9c3e3e96aa9f",
        "modelscope/models/cv/video_streaming_perception/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/video_streaming_perception/longshortnet/__init__.py": "7460cc59dc50c22331e699bd3423ceaceb5f2bc8c5a32463214fa70975ae77db",
        "modelscope/models/cv/video_streaming_perception/longshortnet/longshortnet.py": "b7b960b467691734c2ac708edd597d61ed12533dbcb37db1d08ebc6ae3e0b565",
        "modelscope/models/cv/video_streaming_perception/longshortnet/exp/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/video_streaming_perception/longshortnet/exp/longshortnet_base.py": "e00683d31f6a1eabdee2c100adf2451da2fef3641757b221236a8811814cdba3",
        "modelscope/models/cv/video_streaming_perception/longshortnet/models/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/video_streaming_perception/longshortnet/models/dfp_pafpn_long.py": "67661b21bb3e0f36609cac32b3f6390930bebd7338fed7aa8a933cc7b0154d43",
        "modelscope/models/cv/video_streaming_perception/longshortnet/models/dfp_pafpn_short.py": "63ad478cdadd623e42c1382cadcc0db936c07ecb5ea32f3e9bd7eeb5cc682b76",
        "modelscope/models/cv/video_streaming_perception/longshortnet/models/longshort.py": "fdf1d7596b66d2da9ad62d63d59b91dfcc62a15d5a87ad9aaef6127894056222",
        "modelscope/models/cv/video_streaming_perception/longshortnet/models/longshort_backbone_neck.py": "8de8969ab38ac8afba0e656e1111241709e4f5f1ba79a76eba5751a64d6bb5fe",
        "modelscope/models/cv/video_summarization/__init__.py": "a6aa3c66dad8e581d5722375c4963cb88e83b6dbc0e466d3db3ad21dcf5b23e3",
        "modelscope/models/cv/video_summarization/base_model.py": "a09f8b00f01b2345cd374a9c616b89882c1482c376a20aaaed805106702674c9",
        "modelscope/models/cv/video_summarization/pgl_sum.py": "a2b292223f60ef0c8a570479135afdb01e24174a9ca50e893c7f91b373434b92",
        "modelscope/models/cv/video_summarization/summarizer.py": "595df749e77951b9d7cd8cd2424f175057e48ff3791ff9ff88309bc644fe1411",
        "modelscope/models/cv/video_summarization/kts/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/cv/video_summarization/kts/cpd_auto.py": "8782069a8d1f4a78b9f80a163a32bf16673c43592a2b766687b0386537d7f905",
        "modelscope/models/cv/video_summarization/kts/cpd_nonlin.py": "668f33a43bbf27968022917e7b61e9ccb8fc3dee9990743da9afe6fb65228bab",
        "modelscope/models/cv/video_super_resolution/__init__.py": "2ae34f1acf0fd627aad4467608d302907ddba23d5edc5fc8594c054f1f57c7b8",
        "modelscope/models/cv/video_super_resolution/basicvsr_net.py": "faa7d2baae8ee7cca78bfbbb8034d985a177c8598ead4ca450cb59071d336643",
        "modelscope/models/cv/video_super_resolution/common.py": "1b1b014cba459332089094ad189b98ba2c6376dd501beb016a853c43d3a6d6cd",
        "modelscope/models/cv/video_super_resolution/msrresnet_lite_model.py": "f07e7b4e00d7258faafbaefa6c0aedaa1d6f7fa7d8272684f25c8eb5474e7836",
        "modelscope/models/cv/video_super_resolution/real_basicvsr_for_video_super_resolution.py": "294ea4847594369b4438bc9a1892ecbae3a62c3d268ac68feeb8a3e703d3dd04",
        "modelscope/models/cv/video_super_resolution/real_basicvsr_net.py": "1f0695fc02f9479a73e20c915dd7af843252cf9d7bb359004cef2d8f2a529495",
        "modelscope/models/cv/vidt/__init__.py": "9554a427e921204eca2949c99b132e439a6a2ac1a1e4bc3a8319b03e9da3d94b",
        "modelscope/models/cv/vidt/backbone.py": "66f67e1d3820b92498c37189dd57f4e68e9a98eb1c9f6c5154e45a804a051ce7",
        "modelscope/models/cv/vidt/deformable_transformer.py": "e955268d4dd080b551d76c43aa6824c3c8b406d26925e5d08b7a1e760cb13352",
        "modelscope/models/cv/vidt/fpn_fusion.py": "31ccc2a416a71a78bad41b5113bd026e2656b72867e57515973960a72016db01",
        "modelscope/models/cv/vidt/head.py": "25243779bd4c6c3831d73a164b50ccb0358fd4f19d39a2046001a09042ba1d77",
        "modelscope/models/cv/vidt/model.py": "b3aaae2691a6b76b0b136bb63a08f2e1da2c2813c3df78007bb122cfbb014446",
        "modelscope/models/cv/virual_tryon/__init__.py": "209b0a3e085e2203c16ce82ae2cf3040b9970b952a900c0de1dc23c887e2999b",
        "modelscope/models/cv/virual_tryon/sdafnet.py": "e1f985d56ad0fbbd5a6e5cae4ebd4c2902c12314e8ebe9f4619894f99c092ace",
        "modelscope/models/cv/vision_efficient_tuning/__init__.py": "0612bffae89b4fcf99c3438afc86fe044ec5d99269296114f2083dd7eab247b3",
        "modelscope/models/cv/vision_efficient_tuning/backbone.py": "3b1263d8b1cc9f43b5d8e9a78a30c9232634548c09eb2797477b3ae7216876d7",
        "modelscope/models/cv/vision_efficient_tuning/head.py": "b6efa231239035703b7311960edb5a3f237d087ea271cc5110526e704647c4d1",
        "modelscope/models/cv/vision_efficient_tuning/model.py": "34e317041c025581064db7e5b350662792c3923b3acc891482118530d93d9bc1",
        "modelscope/models/cv/vision_efficient_tuning/petl.py": "a2589342f5315f097a1ddc252a76e16e4f681de19ce2f8b54737483ea2c5e665",
        "modelscope/models/cv/vision_efficient_tuning/timm_helpers.py": "ae7e92f14542ae863c46cf704bf11383640b31ffd112ded5913ce1599716ea07",
        "modelscope/models/cv/vision_efficient_tuning/timm_vision_transformer.py": "1c8c6fe9ea0259b20b6cc4f81983ad0bf4ecdec7959d01766c2d2bca7515dab6",
        "modelscope/models/cv/vision_efficient_tuning/timm_weight_init.py": "b97301bf0ad96564bbb54923165591d209ffb8ce50ec009b98fc439363ac37f2",
        "modelscope/models/cv/vision_efficient_tuning/vision_efficient_tuning.py": "7e6599e17c1718b9cb490273256fb0788a88920bbc110488b8ae09e719c97084",
        "modelscope/models/cv/vision_middleware/__init__.py": "0df30e76ae60c1758f8377d319ae361d5521b877d5f685c0ed375fcf5b01458d",
        "modelscope/models/cv/vision_middleware/backbone.py": "0ce058efbf3e2bd5413a35d3c027bc3506aa3a7cfdd5a2e6a0abc9631587833a",
        "modelscope/models/cv/vision_middleware/head.py": "75acdfacfabb23b7e2119fb2ea04f6470429bbf518cfb489690e14c41d557677",
        "modelscope/models/cv/vision_middleware/model.py": "646bd11e5abe860cf248cc823c31b692c557c26fbe7b4977a22089e516c75119",
        "modelscope/models/cv/vision_middleware/vim.py": "837ffc2d47a3556a46765a69fc61976ff29a47c687cadbe433a5c02caafe2baf",
        "modelscope/models/cv/vop_retrieval/__init__.py": "31ce43ac5845392a83a5d8de0d7aebf6540d922f553bd3fd96b6d47910a8758d",
        "modelscope/models/cv/vop_retrieval/backbone.py": "3d1d7ce058d3c85383b422f9ba5a6dc179153f6a3504970b9df6f00a601c687e",
        "modelscope/models/cv/vop_retrieval/basic_utils.py": "3361fb3b3138c1d48d324eb44564ad76df6c34f0a42a0bae3df30578391a0cad",
        "modelscope/models/cv/vop_retrieval/model.py": "d0cb702482cf62565ddfabfbb478760659f0fde2b987d20b15c30c9dff2b431c",
        "modelscope/models/cv/vop_retrieval/model_se.py": "c584aca365146d077540dd2a2590bbee896d596a6cf835bc529b786cf1892bd7",
        "modelscope/models/cv/vop_retrieval/tokenization_clip.py": "de11c98b2da854aa21d905c7d43e0cc3419046869f8596010370167bc80bcc37",
        "modelscope/models/multi_modal/__init__.py": "90f5d21047c7c676447a1d71828522db5901e7da9e9123614aff7e3c1d7219ba",
        "modelscope/models/multi_modal/dpm_solver_pytorch.py": "5e59cf6746a95f6239eb1e8c0fbbd0ae6f7ebd18d4e93314d5e90dac2d94871e",
        "modelscope/models/multi_modal/mplug_for_all_tasks.py": "3bb8e87bb03ff112c7a7b02172b1d30e0fd2ef66126881dad7018e09d59963dc",
        "modelscope/models/multi_modal/ofa_for_all_tasks.py": "3c95b5bd02077653022dcbed0f151a399d9f3701f4f15e1353fcb90e636fbba1",
        "modelscope/models/multi_modal/ofa_for_text_to_image_synthesis_model.py": "66e3e1054144b8bbe360a2d691657115fb604d9626d2af7b298987fc01f5341f",
        "modelscope/models/multi_modal/clip/__init__.py": "45c7c5e46bc9553e92a7b0316d1747d17b9b3e38f5be3c715ec89b80f9be8189",
        "modelscope/models/multi_modal/clip/bert_tokenizer.py": "cf98e4a6f62927e92e1a9254c919d4ef9b0ad8690503648c61b317566e1573d9",
        "modelscope/models/multi_modal/clip/configuration_bert.py": "25114f71ef9134ccdd2ee34549d2c76da2577158e93abc6034327adf3781815c",
        "modelscope/models/multi_modal/clip/model.py": "b9df134c1bab5d4177fce73c5346d1954dea5cc3ab29d756479863e774c960ce",
        "modelscope/models/multi_modal/clip/modeling_bert.py": "2341ea33000a02d1bbcdc500f7fcb372db00bd2dce19f5ea729d159cda548bf8",
        "modelscope/models/multi_modal/clip_interrogator/__init__.py": "489ab0accc24fce8f0e29a657c4d5b884545660fb73f913a0fe3511d81ab87ea",
        "modelscope/models/multi_modal/clip_interrogator/model.py": "739c48bbfea9c7d925209606a2fd8a75efbe621b707e245cdcaa5c751d8fee57",
        "modelscope/models/multi_modal/diffusion/__init__.py": "63b72440829532666e4933f6868894a8b5338ae7e183c9c1c4a83b9773ad2ea6",
        "modelscope/models/multi_modal/diffusion/diffusion.py": "ac1b8e91c7df06c40276b830b5b0a9a79fa6dd8023138e4ad5b9970e2c6a4d4f",
        "modelscope/models/multi_modal/diffusion/model.py": "31822479e6ee528cec34bb828e734b9196769754fd6520936d5c6b5b6f34b736",
        "modelscope/models/multi_modal/diffusion/structbert.py": "6a636689c2b97d8a9dc419ec49cd7cf00734b78bc01da3c9a6f518368cc551e8",
        "modelscope/models/multi_modal/diffusion/tokenizer.py": "fc7642e6a6984f7294785b6a659338f286e8d373840c3d6a8a6c56ad102825b9",
        "modelscope/models/multi_modal/diffusion/unet_generator.py": "a3efe684d7a35016eae1aacf4575d98c67488a81078e85d509eaa22d52458072",
        "modelscope/models/multi_modal/diffusion/unet_upsampler_1024.py": "6fc2580c8ee3edc4c69a3c646fbbb66a2ec9d93bcad48c93671cab372df5c3f3",
        "modelscope/models/multi_modal/diffusion/unet_upsampler_256.py": "898bbfe494e5990fefc2aace5de89075a0b71bc67cee1846ff2bc68ac5c1764c",
        "modelscope/models/multi_modal/efficient_diffusion_tuning/__init__.py": "da54218e03036b8c5c4bead8a66c461568f3b8b139c28363c34bd8dbcc16074e",
        "modelscope/models/multi_modal/efficient_diffusion_tuning/control_sd_lora.py": "c3590115ce5a4ce6f74ce1145dd7a727ec1b8093e85bc313c7176385a6c51a57",
        "modelscope/models/multi_modal/efficient_diffusion_tuning/efficient_stable_diffusion.py": "882072f2554578cdb2e4f4fec439a1d0cd9548a85141d0fb838a72d356820f86",
        "modelscope/models/multi_modal/efficient_diffusion_tuning/sd_lora.py": "8108df46c20f31842fcc714691edb50107ae8fa04cca62e78ec28ab8baf7c25b",
        "modelscope/models/multi_modal/freeu/__init__.py": "3cc673a7d9eb6acad3a6ea4857c64ee3282fb7e4b0533e63632956a3dc404209",
        "modelscope/models/multi_modal/freeu/free_lunch_utils.py": "e512e4ccf405dbd5715605c9928d379c28241dae7ab2094561f755942af08b7a",
        "modelscope/models/multi_modal/gemm/__init__.py": "f7dfe2ef851e579dc7b3faa679c607a97d21ebb2956f962a64a75960d1bb614e",
        "modelscope/models/multi_modal/gemm/gemm_base.py": "44ec3d29cdb4970dfd5c5acbe54789ac9e5ff9df2892bdb74bd740c1a39dec62",
        "modelscope/models/multi_modal/gemm/gemm_model.py": "e589aaaea23f0a30568ac16f6e3c2c8464694e2b0a71396632200dfb3505ae9b",
        "modelscope/models/multi_modal/gemm/tokenizer.py": "b870369d46569359bef8c2267d3a46a95ca8d7f7d90efb843f9b1ccbed5c4e29",
        "modelscope/models/multi_modal/guided_diffusion/__init__.py": "697ff20a0ec3c494a92cfe1b998b404ae6185325dc7322ee0d717d1863ef3888",
        "modelscope/models/multi_modal/guided_diffusion/gaussian_diffusion.py": "8ccbac39e4db2f96ed72991a42c93926e6aceb169a38cae72a248fd7a1214d59",
        "modelscope/models/multi_modal/guided_diffusion/respace.py": "7e8fe88e0fe06018c01011fbd4acb71e6da30b31c4c9817980ac512d6834f4d0",
        "modelscope/models/multi_modal/guided_diffusion/script.py": "e2768e37d63d917928a48f7382315f88001f2a7d92a3a73131b34d91cffb2242",
        "modelscope/models/multi_modal/guided_diffusion/unet.py": "6fd094be3586762e2d3241100d0dd8ddfa3103fcfc0dd8877783cf6cab954179",
        "modelscope/models/multi_modal/image_to_video/__init__.py": "954e049fe90934f8edf25555926bfeda50fdcee219d8c16993c54fde2170f5d5",
        "modelscope/models/multi_modal/image_to_video/image_to_video_model.py": "639487456d95f4e70290023e091f40e52298f967225ba4170cf90da94eae2483",
        "modelscope/models/multi_modal/image_to_video/modules/__init__.py": "9f46cf49c8e8e96493e3e5f58c25dd871af8acbb430737832e6ea459d0e9e04a",
        "modelscope/models/multi_modal/image_to_video/modules/autoencoder.py": "8d7a2bc2ddfbf1b0e301b15e5b59e87e40c08f00e46eb9ec07e64c5061f9add4",
        "modelscope/models/multi_modal/image_to_video/modules/embedder.py": "d943a106613c03f9ab076bd7381799ed18a180fb5640fd41a0041cecdf1858a7",
        "modelscope/models/multi_modal/image_to_video/modules/unet_i2v.py": "d48d6ca1711f5c38eee409ae08825687b65d58b2447d4353776de13d5a1e4a04",
        "modelscope/models/multi_modal/image_to_video/utils/__init__.py": "4e05f81cf8a83d439baaec4b4276dcd7b4bf8b489b24770934ffb8b3b73ee9cf",
        "modelscope/models/multi_modal/image_to_video/utils/config.py": "a61a7d192bb8c2598ab7d860c5a9db9df24cfafc3f6d1995172ffa2afad4daf5",
        "modelscope/models/multi_modal/image_to_video/utils/diffusion.py": "06c2f9805293d8683b95b9324de32822523a2a06ac21708c2420e23bd3996002",
        "modelscope/models/multi_modal/image_to_video/utils/seed.py": "57bc565095c4b948e2b5b530e23132172769eacfa4f117870e7771a21da8194e",
        "modelscope/models/multi_modal/image_to_video/utils/shedule.py": "71637ca2792ef52c1d582ea2f43127ac7347d4e55244d42b6f112721b908d212",
        "modelscope/models/multi_modal/image_to_video/utils/transforms.py": "a0a34576fa810525f929811ad6b22281e153c10fa399a4e5ceba964a1fdb08e0",
        "modelscope/models/multi_modal/mgeo/__init__.py": "11f84e401c8ca23036825e786c8bb1cdebef7f380e25e9cf88ff42ca0dc826f1",
        "modelscope/models/multi_modal/mgeo/backbone.py": "f1389cf7fd552aeeb4dbb1626614304dc1d64e3c921b3c0192b0a659d253adcc",
        "modelscope/models/multi_modal/mgeo/text_classification.py": "acbf0e0712fe6c4c473ee1dd65a0259daf7a2715fc88cc64693a425c01ee5a61",
        "modelscope/models/multi_modal/mgeo/text_ranking.py": "56103559f3fe45c63cbef422d2e54f9823fd34dc3930e3c420eced8b87865892",
        "modelscope/models/multi_modal/mgeo/token_classification.py": "6ec5e75b9f7c2816bc2bb215279f96f11d5c036ea966aed286e093303ad7e938",
        "modelscope/models/multi_modal/mmr/__init__.py": "67aa2ad2a14b4369849588c084abe6b126583a8518a5d184bce3f74f08c6ed10",
        "modelscope/models/multi_modal/mmr/dataloaders/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/multi_modal/mmr/dataloaders/rawvideo_util.py": "111e40decc730558350c7cb7b81b40fe265991366b6a65b1c059223744670462",
        "modelscope/models/multi_modal/mmr/models/__init__.py": "6a093a4746aed4175f25f49e82e172d8a98605f5102829a337122d18d2814f77",
        "modelscope/models/multi_modal/mmr/models/clip_for_mm_video_embedding.py": "ac6d5502b060ed12ef86424f80d56e05f29f22f5a5adf9aad2974c48118966d5",
        "modelscope/models/multi_modal/mmr/models/dynamic_inverted_softmax.py": "fe7ac21c9310ef8eda49e8622b29ec27f21e5a82726ce47527a7c31c5cc8a111",
        "modelscope/models/multi_modal/mmr/models/modeling.py": "118db081df33c24c6a2749551bd50355d1cffd937a0861354d24c6097d36b28a",
        "modelscope/models/multi_modal/mmr/models/module_clip.py": "73d74ec9ae53dbec23c99afa654b61c19097b836f49c443b142642090a718a91",
        "modelscope/models/multi_modal/mmr/models/module_cross.py": "44e494294467c2b29d8a62d63e4f31af59129853bb0830444aee63c8ddf66361",
        "modelscope/models/multi_modal/mmr/models/tokenization_clip.py": "43dab59cbff5fd6cc5441ec0cdc2d157100050f7036fe67abaeec0065670e22c",
        "modelscope/models/multi_modal/mmr/models/until_module.py": "a2c3091c57e017e773e3557194ea2cc9533e8284f76b74d0990955fffd11194f",
        "modelscope/models/multi_modal/mplug/__init__.py": "885fbaefd13cd8564e77b564cd6e43c3616f73ad1e9f2ad5a236ad906ea25263",
        "modelscope/models/multi_modal/mplug/configuration_mplug.py": "f1ad574c57c914261a52d9261778cd9ea69ce0dc8b71eff3965d06f0e0af6016",
        "modelscope/models/multi_modal/mplug/modeling_mplug.py": "e80c4a8b726e053d35fff3e2c061d2e3f9d5d811946d6e1955a3293736651486",
        "modelscope/models/multi_modal/mplug/mvit.py": "d673c951819f77d3f5b4f1603adab0a7d509687d78c41dcebf05201301302774",
        "modelscope/models/multi_modal/mplug/predictor.py": "c254cf9f58f408485d335db59e7783c7780fb508a8aa7b14f33dea984d6f73db",
        "modelscope/models/multi_modal/mplug/clip/__init__.py": "5154ec8153c3bcde0b59e116b866b959b1057f306db0ddbacc6ab86bbd6dff0a",
        "modelscope/models/multi_modal/mplug/clip/clip.py": "2f4a3ebb0d13673963a5ee1e2e828aae7b28b8faf6dfd94d81e15bf5d0fa237e",
        "modelscope/models/multi_modal/mplug_owl/__init__.py": "d03f3b2f49b312f342ab2de22378c0c21b9dacfe7a55b43b9aad852bcb1bd003",
        "modelscope/models/multi_modal/mplug_owl/configuration_mplug_owl.py": "1410b0fd61bfcdcc043a1532d2d7eaf7fd9ec225b96dda95dbac9423cb354514",
        "modelscope/models/multi_modal/mplug_owl/modeling_mplug_owl.py": "c3928edb3f9febfe63f82903d62f32ac25e70fe2dc064df632f1cbdde433372b",
        "modelscope/models/multi_modal/multi_stage_diffusion/__init__.py": "1c28842c97b144712ca68ea87a1615d90c813cf357ee463bc11088597b52e730",
        "modelscope/models/multi_modal/multi_stage_diffusion/clip.py": "6741024651684ea011bca8749b4492aa018682e6e0a9cf765a55a0df2fcab923",
        "modelscope/models/multi_modal/multi_stage_diffusion/decoder.py": "747ef1a438e69f0427cdfa76c296caa257a0def435b7161ce988956ccc47ada5",
        "modelscope/models/multi_modal/multi_stage_diffusion/gaussian_diffusion.py": "d52b33ba031685becd0530bca807c1e2f65ad44b0c1cc90727a68fcbb40badab",
        "modelscope/models/multi_modal/multi_stage_diffusion/model.py": "a88a98b0c4f7f140f3dc1c21f6cb3ba0db63fa606db5022e66c70cb6614fc9dd",
        "modelscope/models/multi_modal/multi_stage_diffusion/prior.py": "4f0a2e78fd262d6f4e4a165939d869f498c34eff8c7b73ef31c8291f2f4f553f",
        "modelscope/models/multi_modal/multi_stage_diffusion/tokenizer.py": "922901eb12c0b22dc2c693636dd2d91a529e257c0641c1d28d76831092cce3dc",
        "modelscope/models/multi_modal/multi_stage_diffusion/upsampler.py": "9e591ace4c6dd12fe379a0aa537721d4814505f0d28dc477ce9ee383fcd4e74c",
        "modelscope/models/multi_modal/multi_stage_diffusion/xglm.py": "dbd607fcd51708f23226ca5ebb3a5c95b6890c1a54e376fe008bc47a9e3e00e4",
        "modelscope/models/multi_modal/ofa/__init__.py": "067d9c7496fc5bbd319caad2317c44178af11559e72c3fe555db9f8fb5aedf51",
        "modelscope/models/multi_modal/ofa/configuration_mmspeech.py": "36a9081ad706e6dac5fc2407366b57c124991406f2a0a044b77566b982bc0e3d",
        "modelscope/models/multi_modal/ofa/configuration_ofa.py": "f48710b5d5b4835a059a4e57222e183c90dd27db9287703c74aa09bef1836085",
        "modelscope/models/multi_modal/ofa/modeling_mmspeech.py": "5ad1f00b97632c89c584746a7d940ec5834e3df83abeb4906b5bdad0db77e748",
        "modelscope/models/multi_modal/ofa/modeling_ofa.py": "77b2af01d8127722e6da8457b9baadab04c0fe72a2ea036780c49196a8073d59",
        "modelscope/models/multi_modal/ofa/resnet.py": "c3058a8feb927947ac031122aab2cb3e1da980711120f9a6523117c8b1221312",
        "modelscope/models/multi_modal/ofa/tokenization_ofa.py": "305966849caa535375e8f28e7f80045dc021192686a159d268b68000f16ae34b",
        "modelscope/models/multi_modal/ofa/tokenization_ofa_fast.py": "acf4d2e740056d670c6ff80c1b856cbcf007a17acc5a958c658cef8452d35499",
        "modelscope/models/multi_modal/ofa/vit.py": "507ac2c10a7030b923f4242a1beaadfd969953014e664e2f11572ca8c7ca98e1",
        "modelscope/models/multi_modal/ofa/adaptor/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/multi_modal/ofa/generate/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/multi_modal/ofa/generate/incremental_decoding_utils.py": "7090e0dd189a2bb3450ce3486f65daaa4454e4b5a5e86650afd56cdb75421846",
        "modelscope/models/multi_modal/ofa/generate/multihead_attention.py": "2c7da20dd7a19b23afff7fc44ee6578ab3b994251e6fb016970a8f9d34b3af4b",
        "modelscope/models/multi_modal/ofa/generate/ngram_repeat_block.py": "bb644480a4bee51ece4da3586bf0bb1b7b68330025fbb5817ac942639941e9cd",
        "modelscope/models/multi_modal/ofa/generate/search.py": "df6e7700c09fa7e733b1c57e4beb91e39f93a1d866efa30cc09f2575bb0776fa",
        "modelscope/models/multi_modal/ofa/generate/sequence_generator.py": "85e0a344361c795d2a05eea8e49be175ca2058ef3f63de6f7fdecdda23d3e32e",
        "modelscope/models/multi_modal/ofa/generate/token_generation_constraints.py": "8e60f4e4e2c6d6aeb0f7592e4b7255827c3625acc3f5333e10022a37deb0c6af",
        "modelscope/models/multi_modal/ofa/generate/utils.py": "1233f626ed08d86845696ad286fcf9a1564b6b5fd88a5481fd72a358c8f87cd1",
        "modelscope/models/multi_modal/ofa/utils/__init__.py": "23f00d77175c207a64233217735c8a3a55b0cdbe286341704cfab5918b60cd0c",
        "modelscope/models/multi_modal/ofa/utils/constant.py": "11a901af23259945b601b06cec7f970cdd8603fdc1ca0a9f79fe3c929e0dc867",
        "modelscope/models/multi_modal/ofa/utils/utils.py": "96684634449ef9950131e7ee2534b632e864e8f7d033641522276cec5954d5d1",
        "modelscope/models/multi_modal/prost/__init__.py": "5c4d010f57922979ccf453a4e633b5f04b2f1e16bed353c2110e1a7d462ee90d",
        "modelscope/models/multi_modal/prost/dataloaders/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/multi_modal/prost/dataloaders/rawvideo_util.py": "111e40decc730558350c7cb7b81b40fe265991366b6a65b1c059223744670462",
        "modelscope/models/multi_modal/prost/models/__init__.py": "89cf7eed3a1eb25bcbf6f2ec3b6a92613a553a34c28767e12d6f881d4e044b45",
        "modelscope/models/multi_modal/prost/models/modeling.py": "7ad25f8de857509f6c49085dbc82bfc908c02256659892a8e0b7c1ddcc187f58",
        "modelscope/models/multi_modal/prost/models/module_clip.py": "44fc6679bb46c93376f4cb264c91d4e6ea9f5ee7f73b5e4a24da76137c13add9",
        "modelscope/models/multi_modal/prost/models/module_cross.py": "01fe6084eb78af23618f871a7b1cb86deead4479202df116f0c1736cb5d6c638",
        "modelscope/models/multi_modal/prost/models/prost_model.py": "4e43168596adcc6206bf507a033534736f247a06fc68865fe21cea9854598c6a",
        "modelscope/models/multi_modal/prost/models/tokenization_clip.py": "43dab59cbff5fd6cc5441ec0cdc2d157100050f7036fe67abaeec0065670e22c",
        "modelscope/models/multi_modal/prost/models/until_config.py": "00f77c3a6995a17efb53a944f3a1fe9be28970e3cf5f7ec2ee51a9373ba0899a",
        "modelscope/models/multi_modal/prost/models/until_module.py": "9596bd8e13c10bcef20a8f9f6ce758e65d89fe6649fe5afc05f9879987a47ad6",
        "modelscope/models/multi_modal/rleg/__init__.py": "5bcc07dfe94c9dd6425e1326c225de5e1ab9fca80fe5a2b8d81f2ed0647740b0",
        "modelscope/models/multi_modal/rleg/model.py": "7397bd08f46fe828064078bc1515af1000d2efb3755881e1e76508665979971f",
        "modelscope/models/multi_modal/rleg/rleg.py": "88942546580ba493dbd2bffa9f3e1361c45c4f47c4c8aaca40daca6ddac2b97f",
        "modelscope/models/multi_modal/soonet/__init__.py": "ea0c9b8184b9d185efaa413a8f108c0ae67677b9a8bc2049d38d66c3eab0c875",
        "modelscope/models/multi_modal/soonet/blocks.py": "6ead475431b3a15b8b4f4f0a8af336518b0faba7aa6de0056a331750fa2398bb",
        "modelscope/models/multi_modal/soonet/clip.py": "4c9ce946e3ef16206af7b6efb58abc6d0370ddd59a5d97919a7d26dd400a743e",
        "modelscope/models/multi_modal/soonet/model.py": "e32d9e8805468f552e282d1d06d4591c9db2f9baf2825048476494f06a93e0d8",
        "modelscope/models/multi_modal/soonet/swin_transformer.py": "40038d50a460082fae62ef30feace1137af894f9806e6beaaf975db0faea6973",
        "modelscope/models/multi_modal/soonet/tokenizer.py": "fe8d4cf9825d0653076656efe8e09012768c87e637b7afddf008e77fec125973",
        "modelscope/models/multi_modal/soonet/utils.py": "89306d8e6c7bee3e1bf6f326ca26e1aa32d04dadfbebd2df7dcacb20a662300e",
        "modelscope/models/multi_modal/stable_diffusion/__init__.py": "9a350858e15098956f3e1e4c3b116057e2f1e3eb5bfb423d97d9dcf083a61890",
        "modelscope/models/multi_modal/stable_diffusion/stable_diffusion.py": "70410ec882bbcf218980fb47d4e55e63880d37e96e7f2e0947aae27ad4b62634",
        "modelscope/models/multi_modal/stable_diffusion/stable_diffusion_xl.py": "1fb5bb201090a677e0b6253eccde16b90d8e3b15dcef5c949f253d8e9aae2243",
        "modelscope/models/multi_modal/team/__init__.py": "77560dde6b41b08a677c30d1d9881ae52c899b92dc6439128dbd8ae3633b7748",
        "modelscope/models/multi_modal/team/team_model.py": "751711314fff44ceb1c8d7152e96fec28d84767d69f782e05879925144566821",
        "modelscope/models/multi_modal/team/utils.py": "9b62ddf071a3f9266b5d144c4b92caa073cfca4d19ee737bd2b8832ded9c9922",
        "modelscope/models/multi_modal/video_synthesis/__init__.py": "28f24b447853bf72cbdc8900f42c43775c26d44774159df3b3c220a067e35ee9",
        "modelscope/models/multi_modal/video_synthesis/autoencoder.py": "57703b8475232daf2da2e9eadf469c3f23a2c4002c3989c0c94547a49f9799ea",
        "modelscope/models/multi_modal/video_synthesis/diffusion.py": "6b62600259dac0a9b2d29a6a814c391865eb08a0e513f526c9c8841ba7253932",
        "modelscope/models/multi_modal/video_synthesis/text_to_video_synthesis_model.py": "dc066e44cf5d9115104da647cee1bd842288920acb6c3517827031444ff69ff0",
        "modelscope/models/multi_modal/video_synthesis/unet_sd.py": "48f98998de0fd158bd97620d10955da9a9d503d172a61de1d2d81806caea8fcf",
        "modelscope/models/multi_modal/video_to_video/__init__.py": "6132bfd9b6ae18f498cdf730ca20e00d4e3e4480e4291fdfa0fc8d8c23f5ab63",
        "modelscope/models/multi_modal/video_to_video/video_to_video_model.py": "5938125cf28f9f18aa44c3df6103a395aa868477d31368fd1b1ee89873fe53ce",
        "modelscope/models/multi_modal/video_to_video/modules/__init__.py": "62dbeacda1158d8e7144a341b586d9e5c3ce46918b2f0b72b7509c7fb30b43b2",
        "modelscope/models/multi_modal/video_to_video/modules/autoencoder.py": "f286c67d32b1525fbd31fa66f3f9d09c2276ea96a84296ed43116bde347c2a16",
        "modelscope/models/multi_modal/video_to_video/modules/embedder.py": "91843012c657fedc91dcdfe8366882e351c0537570e60530f706e955ed4108b5",
        "modelscope/models/multi_modal/video_to_video/modules/unet_v2v.py": "59aac3114197685dce7cf1ce35973ea2246483dc24391a3067ef56195894ee7b",
        "modelscope/models/multi_modal/video_to_video/utils/__init__.py": "4e05f81cf8a83d439baaec4b4276dcd7b4bf8b489b24770934ffb8b3b73ee9cf",
        "modelscope/models/multi_modal/video_to_video/utils/config.py": "04cc03e3bd179be5a1540273ba3c1fe71e3a6adcffb32ad07e77f8ec0578f928",
        "modelscope/models/multi_modal/video_to_video/utils/diffusion_sdedit.py": "679f6b7d79c0933a98f0f896a2543f56d7e7824734aeb7c81588050e9a0f78dc",
        "modelscope/models/multi_modal/video_to_video/utils/schedules_sdedit.py": "858f88ecf396e73f45b53a6416a0b9608fad2116239f8c51a92e04d56f3c5b12",
        "modelscope/models/multi_modal/video_to_video/utils/seed.py": "57bc565095c4b948e2b5b530e23132172769eacfa4f117870e7771a21da8194e",
        "modelscope/models/multi_modal/video_to_video/utils/solvers_sdedit.py": "c463b0ec770738c3676dc2ff4edb48b1c8fea5229456432a80488aeeb0e63eee",
        "modelscope/models/multi_modal/video_to_video/utils/transforms.py": "a0a34576fa810525f929811ad6b22281e153c10fa399a4e5ceba964a1fdb08e0",
        "modelscope/models/multi_modal/videocomposer/__init__.py": "7c725c6e3a66d2e1fba23320bb43b1ecabbbe9b2ffcc82fce97ccb76adc3f54c",
        "modelscope/models/multi_modal/videocomposer/autoencoder.py": "d89d797658d6ba595886a94d607c85cc8ef7ff9bb7b412c63de37d2a1df2faa8",
        "modelscope/models/multi_modal/videocomposer/clip.py": "d3b7ffe9f14f5327a3c61506842a6d9c7418648adc9bc543095fc4149303f159",
        "modelscope/models/multi_modal/videocomposer/config.py": "3f1b7082d06782fd5ffb8dd844f9e47f1839832d13c5097300852940a5ca8378",
        "modelscope/models/multi_modal/videocomposer/diffusion.py": "72d344261f4aa25f6ac9e53047f547f096cc260aec7dbb7716eb2bc3908518a4",
        "modelscope/models/multi_modal/videocomposer/dpm_solver.py": "814cf2e8ed9d4e81db843d0e7d3075e969be2285cd0436627ff1ce22abb25a7b",
        "modelscope/models/multi_modal/videocomposer/mha_flash.py": "755e87d96898947d07c9d86552db0ad46fd9d3f8392a1b84e0524a84950b8df3",
        "modelscope/models/multi_modal/videocomposer/unet_sd.py": "a2a7a8dc6537afb1ed707518d7a4a379937d72f0efed056f2e73871e5f6de1aa",
        "modelscope/models/multi_modal/videocomposer/videocomposer_model.py": "75171af9d54f3475e3d574d42f7cda8329133134d4b69d885268b95365803cb1",
        "modelscope/models/multi_modal/videocomposer/annotator/__init__.py": "23f00d77175c207a64233217735c8a3a55b0cdbe286341704cfab5918b60cd0c",
        "modelscope/models/multi_modal/videocomposer/annotator/util.py": "4818c6d2ec60a322304a7738d8dacee45f2a50caf1b4014e85aaa35c02bce9d6",
        "modelscope/models/multi_modal/videocomposer/annotator/canny/__init__.py": "48acc47e01f0f05fa5b498873d8a9275e10585564e489a6e91f09c6f6f4a774a",
        "modelscope/models/multi_modal/videocomposer/annotator/histogram/__init__.py": "a4e56b73eeeccf0d0b3c2878eeee285fba284d54795d568c66e01b31f52e0a79",
        "modelscope/models/multi_modal/videocomposer/annotator/histogram/palette.py": "921331e77d2d16e47ede49faaa193068fd8d8d285c7df0bf348477881374f899",
        "modelscope/models/multi_modal/videocomposer/annotator/sketch/__init__.py": "ad4e6b184ea81e06cf70455611788f0fe8c72441ee463c6216d7c66ddc163781",
        "modelscope/models/multi_modal/videocomposer/annotator/sketch/pidinet.py": "c4475a975f2981b2d990b48ae3cb6a31e6dd85e51910479d683dc792443345f7",
        "modelscope/models/multi_modal/videocomposer/annotator/sketch/sketch_simplification.py": "55ae56573874e4c4e4e59f01105b9760cc14a61d3fd4db5107f2aee198ce80ff",
        "modelscope/models/multi_modal/videocomposer/data/__init__.py": "b73099f2330864ad779c7e66d3a42dc53a4b4f1fc4f2c88ff1d333d0b4d4156e",
        "modelscope/models/multi_modal/videocomposer/data/samplers.py": "c0695c78021a0650456f69c877635307ab5e4134369402a04fb462235d3a80a2",
        "modelscope/models/multi_modal/videocomposer/data/tokenizers.py": "3818039d99debe1c4996f2abc3fa854b6fb99d288c480bb77d25801bba4f0152",
        "modelscope/models/multi_modal/videocomposer/data/transforms.py": "ed87aa7240f64087276935fe2bb48da4cd870dcf2c444f5727bd9aa2df978fb4",
        "modelscope/models/multi_modal/videocomposer/models/__init__.py": "8d113e982e636ab40efbe99770541af4c670b51b11af90813bfc7ab511b232cb",
        "modelscope/models/multi_modal/videocomposer/models/clip.py": "874319d2c14e50cf60dd482a24c7461d4524378d8786206c0c7c5f57390c7b8d",
        "modelscope/models/multi_modal/videocomposer/models/midas.py": "0f7f57736afb03ce0a38f4cb6ba1d7136b13d3893b73262abd8749076c1a3f0b",
        "modelscope/models/multi_modal/videocomposer/ops/__init__.py": "08c6e464b9bd2ea0ef1b5c712b69dd46ef5dafb6585bbb31d39c5bc821c54fad",
        "modelscope/models/multi_modal/videocomposer/ops/degration.py": "093c74e294419b466ba1dc350f5258da90f8f6156235ddc3c0b9c7c64e8b25bd",
        "modelscope/models/multi_modal/videocomposer/ops/distributed.py": "1cbdb1528a31588cefa2972a3b82c3db33c8ac497731e1cfbc439b16bfb33175",
        "modelscope/models/multi_modal/videocomposer/ops/losses.py": "92be5df2153f8db3bfbc325fac77bd6603fa9ec71ef4ec6cdbcd635ccfeea636",
        "modelscope/models/multi_modal/videocomposer/ops/random_mask.py": "760e006a21eccf6aa73b290229234b1f2bbcdb297b5251b483b30ea11b7d7d21",
        "modelscope/models/multi_modal/videocomposer/ops/utils.py": "c2dd554c4f276cb231d2900ba64d97e56d5c12a4ea23b1d50b2cdaf849683699",
        "modelscope/models/multi_modal/videocomposer/utils/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/multi_modal/videocomposer/utils/config.py": "eb4ea46bff9250a34088322e7838bb40aa243a45e871666e651f625879a53d5c",
        "modelscope/models/multi_modal/videocomposer/utils/distributed.py": "89d7bbc7447cccce86d48a7edc65a6b41a64481049f04750287f62c610a7151e",
        "modelscope/models/multi_modal/videocomposer/utils/utils.py": "a832b52e0b6b1fae87d55cfce2b63ff71b5f9431a80da08a8bb7d36547bf6c3f",
        "modelscope/models/multi_modal/vldoc/__init__.py": "1c9868535a74a931464fcc87d7b7e0cc00a1ab9efe514d1117a6b57d777b0b18",
        "modelscope/models/multi_modal/vldoc/conv_fpn_trans.py": "7a546a32415631bb0c66fc00a4d00b8fac3a5319159c321959534cdffdb14cde",
        "modelscope/models/multi_modal/vldoc/convnext.py": "7a7f4355fabbcc06e2b11c3d781a1c0d9492e16e179d9d327151758eca8363bd",
        "modelscope/models/multi_modal/vldoc/model.py": "23e4babf3a9fac38a15f84e3631977203a5b277df05a15ff823b9f8e4491a482",
        "modelscope/models/multi_modal/vldoc/modeling_layout_roberta.py": "7690af6a42d0e8be4fb4bd7a31a1d62f624f96598b10aa8315ea9da883beb61d",
        "modelscope/models/multi_modal/vldoc/processing.py": "3f4ead605846cbd3acaf334cc7d3065fb1afc1fe5825f2e8bc558f584124e587",
        "modelscope/models/multi_modal/vldoc/tokenization.py": "361196480a73e003067aecb5642a5c4b76f6ea74111fc636acaea7cd072a47e9",
        "modelscope/models/multi_modal/vldoc/transformer_local.py": "70f37952252b629304ea5b0370261bb01da59e4b860cc6c6e4cf4f71892d59d7",
        "modelscope/models/nlp/__init__.py": "ea412740468b6c2e0ef6a31c9e538eca7761f9ad9e1a836735495920a1d1b0f7",
        "modelscope/models/nlp/T5/__init__.py": "e4dc42809c6c91f9acd962289115f982291ceb5ab474eb44c4aa18c05d47396b",
        "modelscope/models/nlp/T5/backbone.py": "c793c0dccfaf7522d495a6b9466950d20a06655026353e0e9fab69d6b73187b0",
        "modelscope/models/nlp/T5/configuration.py": "8381faf952a364b166b41b8b2102fc087fe88cb97d505213eda89b401ab31b15",
        "modelscope/models/nlp/T5/text2text_generation.py": "84bdf7f8311538ad2ccebd5040a7941857ffd6f204a7fc0e97593dc3e0a69c7a",
        "modelscope/models/nlp/bart/__init__.py": "a4a25aeb907d4602e9bd67f2460a543bdd6e5735a71354d50e85f4933c362c3f",
        "modelscope/models/nlp/bart/text_error_correction.py": "bbdff771a796f77950cad0625d1847942497fb2947709c4f425c6f6aaea2d637",
        "modelscope/models/nlp/bert/__init__.py": "59bb584ca75c76ca3c0972449a39573034d7dfd1258a3f3823b67cef9055764a",
        "modelscope/models/nlp/bert/backbone.py": "31cbb2fb6942c583e152472419cbd7e4af453e235b97c38eff6a1c0a9886e2a0",
        "modelscope/models/nlp/bert/configuration.py": "44f2efbdf1e1a4b91a1fb3c21fdf86eb5a16880b610e833160bdf54ae5ef5d4d",
        "modelscope/models/nlp/bert/document_segmentation.py": "5453cba11da60fa45cf24b4f4a17febdd62130456613045dcbb0699f585df5fe",
        "modelscope/models/nlp/bert/fill_mask.py": "25c5775c05078dde80ea1ec8af44735cd9a9342696f4ecf72ec640e2e6d88422",
        "modelscope/models/nlp/bert/sentence_embedding.py": "8b6b8189830cb801456aa5a52f88d68cd48e5718f03abf25f0176734710dae08",
        "modelscope/models/nlp/bert/siamese_uie.py": "dc1465ee7658070cb3434b8ac5e0832cda891f3ecc76bff533b57368428ea4c7",
        "modelscope/models/nlp/bert/text_classification.py": "d41ab5603578212edfc6408118f3fd4efef107c5e24deaccd5ba3471748bc5de",
        "modelscope/models/nlp/bert/text_ranking.py": "22259ad7a1d1ec7d6d716d15495d99ca4b79f6cc0865ac8229824045eae5a8bd",
        "modelscope/models/nlp/bert/token_classification.py": "6db5100f30d29f7e4386b3711406488ef6167716e54285e75f7d304fb4b0eecc",
        "modelscope/models/nlp/bert/word_alignment.py": "b4f377c168c8c6d6837b22de55dd08f86f1f888ab614d0089586fe60ef018e36",
        "modelscope/models/nlp/bloom/__init__.py": "c6c741d3fa868e12bab08c0fa3b72410230d03cd8116b49a02fe3cba9c9c8b77",
        "modelscope/models/nlp/bloom/backbone.py": "f3c51d6a9afe9b2635d899ec5c441670d55d58593dbb64b1b1f66da4d6f94980",
        "modelscope/models/nlp/bloom/sentence_embedding.py": "f13b2bdf1cceb435c2d2e704b40d36c894dd68e9754970b91a7454bc60c59dbc",
        "modelscope/models/nlp/bloom/text_generation.py": "486dd01d0938de932747c59ecc17e9a1ae55f4a4ec6bb67a331d04156df8af6a",
        "modelscope/models/nlp/canmt/__init__.py": "13b43e8dba83213afb0c1ff8adc3053f55a729bae9457dc39c4ccb6a1f1421fb",
        "modelscope/models/nlp/canmt/canmt_model.py": "7f4800cd08aea7939b366987c6b70dd3678390b18221900f23c9f97955b852d5",
        "modelscope/models/nlp/canmt/canmt_translation.py": "2e429d1be5804e3f3af7782716e2374b7f227cc5440ced5f42dbe76415c97469",
        "modelscope/models/nlp/canmt/sequence_generator.py": "73121e5067834443807a915d730e50cbc27e4907be7ff7c82c765cce83632f25",
        "modelscope/models/nlp/chatglm/__init__.py": "9979c722fab493368c4467e27e1ede47634663578e93433648e8978d92d3b5ec",
        "modelscope/models/nlp/chatglm/configuration.py": "ff007a72cc09d5c048f356b8e7391cf8d671209b72fc20c20b4639b184c05a70",
        "modelscope/models/nlp/chatglm/quantization.py": "dfa4ee8c4217a379abcb69880abe12496917845bc21dc0e0805d2d332363d48c",
        "modelscope/models/nlp/chatglm/text_generation.py": "0ae93b0dfe32cd6a579c2291eee5b2d0e125c957a2e1d41b13d090e1c05d9fef",
        "modelscope/models/nlp/chatglm/tokenization.py": "b5a1cab1c051e5f4e558fd9a2ad682f1ae50cff54bec2ec6d64e20f94f383488",
        "modelscope/models/nlp/chatglm2/__init__.py": "5ab56b95cf119678520a04a74fe4903cb537d9d7d26c4b63a0a794d40cdedb92",
        "modelscope/models/nlp/chatglm2/configuration.py": "c50aba5efd7d6c33b7a705c828d3c8ae7d57d45afa979b5be66b787eb01dd8f4",
        "modelscope/models/nlp/chatglm2/quantization.py": "3a9d197e5b94fddbee030e44280088e504a99c50ab1a2eb478a4012a128e9f7e",
        "modelscope/models/nlp/chatglm2/text_generation.py": "fc507a6d35f3bc253f61107bbce83ce836f8084b103caf473b93ae2391927575",
        "modelscope/models/nlp/chatglm2/tokenization.py": "16a518478648c661fc5e6e4b9cc6f145bab454800bfe09b645e0fdbdfbe45338",
        "modelscope/models/nlp/codegeex/__init__.py": "96f59a0ef83da612ec9defe1533a0e50dc284e5ee630c03d7473d5aca2fbe63b",
        "modelscope/models/nlp/codegeex/codegeex.py": "f363a1f4174f47093c1d47119c0f2d95fd67af5f731728c6eec55a5a14550897",
        "modelscope/models/nlp/codegeex/codegeex_for_code_generation.py": "a4ba8f9796c362cbdf240bd098c104186614dbaa1a7f88990cac46f6e1423547",
        "modelscope/models/nlp/codegeex/codegeex_for_code_translation.py": "4b8a408461977b84e56934a689d42ad3777bd3729871f4e839529cb857ab91c7",
        "modelscope/models/nlp/codegeex/inference.py": "f7a2cebae2a2f2d3aacd1efe20b123272b0950511d5f4058c0b106eec191c51d",
        "modelscope/models/nlp/codegeex/tokenizer.py": "2c083abd5a9c452299e5b55e814d3dd3fbdca21b24b49ac22bab240ace7c0a2c",
        "modelscope/models/nlp/csanmt/__init__.py": "1a1bc9093c3f123b90c37730c7c9e2b2c3cba1b172cdf7b2baed40745779185c",
        "modelscope/models/nlp/csanmt/translation.py": "3de97738bedfef432ef71003040786542ad93b3948762e73edd399f08e2bf313",
        "modelscope/models/nlp/deberta_v2/__init__.py": "cccfc5ae9c58c08243fa204248f181b49b6c0afda71ade59bf4e7af375be8e12",
        "modelscope/models/nlp/deberta_v2/backbone.py": "e33fe8daf25713384584b5b3e0f6c1b0080f377b1e39dd22aabdb8947b2c16eb",
        "modelscope/models/nlp/deberta_v2/configuration.py": "c3dd266676883f5f33d0c5a00b50c69c5cc7d504fe10e87c0f1fe91c6736be9d",
        "modelscope/models/nlp/deberta_v2/fill_mask.py": "d2355dc8254a53b8fbd652a75ef10072f9f862175f33a8e7f654f530186a8b56",
        "modelscope/models/nlp/deberta_v2/tokenization.py": "22106f55553158c67a128be7b936f006317954a64d15dbe94b320cb581f7cdff",
        "modelscope/models/nlp/deberta_v2/tokenization_fast.py": "36d88226ae4e76fdd42e30ebf933f10a192e80d53476f4cda958918528c4cde6",
        "modelscope/models/nlp/dgds/__init__.py": "e8ae76c0f3b5f98f4462830bd0ebca81c1ce81b53c3734e24dbe3b95328c9bd3",
        "modelscope/models/nlp/dgds/backbone.py": "0e09e2bef19962e88855db5b57a699ae3eed11a183a59e6f83012b852a56f2c5",
        "modelscope/models/nlp/dgds/document_grounded_dialog_generate.py": "a39b4ca79597558804a08cb5069f731a36fe1207ae39fd79e94e97acb0960c60",
        "modelscope/models/nlp/dgds/document_grounded_dialog_rerank.py": "17156396abb839e58f875eaff020b45254def78dfd1a62fd75a530228b1c2350",
        "modelscope/models/nlp/dgds/document_grounded_dialog_retrieval.py": "c3703ef0b11f37b9956e3ff39f58255576705f35413392f7d0769e57a0145f81",
        "modelscope/models/nlp/fid_T5/__init__.py": "4e23d9057e8b8861903fdac1c2dd803926debea01c1450013b182e2d721dbc5b",
        "modelscope/models/nlp/fid_T5/text_generation.py": "d119fe892aa7a54cd6e6b3c038ff1494b5808c71ec9ae50a36053d1594137e01",
        "modelscope/models/nlp/fid_plug/__init__.py": "b5fae210243d6751b423f50ca0ae8ca86716654bb42877ec78870af2b5d31762",
        "modelscope/models/nlp/fid_plug/backbone.py": "6f2061e26a85c694eafb678c3eb2da6372d4e2f33ec4cfafd9321322657e97cf",
        "modelscope/models/nlp/fid_plug/configuration.py": "a60b7e72dde3d2af4d7bc333a411d2f9e072ad5606e8af06baa9646bb698c644",
        "modelscope/models/nlp/fid_plug/text_generation.py": "b5309f282c14f434a3b4ee02947eef298eb5432b2e8ce872a89edb20e4d72695",
        "modelscope/models/nlp/glm_130b/__init__.py": "447dfbc6d68d3b2aa833d5c0807e1f187f235184a8540f6c4f0145a3c2ee1fbb",
        "modelscope/models/nlp/glm_130b/initialize.py": "df2d2ef78ce597f2debe6c8f6aafefbbaeadb7f4a9ce3e978f14836b0a1013ac",
        "modelscope/models/nlp/glm_130b/text_generation.py": "3d213292e95978980bdb97bf7408c0cead288849b62685e814f521551eb4bda3",
        "modelscope/models/nlp/glm_130b/generation/__init__.py": "5b935bcb96536f1511ff5206373373b20b236fa47b5724fc388c1e247021a570",
        "modelscope/models/nlp/glm_130b/generation/strategies.py": "f76ed16393cd202e846628ebaf08c017aaecc6a6371368438346d226b15b524e",
        "modelscope/models/nlp/glm_130b/kernels/__init__.py": "33e607af14c9fb10fd946f3b459cb3547d4f4086f2120f619f604e5351fcebc7",
        "modelscope/models/nlp/glm_130b/quantization/__init__.py": "fc06662aeac0e99caa29e421881d1aaca383496b452f03b267d18522bce52d48",
        "modelscope/models/nlp/glm_130b/quantization/functional.py": "be1f487a5532d284153be89145130146b4d869368399c62abc10a597da380ae6",
        "modelscope/models/nlp/glm_130b/quantization/layers.py": "7e07501ea49b1fad571211c860b509338130ab2f29aa2bd3ee2395eb75e2a343",
        "modelscope/models/nlp/gpt2/__init__.py": "fbe7bfbd8704a558ac4f144487315819c419f2c2bdcb810477c562277e45481c",
        "modelscope/models/nlp/gpt2/backbone.py": "ba22c09699255dfd9e47392feebbcfc1689e080f744f2824b05e2820dbc15279",
        "modelscope/models/nlp/gpt3/__init__.py": "3e414373b22ddd560a836a24c1abd54f88ee68558c2781370ad4faebc722c8e1",
        "modelscope/models/nlp/gpt3/backbone.py": "f94221cd886c7b073af772cd17c24feb94dce0dbd0bb3adb00c5bbab52949700",
        "modelscope/models/nlp/gpt3/configuration.py": "5c2674135c18ea101a892e5cd73a955855ae3c18c34d3052354ae71355628a7c",
        "modelscope/models/nlp/gpt3/distributed_gpt3.py": "9b6e6845c82ab5587fa616fdd189a8daad362bccbb946cde00a390abfd84d2ed",
        "modelscope/models/nlp/gpt3/text_generation.py": "bd3e52b9d796569b59b13d6e271f7a6645e068b1fdbc4bdf20a226ba0a4ba0ac",
        "modelscope/models/nlp/gpt3/tokenizer.py": "f7e1d7cd13fe04f2407bc286ab9ad448fb74b3ba7b8a03ab6be74ea069b78d7d",
        "modelscope/models/nlp/gpt_moe/__init__.py": "10dd30096690839d8375ba3b132f16622f58a6baf09002b5541328d35ac3f35d",
        "modelscope/models/nlp/gpt_moe/backbone.py": "f15ff59093b04cb7ee87e950efc0135d5e9d7af54db6e7fb8ac7ad9cc6d8875a",
        "modelscope/models/nlp/gpt_moe/checkpointing.py": "d70c7bd8e7c6d83ed12e701c73a0704a4ae377e203b04545adebb8dfbe1d6f0f",
        "modelscope/models/nlp/gpt_moe/configuration.py": "fdaae8b24cc5a7016e55a7bf1da6e85513a14ed835b80515695bf9e78bc603c7",
        "modelscope/models/nlp/gpt_moe/distributed_gpt_moe.py": "b69d3c49521051812d7c8e1650cc715e573635d13b9add221edd01f39c453436",
        "modelscope/models/nlp/gpt_moe/text_generation.py": "a9320fd3d7dbb94e4b0413c83f5cc03d7170fe215513ea170061d7a11340c718",
        "modelscope/models/nlp/gpt_moe/tokenizer.py": "3a88cddf9bb4d35d84cefa2d5fe477f394bbefad849b74767f62953671509986",
        "modelscope/models/nlp/gpt_moe/moe/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/nlp/gpt_moe/moe/experts.py": "aa9dc43bc3d0a1d1e72edc085b5a71a0d2fb68292069c61d44aa98cf1704f6fd",
        "modelscope/models/nlp/gpt_moe/moe/layer.py": "46712e7405867d048cf778aea0087a779037011495a5cf2b58cef2b6f7c5f0cc",
        "modelscope/models/nlp/gpt_moe/moe/mappings.py": "b9f02db5d1b18198a382ae8ec2428eee8f3e230ce11d56124067cff8d6fc37e6",
        "modelscope/models/nlp/gpt_moe/moe/sharded_moe.py": "ef21ed966c1b5363d9ff53f1d4187153f9059f7c90fb18635c6b0360753df61c",
        "modelscope/models/nlp/gpt_moe/moe/utils.py": "87fce359f4a170e7769314841e5a8812357fec68778b7cb5231c88fe875cd3cb",
        "modelscope/models/nlp/gpt_neo/__init__.py": "f0c7dd43f403ca66417d33dc7c7d15cb0d50881dccf984e48f7882d8f6ad2103",
        "modelscope/models/nlp/gpt_neo/backbone.py": "d24f9450e01d1494e944fdb1a8984ab199eb12bf1498000708d1eb1678b8b5de",
        "modelscope/models/nlp/heads/__init__.py": "2ec65fed88a125287a6c05c7eaa7b72dcaa66a6baadabe98b52da39aa83ee0ef",
        "modelscope/models/nlp/heads/crf_head.py": "7f200e9a459d07aab6513483ce5a899302e78e3bac6df4d89fa3f367d7b7e6cf",
        "modelscope/models/nlp/heads/fill_mask_head.py": "75cf35712e0e25fd06521b4c6c436cd56d7b9fa41e164889df43588ce3f07dcf",
        "modelscope/models/nlp/heads/infromation_extraction_head.py": "a53040da99c70154ef0b815b9f5b62d3f886385b361fe6a9cee5e6675abdc8e3",
        "modelscope/models/nlp/heads/text_classification_head.py": "7423e3f7901ec7f49ca344914f905900365f48f58e5d5897920a2b543a18ce06",
        "modelscope/models/nlp/heads/text_generation_head.py": "345a64fd3da0b98e50f2ffb316d2eb4952abbadb007cd71da28510495938f2f6",
        "modelscope/models/nlp/heads/text_ranking_head.py": "7eb557e143c09f2d50132f114e1fe745239b365aef0d0863c8671e84efed0c0d",
        "modelscope/models/nlp/heads/token_classification_head.py": "b734badfbb18897a4a11a798d63974aa5867981a16a057490b72080bd6acc1a9",
        "modelscope/models/nlp/heads/torch_pretrain_head.py": "9fb6f1547dadb0c147bd07bc266cbc796301da7ac1b5a820fcfcab796c242bc4",
        "modelscope/models/nlp/hf_transformers/__init__.py": "c7894005cbe59dfaed9f666d562503536597426643ca7040b0c049c695bb810f",
        "modelscope/models/nlp/hf_transformers/backbone.py": "1ceef2ca0e0cb54f2859d33d2875d5190be7d0f99bc58124c0342a5095fa38a9",
        "modelscope/models/nlp/llama/__init__.py": "e4e5ab5d5fb7b1eaed6118c0860b82f110f01978122eae7610b93eb700b9eb27",
        "modelscope/models/nlp/llama/backbone.py": "c7c04d65cdf6d2a7eb255330738a615fad1e3962d38475a1a0f7b59787e87160",
        "modelscope/models/nlp/llama/convert_llama_weights_to_hf.py": "0646102da3a610f2b5c7feec7499003f4dcd394f3db03dcfff04891bd02b069f",
        "modelscope/models/nlp/llama/text_generation.py": "f278ddff6bf30263c3daf94f61688aa395a26376344f543c32598174f5a2a913",
        "modelscope/models/nlp/llama2/__init__.py": "22eb0830411b638e41fe9c8a07dc7cfa4d480f1d2fd0391172026dd5fd951e94",
        "modelscope/models/nlp/llama2/backbone.py": "45e345163b7951f44ed2a818b95beebaf2a429620ac16ce6653308cd4dee8735",
        "modelscope/models/nlp/llama2/text_generation.py": "189dc6cc9a4ba90472d478d0075ea783de7ea51f1aeab405589d74244746c2cf",
        "modelscope/models/nlp/lstm/__init__.py": "2f2c3ca3dbf6e7ae36bf186bbada91e59285673b38b3c0afc3acea49c1e454a1",
        "modelscope/models/nlp/lstm/backbone.py": "24de5bf66813568d7ed348755c2d7cd6d1100faa219248d89cf6e2046f7a9c05",
        "modelscope/models/nlp/lstm/token_classification.py": "3fdc1be3de5a8588b001446cdb33b22de861898e22559bd94ce19d0c915f8e1a",
        "modelscope/models/nlp/megatron_bert/__init__.py": "d7a78432627ec943c378d96b0daca15f055fdce23ef31b699bcf67bca911d601",
        "modelscope/models/nlp/megatron_bert/backbone.py": "05e5da3fb07b73df5e372a606077a74a4b9240fb71b5334258498a657d109f56",
        "modelscope/models/nlp/megatron_bert/configuration.py": "a8735836e050bdbbe2f3e0a2e2e9c6e615a6ad61952150781d214001b0ee5b23",
        "modelscope/models/nlp/megatron_bert/fill_mask.py": "cd55a7f94e95a178613c57ae7186ea8f4b54c716891cc5ed78b2d9c35c6643cf",
        "modelscope/models/nlp/mglm/__init__.py": "229dfbac00673cb6f9e856b2413857794cdffb64f9ea1312cca13f9323038556",
        "modelscope/models/nlp/mglm/arguments.py": "d530247c093f1ed5a03da3bdc31915319bcfa8093ec639904864d0e85770780c",
        "modelscope/models/nlp/mglm/blocklm_utils.py": "d9e48374ac85fcd2844fd2a31b02a2bbb4baef9013658bf467bd7c07b4577049",
        "modelscope/models/nlp/mglm/configure_data.py": "56735beaaf24e1db68c79ba3069600fdbcea455294f9371456b4b1257507662f",
        "modelscope/models/nlp/mglm/generation_utils.py": "5eba25ec926e33d4e6c799e8832a13e2c1c5191de229e192c4cad7f0579a5de6",
        "modelscope/models/nlp/mglm/mglm_for_text_summarization.py": "cce64d73e2dc0108b55ef5d5e20667a857622d43d1c877dd31588e073db753e5",
        "modelscope/models/nlp/mglm/process_grid.py": "b70705829707674849af6ad6d53f67437eb065135fc2ba7800e45832a2a29849",
        "modelscope/models/nlp/mglm/run_test.py": "63308317829ee60235d9b1f5ef51f383a8d13c4bcc7803a53eb74b4fd0d5f3da",
        "modelscope/models/nlp/mglm/train_utils.py": "8995e5af7a180608c54aad7ca78abbba610998fa8c23de6b7ed18017a034abaf",
        "modelscope/models/nlp/mglm/utils.py": "ec79f83ded2a9483da21e551412f5e91de0a5fa84fc95c07ce1f1313e8d8f7f9",
        "modelscope/models/nlp/mglm/data_utils/__init__.py": "36ce8be3d5328dfd0a0792a212c8c78e717f5c6100dcd44fb9be52c5a2cf4a9b",
        "modelscope/models/nlp/mglm/data_utils/corpora.py": "44e86ae109b1ebffe31ee4d7246dc9cf94c0e116efd9680b652134a92205d413",
        "modelscope/models/nlp/mglm/data_utils/datasets.py": "863f05aa29d26d94585f9b0f407ababc1edef65c430f7369580bb2f49f2e9e51",
        "modelscope/models/nlp/mglm/data_utils/extraction.py": "4c08ded80f025fa9e9679cead45157f3a39951ec512c2520ebaf22a94e2ef4de",
        "modelscope/models/nlp/mglm/data_utils/file_utils.py": "3fe4db07c2dd1b519bb5245ebc82998db01fe82b4a4839ca47f53163670c7300",
        "modelscope/models/nlp/mglm/data_utils/lazy_loader.py": "45c76655215f0baad6a30aa906da59e246081ab8d246c222d3690202261d68d5",
        "modelscope/models/nlp/mglm/data_utils/samplers.py": "82b46009b9394a654312751139469761929d15406f1d8279e82aa8033597d84b",
        "modelscope/models/nlp/mglm/data_utils/sp_tokenizer.py": "3c2f40df0942810258f4b9f40db7b10c4cf5eea4791b9e1a959328fc518310d6",
        "modelscope/models/nlp/mglm/data_utils/tokenization.py": "ec556db0b38f9325faa3d3e37bf013688e67dfb9ebb726c1da851773b0a35f7d",
        "modelscope/models/nlp/mglm/data_utils/tokenization_gpt2.py": "c3713d4f69a57b5f02974c5b8316e88c68cd51f8e5946006159dac184bfb9c3e",
        "modelscope/models/nlp/mglm/data_utils/wordpiece.py": "9edf69be6674295f921fd34403186eb9549da8a88ec911311c905005b7b13701",
        "modelscope/models/nlp/mglm/model/__init__.py": "fbf70c225dbc09a4d3953735532da6237c03ec02ef89768f408e45455a004612",
        "modelscope/models/nlp/mglm/model/distributed.py": "40e01577d712ee5ab325235d8b6555893f6d54682090eba33e580f2a2688ff37",
        "modelscope/models/nlp/mglm/model/downstream.py": "726bf89c1dbed84fa701b26a08f24e1542136beab8e204cac4085250792fa72b",
        "modelscope/models/nlp/mglm/model/modeling_bert.py": "6702bba298606fc63f484fd4326b67708970ed3c7ad5a20bdb5b2708c990a8fa",
        "modelscope/models/nlp/mglm/model/modeling_glm.py": "9bea2f27744dbd2c9b8d497717a6aa6c07fb8f10387cadc0e4b24a65ea9082fa",
        "modelscope/models/nlp/mglm/model/prompt.py": "80e8f6d940ca2288c11de2e1b7d757ec4984e7911aba81a5f5083ddee0325873",
        "modelscope/models/nlp/mglm/model/transformer.py": "0e8754b5a31930d4cd65bf02eb9f97b935f6ca3562d14a4c9fafb322f0bd0255",
        "modelscope/models/nlp/mglm/test/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/nlp/mglm/test/test_block.py": "76701b8e8ec753d3915f67fa792245ec27437651793f4467b28b31d074628df2",
        "modelscope/models/nlp/mglm/test/test_rel_shift.py": "cf2eb19f13a830c6f9f1d14065cd65a292aec3a360c05527cc2c03bea09247c6",
        "modelscope/models/nlp/palm_v2/__init__.py": "af86890320a5182c73ca9a5e89a9e7bfe26ccc20bd42ab098fe981b3f4774622",
        "modelscope/models/nlp/palm_v2/configuration.py": "feef5c37da00a5fde9a614556f2acf17bba104805ed123046254b155a53bf551",
        "modelscope/models/nlp/palm_v2/dureader_eval.py": "1da0c61e6798aa4ffca6ceb44de81f460d8bdd76a6922c42e6fe02454bac11ef",
        "modelscope/models/nlp/palm_v2/text_generation.py": "c99bbb8b4640006bfa94c6e3961eb85413278edacbb9f55cb3ac3618d21e5358",
        "modelscope/models/nlp/peer/__init__.py": "47050914eecdffc8f2f65cb0394adb0b2d69840c00b1d0ae9df2cc22419a990c",
        "modelscope/models/nlp/peer/backbone.py": "f3dc2e347cb101c1582a67a0d30baa3c676876c83f96bccdd1084aa28fae18e3",
        "modelscope/models/nlp/peer/configuration.py": "49d476887c069c3755555d81df837edf9e5b8e13130743c72bda1b2fb9c4ceeb",
        "modelscope/models/nlp/peer/sas_utils.py": "e0fb44f433c83315c35068f5c2a14a604cfbb4d7b256d162957bf02de665926d",
        "modelscope/models/nlp/peer/text_classification.py": "8ad2e4d84a5f914e69dc3afb0551ca26554fd22518c8be7825d8463b279d722a",
        "modelscope/models/nlp/plug/AnnealingLR.py": "b674821d1a3e67975bc685e2387281060e0d956b722982295de5da40877138a5",
        "modelscope/models/nlp/plug/__init__.py": "fddadeed62cdee28fad96e75a08264602f79b61741f4f0bda49ba513ddb30a98",
        "modelscope/models/nlp/plug/backbone.py": "b06235bff35722c24564ac97938476b421dc4725a39377325a9788c60e76a2f0",
        "modelscope/models/nlp/plug/configuration.py": "a37cad34ee352b69069716345e61a51d98d84629547ab8ad9a9d1cb1552dc08b",
        "modelscope/models/nlp/plug/distributed_plug.py": "ad2b522c7e0b1b719591f4122e2b9bc78d87e6c57d1c987f0e0f6379420a7357",
        "modelscope/models/nlp/plug/generator.py": "eedd7cd26d5fecd50265eafd3c53cc5a381cde2858ead25868aadfa85c53c7b1",
        "modelscope/models/nlp/plug_mental/__init__.py": "1a92ecd9052a9f07e5bdb74285b3249c320708b6776c0e3728ac3c441f4f470b",
        "modelscope/models/nlp/plug_mental/adv_utils.py": "1da19c6ed9cf204cd2eb22037b0f56f83cd873e92a150522c41096c3d0ec81b1",
        "modelscope/models/nlp/plug_mental/backbone.py": "10869a56845ec99a3e82e25dba1a99c74dedeca3ae85c25f194b425d05e50c24",
        "modelscope/models/nlp/plug_mental/configuration.py": "3b9d29e88343cd0c343c0ecd3154a5a2fa84f29698b9cd9fa5b59de4307e5a77",
        "modelscope/models/nlp/plug_mental/text_classification.py": "56d450a83a722dd46b826f55d38c2aa839746aaef32557e51c08f08ca01c02d0",
        "modelscope/models/nlp/polylm/__init__.py": "005a5ccf15d83c79fe584196919c127f09ae8c1c425866c56504951d697e9b08",
        "modelscope/models/nlp/polylm/text_generation.py": "6576310ee0d3c12d807dc6de6d9e1479a4375fe247e16b8cc5e2843b51f1bd21",
        "modelscope/models/nlp/ponet/__init__.py": "9cbf7921154cea212cd84d849b98c9e4c28ed565e225b77c3f7de7305d95e22e",
        "modelscope/models/nlp/ponet/backbone.py": "0b5a01b2ec24a648222e89cbbe25df1fe471a8cec2cc57f348fd123f5b4d09c6",
        "modelscope/models/nlp/ponet/configuration.py": "6ed4ec9338de0548d0c58e8e641a73bdc9d909120aa35192c966f664f9bba103",
        "modelscope/models/nlp/ponet/document_segmentation.py": "6c423ea5cc246115cb3e609f32c823c45fdb07052c84e0dff0a8c1c87e8c38cf",
        "modelscope/models/nlp/ponet/fill_mask.py": "cd1ea01d5d5e73ffd94d2dae42d94e828c5e754139c5f7886a2b136acf554edd",
        "modelscope/models/nlp/ponet/tokenization.py": "862a987a4ba45e2c87b20adb5c6614aac907643f93f6f184c24bad859f56ae8f",
        "modelscope/models/nlp/qwen/__init__.py": "6328980a71cb760551176f8ca59a237d825b0b523c4c9350150ab2e5be577f4e",
        "modelscope/models/nlp/qwen/backbone.py": "753f4de7e8dab6af2b6e2f34db80f8a645c46991bf8825035603380176402f49",
        "modelscope/models/nlp/qwen/configuration.py": "f628ff1dd8c073f883e27389b6c90f013d354e1b1e0e22354ec97b3897cfa075",
        "modelscope/models/nlp/qwen/qwen_generation_utils.py": "a5490a070ee87ed48a45dd79300c7a41f3d174e9a82c2e01abcb3729b72f2d48",
        "modelscope/models/nlp/qwen/text_generation.py": "1a2c560c1a4870b59b9dc757dee1f95a1ece0c14e59f1238db4b51b019645255",
        "modelscope/models/nlp/qwen/tokenization.py": "e6e1642e102fc521832336b652e60a46fa09412af0e20846eac1dd95146fd090",
        "modelscope/models/nlp/space/__init__.py": "f3c62c9b6275816e8de8b1de7c779a1aaa7200ab82d438af4825dacd51526de5",
        "modelscope/models/nlp/space/configuration.py": "c357b0c34a2194971102d019b514d0068cc24d085b716bb1714652d590226418",
        "modelscope/models/nlp/space/dialog_intent_prediction.py": "e2bf98b9ca38fb7689c3482f2d4e00045517ac726fc022d462d732864681a734",
        "modelscope/models/nlp/space/dialog_modeling.py": "3d1b5ba9ad394c517a27e2d9f1db8569c37df1d741194724411ae05a28b7b1de",
        "modelscope/models/nlp/space/dialog_state_tracking.py": "9c66703816f90d5ee27449e1cb3452babe8ce17dd853425415e1b8990b5d2155",
        "modelscope/models/nlp/space/model/__init__.py": "43713735a7ece128b5c99b48424009c6f5784e274e7810b8a811fc569654c978",
        "modelscope/models/nlp/space/model/gen_unified_transformer.py": "f73f4cae7860dee9acfdc5bc9ed8e31f59ad23b8ec49017d270c707931633d37",
        "modelscope/models/nlp/space/model/generator.py": "6fd48ad5491dd2f2827e2322153ed7ede110b68aefcb988260c76f0960652284",
        "modelscope/models/nlp/space/model/intent_unified_transformer.py": "71cfa25f40fb9b33d596a6ac7210cc554563046d886246bfa723c3328b30aa1b",
        "modelscope/models/nlp/space/model/model_base.py": "95efab8ca831bb932bcdd09961ad3d27d0eaa21b10181189e988bbf26516f64a",
        "modelscope/models/nlp/space/model/tokenization_space.py": "9602671f99ba60fee37bda61d575e7c21f0f14d8ab91f17ecd2c89300186253f",
        "modelscope/models/nlp/space/model/unified_transformer.py": "58eadb02dfe82393eeebe4ebb11134833072cc02daaf1c10ad90e548dd445fe1",
        "modelscope/models/nlp/space/modules/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/models/nlp/space/modules/embedder.py": "f612f9ab930a0cf39f72e8aa7b94c0f9e412f25f943924c0395df6b1e13b0ee4",
        "modelscope/models/nlp/space/modules/feedforward.py": "4ffac31b8961015ed00061bc16926d9c1d918ce59b6178609676eb27fec1cf9a",
        "modelscope/models/nlp/space/modules/functions.py": "c17278907dc368c793e73cc455ba90cf5591aa3c2f89e1242d928f026fb125cb",
        "modelscope/models/nlp/space/modules/multihead_attention.py": "f185addf622b25ed5456d6867899fd7c022e759d481257fc0cd44ddcae3af361",
        "modelscope/models/nlp/space/modules/transformer_block.py": "8ab4546955f7cc71f83516517c0614f7a8b9e9306336e43744bd75a8f8e58f07",
        "modelscope/models/nlp/space_T_cn/__init__.py": "a0185716b5fffc58de4ac351f24a7cf8e43276947ea5d8ca0bfe60e57ee3104a",
        "modelscope/models/nlp/space_T_cn/backbone.py": "024c3dcdab8d61439dde3094754d1300c826d4ba08288f11701755f17e2fc2d7",
        "modelscope/models/nlp/space_T_cn/configuration.py": "aaf8488274f391fb3b473b57b14c4adf7ce6400b1c3c467097bfadd2f7676159",
        "modelscope/models/nlp/space_T_cn/table_question_answering.py": "ee83e73f508cad6a4248406f5a6e36a1db65a5f3e6d36ea8cfcee30cfa0a2f61",
        "modelscope/models/nlp/space_T_en/__init__.py": "89da40f008af8daaf8fc571f7f160cf2b51a0594cfba432bf0c9eebee0968598",
        "modelscope/models/nlp/space_T_en/text_to_sql.py": "d88ce8c49806e2e78c5a2be2ddcf81ae4f7c9fa55d4cf13a8cdef4a76e424898",
        "modelscope/models/nlp/structbert/__init__.py": "04ca216149081d86141452b05c809b555f72ec4b6202e669f94cab786a68df9c",
        "modelscope/models/nlp/structbert/adv_utils.py": "840fd1aac1df95ef92cd91f4fede45aa0c854e8745e13e33e14e3c3d21fa3fc4",
        "modelscope/models/nlp/structbert/backbone.py": "4070bd61b8ed678e14712727ae5334b318a17559f054c5a0ac26f3bae5266b55",
        "modelscope/models/nlp/structbert/configuration.py": "4e746eb49b2861c4a51e80bb4d28b74c67a044ef9b0ecf1a01eed3c6f334097b",
        "modelscope/models/nlp/structbert/faq_question_answering.py": "03b24ff039bf34ebbb35235c31ad46a0fba93f234796047c70b1af671bacb4ca",
        "modelscope/models/nlp/structbert/fill_mask.py": "94ce0beec36ad6574f15f4f1bbee51b3992eec60adbf9b5b984b1501a89fa817",
        "modelscope/models/nlp/structbert/text_classification.py": "997eaf21677b6822f300821329ef15438a58e010c8764f9ec5d430d03375c28a",
        "modelscope/models/nlp/structbert/token_classification.py": "52524b72b8bbf711cafa672d6a95ab7746b8ca5f5e086c8c146bf4fa5d2ae378",
        "modelscope/models/nlp/task_models/__init__.py": "edc3f63882ac8047eff49b4f8fdd233d4ff23e5c74ed2310d28e1498e1ec2af1",
        "modelscope/models/nlp/task_models/feature_extraction.py": "0c0e27d53a6ef118054e842b9b3db7fabe8624dc9a350a4b69e84ec8c0f7e073",
        "modelscope/models/nlp/task_models/fill_mask.py": "cdf2f25654d9186524c2360a1bd91972f4e5016738b2ce058854dba18a1fee5e",
        "modelscope/models/nlp/task_models/information_extraction.py": "a72d00c6e1cd212d7a06c0391c9e3999b2d9bcf2f16acf0fc714bfbcebbf4981",
        "modelscope/models/nlp/task_models/machine_reading_comprehension.py": "cb545bdac04d6983ffc3f707546387d1412aeb0baf94e5ce36340ad34ff08f93",
        "modelscope/models/nlp/task_models/task_model.py": "754a10aa0c8ef5fb3834ca5e6e1f2cba3a99469e4ff87c6902d42a40d0a741fb",
        "modelscope/models/nlp/task_models/text_classification.py": "ced3608e49257c00e35ef31e10a7d7568c1527af7e8b62ff451fefa3f76e9cce",
        "modelscope/models/nlp/task_models/text_generation.py": "6ada61a01305ed24549f190cb71068781f7b76bc53e8a8d99a9aead3f73b7b25",
        "modelscope/models/nlp/task_models/text_ranking.py": "01a46eb8926d5c2e807a37c4a0658dcca9f1815fd5ffe438053c2b3dccf7ca41",
        "modelscope/models/nlp/task_models/token_classification.py": "4e811b1e01e0e897fba5b90fa75ca993488b2b512ca1620554bfec95b2b66e85",
        "modelscope/models/nlp/unite/__init__.py": "e18098ebd452aeb4f0c8d90b50db9af8c34465b43afe37f27f8408e66e957440",
        "modelscope/models/nlp/unite/configuration.py": "e35e1e6d03f1206fe7910cee308c2d1cbb8a57e860d1ab6301c41836351b4c12",
        "modelscope/models/nlp/unite/translation_evaluation.py": "edbb659e47251e78c213ea58f00f382bd868ce2531469e567e64fd3ad07029ab",
        "modelscope/models/nlp/use/__init__.py": "917f06e633d32693d7b88aa1d03bdc0cde57d33ca0b194aec1c99a2c4fd2f84c",
        "modelscope/models/nlp/use/transformer.py": "aba6c44497f161cdcaacd165e036e18fbbf762139938fa04c61e42d972379668",
        "modelscope/models/nlp/use/user_satisfaction_estimation.py": "6fcddc9eb1d660c702093b52d3391c5dceb54ae09e3fcfa964dca0546665a8cd",
        "modelscope/models/nlp/veco/__init__.py": "252c201389c493698e6b5661ba917464162b2520fcff6868efb6622e74512eb1",
        "modelscope/models/nlp/veco/backbone.py": "d818fde211339a5606067f3e094a3ca7a1af916f1e615c0e66136eb8b22cfb6f",
        "modelscope/models/nlp/veco/configuration.py": "73b3dec5e3ef980c56d3f2e6f2c22b1ada07878d5e1b39edababdbcd6f4e563f",
        "modelscope/models/nlp/veco/fill_mask.py": "00cd33c2755555d296082abf36f350bfb7425ac39067cf7a76acb65d5f160449",
        "modelscope/models/nlp/veco/text_classification.py": "aded5702466d0c4a0a08bb4b050f3ab888ce94590323bac8c4eed19c0ba370d3",
        "modelscope/models/nlp/veco/token_classification.py": "9cf5e5cc8a453e90c86827f8a7f72df877ac8274fd2ea238266870ce94e15ff6",
        "modelscope/models/nlp/xlm_roberta/__init__.py": "a21437afaf519ece33935d0d4f988dc49aff80ea84c93ce6c90bed03ff6ea3a9",
        "modelscope/models/nlp/xlm_roberta/backbone.py": "f9722651c1f71f2fdd35d9fabf682f7a6a119397c050a3b4be7df0e3c5305524",
        "modelscope/models/nlp/xlm_roberta/configuration.py": "8147764a588a15d7db0d2265af339759cfded3a42add82494744f924f06584d2",
        "modelscope/models/science/__init__.py": "ede7ee9955858cc2c4c3487255f61ac8b090bdca54e1c163230881880e256484",
        "modelscope/models/science/unifold/__init__.py": "a2cdc0e253a18414da4105baf6de04a5751a534c05f3ee6fa9206d8d3bb96d11",
        "modelscope/models/science/unifold/config.py": "1c5e7b912850b9ee8251a22aad3cf780d0d5b34968872c7ab51fac606780c387",
        "modelscope/models/science/unifold/dataset.py": "9879e401cc9afb9330f3f22f3a143ac8afda85423a0a2d2bb64cfa7f8a95081a",
        "modelscope/models/science/unifold/model.py": "3ac26bd1c856827c32975b0540614a5b80c13e32b8aa566dc4f55ea74fb15858",
        "modelscope/models/science/unifold/data/__init__.py": "9fbad6d49a22e5687eba7f57058bbbbe75f6248997ca51f83cceb6071db65b1d",
        "modelscope/models/science/unifold/data/data_ops.py": "87eac226a47c59ec9e00b4f456cbda773ee3b514f44708906dfc5372b901b763",
        "modelscope/models/science/unifold/data/msa_pairing.py": "cbb89e1ad1aea1d0f5d383d94dfadb075bc0cbd660394632cd20d29ac35ca55f",
        "modelscope/models/science/unifold/data/process.py": "6e34300204169f05aa3746f7b0fbcedd5cad7e22d2f59ff3f857eb58be123040",
        "modelscope/models/science/unifold/data/process_multimer.py": "c0e2daee53ce4692c21067fb49cd1fd6c33306fe41fc1afbb875ed8e1f0bf0b0",
        "modelscope/models/science/unifold/data/protein.py": "ebb47a815b89bbd24fa66f8ede7d7ae1b353981c57ceb9de8196d056ae508d9d",
        "modelscope/models/science/unifold/data/residue_constants.py": "28d44f43d57293b7a68f8aed2a15e2a54cf6a800a3afa5508f1af1dd73eaa5f0",
        "modelscope/models/science/unifold/data/utils.py": "8df0e6f0db04369465e414b16a4bad02b475b2d9f4db58e9aba6255319435abf",
        "modelscope/models/science/unifold/modules/__init__.py": "c6313bbb56b2c972d80c59beb7bd51d566b2624d28bc06be0066310475b1baa2",
        "modelscope/models/science/unifold/modules/alphafold.py": "aec64754801ba82f307d1c30cbe6a2d09fe0d5f312b6c1e502fe3c0e1b5fecef",
        "modelscope/models/science/unifold/modules/attentions.py": "fae5c5311374d4e02a835aeddc2f94422476b957a350382409449674b8a9c76c",
        "modelscope/models/science/unifold/modules/auxillary_heads.py": "1697e388a691e59855c4e1bf507e6a48cc5a56f1f839594b70e5239be562eb4b",
        "modelscope/models/science/unifold/modules/common.py": "3065c69fc1e6e03977e3f11ee08ade857901c72ebfe9ba43585817cdc0dd2fde",
        "modelscope/models/science/unifold/modules/confidence.py": "ff5ab61f6f187127f4fee3502dd9abf09361cb933dcd6a862ca036dd969ade03",
        "modelscope/models/science/unifold/modules/embedders.py": "05b7f0fe26dfc08c1b267e4b5e94c58190e2610831aac4de23b425a34ffb3488",
        "modelscope/models/science/unifold/modules/evoformer.py": "89501587f74b83d9e4f892ef1f464600ee3164480043af21b351e7b8c2a5636e",
        "modelscope/models/science/unifold/modules/featurization.py": "25f81bf2d7ef0fcec5ed4651164223dcf6b9249aefb7cb57dfcb852cbfea4ecc",
        "modelscope/models/science/unifold/modules/frame.py": "36a14c727ad47404be60304b6e39e31a8256404e4fdf8188385eaff50d9396d2",
        "modelscope/models/science/unifold/modules/structure_module.py": "9ed679f03c2ed3805bfe474832229229b9d798ad2b8ffc3e7d9fd73ce56f5932",
        "modelscope/models/science/unifold/modules/template.py": "2f9262aeda2e0ba222381acc8f1eb88a243da250638cae3da346537d506cd918",
        "modelscope/models/science/unifold/modules/triangle_multiplication.py": "0f2fb3cce9a01d8eee733ef73cc79f6c4f844a2cc0b08b69827ad7393db01ba0",
        "modelscope/models/science/unifold/msa/__init__.py": "9d7fce0ed63ece334c74615950a3cb533d6e8403c34b9b72324eb0fafafabb29",
        "modelscope/models/science/unifold/msa/mmcif.py": "0ea6324cf36e5d5b637f4ba1992093c7187b8494d678ba3d8edf93e75441dd62",
        "modelscope/models/science/unifold/msa/msa_identifiers.py": "502d66671fff93de5c80adb9dd3990c1b5de3d8d714fba1ed983d80254761d94",
        "modelscope/models/science/unifold/msa/parsers.py": "8dd597404c45fff45ca8e8ce05ab1a302203c133b8cedd813d85276c00934fd5",
        "modelscope/models/science/unifold/msa/pipeline.py": "f45e1ac4087312939d8700a343d965a90c98617b5da050f4edbdf4958fbd6ad3",
        "modelscope/models/science/unifold/msa/templates.py": "413689e3544a890ea55d951aa215a2edcb6b8303a17a47c076381d6468b9390e",
        "modelscope/models/science/unifold/msa/utils.py": "7bdd64cdb39e34b4ac71667923253262708e9dcb6ac46c85b576be6d166395b1",
        "modelscope/models/science/unifold/msa/tools/__init__.py": "99b6dc388add0ed76fba35e40cf36a64f17e88f5b830dd7eaee48853c92f4c31",
        "modelscope/models/science/unifold/msa/tools/hhblits.py": "c5ae8dd837d9199121a848b8217e495f50f8b99ce70d158635c4d315363f8ffb",
        "modelscope/models/science/unifold/msa/tools/hhsearch.py": "f151de6c3645ca4be11f6883ab0504a39c36ff0ae1fd85afdae7bc059b410744",
        "modelscope/models/science/unifold/msa/tools/hmmbuild.py": "fd5a4a8166667e08b84dd3a0a01da691ec5480ec8abf792e7344355415bdc4fe",
        "modelscope/models/science/unifold/msa/tools/hmmsearch.py": "b366e14632abd7a2759fc0a122ad9a31d68e31c7ef07825ed0d98b6e5a2d82e5",
        "modelscope/models/science/unifold/msa/tools/jackhmmer.py": "acfa7538a64e40cc4c04b661d7c860d6f1c4bcd8c9841da3b6838b4e860e0b62",
        "modelscope/models/science/unifold/msa/tools/kalign.py": "c135fc820e66ca777c7c1b3b5fccdf67c3e365bd00e3fdb1c25038a7da7449f1",
        "modelscope/models/science/unifold/msa/tools/utils.py": "1ef5c8dea4a4f97b184e727eb8922005d473a7936316bb29af9a531b7759e3d2",
        "modelscope/msdatasets/__init__.py": "e200c2ef73f10c954070aa8d5b96d8fe9aa53714ced0458bbf5fe5216a6c22bd",
        "modelscope/msdatasets/ms_dataset.py": "a06a2a35f3f180d5b34871c8ce42500932335e502bf6a1683b65f96c87ec768c",
        "modelscope/msdatasets/audio/__init__.py": "23f00d77175c207a64233217735c8a3a55b0cdbe286341704cfab5918b60cd0c",
        "modelscope/msdatasets/audio/asr_dataset.py": "9c00b5d7c780bc2809e0d6e90d57f0891a0aed331bdce8f5e507343b3f87c70d",
        "modelscope/msdatasets/auth/__init__.py": "23f00d77175c207a64233217735c8a3a55b0cdbe286341704cfab5918b60cd0c",
        "modelscope/msdatasets/auth/auth_config.py": "c72c20b17769a24c04dcab923174443c1147ee8fcd195889b3d86486f8b2038d",
        "modelscope/msdatasets/context/__init__.py": "23f00d77175c207a64233217735c8a3a55b0cdbe286341704cfab5918b60cd0c",
        "modelscope/msdatasets/context/dataset_context_config.py": "e572645f7e1bd6ee336ed6f5c97c394b79beafa6fe04fc6aba13828d8df39339",
        "modelscope/msdatasets/data_files/__init__.py": "23f00d77175c207a64233217735c8a3a55b0cdbe286341704cfab5918b60cd0c",
        "modelscope/msdatasets/data_files/data_files_manager.py": "f223a749ff47c8904ccd2c791e745c860bedf07ee0ef82d1f3df1ced83fbba78",
        "modelscope/msdatasets/data_loader/__init__.py": "23f00d77175c207a64233217735c8a3a55b0cdbe286341704cfab5918b60cd0c",
        "modelscope/msdatasets/data_loader/data_loader.py": "bcc859e5dcb86fed4c6856248738d5e055e4c675fa75927aab29c474c216460f",
        "modelscope/msdatasets/data_loader/data_loader_manager.py": "106fab81ddbc9a21ee0f9ad43169bd510b33c618053830d0148446c38e383e55",
        "modelscope/msdatasets/dataset_cls/__init__.py": "9414720fa0e4e46f1d4174f0fa7b051bb26e0865e5e8f967c39fcfd1ba476676",
        "modelscope/msdatasets/dataset_cls/dataset.py": "d9206b12e20787f54badc5229dff9754ae001566d7b3905f4ef568deea4268fc",
        "modelscope/msdatasets/dataset_cls/custom_datasets/__init__.py": "c9f351bb05e1aa9ad02b9147915642eedd4db981f30205c8597b5859f0c4af07",
        "modelscope/msdatasets/dataset_cls/custom_datasets/builder.py": "1b6798102c159a433b8d0e4b4172c97b36b19d655f9fd9231a2adebded54a8c2",
        "modelscope/msdatasets/dataset_cls/custom_datasets/easycv_base.py": "8f203c1bf7dccfbab6a41c654a0771817c4937c247a69b91659402c58c159577",
        "modelscope/msdatasets/dataset_cls/custom_datasets/gopro_image_deblurring_dataset.py": "ded32626c9842cd441e70ca47e95e5b5c982d1a7b5ede04a9b6269824e726d7a",
        "modelscope/msdatasets/dataset_cls/custom_datasets/image_instance_segmentation_coco_dataset.py": "54500d2f3899793dc8082a197f4a320cb1b1fdf4aae2eeb7121092115fb1c89b",
        "modelscope/msdatasets/dataset_cls/custom_datasets/language_guided_video_summarization_dataset.py": "1f41ca7784382e165009ca1a947dc297488d1b4411e633d0a47a81729ca18102",
        "modelscope/msdatasets/dataset_cls/custom_datasets/mgeo_ranking_dataset.py": "9a8aa859536d04ce1af78dd97b2a6a43c234a49cd850c8ce4cd6995d00ee0d91",
        "modelscope/msdatasets/dataset_cls/custom_datasets/ocr_recognition_dataset.py": "ea31bef135fe1521bc5323993e8f9180ba2be409689491300697c3d80a23c4cc",
        "modelscope/msdatasets/dataset_cls/custom_datasets/reds_image_deblurring_dataset.py": "1e31f6eb5337eb2a9c48620ddee026dab6d44c60d48d8bc71bb97614c07d00c2",
        "modelscope/msdatasets/dataset_cls/custom_datasets/text_ranking_dataset.py": "bd85a3ef1a873ed4df27b7eeae8be04dc81e947cb9ed246c665e81a8c6ae6d90",
        "modelscope/msdatasets/dataset_cls/custom_datasets/torch_custom_dataset.py": "63e317b336f9e421acb4d9daa19e7196d91279a482534c09fb91782993d80686",
        "modelscope/msdatasets/dataset_cls/custom_datasets/veco_dataset.py": "31fbf7f85bfda0c33bf64b6e938800af29a31116a014c1507f81e2142d8671f4",
        "modelscope/msdatasets/dataset_cls/custom_datasets/video_summarization_dataset.py": "517535202941e6575267b66c7172c5d000e0be1d513841ec555006d0042f0444",
        "modelscope/msdatasets/dataset_cls/custom_datasets/audio/__init__.py": "b4017937663e182af64cd84618437db4a7320157ff5139fcac65ad20f7061172",
        "modelscope/msdatasets/dataset_cls/custom_datasets/audio/asr_dataset.py": "798848f9ef5262b6940d4c2a4a45068138e9e9a013c7a23f6693c87b3d175a1e",
        "modelscope/msdatasets/dataset_cls/custom_datasets/audio/kws_farfield_dataset.py": "1e0526ed3ce1a22e06a30625fc9546fdf18d2cfc535bae5b9c97cbe8485ecdac",
        "modelscope/msdatasets/dataset_cls/custom_datasets/audio/kws_nearfield_dataset.py": "32538ad97e9de8f87829c8e9db527c92adbff1ff0cb23150219ac537c955a900",
        "modelscope/msdatasets/dataset_cls/custom_datasets/audio/kws_nearfield_processor.py": "3a9ddcaac88d1b01a8390ae2db8689027f044d656119d7c51fa6816481b5cb81",
        "modelscope/msdatasets/dataset_cls/custom_datasets/bad_image_detecting/__init__.py": "c211fcbdccf760c2d066ce24fb8adbeeb43d5b33e24f46151ab439a7a5a9ce13",
        "modelscope/msdatasets/dataset_cls/custom_datasets/bad_image_detecting/bad_image_detecting_dataset.py": "b454b333476ed57b4fc0299e6010b44c5b433ceb8e3e6ec347a7525ce1194294",
        "modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/__init__.py": "105b333ae872ac66d7dd55df7f9f8cc03aa556ed5e6dfbb4ad3dad8a154060c1",
        "modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/build.py": "85ad89ec804aac6cab36d12f508f887ed95d0e2097aa5176b32af8f5f0adc229",
        "modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/collate_batch.py": "75d08fe5e9c4c14df48a150c07ed2d254004e1e1a9654206ef2625d1ae58a4cc",
        "modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/__init__.py": "460cf259fa289df4a233e216f14fec60dfcd03752a545fb4c54b4eea0ef800be",
        "modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/coco.py": "6e255f57c86fedb188139139bbe13da8279f7fd19abd4810baf6cbd6afc8d257",
        "modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/mosaic_wrapper.py": "15671548416a2415f72c61c2155a85381e3776c63fd24526ed99a19106815a41",
        "modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/__init__.py": "f01b80d2f4fc44be6147fdb7bb91bb49ac80496d1372c2e74d2acc3b6018c920",
        "modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/coco/__init__.py": "aab2ce25260082c8f566167ae4faab288dced48cd9f8f7c48ad2376a575354a1",
        "modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/coco/coco_eval.py": "05851a57a372d7d9d9a8580f069e6df1606cef5c9425805784aeef58001cecd5",
        "modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/__init__.py": "abec6de5526d1151a68357c7bd54556aa8b6b9d34cf1b07706c66e9561d8575d",
        "modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/distributed.py": "efbed19bf71134d052d7ab741fe7128973cab6cd34d0c976b2e0934c3f22f8d6",
        "modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/grouped_batch_sampler.py": "db022c283bb224df7622ceb0afd49a0bc1a27170cc340e00b99bd99888dbe937",
        "modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/iteration_based_batch_sampler.py": "33601bf32756000649f0c3a61aaa44f96a527d39a46126b12e9c583232e3f724",
        "modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/__init__.py": "0015899c2bb7af3b950b6ee8b030c70d06f6fdce9337a0a5ee73a21223cb0e4a",
        "modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/build.py": "0fa1def61ca1a0421b8660052112b94bc591f093dbc029c933b96b106828a08f",
        "modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/transforms.py": "5291180cc57514b85dd4e0f7bfa04bf0d0c211c8cf89891b8f5535e64f4218e3",
        "modelscope/msdatasets/dataset_cls/custom_datasets/image_colorization/__init__.py": "56774b5b792a072c45fcb209760ca3ad1df23f9aaeaab4c05ff39860bae673e2",
        "modelscope/msdatasets/dataset_cls/custom_datasets/image_colorization/image_colorization_dataset.py": "1129260d91dfbe10fb6fc22b6b31a1ce5a074f68872d46e3bffc580656a11337",
        "modelscope/msdatasets/dataset_cls/custom_datasets/image_inpainting/__init__.py": "45b488ed1a81e748e299c280349db69885e4a31aaa0bab68c5ee846361f9a7c4",
        "modelscope/msdatasets/dataset_cls/custom_datasets/image_inpainting/aug.py": "21f4c27aebc7a24c88449bcf9fa62ea3876cb579f7c775a8b7da08a75b8493ea",
        "modelscope/msdatasets/dataset_cls/custom_datasets/image_inpainting/image_inpainting_dataset.py": "a5cd435f5ff368c8b9d93b3f51e97ec67ea6c4268f928465c93c90c4c46bf5f8",
        "modelscope/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/__init__.py": "8fb501c9004a7ea177e465fe982b3c46fd91c8709bce22333fe3cdc0e7f84119",
        "modelscope/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/data_utils.py": "f12683ce3fb1a25b934d1c7a7b9ae060c139f1635b6bcb5f0bd7f66a39eaf427",
        "modelscope/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/image_portrait_enhancement_dataset.py": "bbd45761d3922019a2547dad48a4496741f07bb90731560baab52e80ac81e765",
        "modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assessment_degradation/__init__.py": "250a344e2777581ce1722edba5a01b206e5ca4cb42a9ae59e766f68e5d711ea1",
        "modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assessment_degradation/image_quality_assessment_degradation_dataset.py": "19de25dc31c560f33376c484c172bcb813f320a0f5bca7e618c4fa37478a9f0a",
        "modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assmessment_mos/__init__.py": "9745e957dac2a320e046d872565e8a45f8a95baf70d9532994d98a5371252be5",
        "modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assmessment_mos/image_quality_assessment_mos_dataset.py": "ead8440ac4757cc187ce4543cc6ddd54568fc4288d3e1be85bcb203f42b8d6d6",
        "modelscope/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/__init__.py": "12d5978329b370c5add3def50679afcdbb5cd57192f5243fa409e446597a1f75",
        "modelscope/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/movie_scene_segmentation_dataset.py": "3abbc8ead6d202fffe6eae91928ff41511d2177c6d1c1b05de1a8a28e405083e",
        "modelscope/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/sampler.py": "0eb500ecdefd65f982a21a04ac11dd97a1522e84e162e1bc6539a5dae1a9b7ad",
        "modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/__init__.py": "c59bd4f8b131656f24a46a284f149eae2dd402051fd35db25f44189ea86f906f",
        "modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/augmenter.py": "7d9e6badc60d1128ea66dc3e3ad349434f6dd9bdd6515fc26ab0149a146e4c80",
        "modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/data_loader.py": "74997898e0404e0ea8e769f59e571abfe25cc2259506302ff831103191fd0446",
        "modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/image_dataset.py": "1c5db053e7e8c809dcefd7a508885d32bac6ae374d26d22f94043837296aaf49",
        "modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/__init__.py": "e8cad2e852b68be7185b52a69fe77fa99ded384837cf306f1f1de2abc8e96c2a",
        "modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/iou_evaluator.py": "e207086a5b0437d4c22c01e9553dfa7f20a9488a19de69ed4ab4313e171b4d11",
        "modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/quad_measurer.py": "8d044268a1474578e5727c89ea589fd4045243433e6cfe784abda2fa8cb6be87",
        "modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/__init__.py": "fdc1f81f4c9af0de88404e07656906dcd1efe6a1e5e1f388be8673acb84a3fc1",
        "modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/augment_data.py": "6ee055d893345226e8693ec8939b09e0a9a3161d4dc7fbfc626bf2d7cb47ccff",
        "modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/data_process.py": "db8e19045e084098c7d5a7832757af930b71add4819e41e794e7369bff56061c",
        "modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_border_map.py": "8f9ef3b126cf631e16e36a4228b57ffd3935d807f8793db0da875c947b1be269",
        "modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_icdar_data.py": "162b449689b880dbd30e3a8de6fdb341e308091a7be41bd855d0340d526ecdcf",
        "modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_seg_detection_data.py": "7da8f72976ab86b37624aa30ff065e80ce1a05b6a7d871adc99d595d13109c29",
        "modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/normalize_image.py": "e72bce50824cb265ca863b405a276f75e17bebf7a8c249d71d9fb14d4d5c7376",
        "modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/random_crop_data.py": "fbb4317cc510a97689a71f8202ee9b70357aee389432249000f868a969d5ac94",
        "modelscope/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/__init__.py": "a3e908f1c9eaba053ec4305de205520d2987cc51e1bbb999e4b7247c057a6a1f",
        "modelscope/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/referring_video_object_segmentation_dataset.py": "1789c550dfa6cebbb47695598a9aded79c5ece037f5502059af219a561357dc8",
        "modelscope/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/transformers.py": "973035764642ec84127da85f014e333e733d2bbada29149bb918ae902b5b8905",
        "modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/__init__.py": "23b37b402b928920320d97799cc4d6da978fc03850a0a2079683c0cb23a010f6",
        "modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/data_utils.py": "bd02e16bcd8daa7fdd9c8ddc1e9242a3358fa2a193adcd0a43ef3f29d5dd28f4",
        "modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/sidd_image_denoising_dataset.py": "780aed01ae8d635f555a49da3b216cf0336c0062d048a6302899f24d4bd60755",
        "modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/transforms.py": "85800527f5c59820f48e90132a410600fa77adb6dfc0ab07d8b66dd544588bad",
        "modelscope/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/__init__.py": "d0c3041dc99065dac92f4a0f2757b0587c27099a9ee7e932fe131da3ff0c7796",
        "modelscope/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/data_utils.py": "df3448fcce9fa699ec9384f3509d511d54ec7db8c27036d87a6a3fd39f189e30",
        "modelscope/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/video_frame_interpolation_dataset.py": "40e7433839ccda4f95104289a62c01271d544ed3acea2a01546508729e192ecc",
        "modelscope/msdatasets/dataset_cls/custom_datasets/video_stabilization/__init__.py": "ae83086540b1998df0b0b0719a0f3531892c568722f026ec3f9a8882170b9d5c",
        "modelscope/msdatasets/dataset_cls/custom_datasets/video_stabilization/video_stabilization_dataset.py": "bf06259ae67e62cdb869fa493cf9a3f635ea981cd05f1e0cacea21cf49da30df",
        "modelscope/msdatasets/dataset_cls/custom_datasets/video_super_resolution/__init__.py": "560d3422858e4c1777eff5ff07514dab43902fadf716cf0080b8294d3ee54e65",
        "modelscope/msdatasets/dataset_cls/custom_datasets/video_super_resolution/video_super_resolution_dataset.py": "1f083bf36bd7ebf1958cf268d891a48eb90f5da39942c854263bcd4039476d39",
        "modelscope/msdatasets/download/__init__.py": "23f00d77175c207a64233217735c8a3a55b0cdbe286341704cfab5918b60cd0c",
        "modelscope/msdatasets/download/dataset_builder.py": "be9ea1a4060f874eca6b075e4d7db19ae6ec66ce07cc1fb879d4636533349a4a",
        "modelscope/msdatasets/download/download_config.py": "724512c28f112b46ac1adc8fe5dd4f6e2623dc885b7819ba2edbf10545c2e5ef",
        "modelscope/msdatasets/download/download_manager.py": "d06bb4d1d46e1d60d9dd889734341fe465348c9959518a65a7e09ad704e287f5",
        "modelscope/msdatasets/meta/__init__.py": "23f00d77175c207a64233217735c8a3a55b0cdbe286341704cfab5918b60cd0c",
        "modelscope/msdatasets/meta/data_meta_config.py": "a19447e55405f3ad2604179602f51452b2f94d0539b321f18cd1ca23418c5be9",
        "modelscope/msdatasets/meta/data_meta_manager.py": "1ddccece8a97a9950b24112ce4fe1392912feadce4183a4d832d83b63604756a",
        "modelscope/msdatasets/task_datasets/__init__.py": "07b82487bc6ece9bb135a28f46fcacabf2dd51f4f526f29229a9dede004b010a",
        "modelscope/msdatasets/task_datasets/gopro_image_deblurring_dataset.py": "efd55b82356618e08d382108329ae69c1de7f0b87e9d43e83dcd868ebc0d7bd8",
        "modelscope/msdatasets/task_datasets/reds_image_deblurring_dataset.py": "7e78e4652ba9160e5e4a7e9a9eeecdb568e32d772f24eac46b1153633e1a1eca",
        "modelscope/msdatasets/task_datasets/sidd_image_denoising.py": "fd71316276b90b5fcf39029fefff1a8834c1d87b159361d69f42d651a751d7bd",
        "modelscope/msdatasets/task_datasets/torch_base_dataset.py": "6631e2ef100819b0ef8359507a5d4967917ad6a3093f071a632039594abdeb9f",
        "modelscope/msdatasets/task_datasets/video_summarization_dataset.py": "75c436339387baac9581f41268f045ac7a222812347d20c072fc7b25829c46a4",
        "modelscope/msdatasets/utils/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/msdatasets/utils/dataset_utils.py": "62a288a5577ab784c245b13ca10f8d239a30908cd9cdab79abbb89a8904067f8",
        "modelscope/msdatasets/utils/delete_utils.py": "b3178f5d053c132badc3d6590d7d63e94dc3464d4f2a9184dcb6fb06e3db47b5",
        "modelscope/msdatasets/utils/hf_datasets_util.py": "4f8b41b79ca3e4510ed53eadec53fda438014ac44698560c2aaef37eca1c8192",
        "modelscope/msdatasets/utils/hf_file_utils.py": "ac7a905bd6da3dab237687d91d9c0deacfbc38f447bacb9b65cfd5e19d80581e",
        "modelscope/msdatasets/utils/maxcompute_utils.py": "5df3c6b9180f725e916ff52d1c39fc7d38e7b50f3230ef1b6ca22a5985e65264",
        "modelscope/msdatasets/utils/oss_utils.py": "ffa53cddf69f90a623787b58e9740145fa49b4977f8b835bcf0a370eacc203e6",
        "modelscope/msdatasets/utils/upload_utils.py": "4596dd69272c1a72a18d8587cfbd8e69c5775854c35f90633c8070c18abdd981",
        "modelscope/ops/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/ops/4knerf/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/ops/4knerf/adam_upd.cpp": "d722bd9df70d2a14e349f238130ad259bc643cbcf7bf1885e71b194b1fe2dffb",
        "modelscope/ops/4knerf/adam_upd_kernel.cu": "ed851383e72dec39a29205b0a1204931407dcf57764fded089901c6c4fc5f86d",
        "modelscope/ops/4knerf/render_utils.cpp": "104af14db3861befaa19ae11aaa5f2066a30c6e35bc65e8f669f6166d8ee7fbb",
        "modelscope/ops/4knerf/render_utils_kernel.cu": "86e73b0c0f0da6f2061aa02501a5b8b3ea445ad1155718d2cb5edc5551161f9d",
        "modelscope/ops/4knerf/total_variation.cpp": "3924c500f7ce7c9317828d43ec5278286a04936355d06a9d2e8344a89b4b256d",
        "modelscope/ops/4knerf/total_variation_kernel.cu": "ee24b6ad06d0d301436acce01d83de6f0425b453ecbb7ed270e3f3eb746005f0",
        "modelscope/ops/4knerf/ub360_utils.cpp": "717ddeff5d979e3c0938ff64588b2f623b263877b6072a1924ef5c168b7fa7b0",
        "modelscope/ops/4knerf/ub360_utils_kernel.cu": "b5f746678478ebfdc5a53a5cbe8989e330baa6fb12ce73da03cdf8304dea95cf",
        "modelscope/ops/ailut/__init__.py": "30b42530f55d493e123c790e4d9bf12d3e8ac97006d42a3d59ac8fa759d9b054",
        "modelscope/ops/ailut/pyinterfaces.py": "53e76bad625d5272aff4704cb9650a709160153b230c2fcaaca4c3caf8dd488f",
        "modelscope/ops/ailut/Ailut/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/ops/ailut/Ailut/csrc/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/ops/ailut/Ailut/csrc/ailut_transform.cpp": "89f7635446d415b2eacf831f0fae6317e6405ed766ce37ac08ff244a7860fa04",
        "modelscope/ops/ailut/Ailut/csrc/ailut_transform_cpu.cpp": "a016e9f4bcb7338c04940aea7e35ab02f201e4eb114f2238e1aad15d7b755285",
        "modelscope/ops/ailut/Ailut/csrc/ailut_transform_cuda.cu": "f97efb40eadbf5a7f819802675c94668b3ee0459964f58a4c10c1e98f005ca59",
        "modelscope/ops/human_image_generation/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/ops/human_image_generation/fused_act.py": "5cdf99f0d938f531bda8219fc20f8ede95cdc182042454c18718764b8f6a5b34",
        "modelscope/ops/human_image_generation/fused_bias_act.cpp": "a13fa2ff6417872a2167bada3893cb66af131cb60333ed61695374f629d9d1da",
        "modelscope/ops/human_image_generation/fused_bias_act_kernel.cu": "3e9d7e45215b62ff060e67d47613c707bbfad8156d6839fbaeeb9570bab14fbf",
        "modelscope/ops/human_image_generation/upfirdn2d.cpp": "591f89ebecfde7f886f90e9ad2959a246c3c5de51a36387a68d512d1b5cce1c1",
        "modelscope/ops/human_image_generation/upfirdn2d.py": "a77dd1f0f1db0f0c7c18a5d3f275cca2ef6993f2eb68a8a460b3d7fff0278226",
        "modelscope/ops/human_image_generation/upfirdn2d_kernel.cu": "b66c5871739ec52b2c9200d8f67a3664c21300077d77901e1ae6c4a306a69763",
        "modelscope/ops/image_control_3d_portrait/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/ops/image_control_3d_portrait/dnnlib/__init__.py": "e4475bea0bffcecfbd22562c0d1c187ac9517306d5ca1bf5d8f4ddb44fd6c433",
        "modelscope/ops/image_control_3d_portrait/dnnlib/util.py": "d5df0e7215a123da25169c3646d446ed0e2502f3695680cd9449eaaa92b8a0ca",
        "modelscope/ops/image_control_3d_portrait/torch_utils/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/ops/image_control_3d_portrait/torch_utils/custom_ops.py": "109f4c9c6b2691f58b6b20a62337697f74d9e6dc64e2d8fa840bd455b11606fe",
        "modelscope/ops/image_control_3d_portrait/torch_utils/misc.py": "2dfff7f2900dfa04cdeb38166405443a5967b64cf54b263a3e5a187e124529cb",
        "modelscope/ops/image_control_3d_portrait/torch_utils/persistence.py": "d240da31e9bb29b29b50c5bbdd8e2b41c120fe4cb58635c8fc76029b4774769f",
        "modelscope/ops/image_control_3d_portrait/torch_utils/ops/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/ops/image_control_3d_portrait/torch_utils/ops/bias_act.cpp": "dc42d0c37c6437a217fee05bc1f56f5db82be3b7039057df6a8051fa9a3a581e",
        "modelscope/ops/image_control_3d_portrait/torch_utils/ops/bias_act.cu": "10333cd3e76470a1c8a89a8fd657adafa7e9a2e5be4585dd1d8830045640733e",
        "modelscope/ops/image_control_3d_portrait/torch_utils/ops/bias_act.h": "2d8065a331a77c22c61681431774b3b6f138d8c1139f5b80416566f16a5d42ae",
        "modelscope/ops/image_control_3d_portrait/torch_utils/ops/bias_act.py": "b75f7c081295e0ab8252293fc3640442c68bf229a1f03a1d7dcdc6f9b3fd93dc",
        "modelscope/ops/image_control_3d_portrait/torch_utils/ops/conv2d_gradfix.py": "cf2b2dc4e11b6a19233d9e64a65578eb05b3dead6e09f88d78287e37e984749d",
        "modelscope/ops/image_control_3d_portrait/torch_utils/ops/conv2d_resample.py": "f9f5cff9fa419e4b0105957870c37dff60caedda85e2c1ed4c97ee50265e5049",
        "modelscope/ops/image_control_3d_portrait/torch_utils/ops/filtered_lrelu.cpp": "3ca8712943dd2e0c73e1cba0cf92b1fcfb7c3ce322dee5953c8aa751e488d2cb",
        "modelscope/ops/image_control_3d_portrait/torch_utils/ops/filtered_lrelu.cu": "e18951ddf65d1040e009f1f740cb186d1acadaa3549791e2c3fe66c99a2f2b3b",
        "modelscope/ops/image_control_3d_portrait/torch_utils/ops/filtered_lrelu.h": "776ee281411209a5a9a3705c97ee95a726c414561549c7d71875660c8f95bebf",
        "modelscope/ops/image_control_3d_portrait/torch_utils/ops/filtered_lrelu.py": "d67b05e20ef3fb1924387a3c9deb98e009da19e1f9adc5ca3c1c0a8f008e5761",
        "modelscope/ops/image_control_3d_portrait/torch_utils/ops/filtered_lrelu_ns.cu": "d22a27c1fd77f3676cad1e9dac4d0b6020acb87405c9a53ca4eb4e39fc7b18dc",
        "modelscope/ops/image_control_3d_portrait/torch_utils/ops/filtered_lrelu_rd.cu": "b96439da3713d5612c813091ca1587a8975cb62893e622ccb327e3aaedd90856",
        "modelscope/ops/image_control_3d_portrait/torch_utils/ops/filtered_lrelu_wr.cu": "27ec652e6256972dcd97ab58d66f23cd7b66a1653afcc83b9abb04b49ace4097",
        "modelscope/ops/image_control_3d_portrait/torch_utils/ops/fma.py": "99b329440c17cd0d48af6a2dd80c478d811b353d318ea440827a613a6df7bb49",
        "modelscope/ops/image_control_3d_portrait/torch_utils/ops/grid_sample_gradfix.py": "fb7f82800b90cce50c64f857ca38a1ef208ba94d1e69e3c6bd4ce3851124e164",
        "modelscope/ops/image_control_3d_portrait/torch_utils/ops/upfirdn2d.cpp": "9bc0aaf97d554fc3faa565c25b568cc0eadf6d7ac8e8e62f98cfce77b8cbdc73",
        "modelscope/ops/image_control_3d_portrait/torch_utils/ops/upfirdn2d.cu": "584697760a9d7274d2ce0b8282670f63bc6a6507f13685b2a077dc15fc305db4",
        "modelscope/ops/image_control_3d_portrait/torch_utils/ops/upfirdn2d.h": "674c5a00935d7585b09617c0177bd9132b8affdb2d2764872360ab1174753bc8",
        "modelscope/ops/image_control_3d_portrait/torch_utils/ops/upfirdn2d.py": "2acb04130f5c1829c1f76e6fc7e543f00b3b92bd870545cb939211a68edc1846",
        "modelscope/ops/quadtree_attention/__init__.py": "d6e551fd740631a972635cfd3f5c49ec2522d929d49ef1711c8cfec5174bdf89",
        "modelscope/ops/quadtree_attention/functions/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/ops/quadtree_attention/functions/quadtree_attention.py": "34841bb02feafb9c2fd57302fcc32ced456f94449d9e46e733144ca7f4339756",
        "modelscope/ops/quadtree_attention/modules/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/ops/quadtree_attention/modules/quadtree_attention.py": "9b71ce03710598e6b4d45fc0d450bea063fbcbe6cf7e7021b7df602440b7d5b4",
        "modelscope/ops/quadtree_attention/src/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/ops/quadtree_attention/src/score_computation.cpp": "17c50c3e9edd534867c2be603893daa1d07eae687b099c16332cf284849befd2",
        "modelscope/ops/quadtree_attention/src/score_computation.h": "8d4133d477d12e84058bfee658f8af4faa53f3ba7d73092995121476a5f4ebcf",
        "modelscope/ops/quadtree_attention/src/score_computation_kernal.cu": "5886a0b5101295df7aea9f27c9bd29df149468d40ef656b1f92b3983669b6af9",
        "modelscope/ops/quadtree_attention/src/utils.h": "5180d5c4d8286cf8263df3c89ffdd36eb59f1a06c377525f245285aa26414fd9",
        "modelscope/ops/quadtree_attention/src/value_aggregation.cpp": "56523514deb7d6a2c78a0f421bd9fd2c29f7b9b520de3797e836160d456df954",
        "modelscope/ops/quadtree_attention/src/value_aggregation.h": "a006425e80a23aa270eca0c5a9a938a43d6355cc5f751df7faca6ffacebd882d",
        "modelscope/ops/quadtree_attention/src/value_aggregation_kernel.cu": "51b63ab5d6728e25e1d12a9eb210ae54e295cac1502e7fa0ef01406ef2f82af3",
        "modelscope/outputs/__init__.py": "b2833183e59857a31f319b08abdf2d44a652fd9e9500279f415bcdd4675ea6eb",
        "modelscope/outputs/cv_outputs.py": "7825895b1285cd37c931fbd3ed3868876ba6823ddc8983a93e807211b2e49f4b",
        "modelscope/outputs/nlp_outputs.py": "2948082d9a7c2b96fc013bbad7f42cd81e2a6cf29a578249ef6860ba078cd762",
        "modelscope/outputs/outputs.py": "1427ff8320ecf331a42c9053b3aad212ccb2acdf76580d03eda990465000c630",
        "modelscope/pipelines/__init__.py": "e0c761b2153720c45e7398881bad9fa980920958fc325920b6c3477c4c2fba75",
        "modelscope/pipelines/base.py": "ecea1cac6766422f1a987037074ea7ff4eef5c3bf5fcece79e374c7d1ededd4b",
        "modelscope/pipelines/builder.py": "7f8ae1b02760876ef1b64652cc47085c8253d6c5ea0ac0b8802b17d0c4e13cce",
        "modelscope/pipelines/pipeline_template.py": "b76e0ee185d874e26d66b60719a4c81dc9991b369585bc29a49f85752910a6ad",
        "modelscope/pipelines/util.py": "364e3d823d121bdde4616332edac88b4cdb9ea98882017cf8d423ee8e1a46cd7",
        "modelscope/pipelines/accelerate/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/pipelines/accelerate/base.py": "a3695ff63ab95518c4e7501d2bed47b1eedec1a716a7e382b966ef59f909178e",
        "modelscope/pipelines/accelerate/vllm.py": "2e40152bc68dde180a0158dc135b05535549dc77373dff5cec4e7af79887ea40",
        "modelscope/pipelines/audio/__init__.py": "151ee94a193e5a43d6662b40efb20b7f4b5484682c614ff7bfbd7ba0b7c67a62",
        "modelscope/pipelines/audio/ans_dfsmn_pipeline.py": "86a1238998b1fd2fde86385038f51e239c5748baac617fac0bb3ecfd6e9f9c73",
        "modelscope/pipelines/audio/ans_pipeline.py": "663f6624a70aff152da9bc77dffafad057b8cb831062b49c61dee972c44fcccd",
        "modelscope/pipelines/audio/asr_wenet_inference_pipeline.py": "7906b2fda6cf206dfb790f5d53daa56fe81e8bee9476fcf16006216271c967b7",
        "modelscope/pipelines/audio/audio_quantization_pipeline.py": "96dc04909e8ec976f02fd5b0cde559f32007fe753c7dd4523f79744422db1198",
        "modelscope/pipelines/audio/codec_based_synthesis_pipeline.py": "cb475de2621f4a1b0ecc7497cc091ea3002294ca85641ed02ba4dcf095a255e2",
        "modelscope/pipelines/audio/funasr_pipeline.py": "c1189118d6fd48483b4e4dc795ff6eb942e762172441159914966d18f8fc5d9d",
        "modelscope/pipelines/audio/inverse_text_processing_pipeline.py": "60196cd733a9ca9a305dd564823a58c91300edb2a51626477d0af27bcaf34ab7",
        "modelscope/pipelines/audio/kws_farfield_pipeline.py": "823c3db63147543cfb6557e906ecabf095a8d09d2b7464f2cb7b98fbfc4a3b63",
        "modelscope/pipelines/audio/kws_kwsbp_pipeline.py": "42e20db0d7b2a7edd57b60f05117a931a8c9c7147f23322f9bca94461e4693f5",
        "modelscope/pipelines/audio/language_recognition_eres2net_pipeline.py": "60089f14aa68b6acd007abe9d3f670bfb52a74c345d2ed04b10667609f2f8e66",
        "modelscope/pipelines/audio/language_recognition_pipeline.py": "62781db334b11dcd25c0b52b37150aee2ad1c8161aa25844d71aa3d9a94d8565",
        "modelscope/pipelines/audio/linear_aec_pipeline.py": "90b713d929941cb0b4a924da321aebf0067a2db36d9f2e8ad43cc5bd978c9da9",
        "modelscope/pipelines/audio/segmentation_clustering_pipeline.py": "4ee48008e1a03512deb9626a0593303e55db46ef132156936b715472f36b35e7",
        "modelscope/pipelines/audio/separation_pipeline.py": "f74472af17c05f76353059f81fdb89dfb52f5533b14d1bfacbadb731c97ed67d",
        "modelscope/pipelines/audio/speaker_change_locating_pipeline.py": "fc3c83a57733ed8bf3b8baeec0fcd72e2332d9f020b5b37038127d91a02fc686",
        "modelscope/pipelines/audio/speaker_diarization_dialogue_detection_pipeline.py": "b3ea3c01b30eb4e7a8a1a80a8ef68f31b76db12252f4195dcd302a540cd25f48",
        "modelscope/pipelines/audio/speaker_diarization_semantic_speaker_turn_detection_pipeline.py": "26e44a6f4f23116bdcbbfa79761c304c01b5903e5d4a81c1c5a8b506bc5fd44c",
        "modelscope/pipelines/audio/speaker_verification_eres2net_pipeline.py": "029cb4d8198d98c3f8e5c5fecfc633a20423c8a14861c5ef00482132c0fc86a1",
        "modelscope/pipelines/audio/speaker_verification_eres2netv2_pipeline.py": "78aeba0a7f96bb01e2ef400087bb098c70e164888c882130c11283a422248a59",
        "modelscope/pipelines/audio/speaker_verification_light_pipeline.py": "6c57dc7b78191d7033c478085616177d1290131755b9744b5cd6704f3b40b46e",
        "modelscope/pipelines/audio/speaker_verification_rdino_pipeline.py": "4c0a8cb8a1fc1f434ff40a45318e92dff160b129be5ec680b35d0d99df4b30ea",
        "modelscope/pipelines/audio/speaker_verification_res2net_pipeline.py": "0e8e1d5776957d50d1873f5d0231785e611a09d8c60a7ca695dd70ffc7350094",
        "modelscope/pipelines/audio/speaker_verification_resnet_pipeline.py": "749c8c01086415799784baeae807a7a76cf56d817e38e2868ff9e70abdf0dcaf",
        "modelscope/pipelines/audio/speaker_verification_sdpn_pipeline.py": "93ac6331e32bb8f8cd0f6018ccbf8872d903a692aac9828c0140eba8545e0266",
        "modelscope/pipelines/audio/speaker_verification_tdnn_pipeline.py": "221146e1d0edd6602fde8bf6f4b6f035d6fc4228fb83c0c831d62d95e59d4092",
        "modelscope/pipelines/audio/speech_separation_pipeline.py": "70b348916d0a6eda13d1dc41ebd9c414ed1e2de5342660fef837c5c3f7bbf487",
        "modelscope/pipelines/audio/text_to_speech_pipeline.py": "2d3166c5d41ff96ccb56e560f22e2234ec1c7c094ff8356be5a203877b5a62f2",
        "modelscope/pipelines/cv/__init__.py": "4c14f20129dd5fc61df341642330ee201d9ad4ffacffc74d16c697f28f592762",
        "modelscope/pipelines/cv/action_detection_pipeline.py": "eda08dd5fc643823571f38588f2e33e1a3615955b5f8b38a8558bdcbd02c868c",
        "modelscope/pipelines/cv/action_recognition_pipeline.py": "53c5ea6d547b8de78e721398b2dc3f7874d55b521fdab24584e060406f6213ca",
        "modelscope/pipelines/cv/animal_recognition_pipeline.py": "e15d39235c5f176fd7a601a7afef59f5f7fd866296bc2890bdc26fdacac53d96",
        "modelscope/pipelines/cv/anydoor_pipeline.py": "4ddce1029ee2cb359c19c679122aee7eaebd33064dff8415726da77cd80653cc",
        "modelscope/pipelines/cv/arc_face_recognition_pipeline.py": "ee505dac3c95e5dd032fe7f28491ae9d5b79f7996f5922f59c316e01e6fbf7bb",
        "modelscope/pipelines/cv/bad_image_detecting_pipeline.py": "7d5d68da36e083d0fc6bed99f09515515ac0d4a9fafd408c426b39a48866dc94",
        "modelscope/pipelines/cv/body_2d_keypoints_pipeline.py": "022a8d7f7ee21420e75f1ec70f33ed427877f677b940aa95cb650c4bcd3113b2",
        "modelscope/pipelines/cv/body_3d_keypoints_pipeline.py": "b6ecf8f0e61c6fa8936e15d05cc3db8ff336089bab137bdebf2eb5c624264c6b",
        "modelscope/pipelines/cv/card_detection_correction_pipeline.py": "f2c60c21a0253c3f6a9533d47307f853a07ed72786e0c597a547fc418966f292",
        "modelscope/pipelines/cv/card_detection_pipeline.py": "efa6650355a4ca20eea94cfe20e61b955490db18f312ea6fa5ecaba6f8d35cfd",
        "modelscope/pipelines/cv/cmdssl_video_embedding_pipeline.py": "ebbe52cf4d4c5af87720b98ddc1342bda5f166442a8100e3cffb22c23c80dcf7",
        "modelscope/pipelines/cv/content_check_pipeline.py": "66ad6f9ba1dcb9184d2d0c2f62e1bc4af34739ac5124c5978dc12e6f06c2af05",
        "modelscope/pipelines/cv/controllable_image_generation_pipeline.py": "cdb53f3b869576a6ec33b8d497c2ca49a0eab4cceac9390505db9bbc785e5876",
        "modelscope/pipelines/cv/crowd_counting_pipeline.py": "27811c7b3f15037f7dedd6905e9df919c94879bc8e0ec239dc5bf17fe39be36f",
        "modelscope/pipelines/cv/ddcolor_image_colorization_pipeline.py": "14ac63c1f9464026f03c6505dd198b8295f359a35d8ba64eee9bcbd47992ae95",
        "modelscope/pipelines/cv/ddpm_semantic_segmentation_pipeline.py": "a487a6b50fb3e564e882775a5d8205c7af8f8e509eb7851c1433e14e26f19c08",
        "modelscope/pipelines/cv/dense_optical_flow_estimation_pipeline.py": "2707de9f399e91e5bd074941ca70b19e827f19b634f912aac0d1090bf7127998",
        "modelscope/pipelines/cv/face_attribute_recognition_pipeline.py": "c37f9b5d77b7410ced545e3b796700b4255c85654390624149b8ba308acd29c0",
        "modelscope/pipelines/cv/face_detection_pipeline.py": "4e94ac1c2f8a56df4f8a2a51c1f59550ab84e3a3511a7e33d299c22ac8d695cc",
        "modelscope/pipelines/cv/face_emotion_pipeline.py": "2cdf8b5ccc5855dc5dece4d3b860054e9338a41ccdf64c4e2453d6d89b8de718",
        "modelscope/pipelines/cv/face_human_hand_detection_pipeline.py": "4bb53bf9594d2ca8d4d3958a4adbdff6a67fb052b104c2f013deb87a1435c989",
        "modelscope/pipelines/cv/face_image_generation_pipeline.py": "c7f9485dac38b41a626c7b1e7f86a45e9d9b8cd8eb8f2466d43e942abe7bd2a0",
        "modelscope/pipelines/cv/face_liveness_ir_pipeline.py": "e4682d342c22b88062580f6966bc260641b0e91fe09c98e1ac371086ddae6535",
        "modelscope/pipelines/cv/face_liveness_xc_pipeline.py": "a86b92163fe18d3697373ea1051f493d8a196fad328e2413ea0abcb7a021312e",
        "modelscope/pipelines/cv/face_processing_base_pipeline.py": "1b87325b07d2b0fb8d387bc4bc8c1dcaed29d3dfc3e365892db315d21d6b4672",
        "modelscope/pipelines/cv/face_quality_assessment_pipeline.py": "fc1b8256b61e4f9673c01e67d604c36e046db506f73cff4705f663b07be271db",
        "modelscope/pipelines/cv/face_recognition_onnx_fm_pipeline.py": "d600504e46c718793b8b4f9fe9421bccc8b5971d4d3de700b15b22e4787c42d0",
        "modelscope/pipelines/cv/face_recognition_onnx_ir_pipeline.py": "f56cf9808f36848f0c0f359dadca22d2debff9f7bd4e4ab9c4d74026a1f99b5e",
        "modelscope/pipelines/cv/face_recognition_ood_pipeline.py": "6c8d6652183a2fb9da71680343c0bfae4c502c57e4a18d2c4a9d3952a631ca48",
        "modelscope/pipelines/cv/face_recognition_pipeline.py": "c19054bb1b0862f3300f9a1a329a9d78dfdca0a9037c70f1844e838d0e225b91",
        "modelscope/pipelines/cv/face_reconstruction_pipeline.py": "4c4822e3afb17782d8916506df7aa77d716be245c1cd389bd1cfee107fc6af1f",
        "modelscope/pipelines/cv/facial_68ldk_detection_pipeline.py": "5c960d4a5bd7860a6047db7d595e6f26ce0a5e62f7a540e84e711b4eab144fb7",
        "modelscope/pipelines/cv/facial_expression_recognition_pipeline.py": "83544e5ff740ee16273bd8d84f0cf0358780a82102e46077b313cc0f78ea122a",
        "modelscope/pipelines/cv/facial_landmark_confidence_pipeline.py": "78a4e735bb9af46477d10a73208c668f5a0645e5cbdf3d9c4fc9f00aef838d23",
        "modelscope/pipelines/cv/fast_instance_segmentation_pipeline.py": "7d3070576a4620b4dc1c3faf72b7383834f3c122c51e1b53b8fdadadb980bbc0",
        "modelscope/pipelines/cv/general_recognition_pipeline.py": "b399ae25d2fd864daa21bd0d43f5a3b4056c6eced51a46ccb537493b2a82cda5",
        "modelscope/pipelines/cv/hand_static_pipeline.py": "4a6891f5cfd80d3eeadcb243cab69b1d9c657c6ae2230921bf087ffa31514c9d",
        "modelscope/pipelines/cv/head_reconstruction_pipeline.py": "da8edebdac64175c010b8f3010c55b8fd5a85b189ee73146737684da938c77c9",
        "modelscope/pipelines/cv/hicossl_video_embedding_pipeline.py": "e7f8586a1697d4612c032a234b728edc176f9a6696fb9df968cd35491254316b",
        "modelscope/pipelines/cv/human3d_animation_pipeline.py": "0383a759776cbb911b916359bb926b9ceeef5cb4c99ee41aac232a1a85d02e0f",
        "modelscope/pipelines/cv/human3d_render_pipeline.py": "3bcf0fe30d899c1cf84a549de4883590b9e904e5359b69229fc643d98a8b1d3b",
        "modelscope/pipelines/cv/human_image_generation_pipeline.py": "2bf39d43bf8099a11a004b89a091f5b66c2347df6a0694da98d086e4decb9c39",
        "modelscope/pipelines/cv/human_normal_estimation_pipeline.py": "d7967baa065753c078db7633a09abcec608ae382ae5b925cf47e4ba08c93b301",
        "modelscope/pipelines/cv/human_reconstruction_pipeline.py": "ebcf40288f0c5fbbbb01095c0a949c07caa6c87eedc0f4fe3b509d991cf34bf4",
        "modelscope/pipelines/cv/image_body_reshaping_pipeline.py": "51a21308b4083fca9b531251ceacbe09edfac86aa00e522eeb738137b99bddd2",
        "modelscope/pipelines/cv/image_bts_depth_estimation_pipeline.py": "169daa6711a0d88080a11e6e3145602f735ad86059136bbbe7b69c3016af064e",
        "modelscope/pipelines/cv/image_cartoon_pipeline.py": "93461105a91bf6235253a337e0e079448ca2329d7a6e5b3588a351715ec085f7",
        "modelscope/pipelines/cv/image_classification_pipeline.py": "9b264b96a63ec934dd587b2dc2afcd939f2245fe665d45df83c8ae321dba07ad",
        "modelscope/pipelines/cv/image_color_enhance_pipeline.py": "07602af91f5c47b8dad50937df88063660c93f6a2f3249154f23e4174166ff07",
        "modelscope/pipelines/cv/image_colorization_pipeline.py": "5e5857666c1ddc21bf4364fb352ec8d6409a82fb1ca231ad309b58ed1c837de2",
        "modelscope/pipelines/cv/image_control_3D_portrait_pipeline.py": "3de597649371487e5f88918f34e3dca0e7874cc76c26a7b5d5543c26b3980bc7",
        "modelscope/pipelines/cv/image_debanding_pipeline.py": "cfab2e64925301f02696195192d7cdce595ebdba727f93228c980d67fd6b1ab3",
        "modelscope/pipelines/cv/image_deblur_pipeline.py": "1ac7406a8752e140405c019b8a027f4d1ba47ca4ca05bf3191c41c1507718696",
        "modelscope/pipelines/cv/image_defrcn_fewshot_pipeline.py": "d859f46fbc46838094e1eebe1122a8735d80e7e28ca569c34faf5db68b508433",
        "modelscope/pipelines/cv/image_denoise_pipeline.py": "0f5cb9b506d19f78e4d9835be896e942eb6956d256b3a9b0f8dd2edbfc90a236",
        "modelscope/pipelines/cv/image_depth_estimation_marigold_pipeline.py": "6745c572b9f38970ef15ef4ec666fc3745ebcb5a4d1a6bfeafe34dd34891f621",
        "modelscope/pipelines/cv/image_depth_estimation_pipeline.py": "1186da4e31fc4816d2d4ecc4eb9f91cce24eba1d5f102e1e84283fe96fd8beed",
        "modelscope/pipelines/cv/image_detection_pipeline.py": "b62d16181a850eaac266eed1967094d5c98fcd835d007d48c00630b76e31a741",
        "modelscope/pipelines/cv/image_driving_perception_pipeline.py": "ce5ac4eba61b158206fd49f17350d62dcba57c5de6a98dc2200edbd25252b812",
        "modelscope/pipelines/cv/image_editing_pipeline.py": "d78b5cc4482c51015efb1d05e82dd7f66524a183b2385326fdeb98913a5993b4",
        "modelscope/pipelines/cv/image_face_fusion_pipeline.py": "b991a55a4df6018eb1c0ae282a1bca4210d04f11ded24593d39a3f585177623b",
        "modelscope/pipelines/cv/image_human_parsing_pipeline.py": "d8bffe63ebcf74b87e6f0f9162ecfcb4061141293ae57160a2b37c250babecbb",
        "modelscope/pipelines/cv/image_inpainting_pipeline.py": "8ba83c030146c96a30f71351b5036afea144d0ae44128663712eac09d4b8a363",
        "modelscope/pipelines/cv/image_inpainting_sdv2_pipeline.py": "0b875578ba396591273a75276af6e99063e9293ffb01db74b3aa66a8bd280462",
        "modelscope/pipelines/cv/image_instance_segmentation_pipeline.py": "c974c38a430e976012c90bd623a7cc90ca8ef97f75f29da8914abf1f46997985",
        "modelscope/pipelines/cv/image_local_feature_matching_pipeline.py": "f517ef3d809b14045d59131aa88646911efdab7d2538cddfd257311feef7b241",
        "modelscope/pipelines/cv/image_matching_fast_pipeline.py": "09474295f02c846a514e132d9be78058cc2c5804e92164e3ea23205179a6fe06",
        "modelscope/pipelines/cv/image_matching_pipeline.py": "ba1058461dfdb228c25fec5fc5ad064ef7a225a832462124bd741297e6679cf3",
        "modelscope/pipelines/cv/image_matting_pipeline.py": "b03336422bd06fc7f685454e6025c9a55d9769b006c77e983feb87c4af1013ec",
        "modelscope/pipelines/cv/image_mvs_depth_estimation_pipeline.py": "15c720c3631016823d77f1aeb325b25268897f2d039e9c9c64a825be75999b13",
        "modelscope/pipelines/cv/image_normal_estimation_pipeline.py": "4a80db5687027024fda71e83cf71aca879bf528da0b04b24f65ca7faa1a2f21f",
        "modelscope/pipelines/cv/image_open_vocabulary_detection_pipeline.py": "d6839b890b9d56f4a13580d9ed4a2a15b1b8fbf47fcc39a1dd6f5ed4db284743",
        "modelscope/pipelines/cv/image_paintbyexample_pipeline.py": "bb97258b5925d2c4618405627201bf33f7b9e58840f4f68672132404852dfcb7",
        "modelscope/pipelines/cv/image_panoptic_segmentation_pipeline.py": "7ad75d9b3a075f80d3f214062d7ac66050cfc43568d0c8dab93630bb4d662502",
        "modelscope/pipelines/cv/image_portrait_enhancement_pipeline.py": "a6147ea4752d247abb0b10436a2229d3e92120a296fbbda51a951543e0bcd49b",
        "modelscope/pipelines/cv/image_quality_assessment_degradation_pipeline.py": "1f3af7a785068a7599576fc608f16ca3470c6463184ccdf0320203d1d7b53887",
        "modelscope/pipelines/cv/image_quality_assessment_man_pipeline.py": "2a0d0749b8c55c433f1daade9af13c18d54f4c560786ad5f38b4a2f482c24f4a",
        "modelscope/pipelines/cv/image_quality_assessment_mos_pipeline.py": "f7d0703d95da99cdeb1310945e1bab5d69ef80fc59a49522665ab1609b015bfa",
        "modelscope/pipelines/cv/image_reid_person_pipeline.py": "92eb9009b3e9d650da000b24921609aeafee3f4da2651056763432065f8dddf3",
        "modelscope/pipelines/cv/image_restoration_pipeline.py": "92344671352174fb3f92591430a72f03681c58841c64d4c413291a2c8b7f1a14",
        "modelscope/pipelines/cv/image_salient_detection_pipeline.py": "8c62f5098c610bc7add35a4f9a4c89a564aae8e951b8a1938e76c20a95fd1291",
        "modelscope/pipelines/cv/image_semantic_segmentation_pipeline.py": "9fda733eff7c05bb56422f8d469d1b0d8cee3b69685036041e5931031179fcdc",
        "modelscope/pipelines/cv/image_skychange_pipeline.py": "6832336dea85fe916fbe8ddbbcd1c55b9edea5229f5f41bee264f158b7e1ca46",
        "modelscope/pipelines/cv/image_structured_model_probing_pipeline.py": "1fd395450282bc7599eeff245ed810218f9a33f22d3be4f62b684a8b630e55e5",
        "modelscope/pipelines/cv/image_style_transfer_pipeline.py": "eed606fa7b70a1a587803fed9eb31936ea9f16db569357974682b70618a7539e",
        "modelscope/pipelines/cv/image_super_resolution_pasd_pipeline.py": "a7ad4cd4caef5dd5818a58558c7a32e1d8c4fc6ca825f8905c65f84676712f18",
        "modelscope/pipelines/cv/image_super_resolution_pipeline.py": "86e3f32ca9ada550d1e97829cbccaafbbd0c3c016a074244e29323628e6ea122",
        "modelscope/pipelines/cv/image_to_3d_pipeline.py": "646734158275b36790e05b6d14138501f65200318f344b640b13a51e394a2446",
        "modelscope/pipelines/cv/image_to_image_generate_pipeline.py": "b23a482e0ad8fddac8b5a6d5fdc5163d4d563c8faaa1dc99d6d10261a55ea482",
        "modelscope/pipelines/cv/image_to_image_translation_pipeline.py": "d92f6a147bfcc5909671a3f33c520f45b597a6cc898857dfde0bb552bbfd3ed1",
        "modelscope/pipelines/cv/image_try_on_pipeline.py": "7c86ee0c7eca4c404da5b7def7440cbd88197d494632d52fde94b73c5c302f24",
        "modelscope/pipelines/cv/image_view_transform_pipeline.py": "55f90a72193a5510dd0d1e76b6f81c175ac04346f8c84bb40a205cbb9804ef04",
        "modelscope/pipelines/cv/indoor_layout_estimation_pipeline.py": "d0446bf1ff43bbafd2cbfbebde09fd8dddcb19be41160a64efacdd322cb79639",
        "modelscope/pipelines/cv/language_guided_video_summarization_pipeline.py": "d3f585431e9cbcdfb58af0b7801ad61b81a98fe2687907a90c065a41699fde76",
        "modelscope/pipelines/cv/license_plate_detection_pipeline.py": "c43432b2198fd20e2c8667392102255551b7c179c395342bcf5107933bdf6349",
        "modelscope/pipelines/cv/lineless_table_recognition_pipeline.py": "de9580e45edb4d9ff73749f2da6037ac3dd7e1ab48114499a299ffd84bfdf96c",
        "modelscope/pipelines/cv/live_category_pipeline.py": "0e1f91296a6518c9e5a1157c174d1d0b5379bc4e9b4bd5f9544888a77a0386a5",
        "modelscope/pipelines/cv/mask_face_recognition_pipeline.py": "029d4fbb63dfb5e3f52c25c8460dbe738f40887a9aa8edd394cd887db0c0c5ac",
        "modelscope/pipelines/cv/maskdino_instance_segmentation_pipeline.py": "0addaddd036a41d8bcbd6dd736a35fdb1285501b79fe2144dbdc83f44e7549dd",
        "modelscope/pipelines/cv/mobile_image_super_resolution_pipeline.py": "a50b0cd598e428ecf3775483b21e41edf3f6fc8cfe63ad263b6ec1db80c19a3c",
        "modelscope/pipelines/cv/mog_face_detection_pipeline.py": "285165b32ffb4ba4c08f51c252d797ed151f301cb1883258ce792ea9fdda22da",
        "modelscope/pipelines/cv/motion_generation_pipeline.py": "a044a0a30a27dea347a290eec23a47db26da33127c6d034c90b58723df5e582a",
        "modelscope/pipelines/cv/movie_scene_segmentation_pipeline.py": "81109cd3cdb75a25eb941027241f2e96046636e26e2127ebecd6fd47fe546df4",
        "modelscope/pipelines/cv/mtcnn_face_detection_pipeline.py": "ae3d2f155e2842d79623e47cdebac1e04521a271e304140e81fe702f9e366356",
        "modelscope/pipelines/cv/nerf_recon_4k_pipeline.py": "c044b028184c1804aff3e366fcd9640fe32643870deb7bedfd882ddba2f3bffa",
        "modelscope/pipelines/cv/nerf_recon_acc_pipeline.py": "21cb28eb44d744b9c0373a33383ec1489915ab95d89de5021c63db90ada0ab72",
        "modelscope/pipelines/cv/nerf_recon_vq_compression_pipeline.py": "6b1007852114a75be8cd0cc87363cdf872cd5ea25bdd8f2b1061409d442c2bf2",
        "modelscope/pipelines/cv/object_detection_3d_pipeline.py": "f7ab5432f6c6a4b2972ac36801d88593e43baf74be128b8f1fab771261eeb6ec",
        "modelscope/pipelines/cv/ocr_detection_pipeline.py": "ff9b638dca654d0ec0f24f2c90420cf89fca5a8ab14b9dc1cfb3b092e7afa089",
        "modelscope/pipelines/cv/ocr_recognition_pipeline.py": "2f2ebaa86fdc836b91b6351fa96cea65aa591324e75236ca4bba3325b6e7572e",
        "modelscope/pipelines/cv/panorama_depth_estimation_pipeline.py": "7ec5640dccbac1bf78f86ede97efdb3ba988e47c8eba3ef7e57ec84ef86dd222",
        "modelscope/pipelines/cv/panorama_depth_estimation_s2net_pipeline.py": "47aed314c3ab4f555132fa8ac17f042028bfb3aaf50f303dd56c76ee1fd71aba",
        "modelscope/pipelines/cv/pedestrian_attribute_recognition_pipeline.py": "d59b533839ccc9d5f7e87cae4c5623567a85412a767a6c40d0c055cf59fe337f",
        "modelscope/pipelines/cv/pointcloud_sceneflow_estimation_pipeline.py": "0837266577707b6d1b6f3aba07130cd2017e3afbee093b238d5408f25776f1e6",
        "modelscope/pipelines/cv/product_retrieval_embedding_pipeline.py": "df2e0f5dffd4831e322ba3189bfb5ecda055c627b8c1870f4db6150e513d7abf",
        "modelscope/pipelines/cv/product_segmentation_pipeline.py": "6ed5ed9b5a9211fb4334ebc8fbac57dea74d706bdc9cf4489ad53c44b351eb90",
        "modelscope/pipelines/cv/realtime_video_object_detection_pipeline.py": "3a0e1ff3adb1f9bfed9dc0764c1b51714bb37e90ad109b3f6fea1f290564b692",
        "modelscope/pipelines/cv/referring_video_object_segmentation_pipeline.py": "5941644e2c0a833c82333b51c42eb9c96bd0567d604b62f7de92c7ab7a03b8a3",
        "modelscope/pipelines/cv/retina_face_detection_pipeline.py": "f1c44d8c196bb1be5a8a181e2349dc7c6bff5f330c03ca339460c5a8b7686846",
        "modelscope/pipelines/cv/rife_video_frame_interpolation_pipeline.py": "074c6034a2d62a97e5dff93309ad976a97277a7d1101785a4bdfd904f88db333",
        "modelscope/pipelines/cv/self_supervised_depth_completion_pipeline.py": "17d2a5ddc55414fe0502382148fd5b40a2fb906d761af16ed8f927f656cedaea",
        "modelscope/pipelines/cv/shop_segmentation_pipleline.py": "d56e6883dfb531979414b30af88c1bee0abb0834d286e281d51060bdc43d9b8f",
        "modelscope/pipelines/cv/skin_retouching_pipeline.py": "28936e212dffbb95e36de62139ac67433f78ea4c9f624c7ac7be0fe8a8b762ab",
        "modelscope/pipelines/cv/surface_recon_common_pipeline.py": "a0474323ab0b1d2a9cb342118a940a8513ad1cd00e43f2a7fda474bb284b1e81",
        "modelscope/pipelines/cv/table_recognition_pipeline.py": "f26a44c3d099846532100932b66a72c9953f6dd1315686637cf2ff2eb109b93d",
        "modelscope/pipelines/cv/tbs_detection_pipeline.py": "c5b941a04cec86592b604077f4ca1a5209e58881ca2817e51fc665155a86f3ac",
        "modelscope/pipelines/cv/text_driven_segmentation_pipleline.py": "72402bce923d3741cb124a3b62ab986771fb5a9aaf5e0ff4e534e2e645df862c",
        "modelscope/pipelines/cv/text_texture_generation_pipeline.py": "ca14c5183bb6648d517b5cc16cecf6b9330f38536f3c68698c16f8dc508a8f86",
        "modelscope/pipelines/cv/text_to_360panorama_image_pipeline.py": "c7e066c5aaf8b566f2751c6de0c8e811a96b44efa552452af970ddcf3c531799",
        "modelscope/pipelines/cv/text_to_head_pipeline.py": "e4f603d1a7566963fb7a68201be619e8403f3f1a652f0651bddaf8a7d707f215",
        "modelscope/pipelines/cv/tinynas_classification_pipeline.py": "2ffdfa030a7457943e7d72ab46094b1e37c7cc85212cb4c94c863ea630c1d134",
        "modelscope/pipelines/cv/tinynas_detection_pipeline.py": "1a7c1c541837e6213a9b2d859341ebddb6682cbfb797ba5d5791060d32d7ce8f",
        "modelscope/pipelines/cv/ulfd_face_detection_pipeline.py": "32620703eb7aca049d53c88d74e1d125700422bb898b8251f80d3a8cbdf8a513",
        "modelscope/pipelines/cv/video_category_pipeline.py": "fe78b0e14c5221506563ebbbbfa57a3ad94d90ec45efde5be3b2272a740c3a91",
        "modelscope/pipelines/cv/video_colorization_pipeline.py": "f9cdfa61b89aa047190c1642bb706ca6bcbfdf9dae53c8d784a91390f39bdcde",
        "modelscope/pipelines/cv/video_deinterlace_pipeline.py": "d02c2f7d0cc9ab38e4c59875f59b853db3e67f847458b41fc18873368dab9332",
        "modelscope/pipelines/cv/video_depth_estimation_pipeline.py": "6b83f1e36c64a5c428c0b8484e80b245efee2a05f6d71c9eb9bfe1b19fdc5ac0",
        "modelscope/pipelines/cv/video_frame_interpolation_pipeline.py": "4414994b685c83f6278ea28e0c107de3bebf7ec7472e42c35575ff7bf9a86e19",
        "modelscope/pipelines/cv/video_human_matting_pipeline.py": "3de50e95566820a3ae1660e3bee0887aae2927582c4f4e592794ff27c9a7e940",
        "modelscope/pipelines/cv/video_inpainting_pipeline.py": "6d77ca8afa76aa17c437c9a785e4327fc875df42ec6caad02ceaacb2b2d17e0a",
        "modelscope/pipelines/cv/video_instance_segmentation_pipeline.py": "ce5fba3c8ae4106ad2c8dff16466d8d160f35c8c41cfb65600e23603a0e6b8d4",
        "modelscope/pipelines/cv/video_multi_object_tracking_pipeline.py": "46a27b1bcda023073d7fa26527395a05c1e688d6af289e7adf21e52ce722c418",
        "modelscope/pipelines/cv/video_object_segmentation_pipeline.py": "b3974fa0a956a9276424f311eeaaa56538474cb62e63d02807ffc502de37d37d",
        "modelscope/pipelines/cv/video_panoptic_segmentation_pipeline.py": "1d594d8dd773c39dc637d74a95ef9dcbde556bcbed09407109d0af5e9a898ef9",
        "modelscope/pipelines/cv/video_single_object_tracking_pipeline.py": "1f22567f08ecbe0a7853c3a2d89ed0107252ca6b25227bb05003465ebe97838e",
        "modelscope/pipelines/cv/video_stabilization_pipeline.py": "9ebf9fbfc4993993b5d59de770a04c8665a2e38375fec9ab9f45f002a1c1c764",
        "modelscope/pipelines/cv/video_summarization_pipeline.py": "bd31743735bc441c456af62b38909ec6c81987122a82acaa045c4c2748f1c854",
        "modelscope/pipelines/cv/video_super_resolution_pipeline.py": "1104bbdfa8b977e8ae04fcbc11f00b611134f9ee762677c706efef79acd8c233",
        "modelscope/pipelines/cv/vidt_pipeline.py": "293264c504645501d5169e561288a1cae7dc75ec91c24a9ec8e85de96f915489",
        "modelscope/pipelines/cv/virtual_try_on_pipeline.py": "0e22c3059c73cab946848a2768444730f852c5036a03ed01134fec1f96daea12",
        "modelscope/pipelines/cv/vision_efficient_tuning_pipeline.py": "1497138f037d7d9ede0d78154d9105885ae0d5fe48ba123990c9dce04a2d0cea",
        "modelscope/pipelines/cv/vision_middleware_pipeline.py": "0975b242d7541c04438134bf6bf19c8afd6e6895f84483b2417d5965621870fb",
        "modelscope/pipelines/cv/vop_retrieval_pipeline.py": "c46614f73bc7bb3b15a5ecececf2c50dbdc7ac4d8699ceece51325ce60100506",
        "modelscope/pipelines/cv/vop_retrieval_se_pipeline.py": "13f477d65d808adeee2d6a1d98e14f3756576d0b253bbff85b092ad2ec2ab402",
        "modelscope/pipelines/cv/ocr_utils/__init__.py": "5072903bac4e0f9a503a0e8c5f1e7251a2621b9bf1482632aeb377e7805b84ef",
        "modelscope/pipelines/cv/ocr_utils/model_convnext_transformer.py": "789f31d122c588cc5e8048511439a1d64063a30dd59a8f04042977596536893a",
        "modelscope/pipelines/cv/ocr_utils/model_dla34.py": "dee82c1909594577a1d9ee2ab8be0fee1c26deb4dff05011bc21f99f89987800",
        "modelscope/pipelines/cv/ocr_utils/model_resnet18_half.py": "d044ad3eb4723b775138b7c3d03d63e96aaddf3cf2479cd17c060c018c9d25df",
        "modelscope/pipelines/cv/ocr_utils/model_resnet_mutex_v4_linewithchar.py": "789c6b22edd6698ad25fcdbd468d9862e0a10ba8afebb3faa40d901f496866dc",
        "modelscope/pipelines/cv/ocr_utils/model_vlpt.py": "a1dae78ba824e95e5fb71c3628eda383042f37fd0139c894d66090fcee997391",
        "modelscope/pipelines/cv/ocr_utils/ops.py": "c3a88c84d5d3c7a1820698b198ad0ea08f99b07fd056b114f15e14513f9fefd2",
        "modelscope/pipelines/cv/ocr_utils/resnet18_v1.py": "936c77e513bb17c1459a1a61fd8852a78c0e21814b97e59b581eec6a3c79cadf",
        "modelscope/pipelines/cv/ocr_utils/resnet_utils.py": "a95c1aed13cbd8b4a2cfbac95d5e2b213241be96e29ad4eef4d1fcc45db12c71",
        "modelscope/pipelines/cv/ocr_utils/table_process.py": "97a39a505dba9ac052997ec1383b911402c0635ced84a27cf92a59a6075cb5af",
        "modelscope/pipelines/cv/ocr_utils/utils.py": "accae272f51e0e962f883649122e77599b0842165de7734c30d79c9919314ec2",
        "modelscope/pipelines/cv/ocr_utils/ocr_modules/__init__.py": "115d7f3971f1dfe6d90a839f975cd0e9bcce4b8d37179a46e3be48e82253fdb0",
        "modelscope/pipelines/cv/ocr_utils/ocr_modules/convnext.py": "72efe83f3139ec93a22ef41b7502efa3e5ce1cdfbd76b7686bac1d0ef702f642",
        "modelscope/pipelines/cv/ocr_utils/ocr_modules/timm_tinyc.py": "b244726bd34ff1b2495de30600cf6f3f449705d638b9a766672377a4926da927",
        "modelscope/pipelines/cv/ocr_utils/ocr_modules/vitstr.py": "d3d4a6c9d4a388c2ddbc870c4028711c0c3a149f6099a79248cfc44b1d5d7e3d",
        "modelscope/pipelines/cv/tbs_detection_utils/__init__.py": "3727adff524e0616022eadd8f4af21a0778b29fc4c77bdfefd1afce2cbf5e4b7",
        "modelscope/pipelines/cv/tbs_detection_utils/utils.py": "5795d91ee1cceefc9a55d80927f353f9210583eedd8b6130d4abec4a4cfcf01c",
        "modelscope/pipelines/multi_modal/__init__.py": "e008d5288ac1bf97d65793378cfa539bc16c6c4a4d10b54fddae7b8c1d3a1801",
        "modelscope/pipelines/multi_modal/asr_pipeline.py": "d7f9064dc92713f1e4cf87658a611ca509cfccd5688357d59caa3703a2ca61fd",
        "modelscope/pipelines/multi_modal/document_vl_embedding_pipeline.py": "273f04c17d0f9d4b3c6c41319a206a1c1c8262253826461b9a8ee2b44947b9c8",
        "modelscope/pipelines/multi_modal/efficient_diffusion_tuning_pipeline.py": "0c48a3d3b74de2678ddb8c960a337cf6dc507c604287a74121782fb9b5ce3921",
        "modelscope/pipelines/multi_modal/generative_multi_modal_embedding_pipeline.py": "1b6fb2e0bf2f0f0cbb4503304fc3496f54b0782669b894d04f6f465f1fe0003f",
        "modelscope/pipelines/multi_modal/gridvlp_pipeline.py": "f17d0ed6421621603b8f526356432123ea53f1623a5bb86d2d2a6d3d52efaf99",
        "modelscope/pipelines/multi_modal/image_captioning_pipeline.py": "4bdc567c5d302a38ba218675aec090dd5bf24fa1ce3427f4082a9972aa446111",
        "modelscope/pipelines/multi_modal/image_text_retrieval_pipeline.py": "cede9a947fb13064d79844c41f26b19472bd8374143c453af6dfa618dfeae1cb",
        "modelscope/pipelines/multi_modal/image_to_video_pipeline.py": "5b9c6b81acb63cff10d04dcd6a27ecb07f8abd624b8447d0eb7adc294af2dd81",
        "modelscope/pipelines/multi_modal/mgeo_ranking_pipeline.py": "441329ec27d3c82a1921a6111ac1f15aef241908aa1d76a7bc4ca9d73f0d7909",
        "modelscope/pipelines/multi_modal/multi_modal_embedding_pipeline.py": "cd391381b2df44d870dd2feae86d8a329415c36296be4c6d6cfa4debaacdce41",
        "modelscope/pipelines/multi_modal/multimodal_dialogue_pipeline.py": "d2245ac3a0f2fb2a4e07bb184833335a666b2cbf7d0ec9e10e386e54f9f85ffa",
        "modelscope/pipelines/multi_modal/ocr_recognition_pipeline.py": "fba03cb7e5b1c3a365c48b550b09498d7c7ddb729003b121edf4fb396f1e1f13",
        "modelscope/pipelines/multi_modal/prost_text_video_retrieval_pipeline.py": "3af714c49babbbb55e9920009eafaff43b3a468f4ae6ada1556fe24595162b19",
        "modelscope/pipelines/multi_modal/soonet_video_temporal_grounding_pipeline.py": "42cd607d98cae58174629e74dbd6e81bfcdf3af2db771125a4e97e72abd4c252",
        "modelscope/pipelines/multi_modal/sudoku_pipeline.py": "1065ba04cc393f08a62cb2d0133957c07af7dff55ea5c180805a7ceff0ed3c63",
        "modelscope/pipelines/multi_modal/team_multi_modal_similarity_pipeline.py": "06fff0eb3020ce1e901451b378a5d923c75334b6073f4db75fc70482c5867336",
        "modelscope/pipelines/multi_modal/text2sql_pipeline.py": "bf780d3313f20e3e5108547950994b18f27e632acd4ff418b6ed2c3addc3bd5d",
        "modelscope/pipelines/multi_modal/text_to_image_freeu_pipeline.py": "91a318cfd44c6d6a9c7095a1eec5f40bbab0d4b71c0c8e126ed420e7ad9dc7d5",
        "modelscope/pipelines/multi_modal/text_to_image_synthesis_pipeline.py": "01ee925ef686248e89606151ef78dcc48bbd3c717aef1789e0954b386667ced4",
        "modelscope/pipelines/multi_modal/text_to_video_synthesis_pipeline.py": "ccfba186fc35df121129de1de106ee897fe24d3ee91bbd0049af826d6c5ae17f",
        "modelscope/pipelines/multi_modal/video_captioning_pipeline.py": "66e522f679c9733fadc36e9fc3ecf5a74e806c71f33f49c696535f7e759d8d0d",
        "modelscope/pipelines/multi_modal/video_multi_modal_embedding_pipeline.py": "914fd432a0156a983495c31f0980b77a6e811644730568f2ddd22fc4ecc173d2",
        "modelscope/pipelines/multi_modal/video_question_answering_pipeline.py": "ed700098c54c054f21cedb31262be2a8635062cbde0b4d458f9e78b260edc13f",
        "modelscope/pipelines/multi_modal/video_to_video_pipeline.py": "10248e375457368dc87f4a0297fb645f614ec8a8083090dd86aa4c31aff94494",
        "modelscope/pipelines/multi_modal/videocomposer_pipeline.py": "55d8cbe01fbc7a632932bbfa738a83c94098e76cb5cec3b4fbc4ad2fe32d77ed",
        "modelscope/pipelines/multi_modal/visual_entailment_pipeline.py": "69b0efeabb308de98b81f756eb55d46dceb480d2f8724534a10dcd89c417bd39",
        "modelscope/pipelines/multi_modal/visual_grounding_pipeline.py": "922841fbd7084d6e145fad7cd3a58e5f95645ca871a2ab9c648c609d0b2eb7a1",
        "modelscope/pipelines/multi_modal/visual_question_answering_pipeline.py": "88391b52145a7b6a313e341e9f6363a2c0a2bd6159a83dcd6c64b440b02f080c",
        "modelscope/pipelines/multi_modal/cone2_pipeline/__init__.py": "119ae51b84d899bdc7bc789d30cbf9e4bcca85a220f19ef70fbb13664ddccac0",
        "modelscope/pipelines/multi_modal/cone2_pipeline/cones2_inference_pipeline.py": "fb5cb1656b4a368b5c40e2f79aa19fe72b9b1dc83a56fbaf2ead2c2b418af8f8",
        "modelscope/pipelines/multi_modal/diffusers_wrapped/__init__.py": "766117c64f6e00adaac121432babb2be47d5594fb475d1878b55a556f8f1ea04",
        "modelscope/pipelines/multi_modal/diffusers_wrapped/devices.py": "6e42a9abc923965472f25e8c14d23b275eb2f584355ddd104b3e2b93afb20348",
        "modelscope/pipelines/multi_modal/diffusers_wrapped/diffusers_pipeline.py": "258bd7daa5515c75543eab401412d3d3888c5c221989aef948650b921855a08f",
        "modelscope/pipelines/multi_modal/diffusers_wrapped/pasd_pipeline.py": "2215d65074821d1523143fe719abb72da6e19a0109c3d2fc45af14ea207a8389",
        "modelscope/pipelines/multi_modal/diffusers_wrapped/vaehook.py": "b22deca5c5063c43a57baa77906336a54df15041511c41ddb7fe5f4b771493bc",
        "modelscope/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/__init__.py": "fe82bb0bd1fcdac17b39b042889dc5e050871b0c138733e1c8c5be00c680c96a",
        "modelscope/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/chinese_stable_diffusion_pipeline.py": "cdc61cb91e27c33fd21f26ea26d8152583753569c1ca784716d7785ae61c4e8e",
        "modelscope/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/stable_diffusion_pipeline.py": "cc5192c1799a0541ef23f894f5472d8cac259b5df4824deddeac9d0123a39d79",
        "modelscope/pipelines/multi_modal/disco_guided_diffusion_pipeline/__init__.py": "d236b77855bff0f5807078e23ab93fea96f1320ae451e3919ca51a2c10560b49",
        "modelscope/pipelines/multi_modal/disco_guided_diffusion_pipeline/disco_guided_diffusion.py": "bac8d2cf210dd316279c6a9d11fb45ab14585cda4e0d15b3b7046dfd63779d23",
        "modelscope/pipelines/multi_modal/disco_guided_diffusion_pipeline/utils.py": "ec01d3cc462f0840c8bddf94d0767cafe112db6026ce3f6ad91a726bb3e870d7",
        "modelscope/pipelines/nlp/__init__.py": "c3e3af01eb3615dc4b2c645e2c6f3acef3c26ad0f5e30bd176d63c66f76c63dc",
        "modelscope/pipelines/nlp/automatic_post_editing_pipeline.py": "e769c5779dc0dc6a7802d0f52777a95f2a6a8b893528792ea1e3fb517132f149",
        "modelscope/pipelines/nlp/canmt_translation_pipeline.py": "61941e4a0cd658467156fbee0128d631c0d5447268b13f8fdd8df2b66fc441ee",
        "modelscope/pipelines/nlp/codegeex_code_generation_pipeline.py": "7d77de90698f24be9327c95f0b1fd7281ceb7c0fb05ae7f6aba5dbf27f8d99d5",
        "modelscope/pipelines/nlp/codegeex_code_translation_pipeline.py": "aae2e65441d90e60c637c91906748e877104e9b90cdc9d4ebea05c56c50b3eb0",
        "modelscope/pipelines/nlp/conversational_text_to_sql_pipeline.py": "e4799e361d504dcb7f5f33ed201dbe1549e5c4fa4bf59873ed122f200f781a22",
        "modelscope/pipelines/nlp/dialog_intent_prediction_pipeline.py": "de5213c17c2afae62dcac070560627074be8bc2595e4316004e9c9100a46795e",
        "modelscope/pipelines/nlp/dialog_modeling_pipeline.py": "d3cab60b747df4172ea68dd3c2d3ae5f48941aa8b8d5836ec9a68eff688d8633",
        "modelscope/pipelines/nlp/dialog_state_tracking_pipeline.py": "71ad1f3829a627e8b31020d1c160a4f05d7fe895d6917aa1ebfad5526e263188",
        "modelscope/pipelines/nlp/distributed_gpt3_pipeline.py": "3bed4ae5f24e09848f9fd678668d2d86fde2b001cf3699b598c16d79d62a1f30",
        "modelscope/pipelines/nlp/distributed_gpt_moe_pipeline.py": "325eb865da2071a029ee539087d0c2cc0a6d085dc70f043d85bd2c7a321394c2",
        "modelscope/pipelines/nlp/distributed_plug_pipeline.py": "84bc4502dd03ee7c1e4a019199fabff97faafb2436aa3871bad7ad37162af918",
        "modelscope/pipelines/nlp/document_grounded_dialog_generate_pipeline.py": "1c194eb6d35840a06c936ce5d6ac48dba2fb11eecb8fd04b81e20150cfe04db5",
        "modelscope/pipelines/nlp/document_grounded_dialog_rerank_pipeline.py": "53f7830d8bfa57792e9990a1fdeb6a1923605dc51444588f1e6ae7de69628d85",
        "modelscope/pipelines/nlp/document_grounded_dialog_retrieval_pipeline.py": "a82d7e1cc956fc5bcaaf2e91389b131b0fb20f7ec5b4e4a48aa0dafce74facb8",
        "modelscope/pipelines/nlp/document_segmentation_pipeline.py": "6174688406e46321f80fe9a7c9a279b1e980df8b933f5c1c72ef0f0092415904",
        "modelscope/pipelines/nlp/extractive_summarization_pipeline.py": "123ea292a60c6e22ea64c93903fe7aefc952140d6e109951883bad69c1df4082",
        "modelscope/pipelines/nlp/faq_question_answering_pipeline.py": "20b8a12587d1019da70158b19106062888916643d14d06f3b9e1805bc70bca96",
        "modelscope/pipelines/nlp/fasttext_text_classification_pipeline.py": "17a39a54134c5be9a30bf96c943e901979d48faf161cc72b81864bc8ec4e9445",
        "modelscope/pipelines/nlp/feature_extraction_pipeline.py": "ca4e33b6310f96dab7381e17a7347da34b9d5129e21296f46fe964f1b1d79687",
        "modelscope/pipelines/nlp/fid_dialogue_pipeline.py": "3391f884a9c9fcf0106188a655777f8a00ea66458aaf23a6fa6c2e38da6ec359",
        "modelscope/pipelines/nlp/fill_mask_pipeline.py": "7907d2c089da013ff191a1f6c6dae7828be4c7abf5254987093b89f93ff68e1a",
        "modelscope/pipelines/nlp/glm130b_text_generation_pipeline.py": "a1958214c2f90a698a03f45c8c069f44e2ee00433f587162f4fce5c29da740a3",
        "modelscope/pipelines/nlp/information_extraction_pipeline.py": "b17edabd522429085723ec141c5e9e5c2be820ca001af591385812c6d37bc283",
        "modelscope/pipelines/nlp/interactive_translation_pipeline.py": "58f5e1f43dace8dd76c14b7ebfcb61c370d0b0be680556a3c1a52ac6b99128e6",
        "modelscope/pipelines/nlp/language_identification_pipline.py": "6fb0d5455ca2ed38f46a2ea402d92c6037e5ed634aef8f5ee05f377df2c8278c",
        "modelscope/pipelines/nlp/llm_pipeline.py": "3f9f20f8f8fff6a6a2ec88cb039e7408937d95ff547b6932a6463ec8d76e2860",
        "modelscope/pipelines/nlp/machine_reading_comprehension_pipeline.py": "1a8033a17a2d245181da9a7da5b898b45612a486a8c320bf785a2e7e0d5a558e",
        "modelscope/pipelines/nlp/mglm_text_summarization_pipeline.py": "a7314d7c9fd41253f8d81f6368c54704ae967a2b5a4e1105e5d03eab3aef7865",
        "modelscope/pipelines/nlp/named_entity_recognition_pipeline.py": "b067459a2fcd13497fab7315cb5e4b82003db733fb30a5e5a4b03de351cb0da9",
        "modelscope/pipelines/nlp/polylm_text_generation_pipeline.py": "072310095537fde02a10e3a956265b237e6111f8856e0b5d67357693aaae7334",
        "modelscope/pipelines/nlp/sentence_embedding_pipeline.py": "929740ffef07bb069d004e702f0ec306dcdad352454f85776a8dc7b49254a6d6",
        "modelscope/pipelines/nlp/siamese_uie_pipeline.py": "a640667efbb811d28a296e5b0f2275cf54e2a02129e1baf725c9c359523fc5c3",
        "modelscope/pipelines/nlp/summarization_pipeline.py": "c006ee2d53211119c87c42ca9c678d58a016b605dcbc6521542e15d3c67253c7",
        "modelscope/pipelines/nlp/table_question_answering_pipeline.py": "1230d3a98e51ae09ff481d5c3cf4e2e4b557fe51bd2d2972e50ae92aab3cc358",
        "modelscope/pipelines/nlp/text_classification_pipeline.py": "41f75a1440d896588e6a59d761692089d02eda147d04c9db7bd74cbb7084cddb",
        "modelscope/pipelines/nlp/text_error_correction_pipeline.py": "1b14fe4dd6e851bbbace11ce9c038be9ca6cf8c03a62cb9d88cbb13906fb09a5",
        "modelscope/pipelines/nlp/text_generation_pipeline.py": "37e06159a60a582e3c037a6db97e12c3d1bce855ae14522db3c91228093cb3b5",
        "modelscope/pipelines/nlp/text_ranking_pipeline.py": "da8c68a5e68c4dc15e32c03cb5fb7b204ebe1916ec77bd2c469da9b45d93c7e6",
        "modelscope/pipelines/nlp/token_classification_pipeline.py": "5d444b0f81f89b88ffaf544f327413e862bc5fb5d34f78b790c40b8f75beb886",
        "modelscope/pipelines/nlp/translation_evaluation_pipeline.py": "273d90c2040aba4d168d164a159dd8c77f14c0ee86217f09b6a946b53a2a6ce5",
        "modelscope/pipelines/nlp/translation_pipeline.py": "2ac1b113a43109da7a8a71a468327a4397a76fc1b7be003cb514e66675f62709",
        "modelscope/pipelines/nlp/translation_quality_estimation_pipeline.py": "f6992255bfdc95c51b86ab94ebb2d72dd002944bea4f1d0eb476095a8c9567c9",
        "modelscope/pipelines/nlp/user_satisfaction_estimation_pipeline.py": "c41f86fd7114f3e8ecafaa05eea1f817b1d0f9b515e2074e49cc802b2ce7380c",
        "modelscope/pipelines/nlp/word_alignment_pipeline.py": "b1b7f20dfdf917c9a98651999ca33a8ce23d74008b0ba46f4e2df5debfe46d0f",
        "modelscope/pipelines/nlp/word_segmentation_pipeline.py": "05878c2d1cf5d17f951bbcf35d5ffde51662f2546cf5a2ea510d55f3ab6be88b",
        "modelscope/pipelines/nlp/zero_shot_classification_pipeline.py": "cdfe3a77dc9273888e69225826cacae49624378db7049f2b89a8f150bfbc74a3",
        "modelscope/pipelines/science/__init__.py": "05877e2d1a3a6d411a593252ae06679eb3a0d883c5d0cb2a8d43fb8cb79f4e25",
        "modelscope/pipelines/science/protein_structure_pipeline.py": "0385de55b1b153bc1e2f0c932e0b86d12b161fea9f71b2f8925100ddc526b86a",
        "modelscope/preprocessors/__init__.py": "bbc6742618fda706a2d9e74f7965317342a4a8892970930d56cf1c3f4d3d6f49",
        "modelscope/preprocessors/asr.py": "31b911e94d1f337bbfe6f7b4e965242ef79e46877386fb67dded0066ac8dcc18",
        "modelscope/preprocessors/audio.py": "995d5d7bb1f265a6512727218b4b7fe36003872ca134e70c2b70cad380fe85e8",
        "modelscope/preprocessors/base.py": "5d8da56584ae384b637c255031a1bc8696304c2f7f4b673d1f8ffbdf6701c1c4",
        "modelscope/preprocessors/builder.py": "2279733c962bc9b02400dd04441e1f725f90de887a881edcba269cd75f4bd5a4",
        "modelscope/preprocessors/common.py": "d610ca8c9ddddb2e6b920937eaddd4b9b39baac48cee1e5719c2d0a84a2a8859",
        "modelscope/preprocessors/image.py": "ba44792df22b0e85de06529f2f4cc17500c01e134ab637b2152a8d63d60faff3",
        "modelscope/preprocessors/kws.py": "652230a9db2ed2146d3e92ea791ec3c5a7b9cd1057e8b81e4bfed8dd5fc90867",
        "modelscope/preprocessors/multi_modal.py": "b59afc91274e2911d50d68ef43a19a0e8d23343877b8681d7851571f922cc271",
        "modelscope/preprocessors/speaker.py": "694be9c157dd3daa75253054be4f074603571d6f7df96250417ebdb6801fd9f1",
        "modelscope/preprocessors/tts.py": "a7531c8eae27b206ac4e031236baf77dd0e6723e0c1a9adcbf25654093cfafd8",
        "modelscope/preprocessors/video.py": "72fc6a16c5a744f81266e804df9ede47b572a5a048e4da6a4485b1626e193bc6",
        "modelscope/preprocessors/cv/__init__.py": "b91324c734ed21e25f4cdf32772e2b48049d8adc03e01cc22d9e421689d4a7c4",
        "modelscope/preprocessors/cv/action_detection_mapper.py": "2fb1bfa6033ab72c3fa0b75c0e4fbabd6ec0aaae124a9ef9650efac6906f12f9",
        "modelscope/preprocessors/cv/bad_image_detecting_preprocessor.py": "5affc8f559152f5f20cc3bc7748d8557b97c1a4dca131d2ced2ee194c51a6079",
        "modelscope/preprocessors/cv/controllable_image_generation.py": "0f9889787d01efb35b9ac6c2e82e244b5ebc24ac5e22738734d88c8eda9baf55",
        "modelscope/preprocessors/cv/cv2_transforms.py": "5d9ed15da6a26cbb9604bc3f8207f507b24ac151529f840dd4eadcf908c5adb6",
        "modelscope/preprocessors/cv/image_classification_preprocessor.py": "c456737cf91bcb5f9a16b34e901a81334f6170901e8561877b38f4688233e72f",
        "modelscope/preprocessors/cv/image_quality_assessment_man.py": "44e2294bb3de59d1e6da69059420a486476e34add0d29b7d151357be06495b62",
        "modelscope/preprocessors/cv/image_quality_assessment_mos.py": "81320bafc68f4d25ce1a5a8292e7b0c6b49b211b10c1afa83c2dbb8eb09aed77",
        "modelscope/preprocessors/cv/image_restoration_preprocessor.py": "3cecdc629d1df6349aa9dd20dcb0f090c5eb2bb9eb81bf4ea4a8e34e9acd876b",
        "modelscope/preprocessors/cv/mmcls_preprocessor.py": "52a1cc1a157e1fe09fd8fde5acc3407a6695472ebb110f3c9a3648b1129b3d8b",
        "modelscope/preprocessors/cv/timer.py": "5759d150a98e5a2a8d450b0c6e4193839b58415a0890890593310053d678ba9a",
        "modelscope/preprocessors/cv/util.py": "3e7a232ddfb587c3f58d2559ed1827a6fa620cedce26b46364ea7b7f9bd6a2e9",
        "modelscope/preprocessors/cv/video_stabilization.py": "f9149af322c43d1ac45d4dabed4afd56dc27fe76e92f7a8c53a9d97d14c2f566",
        "modelscope/preprocessors/cv/video_super_resolution.py": "a126374e77141d494f0ef4d504de00333f29233747a992916218ddf151b63e62",
        "modelscope/preprocessors/movie_scene_segmentation/__init__.py": "9875d554e19030825908c5f9d418acf328961616785cd89d378c9c08ae73cd29",
        "modelscope/preprocessors/movie_scene_segmentation/transforms.py": "9983b84bd2b2a4c89a20451adc9603a2be2c11427e678da48b8879060a599f5e",
        "modelscope/preprocessors/nlp/__init__.py": "55ff51e0df989a2cc2adc299fcf5923e4dd2b6e7d5356809915e42ccf05ed936",
        "modelscope/preprocessors/nlp/bert_seq_cls_tokenizer.py": "6223a03c13829d0f9416f8c05c4074e3fe4583f3051cadd5dd08cdcd20211b80",
        "modelscope/preprocessors/nlp/canmt_translation.py": "4807e321b456750d82e21f8bc96ec948bb30e1d6577402bcd9817e4171ebc963",
        "modelscope/preprocessors/nlp/dialog_classification_use_preprocessor.py": "59e36fd480ec7e25e2f63a7c20e6f3c4cf2480621e1f1df1e12fc8204dd203da",
        "modelscope/preprocessors/nlp/document_grounded_dialog_generate_preprocessor.py": "fa23981c92b79871e5dcb634e3305144c6a49f15e300ea076a84436159484610",
        "modelscope/preprocessors/nlp/document_grounded_dialog_rerank_preprocessor.py": "bd4feeaa696c5e8fa67cd2235488b760c15d23219dca21ee720c60979e0d051d",
        "modelscope/preprocessors/nlp/document_grounded_dialog_retrieval_preprocessor.py": "c2f9ab535bd2fb161e588f0da14ffd096d3e5333065955f926f2eb87623ee400",
        "modelscope/preprocessors/nlp/document_segmentation_preprocessor.py": "1c8df96e8d379a2212656f9f84c9dd5440a813793c65fabba645386b01e78c0e",
        "modelscope/preprocessors/nlp/faq_question_answering_preprocessor.py": "65bc04f53d07a62a4c8b0270ca0129668b7693f730f541910b5aaa7d2d91fd39",
        "modelscope/preprocessors/nlp/feature_extraction_preprocessor.py": "56635f6ca1e173779dff4f46def59b155bc245924b81350252778aebba656251",
        "modelscope/preprocessors/nlp/fill_mask_preprocessor.py": "0df70d98e90545b13894e0d8797967dd39e5d5811c02d3417df12a1629702837",
        "modelscope/preprocessors/nlp/machine_reading_comprehension_preprocessor.py": "23222bbc492bf92be6f966a2b65a1bf91aeec16af0024311f2780a2446ccc7d4",
        "modelscope/preprocessors/nlp/mgeo_ranking_preprocessor.py": "488360ff9c97f4b821538068f771a8eae2efd96c3cdf847db321593fdd3740ad",
        "modelscope/preprocessors/nlp/mglm_summarization_preprocessor.py": "4c37571942bb59ae2fba4cab2166b5047fa0434399e3ff847097d4db3d6308e5",
        "modelscope/preprocessors/nlp/relation_extraction_preprocessor.py": "ad87d571fe05f756bd0abedc0c2a228926542465be29f59f6760e93af84e2a5a",
        "modelscope/preprocessors/nlp/sentence_embedding_preprocessor.py": "a24e477ef1d0c419a85721781805bc8c2715f274bfa0a6464ef93e4b2df9235d",
        "modelscope/preprocessors/nlp/siamese_uie_preprocessor.py": "80a83d5d2f359a5de18a14d31cbaa6985744929d61c07339d06e0ffc18c8527b",
        "modelscope/preprocessors/nlp/text_classification_preprocessor.py": "4700f790ce3afb678275548c5f0e389ffd362e61b77dd72d37cdec0b367ea41a",
        "modelscope/preprocessors/nlp/text_clean.py": "e761bf2fbcd4fa21559ad393cefd3d044d5d067312000be964064fac80150a7d",
        "modelscope/preprocessors/nlp/text_error_correction.py": "81e279d631f7f96f2f3c567a99b113cea8849983a8cf0f1ae3f1c530cf32411d",
        "modelscope/preprocessors/nlp/text_generation_preprocessor.py": "13b83c65b9a34d66d6d96bb3f18d0322f642be253533309fc0f83e33b526ee53",
        "modelscope/preprocessors/nlp/text_ranking_preprocessor.py": "64fc5c2870f39b80ba5c7b8c03dfcfc42ed3d694a9a74d0ef21ce17baa962472",
        "modelscope/preprocessors/nlp/token_classification_preprocessor.py": "85385996cb27a44259e6bbe5eaef46bf064a380c2c2c4c311091c7f90aa13be6",
        "modelscope/preprocessors/nlp/token_classification_thai_preprocessor.py": "4fc7c55e9be54e88f220f50b1df3de6fd1727e27db96ab596f193dd796a8f402",
        "modelscope/preprocessors/nlp/token_classification_viet_preprocessor.py": "8bfd432f4e622fdcc7fd348dc90f81a28253ddf64e1012e2b3deca75d5609444",
        "modelscope/preprocessors/nlp/transformers_tokenizer.py": "3df401be100676b7091ea16cf4d8f8e3b2426e00fe2341d6b23eb10fcd1d6984",
        "modelscope/preprocessors/nlp/translation_evaluation_preprocessor.py": "edada73aebadf96d12197223f612f57df96cbcc5e400c4df6d4244808ce6c18c",
        "modelscope/preprocessors/nlp/utils.py": "41391613a53a2e4ad019574a86c5b1af214a08d7353ce04923e71a0ceeed5e0a",
        "modelscope/preprocessors/nlp/word_alignment_preprocessor.py": "ed9715881125cf32844a1d58454dad1cb93ebefb534fcc9735d0eec45f65fed3",
        "modelscope/preprocessors/nlp/zero_shot_classification_preprocessor.py": "76d1a172f7e50a9bd3b8f498887ef64b3e6e8690815262a82dfab1ff4908fd06",
        "modelscope/preprocessors/nlp/space/__init__.py": "9e2c9719fd09927cde3997141c0121bb76447f2088a70e5ffc5ec3d168bc0d44",
        "modelscope/preprocessors/nlp/space/args.py": "aa291e0b1465187338d4e2f9349af8a1659d571b106f669220dae0767674fcaf",
        "modelscope/preprocessors/nlp/space/batch.py": "3ab9a40fa60756413f4021db09309c14b221e1a269895f351eab2f72f45dff51",
        "modelscope/preprocessors/nlp/space/data_loader.py": "3470e41f6ea0856221f463d4e6775d6fd5fcb72e2a91e6921f3b404dbdfa26a1",
        "modelscope/preprocessors/nlp/space/dialog_intent_prediction_preprocessor.py": "9f2ae02e89bab64a03a07d09a7d5c3fa25e98a7e22750281ffbf9ab0b8d2eb2c",
        "modelscope/preprocessors/nlp/space/dialog_modeling_preprocessor.py": "e348e7d46e4b7580b63f0058f4bcaded46f553a84f8d700aa4a83f0b818300f1",
        "modelscope/preprocessors/nlp/space/dialog_state_tracking_preprocessor.py": "3a98737789df2e6dc72d34e330eb10f7e8f3367c184932c5ff7e3cb887823f46",
        "modelscope/preprocessors/nlp/space/dst_processors.py": "6f86e1a6c47f4a92c490d2e454b27c50c43fb7d3d0dd881039e4a1fde03342ec",
        "modelscope/preprocessors/nlp/space/lazy_dataset.py": "ed73a9c1f6b32a95f0718508d658cb4bfdb489dc83d371af2baeb205b7b760ea",
        "modelscope/preprocessors/nlp/space/preprocess.py": "b246871af55412005fdf361c23ede6e5a8402ba350ea9a5f41da1b0251882c89",
        "modelscope/preprocessors/nlp/space/sampler.py": "7fc0699f94b72db076a5dfbd4e38b0d6aacd2b164b252d35c94eac38629fb76d",
        "modelscope/preprocessors/nlp/space/tensorlistdataset.py": "8a8424f96dbd56ba7655a66df469326e610e3b7deae4d12307c20d78ce452a7a",
        "modelscope/preprocessors/nlp/space/tokenizer.py": "4d78fa590e72783cc5779a107ef931a008453f7b4746854b6ec30a7d9559bd39",
        "modelscope/preprocessors/nlp/space/fields/__init__.py": "21f896db8099817d4a0e23a9027eeb1d060774bb5d17c59b904766e24477c77d",
        "modelscope/preprocessors/nlp/space/fields/gen_field.py": "7836f2198b21451134eb0cc6c0ba2a551b70d22da89800b2c4f0cbbd8af95a15",
        "modelscope/preprocessors/nlp/space/fields/intent_field.py": "e041cbe3c015d285bc616dd056a5a2e3957b8e39d204a261bec7f202a751c3fa",
        "modelscope/preprocessors/nlp/space_T_cn/__init__.py": "63bf09746332e0fc1536a691508509b0f1cad68da2a083ef666928c92514d034",
        "modelscope/preprocessors/nlp/space_T_cn/table_question_answering_preprocessor.py": "994817d37f2a8e32e04194d3c9f98addf56a0421593273cd4898afe0d01179a6",
        "modelscope/preprocessors/nlp/space_T_cn/fields/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/preprocessors/nlp/space_T_cn/fields/database.py": "df24d7b946f4779e002b189c103f6a0ad810fb5244911b223911d38f9a643c97",
        "modelscope/preprocessors/nlp/space_T_cn/fields/schema_link.py": "06fe22d99c45c74aad4970ff81eeee7f796f5892876ad505191533b7d8e67d01",
        "modelscope/preprocessors/nlp/space_T_cn/fields/struct.py": "c17e5b4d7d540a9ab77d755e7ce82c077838b18da45fe880179488afd799dfa8",
        "modelscope/preprocessors/nlp/space_T_en/__init__.py": "4e04cc6a2430c0012e2fe73585486fbffd3ab2f7b6b8cede71bc25046528f7a9",
        "modelscope/preprocessors/nlp/space_T_en/conversational_text_to_sql_preprocessor.py": "58dd80d338ecd963313b275d94e475dbb74a606b22c67b098ad47d0ab13bd6ed",
        "modelscope/preprocessors/nlp/space_T_en/fields/__init__.py": "9d31b4a7a386fe17eaaae1d64f23bd20a0d50ee0baa506bf53b55bd7ffdff0e2",
        "modelscope/preprocessors/nlp/space_T_en/fields/common_utils.py": "2b09aa2285f319f70fe7e680bc1f4a78232240e88c204e0c774c3c1c5fafef24",
        "modelscope/preprocessors/nlp/space_T_en/fields/parse.py": "729942ecfab8102189bd7d598735a7b4d514d972ca7f3273427be6b49d196b77",
        "modelscope/preprocessors/nlp/space_T_en/fields/preprocess_dataset.py": "547aacce7ed9e88b50c5a96225cd527d6c2341e7b876c14b4142df991040c89c",
        "modelscope/preprocessors/nlp/space_T_en/fields/process_dataset.py": "984372073eed291ed793c23306af6147bb7539bc44e5b81229266ce92646862a",
        "modelscope/preprocessors/ofa/__init__.py": "d52e7dad035d2e486a4c54aa833b5297d6764eaa08e4929027c9fa34ee2bfdcf",
        "modelscope/preprocessors/ofa/asr.py": "9777e0bc1f568d837b5b67c3b937c8304bcb9935eb28322aff82ba1495dfa8d2",
        "modelscope/preprocessors/ofa/base.py": "83de97afa436d609758d35e535773cd145788727c32a5394ec1da3253b40dec4",
        "modelscope/preprocessors/ofa/image_captioning.py": "6158d6d83f13b4e204186ae214d3e72ef31addc6528b473b31fb3164f419cbd3",
        "modelscope/preprocessors/ofa/image_classification.py": "30d8534753592420f652ee2a352eedb9f2d7fd19af58842a442ab2d458b1f44e",
        "modelscope/preprocessors/ofa/ocr_recognition.py": "2d039ff2c1f928320a7db8fcae308c0ceacdad3b76b110a5ef83ab5f23f5b226",
        "modelscope/preprocessors/ofa/sudoku.py": "63dd23a5bf6893b97381a835c08da399814bdc237ea8e7d3a1c88c27c36d2275",
        "modelscope/preprocessors/ofa/summarization.py": "cd4f764d6a26d1e154f7d08ab7e83fc38f35a8c9a57b82cc0f50f495c5dd03bf",
        "modelscope/preprocessors/ofa/text2sql.py": "cfadec3c94fe22f0737fe78d4a246674e7a9a3c8ab5b10265d9ab20d41efb876",
        "modelscope/preprocessors/ofa/text_classification.py": "5ac8085014e8dde8b5bef360d94b7d830d6db1dfa283deefca840b263a34d410",
        "modelscope/preprocessors/ofa/text_to_image_synthesis.py": "1d6b1deaf40385ec4093a9a5a4f2d2f8eae9e5b304db6305fc950b25e72cd37a",
        "modelscope/preprocessors/ofa/visual_entailment.py": "4c224e43e3a5c0146e5e1d4ee737b34b82a41e3748d2a4d0f055f44c21edc684",
        "modelscope/preprocessors/ofa/visual_grounding.py": "3b212c4322c033310584563dca6bbdacfc16313e588527e63ffae65feebc0c34",
        "modelscope/preprocessors/ofa/visual_question_answering.py": "abe2739e352c1ed808b5b4e9db7f10487c295fbc72e3051f77f50bcd76c35985",
        "modelscope/preprocessors/ofa/utils/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/preprocessors/ofa/utils/audio_helper.py": "aacde7788d84e134f4b37f0d8592cf2c95316282afef25b862da0bf4cdef5060",
        "modelscope/preprocessors/ofa/utils/bridge_content_encoder.py": "55be4c2792a4a1cb247634734003319070076ff3d72d2d067ce8ccc339f3a31c",
        "modelscope/preprocessors/ofa/utils/collate.py": "385988156ea093580fd8b71a35614699416374ee9699824a508c40cdd4020a81",
        "modelscope/preprocessors/ofa/utils/constant.py": "6fdeefe932636fa0ea42d59a666e02bf95056aede35340aa63eb33fd963c9a0b",
        "modelscope/preprocessors/ofa/utils/get_tables.py": "f9f51b01eaffb2fc6bb834669d2c04baee249cf69bc16defde663f6f428de6ec",
        "modelscope/preprocessors/ofa/utils/random_help.py": "8948bdb47860dfbdf61c662f9166bc3d25e4a9abb1576488b708d6307a091803",
        "modelscope/preprocessors/ofa/utils/text2phone.py": "dcccb6d9c15cfbe5a47554ff45aec9b7e1c2ad6ca7e42bf2d833ff0538e38537",
        "modelscope/preprocessors/ofa/utils/transforms.py": "e04d59e8d1e05c922349b286cedf1f3d918da6fadea7641615bdcb41454ef350",
        "modelscope/preprocessors/ofa/utils/vision_helper.py": "a17c76f51553ef76d6e23c3eee862c0c32600b2a593a03050592710f4f4b82d4",
        "modelscope/preprocessors/science/__init__.py": "8e965d4b83fc2a2a877d19787ede40fb07bb72d6129f3343a8acb1bae5b6f245",
        "modelscope/preprocessors/science/uni_fold.py": "3b73c5b96f0631b85822cbdfe133ea2cfbd6fc54772263a5737f961b68ad092c",
        "modelscope/server/__init__.py": "c27461ecb14b80e082656c7c2084bd1c3e7579f296305eb4ff24e990a098fb0a",
        "modelscope/server/api_server.py": "0d0ddc867c05abe6a3cf6a25fd62c96c74c24319cc75e08a06341a7634709a46",
        "modelscope/server/api/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/server/api/routers/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/server/api/routers/health.py": "37400a7ab5e5f642cb9bc099273b53c04238871318ce975d789491c7dffe5344",
        "modelscope/server/api/routers/model_router.py": "f998c8c9c495718293a3e664492006deb779a1a1dc706a259445278df4beafbd",
        "modelscope/server/api/routers/router.py": "d3ab8dc4daf68e69eb58b45f84e07f20bd639e38c13a83b2cb6e3d9f33b4ea09",
        "modelscope/server/core/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/server/core/event_handlers.py": "0f85963164642d215c86f09ab90879cab1fb2c81af84483e92f2745933a6029e",
        "modelscope/server/models/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/server/models/input.py": "248c1cf270c648f49e052310294bf20766f33c49361a39d01bdc21a4bd5314b8",
        "modelscope/server/models/output.py": "7ad2c7fd1fa86e27eec53e2dcf7291410740f2c235249bd1ab31940e8e154eab",
        "modelscope/tools/__init__.py": "ea75f7edb55cfeddffe4c92474e98cf5db44acc05bf034c2177d122e6d9c1e6b",
        "modelscope/tools/eval.py": "74bb277224a009e45af0f38ef09155c71bcf45f14cf5258461bd16fc0dfe2d8d",
        "modelscope/tools/speech_tts_autolabel.py": "1167683560970bf13717bedff52d6633ebec98c5bfbc4a9b0f72e45fa4ab78d7",
        "modelscope/tools/train.py": "0845627f95c48c4cc57a3c1b37160f94aac59cbf25c7351fc5b67972aa18eaed",
        "modelscope/trainers/__init__.py": "ba961d03557e0464fd05d36420308a72cecd9d7bc44b3c3be80ef4e5a22b4c89",
        "modelscope/trainers/base.py": "6ceb46237664ca3e46d75f5aa063399bfa3a4ffee99b4ff22fabe84e8d2d0d67",
        "modelscope/trainers/builder.py": "310cab69f8a81ba858561c61ff472326708dcfba8675e79de1f537dccd2846b5",
        "modelscope/trainers/cli_argument_parser.py": "6ed3696d11c156c66851cf110668ec74d5cc678bb9b73e32eb0d25908eba3d3e",
        "modelscope/trainers/default_config.py": "d90cb705e4f279da806332d00be56112150dcc5cc327f015f79003b12d28ed41",
        "modelscope/trainers/nlp_trainer.py": "0496fb1baf643bb031ed650fe3810c23f9aa01e100f2114f9c391d09ad91fc3a",
        "modelscope/trainers/trainer.py": "09c933ce4f45dd010ddca4b1d209af344dd543b60c4d24e88c419fdbbe837022",
        "modelscope/trainers/training_args.py": "4f22577e213095734b9b09cdc86746ad66b63089a155c3f9be714f5fdd76b898",
        "modelscope/trainers/audio/__init__.py": "9119774ab71a1ab1fc70fc594a8c128ad98ad631f4df65f31f4c1288bdd720dc",
        "modelscope/trainers/audio/ans_trainer.py": "8810758077f3e104f3a3b1b0a5785c21873aba8b92a5607310c4c188b42662be",
        "modelscope/trainers/audio/asr_trainer.py": "c22d283e3de355decc2d952418ab6064105e4b1b8bfc0478bf33b2774d98f5a9",
        "modelscope/trainers/audio/kws_farfield_trainer.py": "3842210046aa120e5092cd564968a8c1bbbc6cc0ce4862284ffb0a5b58e51b81",
        "modelscope/trainers/audio/kws_nearfield_trainer.py": "79c7b679982323eaa29efde38066381b26019809f1857786ee4bee29c64dcad1",
        "modelscope/trainers/audio/separation_trainer.py": "25e262f9888274932458d3fa41073a85f3956134fb5e141cd9ea0ca838a30d2e",
        "modelscope/trainers/audio/tts_trainer.py": "1f5dbf6517f6cb1237ea99f43729111d3c5d57f63d660eb93037ef16c79aa286",
        "modelscope/trainers/audio/kws_utils/__init__.py": "25ce619fc3ef4ce8464455e715f2a921503f751fce474c0b94ed276343cc39a9",
        "modelscope/trainers/audio/kws_utils/batch_utils.py": "06971e2c48b6bb008299725e0a001067a9f02bd8df29ba9af6794e21985d6db6",
        "modelscope/trainers/audio/kws_utils/det_utils.py": "5a5bd53a05d947bf097d73308d2269d12b8e65e2abe0cfac850f591fcf0e665b",
        "modelscope/trainers/audio/kws_utils/file_utils.py": "d716adb2c9a2cead77ff5416ed87a125d952b23618bbacfd25787ffb60468ace",
        "modelscope/trainers/audio/kws_utils/model_utils.py": "8615b510b1a9e4dca972c181e8be7cc92da89171c647d815677265262d5e5747",
        "modelscope/trainers/audio/kws_utils/runtime_utils.py": "065335cc351d85ce3300bf88a14d02204c9826a3da122612cdcf14d76bedd2f2",
        "modelscope/trainers/cv/__init__.py": "f0a6893986d9744a3369148cfff932fd7cafacf145d87d863b8f2e4832605984",
        "modelscope/trainers/cv/action_detection_trainer.py": "362932a043e2f3ed71bb8ad6e3462fff6cd4deb7c8ec5e2ad80a8564322b275e",
        "modelscope/trainers/cv/card_detection_scrfd_trainer.py": "d19fd35970ddba97d4a2b838fe6d776730b4680aa24a95e523d361f15389673c",
        "modelscope/trainers/cv/cartoon_translation_trainer.py": "fd95f393abd6e67d3d4daedcafc326f6b377051a3f69daf7d8cfec63d72cc524",
        "modelscope/trainers/cv/face_detection_scrfd_trainer.py": "99ae92b533c89c51471c7db398aa5f864d17b2b17452b9adcd222e7fcee58895",
        "modelscope/trainers/cv/image_classifition_trainer.py": "838c5b7ee311248eca8a0d995b7a821f7b96423bf7aa7fc1d62b85e8e6c14d1b",
        "modelscope/trainers/cv/image_defrcn_fewshot_detection_trainer.py": "2a0eb31f7e2f063fc01b38622626a658dda017c52f8765f54b8464a09b2de669",
        "modelscope/trainers/cv/image_detection_damoyolo_trainer.py": "5b81a72f117bd3da35ef34f132a03253d10b7ae5fed7ea3391fe73cc2b9df962",
        "modelscope/trainers/cv/image_inpainting_trainer.py": "616a1baba72aac9299e1b466563b9636a7dbc78dcd8bfbd2341f49dd24f56d9f",
        "modelscope/trainers/cv/image_instance_segmentation_trainer.py": "3b7c98743dbdbd4c064e4b3f46431385ec3442fb2a9777cdb5e5280c9ef50811",
        "modelscope/trainers/cv/image_portrait_enhancement_trainer.py": "40aa751a6c527366664334089b2d71d3a12fd4095da06583a2438837a86747f6",
        "modelscope/trainers/cv/movie_scene_segmentation_trainer.py": "b81342d22e696298be7c2f65ed167214a4512213c5ec52f9139e813eab4dd955",
        "modelscope/trainers/cv/nerf_recon_acc_trainer.py": "8a70e8d7298e3233b87114ce92173b5a713ae10740101d3ca0818dbc67c2913c",
        "modelscope/trainers/cv/ocr_detection_db_trainer.py": "c44216d17f242ae8df77365845dcadb5171a6773552ce1d3c92325f7023dd7c0",
        "modelscope/trainers/cv/ocr_recognition_trainer.py": "34a9855a4510ec09d34b2d1c9857e0e2c975deb64269912ee57882fa1728ace6",
        "modelscope/trainers/cv/referring_video_object_segmentation_trainer.py": "c6fac4f5446ce6e2af1b9b81b125292ba295dac4a6bcca76286cc74e8d260a78",
        "modelscope/trainers/cv/vision_efficient_tuning_trainer.py": "bee3957034f0d22b19e78e62a329a67ed172245c16e2fcd877986d7e58ca5acf",
        "modelscope/trainers/hooks/__init__.py": "ea361293e2c91ebcafe5cfc85b8f93a24db6f0189bd02f1cf8093b73c25e9310",
        "modelscope/trainers/hooks/builder.py": "a2796c892a4817b177d92ad518769169d6cbeef96d3cfa69519d6890a13ad617",
        "modelscope/trainers/hooks/clip_clamp_logit_scale_hook.py": "72a8182fa36992bc6807060cbf9facc779a8da99e520451fc06a60cb1d9f99bc",
        "modelscope/trainers/hooks/early_stop_hook.py": "8c52ecdab4e272f75c63efd9fec9ffad4c34409bce2659db73dfd65bf430f692",
        "modelscope/trainers/hooks/evaluation_hook.py": "b21f42e42aa5fc5297dbf13749f1e38385bf6b34d151237998a8796349a2c129",
        "modelscope/trainers/hooks/hook.py": "afa975a58c4160647eb6b0eb09b20ea915d04f6abc9e987d6f365c966a2e51a6",
        "modelscope/trainers/hooks/iter_timer_hook.py": "e8f6345d62d12d34440e631578c37d1d1beabc1a8c06af50ba96501dafc13d18",
        "modelscope/trainers/hooks/lr_scheduler_hook.py": "491b4e1d78f616d9beffe8375fab2d6b7aafd9bbe25890989e959a3e55cf90d2",
        "modelscope/trainers/hooks/priority.py": "ee870b6b6f0a569dc7d2d3a6f1d082535f4870dc8eee061ce6309e33eff3de74",
        "modelscope/trainers/hooks/checkpoint/__init__.py": "21be34ef20e83fd2bd1f90084151e0223a8d22881161d9083ff146ead4d22787",
        "modelscope/trainers/hooks/checkpoint/checkpoint_hook.py": "3eb93419740bd631f481c3faa3aad35bd7d40ce7ca82b9962e7daf15001c7f2d",
        "modelscope/trainers/hooks/checkpoint/checkpoint_processor.py": "8e4f33003a452bbd4eba1c8d866b18acdd08aad14766f8a76a3905272d42076f",
        "modelscope/trainers/hooks/checkpoint/load_checkpoint_hook.py": "3d4f63430b4c4058239dc17478ab410f7486775deaad0f54a123fa07797d38f6",
        "modelscope/trainers/hooks/compression/__init__.py": "b6f7d17efdf27967e2a585503d88072a9c8acbe1ebce449c33a40f514c44313c",
        "modelscope/trainers/hooks/compression/sparsity_hook.py": "a905d93f1157ea029c8141cd8bfc3ec200050507fae047b7b42ce8374991736c",
        "modelscope/trainers/hooks/compression/utils.py": "90d1cee6f7d4718d007f49bc037bc131d7cf77baa767f8196c387db6ed784c09",
        "modelscope/trainers/hooks/distributed/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/trainers/hooks/distributed/ddp_hook.py": "a171ac50692147621d2ca80752a4d8b374cb7ed6ab1921a950294c550326b6bb",
        "modelscope/trainers/hooks/distributed/deepspeed_hook.py": "28fd9ccd576405d2cd1c75b643ac2eed948c1d38c669777bbe6e0ba9b09d7e45",
        "modelscope/trainers/hooks/distributed/megatron_hook.py": "1750084749d3a14c7a49f791446312fa4c6c90a9f6154fa465c45ca7ca0f329f",
        "modelscope/trainers/hooks/logger/__init__.py": "3eafe7c13965a553cbfd0f9c4c3ff054ef680587895972aa08be3e502fd24f4d",
        "modelscope/trainers/hooks/logger/base.py": "ccd5fd725c214927c05778161a7f967e39ff6f06fff8a3b858c3c2c1f7c857d4",
        "modelscope/trainers/hooks/logger/tensorboard_hook.py": "dd2de207764f32ae7415bd8faa121e78167ed194954dfe142add28882514ee7e",
        "modelscope/trainers/hooks/logger/text_logger_hook.py": "9f8452a5479ad773195c16cff81d4f696dea4df56dbedb7f47bb9c30e369a732",
        "modelscope/trainers/hooks/optimizer/__init__.py": "4685ff8644d6a5cb6417998e3b0cea39d8be104fbb7f31832983fe29448794d3",
        "modelscope/trainers/hooks/optimizer/apex_optimizer_hook.py": "63e273979fd1a38d0a1cce9732105f1768f0d782968a7f3ab8c9f0b7b4a09716",
        "modelscope/trainers/hooks/optimizer/base.py": "11335d4c83526adda5898da23c10ee8f5fca444f383ded80bf4f0cf351dd8d06",
        "modelscope/trainers/hooks/optimizer/torch_optimizer_hook.py": "a181cff28151a9e639c273853e920232cea82914648e8e4289e79b614f27f703",
        "modelscope/trainers/hooks/swift/__init__.py": "ea9a79041c6af8675851887fe23e184be2986383def877b0ff696842f4a6976a",
        "modelscope/trainers/hooks/swift/swift_hook.py": "1c84f827fb68e3feea242dea9b42d0a0961b6e8ff3fe0d74688c90ad18d57f35",
        "modelscope/trainers/lrscheduler/__init__.py": "3403538146c530102d30d6009a7125098a66490981f0bb7522f9caf7d21d0cef",
        "modelscope/trainers/lrscheduler/builder.py": "c93089d38e164792c2ca115e125f8818046a95deee2091df032cee7d0f195896",
        "modelscope/trainers/lrscheduler/warmup/__init__.py": "6f52c052fcd21426694f2e3042b283944f390ed5f6aeb8a7840af2572d2edd5a",
        "modelscope/trainers/lrscheduler/warmup/base.py": "52bab86785d84efe41c06c9f7373d03de9be637005156fdc7878b68e57725689",
        "modelscope/trainers/lrscheduler/warmup/warmup.py": "4585db345e7d3faa4bad9c80a52b349fbc496d12a239038b98829f7b6c49645c",
        "modelscope/trainers/multi_modal/__init__.py": "f393301ed8106e10de327ec31b83e599fed1231c2339341940b5f8f79cdd2498",
        "modelscope/trainers/multi_modal/mgeo_ranking_trainer.py": "dfec59e2e06f58f467ee4ad151a6f44f8ad77b0589967baa929596241424d8d2",
        "modelscope/trainers/multi_modal/clip/__init__.py": "d884614dc51e301f8116fddf9ae13cbfcdd9de618208435154d6d8dbf6768a95",
        "modelscope/trainers/multi_modal/clip/clip_trainer.py": "aac595679dc7275200361ad0d91bdbbb2608022f9a1905646e0ac7e0876d545c",
        "modelscope/trainers/multi_modal/clip/clip_trainer_utils.py": "4724b0db4ec72e1736d6ce60329828efce27d7b58f48b0e909b660421deae433",
        "modelscope/trainers/multi_modal/cones2/__init__.py": "4897e22de5bc8ccd0c65852bc5d5f85f8db8938e9ab226c5ef502156ae6e5991",
        "modelscope/trainers/multi_modal/cones2/cones_trainer.py": "ff123e94d693bf5f2ae961db8affba1249d67c71fca4006d3575f0e65d3351ff",
        "modelscope/trainers/multi_modal/custom_diffusion/__init__.py": "007c4053b1ba5c1488341e9bf06d93e7a79bc3f115352fc00dcbed7512eb70f9",
        "modelscope/trainers/multi_modal/custom_diffusion/custom_diffusion_trainer.py": "f77bfe129772938d9786179c57ad5f7cab763215a01bc567c720c081dbdb8882",
        "modelscope/trainers/multi_modal/dreambooth_diffusion/__init__.py": "00a8271a6ae0f6637901e63edcb7ed7d43a8eed3dbbb953f7761b82264a1030d",
        "modelscope/trainers/multi_modal/dreambooth_diffusion/dreambooth_diffusion_trainer.py": "01f5c05a668b4fb7bc160fda841317c45b9dc0f98e063306e6a5cda9116e4a1e",
        "modelscope/trainers/multi_modal/efficient_diffusion_tuning/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/trainers/multi_modal/efficient_diffusion_tuning/efficient_diffusion_tuning_trainer.py": "6c28e41d9b64848496fdd771ff6be6dac090c199470274dcf0f8fb25fb5a6e91",
        "modelscope/trainers/multi_modal/lora_diffusion/__init__.py": "2968f88efb7db675b94bc6fbb93fc1c4a971a9d2a878995363e42d06b0fca6e8",
        "modelscope/trainers/multi_modal/lora_diffusion/lora_diffusion_trainer.py": "30b38fad93ae6cd322245d4adc06485f3b684f9ed6434230dcde3cf56269d0c6",
        "modelscope/trainers/multi_modal/lora_diffusion_xl/__init__.py": "58732650244ecf1826f7ae00eae71b41de074cc214ca5eb599a8f9c2e3c215c9",
        "modelscope/trainers/multi_modal/lora_diffusion_xl/lora_diffusion_xl_trainer.py": "5d576ad7cec2b9a6fbd7055154439dbd373e281bd42cfcf26b383e6327809b64",
        "modelscope/trainers/multi_modal/mplug/__init__.py": "4cc4ac2a856663a723df5800d9a966a33733e8cdc7a4fc2dbb7ca7fe9a704bb9",
        "modelscope/trainers/multi_modal/mplug/mplug_trainer.py": "4ab1b6da1655bda576a7f9f0adabe6337bf7404aa371b7215c5d255a3123da77",
        "modelscope/trainers/multi_modal/ofa/__init__.py": "a639ae01fff76295bebbdbdc46e92be30a0b09e91805717212282443c554d68c",
        "modelscope/trainers/multi_modal/ofa/ofa_trainer.py": "9a1f98721ee40764bee24e5d09e81eed3595b7630be62befa4c0ca9060f54afc",
        "modelscope/trainers/multi_modal/ofa/ofa_trainer_utils.py": "9bec598d53f4bd1cd7f55cb59e683b6e271e6e8c0afc66961c6e08357920dea1",
        "modelscope/trainers/multi_modal/stable_diffusion/__init__.py": "e6841763693d0fc9e8db893e8db0ff9b15a9ecbcc52a010e5be0089d10330101",
        "modelscope/trainers/multi_modal/stable_diffusion/stable_diffusion_trainer.py": "da983ddacbdd9e5e0ae26d8f9b955e0968236fa8dfe8a63a25ce7412d3cdbaa3",
        "modelscope/trainers/multi_modal/team/__init__.py": "c62a2746805ccd1ba24d9289d5f1e97c5a39a0707691a2744d3d6698677aa448",
        "modelscope/trainers/multi_modal/team/team_trainer.py": "42e7c7180e71454c1cb06c5e2a035e16d85a52c240873022e624bc1dd6f8d8d4",
        "modelscope/trainers/multi_modal/team/team_trainer_utils.py": "bda563c9e79ab3fe1ed6f268cff65982d1273885c31732670831e875ccc7b998",
        "modelscope/trainers/nlp/__init__.py": "b120e316f34f3faa4f2ed97874769299f20e96f8e6d8607f1f602491a5744ecf",
        "modelscope/trainers/nlp/csanmt_translation_trainer.py": "973886f74f06cc7ae5354eb95978ce54f01887bc963eb8f55b8636fcc439ae59",
        "modelscope/trainers/nlp/document_grounded_dialog_generate_trainer.py": "58ad90f8587819c7c63cdbfd42f45dfc4f8a20a03a2fd05bbff84a3ccb6b9eaf",
        "modelscope/trainers/nlp/document_grounded_dialog_rerank_trainer.py": "adb28864ef87505b5007db53b869db4545780cd7da58b46bb5b140ee6a41ee50",
        "modelscope/trainers/nlp/document_grounded_dialog_retrieval_trainer.py": "ac385962b6b553ed0019ca62b569124a1fcb4f6925a168ec8d9e11354e9ae424",
        "modelscope/trainers/nlp/faq_question_answering_trainer.py": "da6c8c289e13852eceabb98cef63ed0ef06fe0c5aa86b8e80e0bd08615f3b616",
        "modelscope/trainers/nlp/gpt3_trainer.py": "8935043a2f424afdbd8aee30b17b56c21fbe596b21e6db398ab57edabfe687da",
        "modelscope/trainers/nlp/gpt_moe_trainer.py": "bc0ccf18a55038b27ade3a6067a49d53f62fcee08f477632a28871cbb5480002",
        "modelscope/trainers/nlp/plug_trainer.py": "c90e11969a5aeac32e9121ffd116de0079f166584054c35a3299801cfb8d0bcc",
        "modelscope/trainers/nlp/sentence_embedding_trainer.py": "7a3e3d936d8024c953bcddba08045c6477132f6a8144623d01f6fb7326d89a10",
        "modelscope/trainers/nlp/sequence_classification_trainer.py": "ee97d7c8f0f3b5664b9bd45486fe6a2811ea15e76f91e5cf847e43391a80fce7",
        "modelscope/trainers/nlp/siamese_uie_trainer.py": "826263c31777702836e491abfdcaf06077b86ee24b2632e9bf2480e4f2700e00",
        "modelscope/trainers/nlp/table_question_answering_trainer.py": "1588eebaa545af03cabf55349098648fce19f0568dc45520a8a716eef138dfb2",
        "modelscope/trainers/nlp/text_generation_trainer.py": "1318355f151b2dae1fb8b8e93f55a0622d8065c405acb8caa9b3dd8d1b5f06db",
        "modelscope/trainers/nlp/text_ranking_trainer.py": "59643d2af1783d0796565ce2849532dcafceb58553670120ef91720bfbaa017d",
        "modelscope/trainers/nlp/translation_evaluation_trainer.py": "9987ca4f672292d74fcc7ae3d441a5c31ca3a62b213f08d44eba2d334a186690",
        "modelscope/trainers/nlp/space/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/trainers/nlp/space/dialog_intent_trainer.py": "f434f6c6e6b0f8cec6c073ac7f5672cb2c49eacf7909fbd0fa5fc4e4c30acfef",
        "modelscope/trainers/nlp/space/dialog_modeling_trainer.py": "94413213b47d0270e388c6b9a20c8eed78b66341c53a6a2da74fd0de07dd462a",
        "modelscope/trainers/nlp/space/eval.py": "e33b418283fdfb1c295aa1d92d40bc9b3e1fc065f9aa4661aa33cd73b2574b63",
        "modelscope/trainers/nlp/space/metrics/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/trainers/nlp/space/metrics/metrics_tracker.py": "b34c5f068b2cb31cd72c269e9ca396af813d08b7471b5ce1bdaf9c81a8342e03",
        "modelscope/trainers/nlp/space/trainer/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/trainers/nlp/space/trainer/gen_trainer.py": "8ed1586f93bfd770d595689616c7549972b0669f530f3ffe25403d480c363055",
        "modelscope/trainers/nlp/space/trainer/intent_trainer.py": "f7a9553780ca4b80bc0b50f6e44e669dbdce3b01898a72a39941e1be88f37f65",
        "modelscope/trainers/optimizer/__init__.py": "3fbcc0ced28cdfdf62b01b58bc7867def71510b70bf7be7bdf7e0a76bcd3bde1",
        "modelscope/trainers/optimizer/builder.py": "2b24268a08dfc81768a1ec832f47243f34bc805a9ffc094514e90dcf0cb1a01e",
        "modelscope/trainers/optimizer/child_tuning_adamw_optimizer.py": "851bc31dfa4f8f07016ac341483bb8884d749c638d00bb5043cf76248ace483b",
        "modelscope/trainers/parallel/__init__.py": "57bc0f4fe434645310beb84a7415fc6110b2554f35ee95c1c4be0f8c50c21545",
        "modelscope/trainers/parallel/builder.py": "f20c905d2413e956ae803611cc2f73414476063f5ea33b96e0a7ddc1761ff60a",
        "modelscope/trainers/parallel/utils.py": "af4b6f1bd2bf152de77bbdd06e8795ee304f120a4f1ad0840e2ce57a032e04f5",
        "modelscope/trainers/utils/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/trainers/utils/inference.py": "bcf5829e203fc65149edac5bdaa1da6200ccef0aed6097e5c95a527db201915e",
        "modelscope/trainers/utils/log_buffer.py": "99359abbc60c834346e27ec058e5f1e4bc454db717635abaf3229e0a166a9807",
        "modelscope/utils/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/utils/ast_index_file.py": "184cad075f81026cc73c0169b974a68268077cfea6015c6af78639f3eaa15a89",
        "modelscope/utils/ast_utils.py": "85db9c65b23d9998eb4349c2532be515e5885345e1f24dcbb98f78e0a6642d5e",
        "modelscope/utils/automodel_utils.py": "ddba21291772a4ff360ea3cdd08c2b3803b2d566fe9c0865844a99a6546f0830",
        "modelscope/utils/checkpoint.py": "336b76bdd9a0969d8bff3788fe4f72607f9836e94862951917d17279d9c69e48",
        "modelscope/utils/chinese_utils.py": "8e261ce23477cd034f47d114fde62835dea3a265e655c50873b5d8d2b0332d16",
        "modelscope/utils/compatible_with_transformers.py": "6049b11fab5f8796a2e46308d4662917096f3443e1736ec53054e067bebf6cb9",
        "modelscope/utils/config.py": "9183d61006525eb467c7a3662b404f408d42a858f225c02dc544b74085476b9e",
        "modelscope/utils/config_ds.py": "f866b60ae74d70ef9e0aa8eb53cfa72e07f7229d9b4196835b5acf6750ce6abd",
        "modelscope/utils/constant.py": "b81c3f85dd4213ee236f45fba932b0b5f70df3330c195f9a0494260ab4b65cea",
        "modelscope/utils/data_collators.py": "0f55d864749c68b686a6ab776fb179d2d43350b4b9cb5c9acfef7ef056a6efa0",
        "modelscope/utils/data_utils.py": "be685eb664f9e37e0733d720d5f127cef97d86d1883ccf808f6cc1deb773dfcd",
        "modelscope/utils/deploy_checker.py": "dddc5f87010b986c8bd328bb317338adf5f073fd31ba25865d3c9721c3dd3e26",
        "modelscope/utils/device.py": "09fe5841cec3008ad5e866bd5db5f373dc8b9d24b0db3787910c3ef77f03346f",
        "modelscope/utils/error.py": "bb66913fbef656cfedcd0b87952b9936fa3960f811c33270b5a6568860db8c55",
        "modelscope/utils/file_utils.py": "fc99267d3f5e05ff1f37c615813b692832fbd39d27cf132b1fb0cb6b152a1b86",
        "modelscope/utils/hf_util.py": "2bbac972850da082f2d6042f7d7f78965894836740517172dcd50f1f60e42d25",
        "modelscope/utils/hub.py": "6ddaedbb8df60f197d94e3952b3682d36e1878cc36baefcd7aecceb62047d422",
        "modelscope/utils/import_utils.py": "4ddf37e6afea4e22091fa327ec5e003b2b81078c738e0fc444fd02f9d9c232a8",
        "modelscope/utils/input_output.py": "8e40aebd0efe7011b41d49eded048c7eae7d8c5699017827da36f5c9f4d9133f",
        "modelscope/utils/input_output_typing.py": "d7fd02010f5e14cba484afea275a66560814ad837ba05ab221425822de97b54d",
        "modelscope/utils/json_utils.py": "3ea5ccd4e534ef500c4d51b0d920923b1d57744731778c86b7035a245cad7951",
        "modelscope/utils/logger.py": "f81e04ba2ecc97531d43f94713b01345422244bc47d742659567580523f4ade5",
        "modelscope/utils/megatron_utils.py": "9dd6b3b5e0e24dc7cbe1d3db063372f1befbef4a3088c1e22c97285594fcf0a9",
        "modelscope/utils/metric.py": "c5e510f42396be57a7cd61776d7882501fd0d8866ac9ba853bb1584231125e6b",
        "modelscope/utils/model_tag.py": "93054053ad19925ff38414da188a2d7e12bd2105ea1da9dc78f42dced01aa815",
        "modelscope/utils/model_type_helper.py": "3a95d66cc97c63b4054b79fc58a096ef5a3023f93d8dfc5a12727474fb9681c2",
        "modelscope/utils/plugins.py": "eda468149fced081b5372655d97dfae33f91f96af218b5551efd259e5e75775e",
        "modelscope/utils/pre_compile.py": "c51acf994d4c74c47f54ba64bbe074380af7f19ecc977f966773a86b5bde5356",
        "modelscope/utils/registry.py": "d92a1bcd1ff24bb98cb1f395a0a7d1e32368b5a806e2eb0540ba5716cc217e90",
        "modelscope/utils/regress_test_utils.py": "2ca1b41dd2e6aae15220891c09a4141b049a1a484e0a485fbb7e5d8678db897d",
        "modelscope/utils/service_utils.py": "824e0923f3d9ed893d1504a4837d7ab195866ab3d9ddd93737e1bcdba415e8b2",
        "modelscope/utils/streaming_output.py": "3b428c9c0c9e6fabab18519a8a9ed827143c1fbc78fd5904d54b728e0e1df4cd",
        "modelscope/utils/task_utils.py": "f630c6d0e093487b9998d736c706cb91b1ffa0e94394822b94f4e85beec8d7eb",
        "modelscope/utils/tensor_utils.py": "0694f688ee01da581d7f90e0c962eb3c342e8287f778c51f7cd56214a6bfab51",
        "modelscope/utils/test_utils.py": "657d0a88dcb00340e1f672ed9461fd92be3814e45f84988ac304881bd0f9cae8",
        "modelscope/utils/timer.py": "65ea7d34c7fb2077716d6c8cfc67d473aa5371a76b4670977844673c4c681ad4",
        "modelscope/utils/torch_utils.py": "525b1e71e7db72af6b35516fad1db4baf26741ae568b92becf0ff2ab3f1e27a9",
        "modelscope/utils/trie.py": "86f282d306b00a51de24a0b91b6ebd2c59d3a1922e1fdacac18e7886106d6e80",
        "modelscope/utils/type_assert.py": "0d825dcbad0391ebb0956d23dcececddadbb02b7d42f6b33213390e29260cc81",
        "modelscope/utils/url_utils.py": "2c23c2615e7d146a06587abb2c7422f98775f8ed451c4ffcd271b77e75df1825",
        "modelscope/utils/audio/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/utils/audio/audio_utils.py": "abef63c831a34576e6b1c4bab06c427740693e6a7dd237b421188af2d2986a6c",
        "modelscope/utils/audio/tts_exceptions.py": "03c6363d3d320d0c6812c92c6e6d0e98605aee811a9b0356eca5f76f29aa055e",
        "modelscope/utils/cv/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/utils/cv/image_utils.py": "c54f72f38ce327dde6b34b2af4dba4bdbf0f2b3bf9b99ad51b2b2c28a5199ffe",
        "modelscope/utils/cv/motion_utils/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/utils/cv/motion_utils/motion_process.py": "889503365b80bfc84b20376fe3a10bf25a7280855553b8fbb932a63f8bfe6d14",
        "modelscope/utils/cv/motion_utils/plot_script.py": "23f6caec3ab8a08b6f735f32f125339d076ed92502d58b7972872b93b5bf64a7",
        "modelscope/utils/cv/motion_utils/rotation_conversions.py": "67e7ac2f3766916cdaa459557beb12d8dc22c50ecb0873447d99bc2694c57a9a",
        "modelscope/utils/nlp/__init__.py": "b759be64e1c2ffd9527cb10738185d0df918f3348acf62afd4c63a375f0936f4",
        "modelscope/utils/nlp/distributed.py": "6230e5dc9af0f46bf71181776e4694384d5039127a0b0943b6d4d333f1cc2970",
        "modelscope/utils/nlp/load_checkpoint.py": "d2ec07ec78f9282c47544eadd991db4da90864bebabb85632dc9b512e3b8d7b2",
        "modelscope/utils/nlp/utils.py": "9a7078eee75f11867850d8c19a33e3b7aa80631ad0688051a520abd01ddf0a5e",
        "modelscope/utils/nlp/space/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/utils/nlp/space/args.py": "746f7d52aceb8a47574145555de543585cf411b83d38a7454734a73c2a811d94",
        "modelscope/utils/nlp/space/clean_dataset.py": "18f30d7caea311b3e1d80fc76249d281038b0a9c4dc6b964b4bc8a9132b53ff5",
        "modelscope/utils/nlp/space/criterions.py": "b590e540fcf94bd8025469dcca8a6ddbe3a8de48ef3ba2db066a76f83b977724",
        "modelscope/utils/nlp/space/db_ops.py": "1461ac7d3340d8b46de56fd3502a3186fd9e75a948a00cefd44145074b0f5218",
        "modelscope/utils/nlp/space/ontology.py": "a2936a25489a26b1d495f3833c72ae7f474eef4b4241c0da935c6fc4987d8aa5",
        "modelscope/utils/nlp/space/scores.py": "f774aab70b3b73876d81e991813e8206e3a7041bca5814d6a979edf0bf27f6c1",
        "modelscope/utils/nlp/space/utils.py": "c092992d23620a85c08c10818597d4361bbe61b8b9b71fa1f1e840b0cb3727e9",
        "modelscope/utils/nlp/space/utils_dst.py": "4e51088449ce7c270ea91d71d755329263f2717ba13ffd27a8ed5b6118e9480a",
        "modelscope/utils/nlp/space_T_en/__init__.py": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
        "modelscope/utils/nlp/space_T_en/utils.py": "976a08c6e244a76dfd9a714ad2207ab6c92e1dc0133dac426cabc9403ea781e4"
    }
}